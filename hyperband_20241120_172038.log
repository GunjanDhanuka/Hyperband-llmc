2024-11-20 17:20:38,651 - INFO - Initializing Hyperband with max_iter=735, eta=3, s_max=6
2024-11-20 17:20:38,651 - INFO - Starting Hyperband optimization at 2024-11-20 17:20:38.651383
2024-11-20 17:20:38,651 - INFO - 
Bracket 6:
  Initial configurations: 729
  Initial iterations: 1
2024-11-20 17:20:38,664 - INFO - 
Bracket 6, Round 0:
  Active configs: 729
  Iterations: 1
2024-11-20 17:20:38,664 - INFO - 
Starting training for config s6_n0:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:20:38,664 - INFO - Running command: ./train_gpt2cu -l 0.0009977479607140977 -o hyperband_runs_20241120_172038/run_s6_n0 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:20:48,522 - INFO - Training completed for config s6_n0:
  Training time: 0:00:09
  Final validation loss: 10.899390
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.43e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin
2024-11-20 17:20:48,523 - INFO - 
Configuration s6_n0 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009977479607140977",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n0",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.899390
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.43e-06
2024-11-20 17:20:48,523 - INFO - 
New best configuration found!
  Config ID: s6_n0
  Validation Loss: 10.899390
  Hellaswag Accuracy: 0.00%
  Training Time: 0:00:09
2024-11-20 17:20:48,523 - INFO - 
Starting training for config s6_n1:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:20:48,523 - INFO - Running command: ./train_gpt2cu -l 0.0006009494647743333 -o hyperband_runs_20241120_172038/run_s6_n1 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:20:58,314 - INFO - Training completed for config s6_n1:
  Training time: 0:00:09
  Final validation loss: 10.904214
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.58e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n1/checkpoint.bin
2024-11-20 17:20:58,314 - INFO - 
Configuration s6_n1 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006009494647743333",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n1",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904214
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.58e-07
2024-11-20 17:20:58,314 - INFO - 
Starting training for config s6_n2:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:20:58,314 - INFO - Running command: ./train_gpt2cu -l 1.9035269492960272e-05 -o hyperband_runs_20241120_172038/run_s6_n2 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:21:08,143 - INFO - Training completed for config s6_n2:
  Training time: 0:00:09
  Final validation loss: 10.911368
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.72e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n2/checkpoint.bin
2024-11-20 17:21:08,143 - INFO - 
Configuration s6_n2 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.9035269492960272e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n2",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911368
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.72e-08
2024-11-20 17:21:08,143 - INFO - 
Starting training for config s6_n3:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:21:08,144 - INFO - Running command: ./train_gpt2cu -l 0.0009583333644205056 -o hyperband_runs_20241120_172038/run_s6_n3 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:21:17,992 - INFO - Training completed for config s6_n3:
  Training time: 0:00:09
  Final validation loss: 10.899862
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.37e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin
2024-11-20 17:21:17,993 - INFO - 
Configuration s6_n3 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009583333644205056",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n3",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.899862
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.37e-06
2024-11-20 17:21:17,993 - INFO - 
Starting training for config s6_n4:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:21:17,993 - INFO - Running command: ./train_gpt2cu -l 2.713033888649979e-05 -o hyperband_runs_20241120_172038/run_s6_n4 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:21:27,804 - INFO - Training completed for config s6_n4:
  Training time: 0:00:09
  Final validation loss: 10.911276
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.88e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n4/checkpoint.bin
2024-11-20 17:21:27,804 - INFO - 
Configuration s6_n4 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.713033888649979e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n4",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911276
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.88e-08
2024-11-20 17:21:27,804 - INFO - 
Starting training for config s6_n5:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:21:27,804 - INFO - Running command: ./train_gpt2cu -l 0.0002710810617150556 -o hyperband_runs_20241120_172038/run_s6_n5 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:21:37,629 - INFO - Training completed for config s6_n5:
  Training time: 0:00:09
  Final validation loss: 10.908247
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.87e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n5/checkpoint.bin
2024-11-20 17:21:37,629 - INFO - 
Configuration s6_n5 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002710810617150556",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n5",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908247
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.87e-07
2024-11-20 17:21:37,629 - INFO - 
Starting training for config s6_n6:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:21:37,629 - INFO - Running command: ./train_gpt2cu -l 0.0004231577128629817 -o hyperband_runs_20241120_172038/run_s6_n6 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:21:47,425 - INFO - Training completed for config s6_n6:
  Training time: 0:00:09
  Final validation loss: 10.906392
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.05e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n6/checkpoint.bin
2024-11-20 17:21:47,426 - INFO - 
Configuration s6_n6 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004231577128629817",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n6",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906392
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.05e-07
2024-11-20 17:21:47,426 - INFO - 
Starting training for config s6_n7:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:21:47,426 - INFO - Running command: ./train_gpt2cu -l 3.516056825356951e-05 -o hyperband_runs_20241120_172038/run_s6_n7 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:21:57,224 - INFO - Training completed for config s6_n7:
  Training time: 0:00:09
  Final validation loss: 10.911176
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.02e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n7/checkpoint.bin
2024-11-20 17:21:57,225 - INFO - 
Configuration s6_n7 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.516056825356951e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n7",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911176
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.02e-08
2024-11-20 17:21:57,225 - INFO - 
Starting training for config s6_n8:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:21:57,225 - INFO - Running command: ./train_gpt2cu -l 1.6253301853700633e-05 -o hyperband_runs_20241120_172038/run_s6_n8 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:22:07,025 - INFO - Training completed for config s6_n8:
  Training time: 0:00:09
  Final validation loss: 10.911406
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.32e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n8/checkpoint.bin
2024-11-20 17:22:07,025 - INFO - 
Configuration s6_n8 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.6253301853700633e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n8",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911406
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.32e-08
2024-11-20 17:22:07,025 - INFO - 
Starting training for config s6_n9:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:22:07,026 - INFO - Running command: ./train_gpt2cu -l 1.2818827558743934e-05 -o hyperband_runs_20241120_172038/run_s6_n9 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:22:16,830 - INFO - Training completed for config s6_n9:
  Training time: 0:00:09
  Final validation loss: 10.911444
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.83e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n9/checkpoint.bin
2024-11-20 17:22:16,830 - INFO - 
Configuration s6_n9 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.2818827558743934e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n9",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911444
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.83e-08
2024-11-20 17:22:16,830 - INFO - 
Starting training for config s6_n10:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:22:16,830 - INFO - Running command: ./train_gpt2cu -l 7.144590740157944e-05 -o hyperband_runs_20241120_172038/run_s6_n10 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:22:26,630 - INFO - Training completed for config s6_n10:
  Training time: 0:00:09
  Final validation loss: 10.910719
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.02e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n10/checkpoint.bin
2024-11-20 17:22:26,631 - INFO - 
Configuration s6_n10 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.144590740157944e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n10",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910719
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-07
2024-11-20 17:22:26,631 - INFO - 
Starting training for config s6_n11:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:22:26,631 - INFO - Running command: ./train_gpt2cu -l 0.00010660500185645368 -o hyperband_runs_20241120_172038/run_s6_n11 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:22:36,433 - INFO - Training completed for config s6_n11:
  Training time: 0:00:09
  Final validation loss: 10.910273
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.52e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n11/checkpoint.bin
2024-11-20 17:22:36,433 - INFO - 
Configuration s6_n11 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010660500185645368",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n11",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910273
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.52e-07
2024-11-20 17:22:36,433 - INFO - 
Starting training for config s6_n12:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:22:36,433 - INFO - Running command: ./train_gpt2cu -l 0.00028311239031055744 -o hyperband_runs_20241120_172038/run_s6_n12 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:22:46,235 - INFO - Training completed for config s6_n12:
  Training time: 0:00:09
  Final validation loss: 10.908110
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.04e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n12/checkpoint.bin
2024-11-20 17:22:46,235 - INFO - 
Configuration s6_n12 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00028311239031055744",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n12",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908110
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.04e-07
2024-11-20 17:22:46,235 - INFO - 
Starting training for config s6_n13:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:22:46,235 - INFO - Running command: ./train_gpt2cu -l 2.9873935168826366e-05 -o hyperband_runs_20241120_172038/run_s6_n13 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:22:56,018 - INFO - Training completed for config s6_n13:
  Training time: 0:00:09
  Final validation loss: 10.911248
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.27e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n13/checkpoint.bin
2024-11-20 17:22:56,019 - INFO - 
Configuration s6_n13 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.9873935168826366e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n13",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911248
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.27e-08
2024-11-20 17:22:56,019 - INFO - 
Starting training for config s6_n14:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:22:56,019 - INFO - Running command: ./train_gpt2cu -l 0.0006305830318046952 -o hyperband_runs_20241120_172038/run_s6_n14 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:23:05,804 - INFO - Training completed for config s6_n14:
  Training time: 0:00:09
  Final validation loss: 10.903849
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.01e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n14/checkpoint.bin
2024-11-20 17:23:05,804 - INFO - 
Configuration s6_n14 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006305830318046952",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n14",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.903849
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.01e-07
2024-11-20 17:23:05,805 - INFO - 
Starting training for config s6_n15:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:23:05,805 - INFO - Running command: ./train_gpt2cu -l 0.0008401301724146576 -o hyperband_runs_20241120_172038/run_s6_n15 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:23:15,598 - INFO - Training completed for config s6_n15:
  Training time: 0:00:09
  Final validation loss: 10.901305
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.20e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n15/checkpoint.bin
2024-11-20 17:23:15,598 - INFO - 
Configuration s6_n15 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008401301724146576",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n15",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901305
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.20e-06
2024-11-20 17:23:15,598 - INFO - 
Starting training for config s6_n16:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:23:15,599 - INFO - Running command: ./train_gpt2cu -l 0.0004914026159065427 -o hyperband_runs_20241120_172038/run_s6_n16 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:23:25,381 - INFO - Training completed for config s6_n16:
  Training time: 0:00:09
  Final validation loss: 10.905568
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.02e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n16/checkpoint.bin
2024-11-20 17:23:25,381 - INFO - 
Configuration s6_n16 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004914026159065427",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n16",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905568
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.02e-07
2024-11-20 17:23:25,381 - INFO - 
Starting training for config s6_n17:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:23:25,382 - INFO - Running command: ./train_gpt2cu -l 1.2826746313094866e-05 -o hyperband_runs_20241120_172038/run_s6_n17 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:23:35,178 - INFO - Training completed for config s6_n17:
  Training time: 0:00:09
  Final validation loss: 10.911443
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.83e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n17/checkpoint.bin
2024-11-20 17:23:35,178 - INFO - 
Configuration s6_n17 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.2826746313094866e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n17",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911443
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.83e-08
2024-11-20 17:23:35,178 - INFO - 
Starting training for config s6_n18:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:23:35,178 - INFO - Running command: ./train_gpt2cu -l 6.0487977915284475e-05 -o hyperband_runs_20241120_172038/run_s6_n18 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:23:44,964 - INFO - Training completed for config s6_n18:
  Training time: 0:00:09
  Final validation loss: 10.910859
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.64e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n18/checkpoint.bin
2024-11-20 17:23:44,964 - INFO - 
Configuration s6_n18 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.0487977915284475e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n18",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910859
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.64e-08
2024-11-20 17:23:44,964 - INFO - 
Starting training for config s6_n19:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:23:44,965 - INFO - Running command: ./train_gpt2cu -l 1.589607447342662e-05 -o hyperband_runs_20241120_172038/run_s6_n19 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:23:54,767 - INFO - Training completed for config s6_n19:
  Training time: 0:00:09
  Final validation loss: 10.911420
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.27e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n19/checkpoint.bin
2024-11-20 17:23:54,767 - INFO - 
Configuration s6_n19 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.589607447342662e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n19",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911420
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.27e-08
2024-11-20 17:23:54,768 - INFO - 
Starting training for config s6_n20:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:23:54,768 - INFO - Running command: ./train_gpt2cu -l 4.71133173239207e-05 -o hyperband_runs_20241120_172038/run_s6_n20 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:24:04,572 - INFO - Training completed for config s6_n20:
  Training time: 0:00:09
  Final validation loss: 10.911039
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.73e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n20/checkpoint.bin
2024-11-20 17:24:04,572 - INFO - 
Configuration s6_n20 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.71133173239207e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n20",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911039
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.73e-08
2024-11-20 17:24:04,572 - INFO - 
Starting training for config s6_n21:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:24:04,573 - INFO - Running command: ./train_gpt2cu -l 1.0440409985508157e-05 -o hyperband_runs_20241120_172038/run_s6_n21 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:24:14,359 - INFO - Training completed for config s6_n21:
  Training time: 0:00:09
  Final validation loss: 10.911462
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.49e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n21/checkpoint.bin
2024-11-20 17:24:14,359 - INFO - 
Configuration s6_n21 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.0440409985508157e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n21",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911462
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.49e-08
2024-11-20 17:24:14,359 - INFO - 
Starting training for config s6_n22:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:24:14,360 - INFO - Running command: ./train_gpt2cu -l 0.000859266840585978 -o hyperband_runs_20241120_172038/run_s6_n22 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:24:24,133 - INFO - Training completed for config s6_n22:
  Training time: 0:00:09
  Final validation loss: 10.901065
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.23e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n22/checkpoint.bin
2024-11-20 17:24:24,133 - INFO - 
Configuration s6_n22 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000859266840585978",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n22",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901065
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.23e-06
2024-11-20 17:24:24,133 - INFO - 
Starting training for config s6_n23:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:24:24,133 - INFO - Running command: ./train_gpt2cu -l 0.0002223649192955048 -o hyperband_runs_20241120_172038/run_s6_n23 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:24:33,921 - INFO - Training completed for config s6_n23:
  Training time: 0:00:09
  Final validation loss: 10.908859
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.18e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n23/checkpoint.bin
2024-11-20 17:24:33,921 - INFO - 
Configuration s6_n23 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002223649192955048",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n23",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908859
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.18e-07
2024-11-20 17:24:33,921 - INFO - 
Starting training for config s6_n24:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:24:33,921 - INFO - Running command: ./train_gpt2cu -l 0.0001763400746646162 -o hyperband_runs_20241120_172038/run_s6_n24 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:24:43,718 - INFO - Training completed for config s6_n24:
  Training time: 0:00:09
  Final validation loss: 10.909423
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.52e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n24/checkpoint.bin
2024-11-20 17:24:43,718 - INFO - 
Configuration s6_n24 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001763400746646162",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n24",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909423
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.52e-07
2024-11-20 17:24:43,718 - INFO - 
Starting training for config s6_n25:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:24:43,719 - INFO - Running command: ./train_gpt2cu -l 0.00036026954346696954 -o hyperband_runs_20241120_172038/run_s6_n25 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:24:53,512 - INFO - Training completed for config s6_n25:
  Training time: 0:00:09
  Final validation loss: 10.907156
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.15e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n25/checkpoint.bin
2024-11-20 17:24:53,512 - INFO - 
Configuration s6_n25 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00036026954346696954",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n25",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907156
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.15e-07
2024-11-20 17:24:53,513 - INFO - 
Starting training for config s6_n26:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:24:53,513 - INFO - Running command: ./train_gpt2cu -l 0.000274180833397406 -o hyperband_runs_20241120_172038/run_s6_n26 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:25:03,307 - INFO - Training completed for config s6_n26:
  Training time: 0:00:09
  Final validation loss: 10.908207
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.92e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n26/checkpoint.bin
2024-11-20 17:25:03,307 - INFO - 
Configuration s6_n26 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000274180833397406",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n26",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908207
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.92e-07
2024-11-20 17:25:03,308 - INFO - 
Starting training for config s6_n27:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:25:03,308 - INFO - Running command: ./train_gpt2cu -l 3.178778847972118e-05 -o hyperband_runs_20241120_172038/run_s6_n27 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:25:13,107 - INFO - Training completed for config s6_n27:
  Training time: 0:00:09
  Final validation loss: 10.911222
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.54e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n27/checkpoint.bin
2024-11-20 17:25:13,107 - INFO - 
Configuration s6_n27 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.178778847972118e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n27",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911222
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.54e-08
2024-11-20 17:25:13,107 - INFO - 
Starting training for config s6_n28:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:25:13,108 - INFO - Running command: ./train_gpt2cu -l 0.0007944460308724998 -o hyperband_runs_20241120_172038/run_s6_n28 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:25:22,892 - INFO - Training completed for config s6_n28:
  Training time: 0:00:09
  Final validation loss: 10.901865
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.13e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n28/checkpoint.bin
2024-11-20 17:25:22,892 - INFO - 
Configuration s6_n28 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007944460308724998",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n28",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901865
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.13e-06
2024-11-20 17:25:22,892 - INFO - 
Starting training for config s6_n29:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:25:22,893 - INFO - Running command: ./train_gpt2cu -l 4.447008837607296e-05 -o hyperband_runs_20241120_172038/run_s6_n29 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:25:32,698 - INFO - Training completed for config s6_n29:
  Training time: 0:00:09
  Final validation loss: 10.911076
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.35e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n29/checkpoint.bin
2024-11-20 17:25:32,698 - INFO - 
Configuration s6_n29 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.447008837607296e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n29",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911076
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.35e-08
2024-11-20 17:25:32,698 - INFO - 
Starting training for config s6_n30:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:25:32,698 - INFO - Running command: ./train_gpt2cu -l 0.0003700750868107223 -o hyperband_runs_20241120_172038/run_s6_n30 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:25:42,487 - INFO - Training completed for config s6_n30:
  Training time: 0:00:09
  Final validation loss: 10.907043
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.29e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n30/checkpoint.bin
2024-11-20 17:25:42,488 - INFO - 
Configuration s6_n30 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003700750868107223",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n30",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907043
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.29e-07
2024-11-20 17:25:42,488 - INFO - 
Starting training for config s6_n31:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:25:42,488 - INFO - Running command: ./train_gpt2cu -l 1.855760373073487e-05 -o hyperband_runs_20241120_172038/run_s6_n31 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:25:52,283 - INFO - Training completed for config s6_n31:
  Training time: 0:00:09
  Final validation loss: 10.911375
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.65e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n31/checkpoint.bin
2024-11-20 17:25:52,284 - INFO - 
Configuration s6_n31 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.855760373073487e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n31",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911375
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.65e-08
2024-11-20 17:25:52,284 - INFO - 
Starting training for config s6_n32:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:25:52,284 - INFO - Running command: ./train_gpt2cu -l 0.00021156434819066822 -o hyperband_runs_20241120_172038/run_s6_n32 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:26:02,108 - INFO - Training completed for config s6_n32:
  Training time: 0:00:09
  Final validation loss: 10.908986
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.02e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n32/checkpoint.bin
2024-11-20 17:26:02,108 - INFO - 
Configuration s6_n32 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00021156434819066822",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n32",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908986
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.02e-07
2024-11-20 17:26:02,108 - INFO - 
Starting training for config s6_n33:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:26:02,108 - INFO - Running command: ./train_gpt2cu -l 3.4102618149788355e-05 -o hyperband_runs_20241120_172038/run_s6_n33 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:26:11,921 - INFO - Training completed for config s6_n33:
  Training time: 0:00:09
  Final validation loss: 10.911203
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.87e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n33/checkpoint.bin
2024-11-20 17:26:11,921 - INFO - 
Configuration s6_n33 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.4102618149788355e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n33",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911203
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.87e-08
2024-11-20 17:26:11,921 - INFO - 
Starting training for config s6_n34:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:26:11,921 - INFO - Running command: ./train_gpt2cu -l 0.000655179765012117 -o hyperband_runs_20241120_172038/run_s6_n34 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:26:21,710 - INFO - Training completed for config s6_n34:
  Training time: 0:00:09
  Final validation loss: 10.903564
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.36e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n34/checkpoint.bin
2024-11-20 17:26:21,710 - INFO - 
Configuration s6_n34 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000655179765012117",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n34",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.903564
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.36e-07
2024-11-20 17:26:21,710 - INFO - 
Starting training for config s6_n35:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:26:21,710 - INFO - Running command: ./train_gpt2cu -l 0.00034809604687483517 -o hyperband_runs_20241120_172038/run_s6_n35 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:26:31,503 - INFO - Training completed for config s6_n35:
  Training time: 0:00:09
  Final validation loss: 10.907310
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.97e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n35/checkpoint.bin
2024-11-20 17:26:31,503 - INFO - 
Configuration s6_n35 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00034809604687483517",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n35",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907310
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.97e-07
2024-11-20 17:26:31,503 - INFO - 
Starting training for config s6_n36:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:26:31,503 - INFO - Running command: ./train_gpt2cu -l 2.8756723931328594e-05 -o hyperband_runs_20241120_172038/run_s6_n36 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:26:41,299 - INFO - Training completed for config s6_n36:
  Training time: 0:00:09
  Final validation loss: 10.911258
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.11e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n36/checkpoint.bin
2024-11-20 17:26:41,300 - INFO - 
Configuration s6_n36 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.8756723931328594e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n36",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911258
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.11e-08
2024-11-20 17:26:41,300 - INFO - 
Starting training for config s6_n37:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:26:41,300 - INFO - Running command: ./train_gpt2cu -l 0.0009748120712873382 -o hyperband_runs_20241120_172038/run_s6_n37 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:26:51,097 - INFO - Training completed for config s6_n37:
  Training time: 0:00:09
  Final validation loss: 10.899665
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.39e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin
2024-11-20 17:26:51,098 - INFO - 
Configuration s6_n37 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009748120712873382",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n37",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.899665
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.39e-06
2024-11-20 17:26:51,098 - INFO - 
Starting training for config s6_n38:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:26:51,098 - INFO - Running command: ./train_gpt2cu -l 9.03331173905607e-05 -o hyperband_runs_20241120_172038/run_s6_n38 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:27:00,888 - INFO - Training completed for config s6_n38:
  Training time: 0:00:09
  Final validation loss: 10.910484
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.29e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n38/checkpoint.bin
2024-11-20 17:27:00,889 - INFO - 
Configuration s6_n38 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "9.03331173905607e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n38",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910484
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.29e-07
2024-11-20 17:27:00,889 - INFO - 
Starting training for config s6_n39:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:27:00,889 - INFO - Running command: ./train_gpt2cu -l 3.168272508141586e-05 -o hyperband_runs_20241120_172038/run_s6_n39 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:27:10,695 - INFO - Training completed for config s6_n39:
  Training time: 0:00:09
  Final validation loss: 10.911226
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.53e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n39/checkpoint.bin
2024-11-20 17:27:10,695 - INFO - 
Configuration s6_n39 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.168272508141586e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n39",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911226
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.53e-08
2024-11-20 17:27:10,695 - INFO - 
Starting training for config s6_n40:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:27:10,695 - INFO - Running command: ./train_gpt2cu -l 0.00027860859556582063 -o hyperband_runs_20241120_172038/run_s6_n40 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:27:20,518 - INFO - Training completed for config s6_n40:
  Training time: 0:00:09
  Final validation loss: 10.908164
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.98e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n40/checkpoint.bin
2024-11-20 17:27:20,519 - INFO - 
Configuration s6_n40 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00027860859556582063",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n40",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908164
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.98e-07
2024-11-20 17:27:20,519 - INFO - 
Starting training for config s6_n41:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:27:20,519 - INFO - Running command: ./train_gpt2cu -l 0.00019696553705341623 -o hyperband_runs_20241120_172038/run_s6_n41 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:27:30,315 - INFO - Training completed for config s6_n41:
  Training time: 0:00:09
  Final validation loss: 10.909166
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.81e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n41/checkpoint.bin
2024-11-20 17:27:30,315 - INFO - 
Configuration s6_n41 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00019696553705341623",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n41",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909166
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.81e-07
2024-11-20 17:27:30,315 - INFO - 
Starting training for config s6_n42:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:27:30,316 - INFO - Running command: ./train_gpt2cu -l 0.0008427581488465726 -o hyperband_runs_20241120_172038/run_s6_n42 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:27:40,109 - INFO - Training completed for config s6_n42:
  Training time: 0:00:09
  Final validation loss: 10.901270
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.20e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n42/checkpoint.bin
2024-11-20 17:27:40,109 - INFO - 
Configuration s6_n42 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008427581488465726",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n42",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901270
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.20e-06
2024-11-20 17:27:40,109 - INFO - 
Starting training for config s6_n43:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:27:40,109 - INFO - Running command: ./train_gpt2cu -l 0.00028564306755181964 -o hyperband_runs_20241120_172038/run_s6_n43 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:27:49,912 - INFO - Training completed for config s6_n43:
  Training time: 0:00:09
  Final validation loss: 10.908079
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.08e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n43/checkpoint.bin
2024-11-20 17:27:49,912 - INFO - 
Configuration s6_n43 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00028564306755181964",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n43",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908079
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.08e-07
2024-11-20 17:27:49,912 - INFO - 
Starting training for config s6_n44:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:27:49,912 - INFO - Running command: ./train_gpt2cu -l 9.008526847110781e-05 -o hyperband_runs_20241120_172038/run_s6_n44 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:27:59,705 - INFO - Training completed for config s6_n44:
  Training time: 0:00:09
  Final validation loss: 10.910478
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.29e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n44/checkpoint.bin
2024-11-20 17:27:59,705 - INFO - 
Configuration s6_n44 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "9.008526847110781e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n44",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910478
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.29e-07
2024-11-20 17:27:59,705 - INFO - 
Starting training for config s6_n45:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:27:59,705 - INFO - Running command: ./train_gpt2cu -l 0.0003320422942338955 -o hyperband_runs_20241120_172038/run_s6_n45 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:28:09,510 - INFO - Training completed for config s6_n45:
  Training time: 0:00:09
  Final validation loss: 10.907503
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.74e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n45/checkpoint.bin
2024-11-20 17:28:09,510 - INFO - 
Configuration s6_n45 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003320422942338955",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n45",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907503
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.74e-07
2024-11-20 17:28:09,510 - INFO - 
Starting training for config s6_n46:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:28:09,510 - INFO - Running command: ./train_gpt2cu -l 4.4069194392507856e-05 -o hyperband_runs_20241120_172038/run_s6_n46 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:28:19,307 - INFO - Training completed for config s6_n46:
  Training time: 0:00:09
  Final validation loss: 10.911074
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.30e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n46/checkpoint.bin
2024-11-20 17:28:19,307 - INFO - 
Configuration s6_n46 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.4069194392507856e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n46",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911074
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.30e-08
2024-11-20 17:28:19,307 - INFO - 
Starting training for config s6_n47:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:28:19,308 - INFO - Running command: ./train_gpt2cu -l 9.334958706607666e-05 -o hyperband_runs_20241120_172038/run_s6_n47 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:28:29,115 - INFO - Training completed for config s6_n47:
  Training time: 0:00:09
  Final validation loss: 10.910444
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.33e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n47/checkpoint.bin
2024-11-20 17:28:29,115 - INFO - 
Configuration s6_n47 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "9.334958706607666e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n47",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910444
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.33e-07
2024-11-20 17:28:29,115 - INFO - 
Starting training for config s6_n48:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:28:29,115 - INFO - Running command: ./train_gpt2cu -l 2.269597012028693e-05 -o hyperband_runs_20241120_172038/run_s6_n48 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:28:38,913 - INFO - Training completed for config s6_n48:
  Training time: 0:00:09
  Final validation loss: 10.911330
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.24e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n48/checkpoint.bin
2024-11-20 17:28:38,913 - INFO - 
Configuration s6_n48 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.269597012028693e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n48",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911330
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.24e-08
2024-11-20 17:28:38,913 - INFO - 
Starting training for config s6_n49:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:28:38,914 - INFO - Running command: ./train_gpt2cu -l 0.00024087829793111455 -o hyperband_runs_20241120_172038/run_s6_n49 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:28:48,726 - INFO - Training completed for config s6_n49:
  Training time: 0:00:09
  Final validation loss: 10.908623
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.44e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n49/checkpoint.bin
2024-11-20 17:28:48,726 - INFO - 
Configuration s6_n49 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00024087829793111455",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n49",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908623
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.44e-07
2024-11-20 17:28:48,727 - INFO - 
Starting training for config s6_n50:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:28:48,727 - INFO - Running command: ./train_gpt2cu -l 0.00032463130841415454 -o hyperband_runs_20241120_172038/run_s6_n50 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:28:58,535 - INFO - Training completed for config s6_n50:
  Training time: 0:00:09
  Final validation loss: 10.907587
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.64e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n50/checkpoint.bin
2024-11-20 17:28:58,536 - INFO - 
Configuration s6_n50 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00032463130841415454",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n50",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907587
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.64e-07
2024-11-20 17:28:58,536 - INFO - 
Starting training for config s6_n51:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:28:58,536 - INFO - Running command: ./train_gpt2cu -l 7.695566826938411e-05 -o hyperband_runs_20241120_172038/run_s6_n51 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:29:08,342 - INFO - Training completed for config s6_n51:
  Training time: 0:00:09
  Final validation loss: 10.910654
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.10e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n51/checkpoint.bin
2024-11-20 17:29:08,342 - INFO - 
Configuration s6_n51 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.695566826938411e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n51",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910654
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-07
2024-11-20 17:29:08,342 - INFO - 
Starting training for config s6_n52:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:29:08,342 - INFO - Running command: ./train_gpt2cu -l 2.876640744533039e-05 -o hyperband_runs_20241120_172038/run_s6_n52 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:29:18,139 - INFO - Training completed for config s6_n52:
  Training time: 0:00:09
  Final validation loss: 10.911258
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.11e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n52/checkpoint.bin
2024-11-20 17:29:18,139 - INFO - 
Configuration s6_n52 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.876640744533039e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n52",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911258
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.11e-08
2024-11-20 17:29:18,139 - INFO - 
Starting training for config s6_n53:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:29:18,139 - INFO - Running command: ./train_gpt2cu -l 0.0007988992971993117 -o hyperband_runs_20241120_172038/run_s6_n53 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:29:27,948 - INFO - Training completed for config s6_n53:
  Training time: 0:00:09
  Final validation loss: 10.901803
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.14e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n53/checkpoint.bin
2024-11-20 17:29:27,948 - INFO - 
Configuration s6_n53 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007988992971993117",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n53",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901803
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.14e-06
2024-11-20 17:29:27,948 - INFO - 
Starting training for config s6_n54:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:29:27,948 - INFO - Running command: ./train_gpt2cu -l 0.00048244579252361273 -o hyperband_runs_20241120_172038/run_s6_n54 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:29:37,755 - INFO - Training completed for config s6_n54:
  Training time: 0:00:09
  Final validation loss: 10.905678
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.89e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n54/checkpoint.bin
2024-11-20 17:29:37,755 - INFO - 
Configuration s6_n54 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00048244579252361273",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n54",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905678
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.89e-07
2024-11-20 17:29:37,755 - INFO - 
Starting training for config s6_n55:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:29:37,756 - INFO - Running command: ./train_gpt2cu -l 0.0001337675100663126 -o hyperband_runs_20241120_172038/run_s6_n55 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:29:47,573 - INFO - Training completed for config s6_n55:
  Training time: 0:00:09
  Final validation loss: 10.909950
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.91e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n55/checkpoint.bin
2024-11-20 17:29:47,574 - INFO - 
Configuration s6_n55 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001337675100663126",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n55",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909950
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.91e-07
2024-11-20 17:29:47,574 - INFO - 
Starting training for config s6_n56:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:29:47,575 - INFO - Running command: ./train_gpt2cu -l 0.00011708911013672442 -o hyperband_runs_20241120_172038/run_s6_n56 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:29:57,375 - INFO - Training completed for config s6_n56:
  Training time: 0:00:09
  Final validation loss: 10.910149
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.67e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n56/checkpoint.bin
2024-11-20 17:29:57,375 - INFO - 
Configuration s6_n56 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00011708911013672442",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n56",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910149
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.67e-07
2024-11-20 17:29:57,375 - INFO - 
Starting training for config s6_n57:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:29:57,376 - INFO - Running command: ./train_gpt2cu -l 2.136021313394652e-05 -o hyperband_runs_20241120_172038/run_s6_n57 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:30:07,180 - INFO - Training completed for config s6_n57:
  Training time: 0:00:09
  Final validation loss: 10.911336
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.05e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n57/checkpoint.bin
2024-11-20 17:30:07,180 - INFO - 
Configuration s6_n57 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.136021313394652e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n57",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911336
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.05e-08
2024-11-20 17:30:07,180 - INFO - 
Starting training for config s6_n58:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:30:07,180 - INFO - Running command: ./train_gpt2cu -l 1.1456681913132879e-05 -o hyperband_runs_20241120_172038/run_s6_n58 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:30:16,976 - INFO - Training completed for config s6_n58:
  Training time: 0:00:09
  Final validation loss: 10.911453
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.64e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n58/checkpoint.bin
2024-11-20 17:30:16,976 - INFO - 
Configuration s6_n58 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.1456681913132879e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n58",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911453
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.64e-08
2024-11-20 17:30:16,976 - INFO - 
Starting training for config s6_n59:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:30:16,976 - INFO - Running command: ./train_gpt2cu -l 1.6724800828004253e-05 -o hyperband_runs_20241120_172038/run_s6_n59 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:30:26,767 - INFO - Training completed for config s6_n59:
  Training time: 0:00:09
  Final validation loss: 10.911396
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.39e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n59/checkpoint.bin
2024-11-20 17:30:26,767 - INFO - 
Configuration s6_n59 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.6724800828004253e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n59",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911396
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.39e-08
2024-11-20 17:30:26,767 - INFO - 
Starting training for config s6_n60:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:30:26,767 - INFO - Running command: ./train_gpt2cu -l 0.00015965375826444814 -o hyperband_runs_20241120_172038/run_s6_n60 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:30:36,576 - INFO - Training completed for config s6_n60:
  Training time: 0:00:09
  Final validation loss: 10.909631
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.28e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n60/checkpoint.bin
2024-11-20 17:30:36,576 - INFO - 
Configuration s6_n60 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00015965375826444814",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n60",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909631
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.28e-07
2024-11-20 17:30:36,576 - INFO - 
Starting training for config s6_n61:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:30:36,576 - INFO - Running command: ./train_gpt2cu -l 0.00012653892822723917 -o hyperband_runs_20241120_172038/run_s6_n61 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:30:46,384 - INFO - Training completed for config s6_n61:
  Training time: 0:00:09
  Final validation loss: 10.910035
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.81e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n61/checkpoint.bin
2024-11-20 17:30:46,384 - INFO - 
Configuration s6_n61 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012653892822723917",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n61",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910035
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.81e-07
2024-11-20 17:30:46,384 - INFO - 
Starting training for config s6_n62:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:30:46,385 - INFO - Running command: ./train_gpt2cu -l 0.00017912708710035022 -o hyperband_runs_20241120_172038/run_s6_n62 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:30:56,173 - INFO - Training completed for config s6_n62:
  Training time: 0:00:09
  Final validation loss: 10.909392
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.56e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n62/checkpoint.bin
2024-11-20 17:30:56,174 - INFO - 
Configuration s6_n62 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00017912708710035022",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n62",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909392
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.56e-07
2024-11-20 17:30:56,174 - INFO - 
Starting training for config s6_n63:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:30:56,174 - INFO - Running command: ./train_gpt2cu -l 5.463719902638342e-05 -o hyperband_runs_20241120_172038/run_s6_n63 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:31:05,980 - INFO - Training completed for config s6_n63:
  Training time: 0:00:09
  Final validation loss: 10.910936
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.81e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n63/checkpoint.bin
2024-11-20 17:31:05,980 - INFO - 
Configuration s6_n63 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.463719902638342e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n63",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910936
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.81e-08
2024-11-20 17:31:05,981 - INFO - 
Starting training for config s6_n64:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:31:05,981 - INFO - Running command: ./train_gpt2cu -l 0.00018928568238554873 -o hyperband_runs_20241120_172038/run_s6_n64 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:31:15,778 - INFO - Training completed for config s6_n64:
  Training time: 0:00:09
  Final validation loss: 10.909257
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.70e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n64/checkpoint.bin
2024-11-20 17:31:15,778 - INFO - 
Configuration s6_n64 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00018928568238554873",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n64",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909257
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.70e-07
2024-11-20 17:31:15,778 - INFO - 
Starting training for config s6_n65:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:31:15,778 - INFO - Running command: ./train_gpt2cu -l 0.0001301387776829843 -o hyperband_runs_20241120_172038/run_s6_n65 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:31:25,582 - INFO - Training completed for config s6_n65:
  Training time: 0:00:09
  Final validation loss: 10.909988
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.86e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n65/checkpoint.bin
2024-11-20 17:31:25,582 - INFO - 
Configuration s6_n65 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001301387776829843",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n65",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909988
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.86e-07
2024-11-20 17:31:25,583 - INFO - 
Starting training for config s6_n66:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:31:25,583 - INFO - Running command: ./train_gpt2cu -l 3.0144798139195283e-05 -o hyperband_runs_20241120_172038/run_s6_n66 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:31:35,377 - INFO - Training completed for config s6_n66:
  Training time: 0:00:09
  Final validation loss: 10.911234
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.31e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n66/checkpoint.bin
2024-11-20 17:31:35,377 - INFO - 
Configuration s6_n66 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.0144798139195283e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n66",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911234
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.31e-08
2024-11-20 17:31:35,377 - INFO - 
Starting training for config s6_n67:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:31:35,377 - INFO - Running command: ./train_gpt2cu -l 2.3131055528625317e-05 -o hyperband_runs_20241120_172038/run_s6_n67 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:31:45,191 - INFO - Training completed for config s6_n67:
  Training time: 0:00:09
  Final validation loss: 10.911322
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.30e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n67/checkpoint.bin
2024-11-20 17:31:45,191 - INFO - 
Configuration s6_n67 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.3131055528625317e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n67",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911322
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.30e-08
2024-11-20 17:31:45,191 - INFO - 
Starting training for config s6_n68:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:31:45,192 - INFO - Running command: ./train_gpt2cu -l 0.00043018629735312866 -o hyperband_runs_20241120_172038/run_s6_n68 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:31:55,004 - INFO - Training completed for config s6_n68:
  Training time: 0:00:09
  Final validation loss: 10.906310
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.15e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n68/checkpoint.bin
2024-11-20 17:31:55,004 - INFO - 
Configuration s6_n68 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00043018629735312866",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n68",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906310
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.15e-07
2024-11-20 17:31:55,004 - INFO - 
Starting training for config s6_n69:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:31:55,004 - INFO - Running command: ./train_gpt2cu -l 1.404954869883979e-05 -o hyperband_runs_20241120_172038/run_s6_n69 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:32:04,804 - INFO - Training completed for config s6_n69:
  Training time: 0:00:09
  Final validation loss: 10.911432
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.01e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n69/checkpoint.bin
2024-11-20 17:32:04,804 - INFO - 
Configuration s6_n69 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.404954869883979e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n69",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911432
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.01e-08
2024-11-20 17:32:04,805 - INFO - 
Starting training for config s6_n70:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:32:04,805 - INFO - Running command: ./train_gpt2cu -l 1.5765390220150567e-05 -o hyperband_runs_20241120_172038/run_s6_n70 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:32:14,607 - INFO - Training completed for config s6_n70:
  Training time: 0:00:09
  Final validation loss: 10.911413
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.25e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n70/checkpoint.bin
2024-11-20 17:32:14,607 - INFO - 
Configuration s6_n70 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.5765390220150567e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n70",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911413
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.25e-08
2024-11-20 17:32:14,607 - INFO - 
Starting training for config s6_n71:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:32:14,607 - INFO - Running command: ./train_gpt2cu -l 1.4618182272645117e-05 -o hyperband_runs_20241120_172038/run_s6_n71 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:32:24,413 - INFO - Training completed for config s6_n71:
  Training time: 0:00:09
  Final validation loss: 10.911424
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.09e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n71/checkpoint.bin
2024-11-20 17:32:24,413 - INFO - 
Configuration s6_n71 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.4618182272645117e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n71",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911424
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.09e-08
2024-11-20 17:32:24,413 - INFO - 
Starting training for config s6_n72:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:32:24,413 - INFO - Running command: ./train_gpt2cu -l 1.2462862817425276e-05 -o hyperband_runs_20241120_172038/run_s6_n72 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:32:34,234 - INFO - Training completed for config s6_n72:
  Training time: 0:00:09
  Final validation loss: 10.911454
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.78e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n72/checkpoint.bin
2024-11-20 17:32:34,234 - INFO - 
Configuration s6_n72 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.2462862817425276e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n72",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911454
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.78e-08
2024-11-20 17:32:34,234 - INFO - 
Starting training for config s6_n73:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:32:34,234 - INFO - Running command: ./train_gpt2cu -l 0.00040336605982500004 -o hyperband_runs_20241120_172038/run_s6_n73 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:32:44,052 - INFO - Training completed for config s6_n73:
  Training time: 0:00:09
  Final validation loss: 10.906631
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.76e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n73/checkpoint.bin
2024-11-20 17:32:44,052 - INFO - 
Configuration s6_n73 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00040336605982500004",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n73",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906631
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.76e-07
2024-11-20 17:32:44,053 - INFO - 
Starting training for config s6_n74:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:32:44,054 - INFO - Running command: ./train_gpt2cu -l 0.000490991692094771 -o hyperband_runs_20241120_172038/run_s6_n74 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:32:53,855 - INFO - Training completed for config s6_n74:
  Training time: 0:00:09
  Final validation loss: 10.905572
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.01e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n74/checkpoint.bin
2024-11-20 17:32:53,855 - INFO - 
Configuration s6_n74 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000490991692094771",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n74",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905572
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.01e-07
2024-11-20 17:32:53,855 - INFO - 
Starting training for config s6_n75:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:32:53,855 - INFO - Running command: ./train_gpt2cu -l 1.6059914122761776e-05 -o hyperband_runs_20241120_172038/run_s6_n75 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:33:03,660 - INFO - Training completed for config s6_n75:
  Training time: 0:00:09
  Final validation loss: 10.911420
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.29e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n75/checkpoint.bin
2024-11-20 17:33:03,660 - INFO - 
Configuration s6_n75 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.6059914122761776e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n75",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911420
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.29e-08
2024-11-20 17:33:03,660 - INFO - 
Starting training for config s6_n76:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:33:03,660 - INFO - Running command: ./train_gpt2cu -l 9.389643925318229e-05 -o hyperband_runs_20241120_172038/run_s6_n76 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:33:13,462 - INFO - Training completed for config s6_n76:
  Training time: 0:00:09
  Final validation loss: 10.910452
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.34e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n76/checkpoint.bin
2024-11-20 17:33:13,462 - INFO - 
Configuration s6_n76 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "9.389643925318229e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n76",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910452
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.34e-07
2024-11-20 17:33:13,462 - INFO - 
Starting training for config s6_n77:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:33:13,463 - INFO - Running command: ./train_gpt2cu -l 0.0004225248406036559 -o hyperband_runs_20241120_172038/run_s6_n77 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:33:23,280 - INFO - Training completed for config s6_n77:
  Training time: 0:00:09
  Final validation loss: 10.906385
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.04e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n77/checkpoint.bin
2024-11-20 17:33:23,280 - INFO - 
Configuration s6_n77 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004225248406036559",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n77",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906385
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.04e-07
2024-11-20 17:33:23,280 - INFO - 
Starting training for config s6_n78:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:33:23,281 - INFO - Running command: ./train_gpt2cu -l 0.00014711150554485092 -o hyperband_runs_20241120_172038/run_s6_n78 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:33:33,072 - INFO - Training completed for config s6_n78:
  Training time: 0:00:09
  Final validation loss: 10.909781
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.10e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n78/checkpoint.bin
2024-11-20 17:33:33,072 - INFO - 
Configuration s6_n78 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014711150554485092",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n78",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909781
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.10e-07
2024-11-20 17:33:33,072 - INFO - 
Starting training for config s6_n79:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:33:33,072 - INFO - Running command: ./train_gpt2cu -l 1.9878885564139002e-05 -o hyperband_runs_20241120_172038/run_s6_n79 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:33:42,863 - INFO - Training completed for config s6_n79:
  Training time: 0:00:09
  Final validation loss: 10.911360
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.84e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n79/checkpoint.bin
2024-11-20 17:33:42,863 - INFO - 
Configuration s6_n79 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.9878885564139002e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n79",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911360
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.84e-08
2024-11-20 17:33:42,863 - INFO - 
Starting training for config s6_n80:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:33:42,863 - INFO - Running command: ./train_gpt2cu -l 0.00036069623181292457 -o hyperband_runs_20241120_172038/run_s6_n80 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:33:52,658 - INFO - Training completed for config s6_n80:
  Training time: 0:00:09
  Final validation loss: 10.907151
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.15e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n80/checkpoint.bin
2024-11-20 17:33:52,659 - INFO - 
Configuration s6_n80 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00036069623181292457",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n80",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907151
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.15e-07
2024-11-20 17:33:52,659 - INFO - 
Starting training for config s6_n81:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:33:52,659 - INFO - Running command: ./train_gpt2cu -l 5.156315282316557e-05 -o hyperband_runs_20241120_172038/run_s6_n81 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:34:02,469 - INFO - Training completed for config s6_n81:
  Training time: 0:00:09
  Final validation loss: 10.910977
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.37e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n81/checkpoint.bin
2024-11-20 17:34:02,469 - INFO - 
Configuration s6_n81 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.156315282316557e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n81",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910977
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.37e-08
2024-11-20 17:34:02,470 - INFO - 
Starting training for config s6_n82:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:34:02,470 - INFO - Running command: ./train_gpt2cu -l 3.3762072734188694e-05 -o hyperband_runs_20241120_172038/run_s6_n82 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:34:12,263 - INFO - Training completed for config s6_n82:
  Training time: 0:00:09
  Final validation loss: 10.911196
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.82e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n82/checkpoint.bin
2024-11-20 17:34:12,263 - INFO - 
Configuration s6_n82 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.3762072734188694e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n82",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911196
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.82e-08
2024-11-20 17:34:12,263 - INFO - 
Starting training for config s6_n83:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:34:12,264 - INFO - Running command: ./train_gpt2cu -l 0.000547532555846819 -o hyperband_runs_20241120_172038/run_s6_n83 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:34:22,074 - INFO - Training completed for config s6_n83:
  Training time: 0:00:09
  Final validation loss: 10.904886
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.82e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n83/checkpoint.bin
2024-11-20 17:34:22,074 - INFO - 
Configuration s6_n83 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000547532555846819",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n83",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904886
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.82e-07
2024-11-20 17:34:22,074 - INFO - 
Starting training for config s6_n84:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:34:22,074 - INFO - Running command: ./train_gpt2cu -l 5.774175026672036e-05 -o hyperband_runs_20241120_172038/run_s6_n84 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:34:31,871 - INFO - Training completed for config s6_n84:
  Training time: 0:00:09
  Final validation loss: 10.910898
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.25e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n84/checkpoint.bin
2024-11-20 17:34:31,871 - INFO - 
Configuration s6_n84 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.774175026672036e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n84",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910898
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.25e-08
2024-11-20 17:34:31,871 - INFO - 
Starting training for config s6_n85:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:34:31,871 - INFO - Running command: ./train_gpt2cu -l 0.0008833451139763101 -o hyperband_runs_20241120_172038/run_s6_n85 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:34:41,704 - INFO - Training completed for config s6_n85:
  Training time: 0:00:09
  Final validation loss: 10.900782
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.26e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n85/checkpoint.bin
2024-11-20 17:34:41,705 - INFO - 
Configuration s6_n85 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008833451139763101",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n85",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.900782
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.26e-06
2024-11-20 17:34:41,705 - INFO - 
Starting training for config s6_n86:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:34:41,705 - INFO - Running command: ./train_gpt2cu -l 0.00020295645737895075 -o hyperband_runs_20241120_172038/run_s6_n86 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:34:51,500 - INFO - Training completed for config s6_n86:
  Training time: 0:00:09
  Final validation loss: 10.909099
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.90e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n86/checkpoint.bin
2024-11-20 17:34:51,500 - INFO - 
Configuration s6_n86 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00020295645737895075",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n86",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909099
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.90e-07
2024-11-20 17:34:51,500 - INFO - 
Starting training for config s6_n87:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:34:51,500 - INFO - Running command: ./train_gpt2cu -l 7.220346499659539e-05 -o hyperband_runs_20241120_172038/run_s6_n87 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:35:01,301 - INFO - Training completed for config s6_n87:
  Training time: 0:00:09
  Final validation loss: 10.910711
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.03e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n87/checkpoint.bin
2024-11-20 17:35:01,301 - INFO - 
Configuration s6_n87 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.220346499659539e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n87",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910711
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.03e-07
2024-11-20 17:35:01,301 - INFO - 
Starting training for config s6_n88:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:35:01,301 - INFO - Running command: ./train_gpt2cu -l 0.0005770588695397528 -o hyperband_runs_20241120_172038/run_s6_n88 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:35:11,120 - INFO - Training completed for config s6_n88:
  Training time: 0:00:09
  Final validation loss: 10.904523
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.24e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n88/checkpoint.bin
2024-11-20 17:35:11,121 - INFO - 
Configuration s6_n88 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005770588695397528",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n88",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904523
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.24e-07
2024-11-20 17:35:11,121 - INFO - 
Starting training for config s6_n89:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:35:11,121 - INFO - Running command: ./train_gpt2cu -l 1.746108526961883e-05 -o hyperband_runs_20241120_172038/run_s6_n89 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:35:20,955 - INFO - Training completed for config s6_n89:
  Training time: 0:00:09
  Final validation loss: 10.911390
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.49e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n89/checkpoint.bin
2024-11-20 17:35:20,955 - INFO - 
Configuration s6_n89 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.746108526961883e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n89",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911390
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.49e-08
2024-11-20 17:35:20,955 - INFO - 
Starting training for config s6_n90:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:35:20,955 - INFO - Running command: ./train_gpt2cu -l 0.00010502700501097615 -o hyperband_runs_20241120_172038/run_s6_n90 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:35:30,766 - INFO - Training completed for config s6_n90:
  Training time: 0:00:09
  Final validation loss: 10.910307
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.50e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n90/checkpoint.bin
2024-11-20 17:35:30,766 - INFO - 
Configuration s6_n90 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010502700501097615",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n90",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910307
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.50e-07
2024-11-20 17:35:30,766 - INFO - 
Starting training for config s6_n91:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:35:30,767 - INFO - Running command: ./train_gpt2cu -l 0.0001480916798201303 -o hyperband_runs_20241120_172038/run_s6_n91 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:35:40,579 - INFO - Training completed for config s6_n91:
  Training time: 0:00:09
  Final validation loss: 10.909760
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.12e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n91/checkpoint.bin
2024-11-20 17:35:40,580 - INFO - 
Configuration s6_n91 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001480916798201303",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n91",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909760
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.12e-07
2024-11-20 17:35:40,580 - INFO - 
Starting training for config s6_n92:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:35:40,580 - INFO - Running command: ./train_gpt2cu -l 4.772177957606211e-05 -o hyperband_runs_20241120_172038/run_s6_n92 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:35:50,383 - INFO - Training completed for config s6_n92:
  Training time: 0:00:09
  Final validation loss: 10.911025
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.82e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n92/checkpoint.bin
2024-11-20 17:35:50,383 - INFO - 
Configuration s6_n92 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.772177957606211e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n92",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911025
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.82e-08
2024-11-20 17:35:50,383 - INFO - 
Starting training for config s6_n93:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:35:50,384 - INFO - Running command: ./train_gpt2cu -l 6.44389844790714e-05 -o hyperband_runs_20241120_172038/run_s6_n93 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:36:00,208 - INFO - Training completed for config s6_n93:
  Training time: 0:00:09
  Final validation loss: 10.910808
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.21e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n93/checkpoint.bin
2024-11-20 17:36:00,208 - INFO - 
Configuration s6_n93 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.44389844790714e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n93",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910808
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.21e-08
2024-11-20 17:36:00,208 - INFO - 
Starting training for config s6_n94:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:36:00,209 - INFO - Running command: ./train_gpt2cu -l 1.8837902636221988e-05 -o hyperband_runs_20241120_172038/run_s6_n94 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:36:10,003 - INFO - Training completed for config s6_n94:
  Training time: 0:00:09
  Final validation loss: 10.911370
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.69e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n94/checkpoint.bin
2024-11-20 17:36:10,003 - INFO - 
Configuration s6_n94 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.8837902636221988e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n94",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911370
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.69e-08
2024-11-20 17:36:10,003 - INFO - 
Starting training for config s6_n95:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:36:10,003 - INFO - Running command: ./train_gpt2cu -l 2.098402140252724e-05 -o hyperband_runs_20241120_172038/run_s6_n95 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:36:19,833 - INFO - Training completed for config s6_n95:
  Training time: 0:00:09
  Final validation loss: 10.911358
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.00e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n95/checkpoint.bin
2024-11-20 17:36:19,834 - INFO - 
Configuration s6_n95 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.098402140252724e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n95",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911358
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.00e-08
2024-11-20 17:36:19,834 - INFO - 
Starting training for config s6_n96:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:36:19,834 - INFO - Running command: ./train_gpt2cu -l 0.00010663452322887851 -o hyperband_runs_20241120_172038/run_s6_n96 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:36:29,649 - INFO - Training completed for config s6_n96:
  Training time: 0:00:09
  Final validation loss: 10.910274
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.52e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n96/checkpoint.bin
2024-11-20 17:36:29,649 - INFO - 
Configuration s6_n96 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010663452322887851",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n96",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910274
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.52e-07
2024-11-20 17:36:29,649 - INFO - 
Starting training for config s6_n97:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:36:29,649 - INFO - Running command: ./train_gpt2cu -l 6.557755299858787e-05 -o hyperband_runs_20241120_172038/run_s6_n97 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:36:39,458 - INFO - Training completed for config s6_n97:
  Training time: 0:00:09
  Final validation loss: 10.910797
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.37e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n97/checkpoint.bin
2024-11-20 17:36:39,458 - INFO - 
Configuration s6_n97 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.557755299858787e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n97",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910797
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.37e-08
2024-11-20 17:36:39,458 - INFO - 
Starting training for config s6_n98:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:36:39,459 - INFO - Running command: ./train_gpt2cu -l 4.455202390787658e-05 -o hyperband_runs_20241120_172038/run_s6_n98 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:36:49,268 - INFO - Training completed for config s6_n98:
  Training time: 0:00:09
  Final validation loss: 10.911076
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.36e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n98/checkpoint.bin
2024-11-20 17:36:49,268 - INFO - 
Configuration s6_n98 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.455202390787658e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n98",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911076
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.36e-08
2024-11-20 17:36:49,268 - INFO - 
Starting training for config s6_n99:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:36:49,268 - INFO - Running command: ./train_gpt2cu -l 3.7709046760575895e-05 -o hyperband_runs_20241120_172038/run_s6_n99 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:36:59,066 - INFO - Training completed for config s6_n99:
  Training time: 0:00:09
  Final validation loss: 10.911156
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.39e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n99/checkpoint.bin
2024-11-20 17:36:59,066 - INFO - 
Configuration s6_n99 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.7709046760575895e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n99",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911156
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.39e-08
2024-11-20 17:36:59,066 - INFO - 
Starting training for config s6_n100:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:36:59,067 - INFO - Running command: ./train_gpt2cu -l 0.0007748331409407934 -o hyperband_runs_20241120_172038/run_s6_n100 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:37:08,876 - INFO - Training completed for config s6_n100:
  Training time: 0:00:09
  Final validation loss: 10.902116
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.11e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n100/checkpoint.bin
2024-11-20 17:37:08,876 - INFO - 
Configuration s6_n100 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007748331409407934",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n100",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.902116
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.11e-06
2024-11-20 17:37:08,876 - INFO - 
Starting training for config s6_n101:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:37:08,876 - INFO - Running command: ./train_gpt2cu -l 5.749340784831916e-05 -o hyperband_runs_20241120_172038/run_s6_n101 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:37:18,685 - INFO - Training completed for config s6_n101:
  Training time: 0:00:09
  Final validation loss: 10.910894
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.21e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n101/checkpoint.bin
2024-11-20 17:37:18,686 - INFO - 
Configuration s6_n101 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.749340784831916e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n101",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910894
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.21e-08
2024-11-20 17:37:18,686 - INFO - 
Starting training for config s6_n102:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:37:18,686 - INFO - Running command: ./train_gpt2cu -l 5.5792576497395886e-05 -o hyperband_runs_20241120_172038/run_s6_n102 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:37:28,491 - INFO - Training completed for config s6_n102:
  Training time: 0:00:09
  Final validation loss: 10.910929
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.97e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n102/checkpoint.bin
2024-11-20 17:37:28,491 - INFO - 
Configuration s6_n102 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.5792576497395886e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n102",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910929
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.97e-08
2024-11-20 17:37:28,492 - INFO - 
Starting training for config s6_n103:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:37:28,492 - INFO - Running command: ./train_gpt2cu -l 5.2512490885307264e-05 -o hyperband_runs_20241120_172038/run_s6_n103 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:37:38,312 - INFO - Training completed for config s6_n103:
  Training time: 0:00:09
  Final validation loss: 10.910956
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.50e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n103/checkpoint.bin
2024-11-20 17:37:38,312 - INFO - 
Configuration s6_n103 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.2512490885307264e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n103",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910956
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.50e-08
2024-11-20 17:37:38,312 - INFO - 
Starting training for config s6_n104:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:37:38,313 - INFO - Running command: ./train_gpt2cu -l 0.0002630435518795737 -o hyperband_runs_20241120_172038/run_s6_n104 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:37:48,147 - INFO - Training completed for config s6_n104:
  Training time: 0:00:09
  Final validation loss: 10.908356
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.76e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n104/checkpoint.bin
2024-11-20 17:37:48,148 - INFO - 
Configuration s6_n104 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002630435518795737",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n104",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908356
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.76e-07
2024-11-20 17:37:48,148 - INFO - 
Starting training for config s6_n105:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:37:48,148 - INFO - Running command: ./train_gpt2cu -l 0.00034298991818401437 -o hyperband_runs_20241120_172038/run_s6_n105 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:37:57,943 - INFO - Training completed for config s6_n105:
  Training time: 0:00:09
  Final validation loss: 10.907381
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.90e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n105/checkpoint.bin
2024-11-20 17:37:57,943 - INFO - 
Configuration s6_n105 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00034298991818401437",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n105",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907381
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.90e-07
2024-11-20 17:37:57,943 - INFO - 
Starting training for config s6_n106:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:37:57,943 - INFO - Running command: ./train_gpt2cu -l 0.0001258765383464653 -o hyperband_runs_20241120_172038/run_s6_n106 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:38:07,732 - INFO - Training completed for config s6_n106:
  Training time: 0:00:09
  Final validation loss: 10.910044
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.80e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n106/checkpoint.bin
2024-11-20 17:38:07,733 - INFO - 
Configuration s6_n106 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001258765383464653",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n106",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910044
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.80e-07
2024-11-20 17:38:07,733 - INFO - 
Starting training for config s6_n107:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:38:07,733 - INFO - Running command: ./train_gpt2cu -l 0.0004308027030496864 -o hyperband_runs_20241120_172038/run_s6_n107 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:38:17,565 - INFO - Training completed for config s6_n107:
  Training time: 0:00:09
  Final validation loss: 10.906294
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.15e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n107/checkpoint.bin
2024-11-20 17:38:17,565 - INFO - 
Configuration s6_n107 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004308027030496864",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n107",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906294
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.15e-07
2024-11-20 17:38:17,565 - INFO - 
Starting training for config s6_n108:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:38:17,565 - INFO - Running command: ./train_gpt2cu -l 9.731126970539572e-05 -o hyperband_runs_20241120_172038/run_s6_n108 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:38:27,365 - INFO - Training completed for config s6_n108:
  Training time: 0:00:09
  Final validation loss: 10.910396
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.39e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n108/checkpoint.bin
2024-11-20 17:38:27,365 - INFO - 
Configuration s6_n108 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "9.731126970539572e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n108",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910396
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.39e-07
2024-11-20 17:38:27,365 - INFO - 
Starting training for config s6_n109:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:38:27,365 - INFO - Running command: ./train_gpt2cu -l 4.17410300860778e-05 -o hyperband_runs_20241120_172038/run_s6_n109 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:38:37,172 - INFO - Training completed for config s6_n109:
  Training time: 0:00:09
  Final validation loss: 10.911108
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.96e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n109/checkpoint.bin
2024-11-20 17:38:37,172 - INFO - 
Configuration s6_n109 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.17410300860778e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n109",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911108
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.96e-08
2024-11-20 17:38:37,172 - INFO - 
Starting training for config s6_n110:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:38:37,172 - INFO - Running command: ./train_gpt2cu -l 0.00017142691261458478 -o hyperband_runs_20241120_172038/run_s6_n110 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:38:46,971 - INFO - Training completed for config s6_n110:
  Training time: 0:00:09
  Final validation loss: 10.909483
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.45e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n110/checkpoint.bin
2024-11-20 17:38:46,971 - INFO - 
Configuration s6_n110 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00017142691261458478",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n110",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909483
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.45e-07
2024-11-20 17:38:46,971 - INFO - 
Starting training for config s6_n111:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:38:46,972 - INFO - Running command: ./train_gpt2cu -l 3.226304448475163e-05 -o hyperband_runs_20241120_172038/run_s6_n111 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:38:56,767 - INFO - Training completed for config s6_n111:
  Training time: 0:00:09
  Final validation loss: 10.911213
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.61e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n111/checkpoint.bin
2024-11-20 17:38:56,768 - INFO - 
Configuration s6_n111 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.226304448475163e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n111",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911213
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.61e-08
2024-11-20 17:38:56,768 - INFO - 
Starting training for config s6_n112:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:38:56,768 - INFO - Running command: ./train_gpt2cu -l 2.3768902620396903e-05 -o hyperband_runs_20241120_172038/run_s6_n112 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:39:06,589 - INFO - Training completed for config s6_n112:
  Training time: 0:00:09
  Final validation loss: 10.911310
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.40e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n112/checkpoint.bin
2024-11-20 17:39:06,589 - INFO - 
Configuration s6_n112 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.3768902620396903e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n112",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911310
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.40e-08
2024-11-20 17:39:06,590 - INFO - 
Starting training for config s6_n113:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:39:06,590 - INFO - Running command: ./train_gpt2cu -l 0.00010921024290408384 -o hyperband_runs_20241120_172038/run_s6_n113 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:39:16,398 - INFO - Training completed for config s6_n113:
  Training time: 0:00:09
  Final validation loss: 10.910244
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.56e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n113/checkpoint.bin
2024-11-20 17:39:16,399 - INFO - 
Configuration s6_n113 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010921024290408384",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n113",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910244
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.56e-07
2024-11-20 17:39:16,399 - INFO - 
Starting training for config s6_n114:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:39:16,399 - INFO - Running command: ./train_gpt2cu -l 0.00022347810711559555 -o hyperband_runs_20241120_172038/run_s6_n114 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:39:26,183 - INFO - Training completed for config s6_n114:
  Training time: 0:00:09
  Final validation loss: 10.908842
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.19e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n114/checkpoint.bin
2024-11-20 17:39:26,184 - INFO - 
Configuration s6_n114 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00022347810711559555",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n114",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908842
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.19e-07
2024-11-20 17:39:26,184 - INFO - 
Starting training for config s6_n115:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:39:26,184 - INFO - Running command: ./train_gpt2cu -l 0.00016711706815664221 -o hyperband_runs_20241120_172038/run_s6_n115 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:39:35,991 - INFO - Training completed for config s6_n115:
  Training time: 0:00:09
  Final validation loss: 10.909536
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.39e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n115/checkpoint.bin
2024-11-20 17:39:35,991 - INFO - 
Configuration s6_n115 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00016711706815664221",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n115",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909536
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.39e-07
2024-11-20 17:39:35,991 - INFO - 
Starting training for config s6_n116:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:39:35,991 - INFO - Running command: ./train_gpt2cu -l 0.0007975447996901649 -o hyperband_runs_20241120_172038/run_s6_n116 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:39:45,807 - INFO - Training completed for config s6_n116:
  Training time: 0:00:09
  Final validation loss: 10.901821
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.14e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n116/checkpoint.bin
2024-11-20 17:39:45,808 - INFO - 
Configuration s6_n116 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007975447996901649",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n116",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901821
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.14e-06
2024-11-20 17:39:45,808 - INFO - 
Starting training for config s6_n117:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:39:45,808 - INFO - Running command: ./train_gpt2cu -l 5.511645674449598e-05 -o hyperband_runs_20241120_172038/run_s6_n117 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:39:55,634 - INFO - Training completed for config s6_n117:
  Training time: 0:00:09
  Final validation loss: 10.910922
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.87e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n117/checkpoint.bin
2024-11-20 17:39:55,635 - INFO - 
Configuration s6_n117 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.511645674449598e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n117",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910922
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.87e-08
2024-11-20 17:39:55,635 - INFO - 
Starting training for config s6_n118:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:39:55,635 - INFO - Running command: ./train_gpt2cu -l 1.0362831346427993e-05 -o hyperband_runs_20241120_172038/run_s6_n118 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:40:05,431 - INFO - Training completed for config s6_n118:
  Training time: 0:00:09
  Final validation loss: 10.911469
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.48e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n118/checkpoint.bin
2024-11-20 17:40:05,431 - INFO - 
Configuration s6_n118 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.0362831346427993e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n118",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911469
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.48e-08
2024-11-20 17:40:05,431 - INFO - 
Starting training for config s6_n119:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:40:05,432 - INFO - Running command: ./train_gpt2cu -l 0.0003510213073172754 -o hyperband_runs_20241120_172038/run_s6_n119 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:40:15,238 - INFO - Training completed for config s6_n119:
  Training time: 0:00:09
  Final validation loss: 10.907272
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.01e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n119/checkpoint.bin
2024-11-20 17:40:15,238 - INFO - 
Configuration s6_n119 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003510213073172754",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n119",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907272
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.01e-07
2024-11-20 17:40:15,238 - INFO - 
Starting training for config s6_n120:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:40:15,238 - INFO - Running command: ./train_gpt2cu -l 9.712216259492791e-05 -o hyperband_runs_20241120_172038/run_s6_n120 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:40:25,038 - INFO - Training completed for config s6_n120:
  Training time: 0:00:09
  Final validation loss: 10.910398
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.39e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n120/checkpoint.bin
2024-11-20 17:40:25,039 - INFO - 
Configuration s6_n120 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "9.712216259492791e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n120",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910398
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.39e-07
2024-11-20 17:40:25,039 - INFO - 
Starting training for config s6_n121:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:40:25,039 - INFO - Running command: ./train_gpt2cu -l 0.0003615226741902246 -o hyperband_runs_20241120_172038/run_s6_n121 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:40:34,869 - INFO - Training completed for config s6_n121:
  Training time: 0:00:09
  Final validation loss: 10.907145
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.16e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n121/checkpoint.bin
2024-11-20 17:40:34,869 - INFO - 
Configuration s6_n121 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003615226741902246",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n121",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907145
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.16e-07
2024-11-20 17:40:34,869 - INFO - 
Starting training for config s6_n122:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:40:34,869 - INFO - Running command: ./train_gpt2cu -l 0.0009278776931084436 -o hyperband_runs_20241120_172038/run_s6_n122 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:40:44,661 - INFO - Training completed for config s6_n122:
  Training time: 0:00:09
  Final validation loss: 10.900253
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.33e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n122/checkpoint.bin
2024-11-20 17:40:44,661 - INFO - 
Configuration s6_n122 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009278776931084436",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n122",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.900253
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.33e-06
2024-11-20 17:40:44,661 - INFO - 
Starting training for config s6_n123:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:40:44,661 - INFO - Running command: ./train_gpt2cu -l 3.839204081365194e-05 -o hyperband_runs_20241120_172038/run_s6_n123 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:40:54,467 - INFO - Training completed for config s6_n123:
  Training time: 0:00:09
  Final validation loss: 10.911136
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.48e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n123/checkpoint.bin
2024-11-20 17:40:54,467 - INFO - 
Configuration s6_n123 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.839204081365194e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n123",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911136
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.48e-08
2024-11-20 17:40:54,468 - INFO - 
Starting training for config s6_n124:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:40:54,468 - INFO - Running command: ./train_gpt2cu -l 8.8058683256885e-05 -o hyperband_runs_20241120_172038/run_s6_n124 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:41:04,272 - INFO - Training completed for config s6_n124:
  Training time: 0:00:09
  Final validation loss: 10.910512
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.26e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n124/checkpoint.bin
2024-11-20 17:41:04,272 - INFO - 
Configuration s6_n124 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "8.8058683256885e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n124",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910512
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.26e-07
2024-11-20 17:41:04,272 - INFO - 
Starting training for config s6_n125:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:41:04,272 - INFO - Running command: ./train_gpt2cu -l 0.0002446362076671156 -o hyperband_runs_20241120_172038/run_s6_n125 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:41:14,092 - INFO - Training completed for config s6_n125:
  Training time: 0:00:09
  Final validation loss: 10.908590
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.49e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n125/checkpoint.bin
2024-11-20 17:41:14,092 - INFO - 
Configuration s6_n125 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002446362076671156",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n125",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908590
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.49e-07
2024-11-20 17:41:14,092 - INFO - 
Starting training for config s6_n126:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:41:14,092 - INFO - Running command: ./train_gpt2cu -l 1.7848172283445305e-05 -o hyperband_runs_20241120_172038/run_s6_n126 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:41:23,881 - INFO - Training completed for config s6_n126:
  Training time: 0:00:09
  Final validation loss: 10.911376
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.55e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n126/checkpoint.bin
2024-11-20 17:41:23,881 - INFO - 
Configuration s6_n126 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.7848172283445305e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n126",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911376
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.55e-08
2024-11-20 17:41:23,881 - INFO - 
Starting training for config s6_n127:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:41:23,881 - INFO - Running command: ./train_gpt2cu -l 5.3066167562155614e-05 -o hyperband_runs_20241120_172038/run_s6_n127 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:41:33,680 - INFO - Training completed for config s6_n127:
  Training time: 0:00:09
  Final validation loss: 10.910950
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.58e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n127/checkpoint.bin
2024-11-20 17:41:33,680 - INFO - 
Configuration s6_n127 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.3066167562155614e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n127",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910950
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.58e-08
2024-11-20 17:41:33,680 - INFO - 
Starting training for config s6_n128:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:41:33,680 - INFO - Running command: ./train_gpt2cu -l 0.000278819280235079 -o hyperband_runs_20241120_172038/run_s6_n128 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:41:43,502 - INFO - Training completed for config s6_n128:
  Training time: 0:00:09
  Final validation loss: 10.908159
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.98e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n128/checkpoint.bin
2024-11-20 17:41:43,503 - INFO - 
Configuration s6_n128 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000278819280235079",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n128",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908159
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.98e-07
2024-11-20 17:41:43,503 - INFO - 
Starting training for config s6_n129:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:41:43,503 - INFO - Running command: ./train_gpt2cu -l 6.846521555189521e-05 -o hyperband_runs_20241120_172038/run_s6_n129 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:41:53,305 - INFO - Training completed for config s6_n129:
  Training time: 0:00:09
  Final validation loss: 10.910769
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.78e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n129/checkpoint.bin
2024-11-20 17:41:53,305 - INFO - 
Configuration s6_n129 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.846521555189521e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n129",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910769
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.78e-08
2024-11-20 17:41:53,305 - INFO - 
Starting training for config s6_n130:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:41:53,305 - INFO - Running command: ./train_gpt2cu -l 7.659035542356148e-05 -o hyperband_runs_20241120_172038/run_s6_n130 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:42:03,109 - INFO - Training completed for config s6_n130:
  Training time: 0:00:09
  Final validation loss: 10.910650
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.09e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n130/checkpoint.bin
2024-11-20 17:42:03,109 - INFO - 
Configuration s6_n130 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.659035542356148e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n130",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910650
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.09e-07
2024-11-20 17:42:03,109 - INFO - 
Starting training for config s6_n131:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:42:03,110 - INFO - Running command: ./train_gpt2cu -l 1.8427402823074757e-05 -o hyperband_runs_20241120_172038/run_s6_n131 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:42:12,915 - INFO - Training completed for config s6_n131:
  Training time: 0:00:09
  Final validation loss: 10.911377
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.63e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n131/checkpoint.bin
2024-11-20 17:42:12,916 - INFO - 
Configuration s6_n131 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.8427402823074757e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n131",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911377
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.63e-08
2024-11-20 17:42:12,916 - INFO - 
Starting training for config s6_n132:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:42:12,916 - INFO - Running command: ./train_gpt2cu -l 5.7364494326903455e-05 -o hyperband_runs_20241120_172038/run_s6_n132 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:42:22,725 - INFO - Training completed for config s6_n132:
  Training time: 0:00:09
  Final validation loss: 10.910892
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.19e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n132/checkpoint.bin
2024-11-20 17:42:22,726 - INFO - 
Configuration s6_n132 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.7364494326903455e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n132",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910892
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.19e-08
2024-11-20 17:42:22,726 - INFO - 
Starting training for config s6_n133:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:42:22,726 - INFO - Running command: ./train_gpt2cu -l 4.556020380668283e-05 -o hyperband_runs_20241120_172038/run_s6_n133 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:42:32,532 - INFO - Training completed for config s6_n133:
  Training time: 0:00:09
  Final validation loss: 10.911051
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.51e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n133/checkpoint.bin
2024-11-20 17:42:32,532 - INFO - 
Configuration s6_n133 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.556020380668283e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n133",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911051
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.51e-08
2024-11-20 17:42:32,532 - INFO - 
Starting training for config s6_n134:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:42:32,532 - INFO - Running command: ./train_gpt2cu -l 0.0004676997157935328 -o hyperband_runs_20241120_172038/run_s6_n134 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:42:42,338 - INFO - Training completed for config s6_n134:
  Training time: 0:00:09
  Final validation loss: 10.905847
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.68e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n134/checkpoint.bin
2024-11-20 17:42:42,338 - INFO - 
Configuration s6_n134 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004676997157935328",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n134",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905847
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.68e-07
2024-11-20 17:42:42,338 - INFO - 
Starting training for config s6_n135:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:42:42,338 - INFO - Running command: ./train_gpt2cu -l 1.8077190453883123e-05 -o hyperband_runs_20241120_172038/run_s6_n135 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:42:52,142 - INFO - Training completed for config s6_n135:
  Training time: 0:00:09
  Final validation loss: 10.911382
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.58e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n135/checkpoint.bin
2024-11-20 17:42:52,142 - INFO - 
Configuration s6_n135 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.8077190453883123e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n135",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911382
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.58e-08
2024-11-20 17:42:52,142 - INFO - 
Starting training for config s6_n136:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:42:52,142 - INFO - Running command: ./train_gpt2cu -l 0.00013344969294550474 -o hyperband_runs_20241120_172038/run_s6_n136 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:43:01,942 - INFO - Training completed for config s6_n136:
  Training time: 0:00:09
  Final validation loss: 10.909942
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.91e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n136/checkpoint.bin
2024-11-20 17:43:01,943 - INFO - 
Configuration s6_n136 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013344969294550474",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n136",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909942
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.91e-07
2024-11-20 17:43:01,943 - INFO - 
Starting training for config s6_n137:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:43:01,943 - INFO - Running command: ./train_gpt2cu -l 3.304466574098125e-05 -o hyperband_runs_20241120_172038/run_s6_n137 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:43:11,754 - INFO - Training completed for config s6_n137:
  Training time: 0:00:09
  Final validation loss: 10.911215
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.72e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n137/checkpoint.bin
2024-11-20 17:43:11,755 - INFO - 
Configuration s6_n137 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.304466574098125e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n137",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911215
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.72e-08
2024-11-20 17:43:11,755 - INFO - 
Starting training for config s6_n138:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:43:11,755 - INFO - Running command: ./train_gpt2cu -l 1.9705502686110482e-05 -o hyperband_runs_20241120_172038/run_s6_n138 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:43:21,542 - INFO - Training completed for config s6_n138:
  Training time: 0:00:09
  Final validation loss: 10.911364
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.82e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n138/checkpoint.bin
2024-11-20 17:43:21,543 - INFO - 
Configuration s6_n138 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.9705502686110482e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n138",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911364
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.82e-08
2024-11-20 17:43:21,543 - INFO - 
Starting training for config s6_n139:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:43:21,543 - INFO - Running command: ./train_gpt2cu -l 4.209041116042326e-05 -o hyperband_runs_20241120_172038/run_s6_n139 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:43:31,348 - INFO - Training completed for config s6_n139:
  Training time: 0:00:09
  Final validation loss: 10.911098
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.01e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n139/checkpoint.bin
2024-11-20 17:43:31,348 - INFO - 
Configuration s6_n139 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.209041116042326e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n139",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911098
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.01e-08
2024-11-20 17:43:31,348 - INFO - 
Starting training for config s6_n140:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:43:31,348 - INFO - Running command: ./train_gpt2cu -l 4.840403230471643e-05 -o hyperband_runs_20241120_172038/run_s6_n140 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:43:41,160 - INFO - Training completed for config s6_n140:
  Training time: 0:00:09
  Final validation loss: 10.911016
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.91e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n140/checkpoint.bin
2024-11-20 17:43:41,160 - INFO - 
Configuration s6_n140 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.840403230471643e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n140",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911016
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.91e-08
2024-11-20 17:43:41,160 - INFO - 
Starting training for config s6_n141:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:43:41,160 - INFO - Running command: ./train_gpt2cu -l 4.0469604444585585e-05 -o hyperband_runs_20241120_172038/run_s6_n141 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:43:50,971 - INFO - Training completed for config s6_n141:
  Training time: 0:00:09
  Final validation loss: 10.911125
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.78e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n141/checkpoint.bin
2024-11-20 17:43:50,971 - INFO - 
Configuration s6_n141 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.0469604444585585e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n141",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911125
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.78e-08
2024-11-20 17:43:50,971 - INFO - 
Starting training for config s6_n142:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:43:50,971 - INFO - Running command: ./train_gpt2cu -l 0.0005665513189493892 -o hyperband_runs_20241120_172038/run_s6_n142 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:44:00,765 - INFO - Training completed for config s6_n142:
  Training time: 0:00:09
  Final validation loss: 10.904655
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.09e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n142/checkpoint.bin
2024-11-20 17:44:00,765 - INFO - 
Configuration s6_n142 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005665513189493892",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n142",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904655
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.09e-07
2024-11-20 17:44:00,765 - INFO - 
Starting training for config s6_n143:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:44:00,766 - INFO - Running command: ./train_gpt2cu -l 1.2306580650160842e-05 -o hyperband_runs_20241120_172038/run_s6_n143 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:44:10,560 - INFO - Training completed for config s6_n143:
  Training time: 0:00:09
  Final validation loss: 10.911458
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.76e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n143/checkpoint.bin
2024-11-20 17:44:10,560 - INFO - 
Configuration s6_n143 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.2306580650160842e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n143",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911458
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.76e-08
2024-11-20 17:44:10,560 - INFO - 
Starting training for config s6_n144:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:44:10,561 - INFO - Running command: ./train_gpt2cu -l 2.6131435949669076e-05 -o hyperband_runs_20241120_172038/run_s6_n144 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:44:20,370 - INFO - Training completed for config s6_n144:
  Training time: 0:00:09
  Final validation loss: 10.911291
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.73e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n144/checkpoint.bin
2024-11-20 17:44:20,370 - INFO - 
Configuration s6_n144 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.6131435949669076e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n144",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911291
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.73e-08
2024-11-20 17:44:20,370 - INFO - 
Starting training for config s6_n145:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:44:20,371 - INFO - Running command: ./train_gpt2cu -l 3.1172416601717864e-05 -o hyperband_runs_20241120_172038/run_s6_n145 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:44:30,163 - INFO - Training completed for config s6_n145:
  Training time: 0:00:09
  Final validation loss: 10.911235
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.45e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n145/checkpoint.bin
2024-11-20 17:44:30,163 - INFO - 
Configuration s6_n145 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.1172416601717864e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n145",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911235
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.45e-08
2024-11-20 17:44:30,163 - INFO - 
Starting training for config s6_n146:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:44:30,163 - INFO - Running command: ./train_gpt2cu -l 0.0008942480821014569 -o hyperband_runs_20241120_172038/run_s6_n146 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:44:39,956 - INFO - Training completed for config s6_n146:
  Training time: 0:00:09
  Final validation loss: 10.900648
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.28e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n146/checkpoint.bin
2024-11-20 17:44:39,956 - INFO - 
Configuration s6_n146 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008942480821014569",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n146",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.900648
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.28e-06
2024-11-20 17:44:39,956 - INFO - 
Starting training for config s6_n147:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:44:39,956 - INFO - Running command: ./train_gpt2cu -l 0.0009244094155573718 -o hyperband_runs_20241120_172038/run_s6_n147 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:44:49,767 - INFO - Training completed for config s6_n147:
  Training time: 0:00:09
  Final validation loss: 10.900288
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.32e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n147/checkpoint.bin
2024-11-20 17:44:49,767 - INFO - 
Configuration s6_n147 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009244094155573718",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n147",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.900288
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.32e-06
2024-11-20 17:44:49,767 - INFO - 
Starting training for config s6_n148:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:44:49,767 - INFO - Running command: ./train_gpt2cu -l 0.00030713444107260913 -o hyperband_runs_20241120_172038/run_s6_n148 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:44:59,593 - INFO - Training completed for config s6_n148:
  Training time: 0:00:09
  Final validation loss: 10.907808
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.39e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n148/checkpoint.bin
2024-11-20 17:44:59,593 - INFO - 
Configuration s6_n148 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00030713444107260913",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n148",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907808
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.39e-07
2024-11-20 17:44:59,594 - INFO - 
Starting training for config s6_n149:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:44:59,594 - INFO - Running command: ./train_gpt2cu -l 2.2025623781003125e-05 -o hyperband_runs_20241120_172038/run_s6_n149 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:45:09,417 - INFO - Training completed for config s6_n149:
  Training time: 0:00:09
  Final validation loss: 10.911321
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.15e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n149/checkpoint.bin
2024-11-20 17:45:09,418 - INFO - 
Configuration s6_n149 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.2025623781003125e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n149",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911321
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.15e-08
2024-11-20 17:45:09,418 - INFO - 
Starting training for config s6_n150:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:45:09,418 - INFO - Running command: ./train_gpt2cu -l 0.0005391268463780815 -o hyperband_runs_20241120_172038/run_s6_n150 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:45:19,230 - INFO - Training completed for config s6_n150:
  Training time: 0:00:09
  Final validation loss: 10.904980
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.70e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n150/checkpoint.bin
2024-11-20 17:45:19,231 - INFO - 
Configuration s6_n150 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005391268463780815",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n150",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904980
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.70e-07
2024-11-20 17:45:19,231 - INFO - 
Starting training for config s6_n151:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:45:19,231 - INFO - Running command: ./train_gpt2cu -l 0.00014027213561098987 -o hyperband_runs_20241120_172038/run_s6_n151 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:45:29,044 - INFO - Training completed for config s6_n151:
  Training time: 0:00:09
  Final validation loss: 10.909866
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.00e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n151/checkpoint.bin
2024-11-20 17:45:29,044 - INFO - 
Configuration s6_n151 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014027213561098987",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n151",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909866
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.00e-07
2024-11-20 17:45:29,044 - INFO - 
Starting training for config s6_n152:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:45:29,044 - INFO - Running command: ./train_gpt2cu -l 0.0008225875504756807 -o hyperband_runs_20241120_172038/run_s6_n152 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:45:38,870 - INFO - Training completed for config s6_n152:
  Training time: 0:00:09
  Final validation loss: 10.901524
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.18e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n152/checkpoint.bin
2024-11-20 17:45:38,870 - INFO - 
Configuration s6_n152 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008225875504756807",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n152",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901524
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.18e-06
2024-11-20 17:45:38,870 - INFO - 
Starting training for config s6_n153:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:45:38,870 - INFO - Running command: ./train_gpt2cu -l 1.9606410797850094e-05 -o hyperband_runs_20241120_172038/run_s6_n153 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:45:48,679 - INFO - Training completed for config s6_n153:
  Training time: 0:00:09
  Final validation loss: 10.911366
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.80e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n153/checkpoint.bin
2024-11-20 17:45:48,679 - INFO - 
Configuration s6_n153 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.9606410797850094e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n153",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911366
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.80e-08
2024-11-20 17:45:48,679 - INFO - 
Starting training for config s6_n154:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:45:48,679 - INFO - Running command: ./train_gpt2cu -l 0.0008562517308020131 -o hyperband_runs_20241120_172038/run_s6_n154 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:45:58,466 - INFO - Training completed for config s6_n154:
  Training time: 0:00:09
  Final validation loss: 10.901108
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.22e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n154/checkpoint.bin
2024-11-20 17:45:58,467 - INFO - 
Configuration s6_n154 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008562517308020131",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n154",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901108
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.22e-06
2024-11-20 17:45:58,467 - INFO - 
Starting training for config s6_n155:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:45:58,467 - INFO - Running command: ./train_gpt2cu -l 0.00041716596685425323 -o hyperband_runs_20241120_172038/run_s6_n155 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:46:08,281 - INFO - Training completed for config s6_n155:
  Training time: 0:00:09
  Final validation loss: 10.906465
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.96e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n155/checkpoint.bin
2024-11-20 17:46:08,282 - INFO - 
Configuration s6_n155 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00041716596685425323",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n155",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906465
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.96e-07
2024-11-20 17:46:08,282 - INFO - 
Starting training for config s6_n156:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:46:08,282 - INFO - Running command: ./train_gpt2cu -l 0.0002729555936444007 -o hyperband_runs_20241120_172038/run_s6_n156 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:46:18,088 - INFO - Training completed for config s6_n156:
  Training time: 0:00:09
  Final validation loss: 10.908225
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.90e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n156/checkpoint.bin
2024-11-20 17:46:18,088 - INFO - 
Configuration s6_n156 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002729555936444007",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n156",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908225
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.90e-07
2024-11-20 17:46:18,088 - INFO - 
Starting training for config s6_n157:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:46:18,088 - INFO - Running command: ./train_gpt2cu -l 6.364720762678631e-05 -o hyperband_runs_20241120_172038/run_s6_n157 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:46:27,896 - INFO - Training completed for config s6_n157:
  Training time: 0:00:09
  Final validation loss: 10.910814
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.09e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n157/checkpoint.bin
2024-11-20 17:46:27,896 - INFO - 
Configuration s6_n157 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.364720762678631e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n157",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910814
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.09e-08
2024-11-20 17:46:27,896 - INFO - 
Starting training for config s6_n158:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:46:27,896 - INFO - Running command: ./train_gpt2cu -l 1.749062418379661e-05 -o hyperband_runs_20241120_172038/run_s6_n158 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:46:37,695 - INFO - Training completed for config s6_n158:
  Training time: 0:00:09
  Final validation loss: 10.911384
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.50e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n158/checkpoint.bin
2024-11-20 17:46:37,696 - INFO - 
Configuration s6_n158 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.749062418379661e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n158",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911384
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.50e-08
2024-11-20 17:46:37,696 - INFO - 
Starting training for config s6_n159:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:46:37,696 - INFO - Running command: ./train_gpt2cu -l 8.663920104922844e-05 -o hyperband_runs_20241120_172038/run_s6_n159 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:46:47,495 - INFO - Training completed for config s6_n159:
  Training time: 0:00:09
  Final validation loss: 10.910515
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.24e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n159/checkpoint.bin
2024-11-20 17:46:47,495 - INFO - 
Configuration s6_n159 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "8.663920104922844e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n159",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910515
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.24e-07
2024-11-20 17:46:47,495 - INFO - 
Starting training for config s6_n160:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:46:47,496 - INFO - Running command: ./train_gpt2cu -l 1.7982521427874008e-05 -o hyperband_runs_20241120_172038/run_s6_n160 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:46:57,302 - INFO - Training completed for config s6_n160:
  Training time: 0:00:09
  Final validation loss: 10.911376
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.57e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n160/checkpoint.bin
2024-11-20 17:46:57,303 - INFO - 
Configuration s6_n160 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.7982521427874008e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n160",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911376
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.57e-08
2024-11-20 17:46:57,303 - INFO - 
Starting training for config s6_n161:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:46:57,303 - INFO - Running command: ./train_gpt2cu -l 0.0001812525761339969 -o hyperband_runs_20241120_172038/run_s6_n161 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:47:07,118 - INFO - Training completed for config s6_n161:
  Training time: 0:00:09
  Final validation loss: 10.909358
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.59e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n161/checkpoint.bin
2024-11-20 17:47:07,118 - INFO - 
Configuration s6_n161 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001812525761339969",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n161",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909358
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.59e-07
2024-11-20 17:47:07,118 - INFO - 
Starting training for config s6_n162:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:47:07,118 - INFO - Running command: ./train_gpt2cu -l 1.8785359974759142e-05 -o hyperband_runs_20241120_172038/run_s6_n162 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:47:16,916 - INFO - Training completed for config s6_n162:
  Training time: 0:00:09
  Final validation loss: 10.911375
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.68e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n162/checkpoint.bin
2024-11-20 17:47:16,916 - INFO - 
Configuration s6_n162 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.8785359974759142e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n162",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911375
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.68e-08
2024-11-20 17:47:16,916 - INFO - 
Starting training for config s6_n163:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:47:16,916 - INFO - Running command: ./train_gpt2cu -l 0.0004359219869977251 -o hyperband_runs_20241120_172038/run_s6_n163 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:47:26,719 - INFO - Training completed for config s6_n163:
  Training time: 0:00:09
  Final validation loss: 10.906233
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.23e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n163/checkpoint.bin
2024-11-20 17:47:26,719 - INFO - 
Configuration s6_n163 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004359219869977251",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n163",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906233
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.23e-07
2024-11-20 17:47:26,719 - INFO - 
Starting training for config s6_n164:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:47:26,719 - INFO - Running command: ./train_gpt2cu -l 0.00029850297884334483 -o hyperband_runs_20241120_172038/run_s6_n164 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:47:36,522 - INFO - Training completed for config s6_n164:
  Training time: 0:00:09
  Final validation loss: 10.907919
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.26e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n164/checkpoint.bin
2024-11-20 17:47:36,522 - INFO - 
Configuration s6_n164 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00029850297884334483",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n164",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907919
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.26e-07
2024-11-20 17:47:36,523 - INFO - 
Starting training for config s6_n165:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:47:36,523 - INFO - Running command: ./train_gpt2cu -l 4.562917852059522e-05 -o hyperband_runs_20241120_172038/run_s6_n165 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:47:46,334 - INFO - Training completed for config s6_n165:
  Training time: 0:00:09
  Final validation loss: 10.911047
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.52e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n165/checkpoint.bin
2024-11-20 17:47:46,334 - INFO - 
Configuration s6_n165 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.562917852059522e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n165",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911047
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.52e-08
2024-11-20 17:47:46,334 - INFO - 
Starting training for config s6_n166:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:47:46,334 - INFO - Running command: ./train_gpt2cu -l 0.0003002284855912264 -o hyperband_runs_20241120_172038/run_s6_n166 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:47:56,131 - INFO - Training completed for config s6_n166:
  Training time: 0:00:09
  Final validation loss: 10.907891
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.29e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n166/checkpoint.bin
2024-11-20 17:47:56,131 - INFO - 
Configuration s6_n166 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003002284855912264",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n166",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907891
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.29e-07
2024-11-20 17:47:56,131 - INFO - 
Starting training for config s6_n167:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:47:56,132 - INFO - Running command: ./train_gpt2cu -l 0.0008525192676792822 -o hyperband_runs_20241120_172038/run_s6_n167 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:48:05,935 - INFO - Training completed for config s6_n167:
  Training time: 0:00:09
  Final validation loss: 10.901144
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.22e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n167/checkpoint.bin
2024-11-20 17:48:05,935 - INFO - 
Configuration s6_n167 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008525192676792822",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n167",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901144
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.22e-06
2024-11-20 17:48:05,936 - INFO - 
Starting training for config s6_n168:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:48:05,936 - INFO - Running command: ./train_gpt2cu -l 0.0003117980439479601 -o hyperband_runs_20241120_172038/run_s6_n168 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:48:15,744 - INFO - Training completed for config s6_n168:
  Training time: 0:00:09
  Final validation loss: 10.907752
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.45e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n168/checkpoint.bin
2024-11-20 17:48:15,744 - INFO - 
Configuration s6_n168 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003117980439479601",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n168",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907752
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.45e-07
2024-11-20 17:48:15,744 - INFO - 
Starting training for config s6_n169:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:48:15,744 - INFO - Running command: ./train_gpt2cu -l 0.00038437001256041916 -o hyperband_runs_20241120_172038/run_s6_n169 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:48:25,542 - INFO - Training completed for config s6_n169:
  Training time: 0:00:09
  Final validation loss: 10.906851
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.49e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n169/checkpoint.bin
2024-11-20 17:48:25,543 - INFO - 
Configuration s6_n169 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00038437001256041916",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n169",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906851
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.49e-07
2024-11-20 17:48:25,543 - INFO - 
Starting training for config s6_n170:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:48:25,543 - INFO - Running command: ./train_gpt2cu -l 0.0003338803294642336 -o hyperband_runs_20241120_172038/run_s6_n170 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:48:35,354 - INFO - Training completed for config s6_n170:
  Training time: 0:00:09
  Final validation loss: 10.907474
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.77e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n170/checkpoint.bin
2024-11-20 17:48:35,355 - INFO - 
Configuration s6_n170 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003338803294642336",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n170",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907474
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.77e-07
2024-11-20 17:48:35,355 - INFO - 
Starting training for config s6_n171:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:48:35,355 - INFO - Running command: ./train_gpt2cu -l 2.26668752230491e-05 -o hyperband_runs_20241120_172038/run_s6_n171 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:48:45,176 - INFO - Training completed for config s6_n171:
  Training time: 0:00:09
  Final validation loss: 10.911330
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.24e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n171/checkpoint.bin
2024-11-20 17:48:45,176 - INFO - 
Configuration s6_n171 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.26668752230491e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n171",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911330
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.24e-08
2024-11-20 17:48:45,176 - INFO - 
Starting training for config s6_n172:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:48:45,176 - INFO - Running command: ./train_gpt2cu -l 4.767282818815135e-05 -o hyperband_runs_20241120_172038/run_s6_n172 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:48:54,986 - INFO - Training completed for config s6_n172:
  Training time: 0:00:09
  Final validation loss: 10.911028
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.81e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n172/checkpoint.bin
2024-11-20 17:48:54,986 - INFO - 
Configuration s6_n172 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.767282818815135e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n172",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911028
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.81e-08
2024-11-20 17:48:54,986 - INFO - 
Starting training for config s6_n173:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:48:54,987 - INFO - Running command: ./train_gpt2cu -l 0.0008431900534300434 -o hyperband_runs_20241120_172038/run_s6_n173 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:49:04,803 - INFO - Training completed for config s6_n173:
  Training time: 0:00:09
  Final validation loss: 10.901270
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.20e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n173/checkpoint.bin
2024-11-20 17:49:04,803 - INFO - 
Configuration s6_n173 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008431900534300434",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n173",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901270
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.20e-06
2024-11-20 17:49:04,803 - INFO - 
Starting training for config s6_n174:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:49:04,803 - INFO - Running command: ./train_gpt2cu -l 1.3628256487402654e-05 -o hyperband_runs_20241120_172038/run_s6_n174 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:49:14,606 - INFO - Training completed for config s6_n174:
  Training time: 0:00:09
  Final validation loss: 10.911443
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.95e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n174/checkpoint.bin
2024-11-20 17:49:14,606 - INFO - 
Configuration s6_n174 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.3628256487402654e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n174",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911443
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.95e-08
2024-11-20 17:49:14,607 - INFO - 
Starting training for config s6_n175:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:49:14,607 - INFO - Running command: ./train_gpt2cu -l 0.0003002626915241805 -o hyperband_runs_20241120_172038/run_s6_n175 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:49:24,405 - INFO - Training completed for config s6_n175:
  Training time: 0:00:09
  Final validation loss: 10.907888
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.29e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n175/checkpoint.bin
2024-11-20 17:49:24,405 - INFO - 
Configuration s6_n175 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003002626915241805",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n175",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907888
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.29e-07
2024-11-20 17:49:24,405 - INFO - 
Starting training for config s6_n176:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:49:24,405 - INFO - Running command: ./train_gpt2cu -l 0.00012006204787344085 -o hyperband_runs_20241120_172038/run_s6_n176 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:49:34,206 - INFO - Training completed for config s6_n176:
  Training time: 0:00:09
  Final validation loss: 10.910131
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.72e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n176/checkpoint.bin
2024-11-20 17:49:34,206 - INFO - 
Configuration s6_n176 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012006204787344085",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n176",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910131
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.72e-07
2024-11-20 17:49:34,206 - INFO - 
Starting training for config s6_n177:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:49:34,206 - INFO - Running command: ./train_gpt2cu -l 0.00037553337942508797 -o hyperband_runs_20241120_172038/run_s6_n177 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:49:44,019 - INFO - Training completed for config s6_n177:
  Training time: 0:00:09
  Final validation loss: 10.906978
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.36e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n177/checkpoint.bin
2024-11-20 17:49:44,019 - INFO - 
Configuration s6_n177 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00037553337942508797",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n177",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906978
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.36e-07
2024-11-20 17:49:44,019 - INFO - 
Starting training for config s6_n178:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:49:44,019 - INFO - Running command: ./train_gpt2cu -l 0.00036266275588751055 -o hyperband_runs_20241120_172038/run_s6_n178 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:49:53,819 - INFO - Training completed for config s6_n178:
  Training time: 0:00:09
  Final validation loss: 10.907129
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.18e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n178/checkpoint.bin
2024-11-20 17:49:53,819 - INFO - 
Configuration s6_n178 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00036266275588751055",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n178",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907129
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.18e-07
2024-11-20 17:49:53,819 - INFO - 
Starting training for config s6_n179:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:49:53,819 - INFO - Running command: ./train_gpt2cu -l 0.00021332768196753135 -o hyperband_runs_20241120_172038/run_s6_n179 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:50:03,627 - INFO - Training completed for config s6_n179:
  Training time: 0:00:09
  Final validation loss: 10.908963
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.05e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n179/checkpoint.bin
2024-11-20 17:50:03,627 - INFO - 
Configuration s6_n179 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00021332768196753135",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n179",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908963
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.05e-07
2024-11-20 17:50:03,627 - INFO - 
Starting training for config s6_n180:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:50:03,627 - INFO - Running command: ./train_gpt2cu -l 1.4163548544712711e-05 -o hyperband_runs_20241120_172038/run_s6_n180 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:50:13,450 - INFO - Training completed for config s6_n180:
  Training time: 0:00:09
  Final validation loss: 10.911425
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.02e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n180/checkpoint.bin
2024-11-20 17:50:13,451 - INFO - 
Configuration s6_n180 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.4163548544712711e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n180",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911425
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.02e-08
2024-11-20 17:50:13,451 - INFO - 
Starting training for config s6_n181:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:50:13,451 - INFO - Running command: ./train_gpt2cu -l 0.00022520718065505214 -o hyperband_runs_20241120_172038/run_s6_n181 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:50:23,260 - INFO - Training completed for config s6_n181:
  Training time: 0:00:09
  Final validation loss: 10.908822
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.22e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n181/checkpoint.bin
2024-11-20 17:50:23,260 - INFO - 
Configuration s6_n181 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00022520718065505214",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n181",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908822
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.22e-07
2024-11-20 17:50:23,261 - INFO - 
Starting training for config s6_n182:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:50:23,261 - INFO - Running command: ./train_gpt2cu -l 1.746509377817829e-05 -o hyperband_runs_20241120_172038/run_s6_n182 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:50:33,061 - INFO - Training completed for config s6_n182:
  Training time: 0:00:09
  Final validation loss: 10.911392
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.50e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n182/checkpoint.bin
2024-11-20 17:50:33,062 - INFO - 
Configuration s6_n182 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.746509377817829e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n182",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911392
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.50e-08
2024-11-20 17:50:33,062 - INFO - 
Starting training for config s6_n183:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:50:33,062 - INFO - Running command: ./train_gpt2cu -l 0.0005536324926595919 -o hyperband_runs_20241120_172038/run_s6_n183 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:50:42,870 - INFO - Training completed for config s6_n183:
  Training time: 0:00:09
  Final validation loss: 10.904802
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.91e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n183/checkpoint.bin
2024-11-20 17:50:42,870 - INFO - 
Configuration s6_n183 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005536324926595919",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n183",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904802
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.91e-07
2024-11-20 17:50:42,870 - INFO - 
Starting training for config s6_n184:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:50:42,870 - INFO - Running command: ./train_gpt2cu -l 0.0002693407255441648 -o hyperband_runs_20241120_172038/run_s6_n184 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:50:52,688 - INFO - Training completed for config s6_n184:
  Training time: 0:00:09
  Final validation loss: 10.908262
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.85e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n184/checkpoint.bin
2024-11-20 17:50:52,688 - INFO - 
Configuration s6_n184 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002693407255441648",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n184",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908262
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.85e-07
2024-11-20 17:50:52,688 - INFO - 
Starting training for config s6_n185:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:50:52,688 - INFO - Running command: ./train_gpt2cu -l 0.0006393198282527764 -o hyperband_runs_20241120_172038/run_s6_n185 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:51:02,496 - INFO - Training completed for config s6_n185:
  Training time: 0:00:09
  Final validation loss: 10.903755
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.13e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n185/checkpoint.bin
2024-11-20 17:51:02,496 - INFO - 
Configuration s6_n185 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006393198282527764",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n185",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.903755
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.13e-07
2024-11-20 17:51:02,496 - INFO - 
Starting training for config s6_n186:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:51:02,497 - INFO - Running command: ./train_gpt2cu -l 0.00035081501592460135 -o hyperband_runs_20241120_172038/run_s6_n186 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:51:12,319 - INFO - Training completed for config s6_n186:
  Training time: 0:00:09
  Final validation loss: 10.907276
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.01e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n186/checkpoint.bin
2024-11-20 17:51:12,319 - INFO - 
Configuration s6_n186 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00035081501592460135",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n186",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907276
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.01e-07
2024-11-20 17:51:12,320 - INFO - 
Starting training for config s6_n187:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:51:12,320 - INFO - Running command: ./train_gpt2cu -l 7.546293615488564e-05 -o hyperband_runs_20241120_172038/run_s6_n187 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:51:22,142 - INFO - Training completed for config s6_n187:
  Training time: 0:00:09
  Final validation loss: 10.910661
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.08e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n187/checkpoint.bin
2024-11-20 17:51:22,143 - INFO - 
Configuration s6_n187 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.546293615488564e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n187",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910661
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.08e-07
2024-11-20 17:51:22,143 - INFO - 
Starting training for config s6_n188:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:51:22,143 - INFO - Running command: ./train_gpt2cu -l 7.906728382402253e-05 -o hyperband_runs_20241120_172038/run_s6_n188 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:51:31,957 - INFO - Training completed for config s6_n188:
  Training time: 0:00:09
  Final validation loss: 10.910623
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.13e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n188/checkpoint.bin
2024-11-20 17:51:31,957 - INFO - 
Configuration s6_n188 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.906728382402253e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n188",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910623
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.13e-07
2024-11-20 17:51:31,957 - INFO - 
Starting training for config s6_n189:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:51:31,957 - INFO - Running command: ./train_gpt2cu -l 0.00022589175006131897 -o hyperband_runs_20241120_172038/run_s6_n189 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:51:41,777 - INFO - Training completed for config s6_n189:
  Training time: 0:00:09
  Final validation loss: 10.908809
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.23e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n189/checkpoint.bin
2024-11-20 17:51:41,778 - INFO - 
Configuration s6_n189 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00022589175006131897",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n189",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908809
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.23e-07
2024-11-20 17:51:41,778 - INFO - 
Starting training for config s6_n190:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:51:41,778 - INFO - Running command: ./train_gpt2cu -l 0.00031228025979209253 -o hyperband_runs_20241120_172038/run_s6_n190 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:51:51,569 - INFO - Training completed for config s6_n190:
  Training time: 0:00:09
  Final validation loss: 10.907747
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.46e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n190/checkpoint.bin
2024-11-20 17:51:51,570 - INFO - 
Configuration s6_n190 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00031228025979209253",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n190",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907747
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.46e-07
2024-11-20 17:51:51,570 - INFO - 
Starting training for config s6_n191:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:51:51,570 - INFO - Running command: ./train_gpt2cu -l 0.0006673650168736646 -o hyperband_runs_20241120_172038/run_s6_n191 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:52:01,384 - INFO - Training completed for config s6_n191:
  Training time: 0:00:09
  Final validation loss: 10.903410
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.53e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n191/checkpoint.bin
2024-11-20 17:52:01,385 - INFO - 
Configuration s6_n191 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006673650168736646",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n191",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.903410
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.53e-07
2024-11-20 17:52:01,385 - INFO - 
Starting training for config s6_n192:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:52:01,385 - INFO - Running command: ./train_gpt2cu -l 0.00022182902515230813 -o hyperband_runs_20241120_172038/run_s6_n192 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:52:11,195 - INFO - Training completed for config s6_n192:
  Training time: 0:00:09
  Final validation loss: 10.908859
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.17e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n192/checkpoint.bin
2024-11-20 17:52:11,195 - INFO - 
Configuration s6_n192 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00022182902515230813",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n192",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908859
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.17e-07
2024-11-20 17:52:11,195 - INFO - 
Starting training for config s6_n193:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:52:11,196 - INFO - Running command: ./train_gpt2cu -l 6.875374172045923e-05 -o hyperband_runs_20241120_172038/run_s6_n193 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:52:21,002 - INFO - Training completed for config s6_n193:
  Training time: 0:00:09
  Final validation loss: 10.910754
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.82e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n193/checkpoint.bin
2024-11-20 17:52:21,003 - INFO - 
Configuration s6_n193 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.875374172045923e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n193",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910754
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.82e-08
2024-11-20 17:52:21,003 - INFO - 
Starting training for config s6_n194:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:52:21,003 - INFO - Running command: ./train_gpt2cu -l 2.3056342429227064e-05 -o hyperband_runs_20241120_172038/run_s6_n194 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:52:30,810 - INFO - Training completed for config s6_n194:
  Training time: 0:00:09
  Final validation loss: 10.911327
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.29e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n194/checkpoint.bin
2024-11-20 17:52:30,810 - INFO - 
Configuration s6_n194 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.3056342429227064e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n194",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911327
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.29e-08
2024-11-20 17:52:30,810 - INFO - 
Starting training for config s6_n195:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:52:30,810 - INFO - Running command: ./train_gpt2cu -l 0.0002802340153113612 -o hyperband_runs_20241120_172038/run_s6_n195 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:52:40,613 - INFO - Training completed for config s6_n195:
  Training time: 0:00:09
  Final validation loss: 10.908135
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.00e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n195/checkpoint.bin
2024-11-20 17:52:40,613 - INFO - 
Configuration s6_n195 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002802340153113612",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n195",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908135
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.00e-07
2024-11-20 17:52:40,613 - INFO - 
Starting training for config s6_n196:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:52:40,614 - INFO - Running command: ./train_gpt2cu -l 4.9536357873638074e-05 -o hyperband_runs_20241120_172038/run_s6_n196 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:52:50,412 - INFO - Training completed for config s6_n196:
  Training time: 0:00:09
  Final validation loss: 10.910996
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.08e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n196/checkpoint.bin
2024-11-20 17:52:50,413 - INFO - 
Configuration s6_n196 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.9536357873638074e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n196",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910996
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.08e-08
2024-11-20 17:52:50,413 - INFO - 
Starting training for config s6_n197:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:52:50,413 - INFO - Running command: ./train_gpt2cu -l 0.00015082984612541916 -o hyperband_runs_20241120_172038/run_s6_n197 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:53:00,224 - INFO - Training completed for config s6_n197:
  Training time: 0:00:09
  Final validation loss: 10.909741
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.15e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n197/checkpoint.bin
2024-11-20 17:53:00,224 - INFO - 
Configuration s6_n197 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00015082984612541916",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n197",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909741
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.15e-07
2024-11-20 17:53:00,224 - INFO - 
Starting training for config s6_n198:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:53:00,224 - INFO - Running command: ./train_gpt2cu -l 3.969539643593268e-05 -o hyperband_runs_20241120_172038/run_s6_n198 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:53:10,021 - INFO - Training completed for config s6_n198:
  Training time: 0:00:09
  Final validation loss: 10.911140
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.67e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n198/checkpoint.bin
2024-11-20 17:53:10,021 - INFO - 
Configuration s6_n198 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.969539643593268e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n198",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911140
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.67e-08
2024-11-20 17:53:10,021 - INFO - 
Starting training for config s6_n199:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:53:10,022 - INFO - Running command: ./train_gpt2cu -l 2.7655327255658013e-05 -o hyperband_runs_20241120_172038/run_s6_n199 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:53:19,832 - INFO - Training completed for config s6_n199:
  Training time: 0:00:09
  Final validation loss: 10.911272
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.95e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n199/checkpoint.bin
2024-11-20 17:53:19,832 - INFO - 
Configuration s6_n199 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.7655327255658013e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n199",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911272
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.95e-08
2024-11-20 17:53:19,832 - INFO - 
Starting training for config s6_n200:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:53:19,833 - INFO - Running command: ./train_gpt2cu -l 1.3073209572681185e-05 -o hyperband_runs_20241120_172038/run_s6_n200 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:53:29,639 - INFO - Training completed for config s6_n200:
  Training time: 0:00:09
  Final validation loss: 10.911443
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.87e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n200/checkpoint.bin
2024-11-20 17:53:29,639 - INFO - 
Configuration s6_n200 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.3073209572681185e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n200",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911443
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.87e-08
2024-11-20 17:53:29,639 - INFO - 
Starting training for config s6_n201:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:53:29,639 - INFO - Running command: ./train_gpt2cu -l 1.0905789715944178e-05 -o hyperband_runs_20241120_172038/run_s6_n201 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:53:39,446 - INFO - Training completed for config s6_n201:
  Training time: 0:00:09
  Final validation loss: 10.911460
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.56e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n201/checkpoint.bin
2024-11-20 17:53:39,446 - INFO - 
Configuration s6_n201 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.0905789715944178e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n201",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911460
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.56e-08
2024-11-20 17:53:39,446 - INFO - 
Starting training for config s6_n202:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:53:39,447 - INFO - Running command: ./train_gpt2cu -l 3.8168026587741846e-05 -o hyperband_runs_20241120_172038/run_s6_n202 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:53:49,235 - INFO - Training completed for config s6_n202:
  Training time: 0:00:09
  Final validation loss: 10.911144
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.45e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n202/checkpoint.bin
2024-11-20 17:53:49,235 - INFO - 
Configuration s6_n202 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.8168026587741846e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n202",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911144
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.45e-08
2024-11-20 17:53:49,235 - INFO - 
Starting training for config s6_n203:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:53:49,235 - INFO - Running command: ./train_gpt2cu -l 2.4459414834825393e-05 -o hyperband_runs_20241120_172038/run_s6_n203 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:53:59,043 - INFO - Training completed for config s6_n203:
  Training time: 0:00:09
  Final validation loss: 10.911306
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.49e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n203/checkpoint.bin
2024-11-20 17:53:59,043 - INFO - 
Configuration s6_n203 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.4459414834825393e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n203",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911306
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.49e-08
2024-11-20 17:53:59,043 - INFO - 
Starting training for config s6_n204:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:53:59,043 - INFO - Running command: ./train_gpt2cu -l 0.000145356795809769 -o hyperband_runs_20241120_172038/run_s6_n204 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:54:08,874 - INFO - Training completed for config s6_n204:
  Training time: 0:00:09
  Final validation loss: 10.909796
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.08e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n204/checkpoint.bin
2024-11-20 17:54:08,874 - INFO - 
Configuration s6_n204 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000145356795809769",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n204",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909796
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.08e-07
2024-11-20 17:54:08,875 - INFO - 
Starting training for config s6_n205:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:54:08,875 - INFO - Running command: ./train_gpt2cu -l 0.0001236261761345846 -o hyperband_runs_20241120_172038/run_s6_n205 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:54:18,678 - INFO - Training completed for config s6_n205:
  Training time: 0:00:09
  Final validation loss: 10.910067
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.77e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n205/checkpoint.bin
2024-11-20 17:54:18,678 - INFO - 
Configuration s6_n205 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001236261761345846",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n205",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910067
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.77e-07
2024-11-20 17:54:18,678 - INFO - 
Starting training for config s6_n206:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:54:18,678 - INFO - Running command: ./train_gpt2cu -l 0.0005960641560476585 -o hyperband_runs_20241120_172038/run_s6_n206 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:54:28,468 - INFO - Training completed for config s6_n206:
  Training time: 0:00:09
  Final validation loss: 10.904273
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.52e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n206/checkpoint.bin
2024-11-20 17:54:28,469 - INFO - 
Configuration s6_n206 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005960641560476585",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n206",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904273
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.52e-07
2024-11-20 17:54:28,469 - INFO - 
Starting training for config s6_n207:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:54:28,469 - INFO - Running command: ./train_gpt2cu -l 0.0001791163401217663 -o hyperband_runs_20241120_172038/run_s6_n207 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:54:38,312 - INFO - Training completed for config s6_n207:
  Training time: 0:00:09
  Final validation loss: 10.909391
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.56e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n207/checkpoint.bin
2024-11-20 17:54:38,313 - INFO - 
Configuration s6_n207 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001791163401217663",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n207",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909391
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.56e-07
2024-11-20 17:54:38,313 - INFO - 
Starting training for config s6_n208:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:54:38,313 - INFO - Running command: ./train_gpt2cu -l 0.00026333300463007446 -o hyperband_runs_20241120_172038/run_s6_n208 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:54:48,118 - INFO - Training completed for config s6_n208:
  Training time: 0:00:09
  Final validation loss: 10.908353
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.76e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n208/checkpoint.bin
2024-11-20 17:54:48,118 - INFO - 
Configuration s6_n208 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00026333300463007446",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n208",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908353
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.76e-07
2024-11-20 17:54:48,118 - INFO - 
Starting training for config s6_n209:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:54:48,119 - INFO - Running command: ./train_gpt2cu -l 0.00038763793333230513 -o hyperband_runs_20241120_172038/run_s6_n209 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:54:57,923 - INFO - Training completed for config s6_n209:
  Training time: 0:00:09
  Final validation loss: 10.906814
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.54e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n209/checkpoint.bin
2024-11-20 17:54:57,923 - INFO - 
Configuration s6_n209 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00038763793333230513",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n209",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906814
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.54e-07
2024-11-20 17:54:57,923 - INFO - 
Starting training for config s6_n210:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:54:57,924 - INFO - Running command: ./train_gpt2cu -l 0.000796614898741513 -o hyperband_runs_20241120_172038/run_s6_n210 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:55:07,720 - INFO - Training completed for config s6_n210:
  Training time: 0:00:09
  Final validation loss: 10.901842
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.14e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n210/checkpoint.bin
2024-11-20 17:55:07,720 - INFO - 
Configuration s6_n210 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000796614898741513",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n210",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901842
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.14e-06
2024-11-20 17:55:07,720 - INFO - 
Starting training for config s6_n211:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:55:07,720 - INFO - Running command: ./train_gpt2cu -l 3.907786696607147e-05 -o hyperband_runs_20241120_172038/run_s6_n211 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:55:17,551 - INFO - Training completed for config s6_n211:
  Training time: 0:00:09
  Final validation loss: 10.911132
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.58e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n211/checkpoint.bin
2024-11-20 17:55:17,551 - INFO - 
Configuration s6_n211 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.907786696607147e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n211",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911132
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.58e-08
2024-11-20 17:55:17,552 - INFO - 
Starting training for config s6_n212:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:55:17,552 - INFO - Running command: ./train_gpt2cu -l 0.0004886431983043564 -o hyperband_runs_20241120_172038/run_s6_n212 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:55:27,379 - INFO - Training completed for config s6_n212:
  Training time: 0:00:09
  Final validation loss: 10.905593
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.98e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n212/checkpoint.bin
2024-11-20 17:55:27,380 - INFO - 
Configuration s6_n212 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004886431983043564",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n212",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905593
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.98e-07
2024-11-20 17:55:27,380 - INFO - 
Starting training for config s6_n213:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:55:27,380 - INFO - Running command: ./train_gpt2cu -l 0.00017491512019772185 -o hyperband_runs_20241120_172038/run_s6_n213 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:55:37,181 - INFO - Training completed for config s6_n213:
  Training time: 0:00:09
  Final validation loss: 10.909445
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.50e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n213/checkpoint.bin
2024-11-20 17:55:37,181 - INFO - 
Configuration s6_n213 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00017491512019772185",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n213",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909445
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.50e-07
2024-11-20 17:55:37,182 - INFO - 
Starting training for config s6_n214:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:55:37,182 - INFO - Running command: ./train_gpt2cu -l 0.00042994844931465285 -o hyperband_runs_20241120_172038/run_s6_n214 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:55:46,989 - INFO - Training completed for config s6_n214:
  Training time: 0:00:09
  Final validation loss: 10.906306
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.14e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n214/checkpoint.bin
2024-11-20 17:55:46,989 - INFO - 
Configuration s6_n214 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00042994844931465285",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n214",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906306
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.14e-07
2024-11-20 17:55:46,989 - INFO - 
Starting training for config s6_n215:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:55:46,989 - INFO - Running command: ./train_gpt2cu -l 0.000259642775094729 -o hyperband_runs_20241120_172038/run_s6_n215 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:55:56,801 - INFO - Training completed for config s6_n215:
  Training time: 0:00:09
  Final validation loss: 10.908391
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.71e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n215/checkpoint.bin
2024-11-20 17:55:56,801 - INFO - 
Configuration s6_n215 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000259642775094729",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n215",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908391
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.71e-07
2024-11-20 17:55:56,801 - INFO - 
Starting training for config s6_n216:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:55:56,802 - INFO - Running command: ./train_gpt2cu -l 7.776321145985571e-05 -o hyperband_runs_20241120_172038/run_s6_n216 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:56:06,607 - INFO - Training completed for config s6_n216:
  Training time: 0:00:09
  Final validation loss: 10.910643
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.11e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n216/checkpoint.bin
2024-11-20 17:56:06,607 - INFO - 
Configuration s6_n216 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.776321145985571e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n216",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910643
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.11e-07
2024-11-20 17:56:06,607 - INFO - 
Starting training for config s6_n217:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:56:06,608 - INFO - Running command: ./train_gpt2cu -l 0.0006502089255387881 -o hyperband_runs_20241120_172038/run_s6_n217 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:56:16,413 - INFO - Training completed for config s6_n217:
  Training time: 0:00:09
  Final validation loss: 10.903620
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.29e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n217/checkpoint.bin
2024-11-20 17:56:16,413 - INFO - 
Configuration s6_n217 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006502089255387881",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n217",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.903620
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.29e-07
2024-11-20 17:56:16,413 - INFO - 
Starting training for config s6_n218:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:56:16,413 - INFO - Running command: ./train_gpt2cu -l 0.0003412585211946685 -o hyperband_runs_20241120_172038/run_s6_n218 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:56:26,222 - INFO - Training completed for config s6_n218:
  Training time: 0:00:09
  Final validation loss: 10.907389
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.88e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n218/checkpoint.bin
2024-11-20 17:56:26,222 - INFO - 
Configuration s6_n218 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003412585211946685",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n218",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907389
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.88e-07
2024-11-20 17:56:26,222 - INFO - 
Starting training for config s6_n219:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:56:26,222 - INFO - Running command: ./train_gpt2cu -l 0.0005228506839588235 -o hyperband_runs_20241120_172038/run_s6_n219 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:56:36,054 - INFO - Training completed for config s6_n219:
  Training time: 0:00:09
  Final validation loss: 10.905180
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.47e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n219/checkpoint.bin
2024-11-20 17:56:36,055 - INFO - 
Configuration s6_n219 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005228506839588235",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n219",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905180
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.47e-07
2024-11-20 17:56:36,055 - INFO - 
Starting training for config s6_n220:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:56:36,055 - INFO - Running command: ./train_gpt2cu -l 1.4428734940093038e-05 -o hyperband_runs_20241120_172038/run_s6_n220 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:56:45,868 - INFO - Training completed for config s6_n220:
  Training time: 0:00:09
  Final validation loss: 10.911427
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.06e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n220/checkpoint.bin
2024-11-20 17:56:45,868 - INFO - 
Configuration s6_n220 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.4428734940093038e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n220",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911427
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.06e-08
2024-11-20 17:56:45,868 - INFO - 
Starting training for config s6_n221:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:56:45,869 - INFO - Running command: ./train_gpt2cu -l 3.0069916460043833e-05 -o hyperband_runs_20241120_172038/run_s6_n221 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:56:55,696 - INFO - Training completed for config s6_n221:
  Training time: 0:00:09
  Final validation loss: 10.911248
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.30e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n221/checkpoint.bin
2024-11-20 17:56:55,696 - INFO - 
Configuration s6_n221 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.0069916460043833e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n221",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911248
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.30e-08
2024-11-20 17:56:55,696 - INFO - 
Starting training for config s6_n222:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:56:55,696 - INFO - Running command: ./train_gpt2cu -l 4.669367737416378e-05 -o hyperband_runs_20241120_172038/run_s6_n222 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:57:05,486 - INFO - Training completed for config s6_n222:
  Training time: 0:00:09
  Final validation loss: 10.911047
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.67e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n222/checkpoint.bin
2024-11-20 17:57:05,486 - INFO - 
Configuration s6_n222 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.669367737416378e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n222",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911047
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.67e-08
2024-11-20 17:57:05,487 - INFO - 
Starting training for config s6_n223:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:57:05,487 - INFO - Running command: ./train_gpt2cu -l 1.7530735640951156e-05 -o hyperband_runs_20241120_172038/run_s6_n223 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:57:15,299 - INFO - Training completed for config s6_n223:
  Training time: 0:00:09
  Final validation loss: 10.911389
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.50e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n223/checkpoint.bin
2024-11-20 17:57:15,300 - INFO - 
Configuration s6_n223 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.7530735640951156e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n223",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911389
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.50e-08
2024-11-20 17:57:15,300 - INFO - 
Starting training for config s6_n224:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:57:15,300 - INFO - Running command: ./train_gpt2cu -l 0.000168743406978023 -o hyperband_runs_20241120_172038/run_s6_n224 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:57:25,106 - INFO - Training completed for config s6_n224:
  Training time: 0:00:09
  Final validation loss: 10.909507
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.41e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n224/checkpoint.bin
2024-11-20 17:57:25,106 - INFO - 
Configuration s6_n224 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000168743406978023",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n224",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909507
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.41e-07
2024-11-20 17:57:25,106 - INFO - 
Starting training for config s6_n225:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:57:25,106 - INFO - Running command: ./train_gpt2cu -l 0.00011499956442887429 -o hyperband_runs_20241120_172038/run_s6_n225 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:57:34,926 - INFO - Training completed for config s6_n225:
  Training time: 0:00:09
  Final validation loss: 10.910180
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.64e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n225/checkpoint.bin
2024-11-20 17:57:34,926 - INFO - 
Configuration s6_n225 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00011499956442887429",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n225",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910180
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.64e-07
2024-11-20 17:57:34,926 - INFO - 
Starting training for config s6_n226:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:57:34,926 - INFO - Running command: ./train_gpt2cu -l 2.522274702300375e-05 -o hyperband_runs_20241120_172038/run_s6_n226 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:57:44,720 - INFO - Training completed for config s6_n226:
  Training time: 0:00:09
  Final validation loss: 10.911301
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.60e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n226/checkpoint.bin
2024-11-20 17:57:44,720 - INFO - 
Configuration s6_n226 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.522274702300375e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n226",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911301
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.60e-08
2024-11-20 17:57:44,720 - INFO - 
Starting training for config s6_n227:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:57:44,721 - INFO - Running command: ./train_gpt2cu -l 5.7087082382645076e-05 -o hyperband_runs_20241120_172038/run_s6_n227 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:57:54,526 - INFO - Training completed for config s6_n227:
  Training time: 0:00:09
  Final validation loss: 10.910909
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.16e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n227/checkpoint.bin
2024-11-20 17:57:54,526 - INFO - 
Configuration s6_n227 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.7087082382645076e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n227",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910909
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.16e-08
2024-11-20 17:57:54,526 - INFO - 
Starting training for config s6_n228:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:57:54,527 - INFO - Running command: ./train_gpt2cu -l 2.896030371122773e-05 -o hyperband_runs_20241120_172038/run_s6_n228 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:58:04,325 - INFO - Training completed for config s6_n228:
  Training time: 0:00:09
  Final validation loss: 10.911248
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.14e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n228/checkpoint.bin
2024-11-20 17:58:04,325 - INFO - 
Configuration s6_n228 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.896030371122773e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n228",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911248
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.14e-08
2024-11-20 17:58:04,325 - INFO - 
Starting training for config s6_n229:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:58:04,325 - INFO - Running command: ./train_gpt2cu -l 0.00079540403785159 -o hyperband_runs_20241120_172038/run_s6_n229 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:58:14,150 - INFO - Training completed for config s6_n229:
  Training time: 0:00:09
  Final validation loss: 10.901861
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.14e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n229/checkpoint.bin
2024-11-20 17:58:14,150 - INFO - 
Configuration s6_n229 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00079540403785159",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n229",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901861
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.14e-06
2024-11-20 17:58:14,150 - INFO - 
Starting training for config s6_n230:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:58:14,150 - INFO - Running command: ./train_gpt2cu -l 0.000343445966883462 -o hyperband_runs_20241120_172038/run_s6_n230 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:58:23,955 - INFO - Training completed for config s6_n230:
  Training time: 0:00:09
  Final validation loss: 10.907373
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.91e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n230/checkpoint.bin
2024-11-20 17:58:23,956 - INFO - 
Configuration s6_n230 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000343445966883462",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n230",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907373
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.91e-07
2024-11-20 17:58:23,956 - INFO - 
Starting training for config s6_n231:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:58:23,956 - INFO - Running command: ./train_gpt2cu -l 2.2092597417092943e-05 -o hyperband_runs_20241120_172038/run_s6_n231 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:58:33,784 - INFO - Training completed for config s6_n231:
  Training time: 0:00:09
  Final validation loss: 10.911330
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.16e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n231/checkpoint.bin
2024-11-20 17:58:33,785 - INFO - 
Configuration s6_n231 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.2092597417092943e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n231",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911330
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.16e-08
2024-11-20 17:58:33,785 - INFO - 
Starting training for config s6_n232:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:58:33,785 - INFO - Running command: ./train_gpt2cu -l 1.9022539478483785e-05 -o hyperband_runs_20241120_172038/run_s6_n232 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:58:43,613 - INFO - Training completed for config s6_n232:
  Training time: 0:00:09
  Final validation loss: 10.911367
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.72e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n232/checkpoint.bin
2024-11-20 17:58:43,613 - INFO - 
Configuration s6_n232 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.9022539478483785e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n232",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911367
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.72e-08
2024-11-20 17:58:43,613 - INFO - 
Starting training for config s6_n233:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:58:43,614 - INFO - Running command: ./train_gpt2cu -l 5.5240437703934586e-05 -o hyperband_runs_20241120_172038/run_s6_n233 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:58:53,421 - INFO - Training completed for config s6_n233:
  Training time: 0:00:09
  Final validation loss: 10.910933
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.89e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n233/checkpoint.bin
2024-11-20 17:58:53,421 - INFO - 
Configuration s6_n233 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.5240437703934586e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n233",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910933
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.89e-08
2024-11-20 17:58:53,421 - INFO - 
Starting training for config s6_n234:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:58:53,421 - INFO - Running command: ./train_gpt2cu -l 0.000853428541786053 -o hyperband_runs_20241120_172038/run_s6_n234 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:59:03,225 - INFO - Training completed for config s6_n234:
  Training time: 0:00:09
  Final validation loss: 10.901127
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.22e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n234/checkpoint.bin
2024-11-20 17:59:03,225 - INFO - 
Configuration s6_n234 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000853428541786053",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n234",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901127
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.22e-06
2024-11-20 17:59:03,225 - INFO - 
Starting training for config s6_n235:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:59:03,226 - INFO - Running command: ./train_gpt2cu -l 0.0006851603833257309 -o hyperband_runs_20241120_172038/run_s6_n235 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:59:13,036 - INFO - Training completed for config s6_n235:
  Training time: 0:00:09
  Final validation loss: 10.903202
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.79e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n235/checkpoint.bin
2024-11-20 17:59:13,036 - INFO - 
Configuration s6_n235 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006851603833257309",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n235",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.903202
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.79e-07
2024-11-20 17:59:13,037 - INFO - 
Starting training for config s6_n236:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:59:13,037 - INFO - Running command: ./train_gpt2cu -l 0.0007215956007704206 -o hyperband_runs_20241120_172038/run_s6_n236 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:59:22,865 - INFO - Training completed for config s6_n236:
  Training time: 0:00:09
  Final validation loss: 10.902754
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.03e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n236/checkpoint.bin
2024-11-20 17:59:22,865 - INFO - 
Configuration s6_n236 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007215956007704206",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n236",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.902754
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.03e-06
2024-11-20 17:59:22,865 - INFO - 
Starting training for config s6_n237:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:59:22,866 - INFO - Running command: ./train_gpt2cu -l 4.125756527195606e-05 -o hyperband_runs_20241120_172038/run_s6_n237 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:59:32,679 - INFO - Training completed for config s6_n237:
  Training time: 0:00:09
  Final validation loss: 10.911112
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.89e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n237/checkpoint.bin
2024-11-20 17:59:32,679 - INFO - 
Configuration s6_n237 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.125756527195606e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n237",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911112
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.89e-08
2024-11-20 17:59:32,679 - INFO - 
Starting training for config s6_n238:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:59:32,679 - INFO - Running command: ./train_gpt2cu -l 0.0001843678883570247 -o hyperband_runs_20241120_172038/run_s6_n238 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:59:42,482 - INFO - Training completed for config s6_n238:
  Training time: 0:00:09
  Final validation loss: 10.909317
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.63e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n238/checkpoint.bin
2024-11-20 17:59:42,482 - INFO - 
Configuration s6_n238 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001843678883570247",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n238",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909317
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.63e-07
2024-11-20 17:59:42,482 - INFO - 
Starting training for config s6_n239:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:59:42,482 - INFO - Running command: ./train_gpt2cu -l 0.00028939503137182925 -o hyperband_runs_20241120_172038/run_s6_n239 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 17:59:52,308 - INFO - Training completed for config s6_n239:
  Training time: 0:00:09
  Final validation loss: 10.908033
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.13e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n239/checkpoint.bin
2024-11-20 17:59:52,308 - INFO - 
Configuration s6_n239 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00028939503137182925",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n239",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908033
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.13e-07
2024-11-20 17:59:52,308 - INFO - 
Starting training for config s6_n240:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 17:59:52,308 - INFO - Running command: ./train_gpt2cu -l 0.00017541311890604766 -o hyperband_runs_20241120_172038/run_s6_n240 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:00:02,111 - INFO - Training completed for config s6_n240:
  Training time: 0:00:09
  Final validation loss: 10.909435
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.51e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n240/checkpoint.bin
2024-11-20 18:00:02,112 - INFO - 
Configuration s6_n240 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00017541311890604766",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n240",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909435
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.51e-07
2024-11-20 18:00:02,112 - INFO - 
Starting training for config s6_n241:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:00:02,112 - INFO - Running command: ./train_gpt2cu -l 8.34552477248499e-05 -o hyperband_runs_20241120_172038/run_s6_n241 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:00:11,927 - INFO - Training completed for config s6_n241:
  Training time: 0:00:09
  Final validation loss: 10.910566
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.19e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n241/checkpoint.bin
2024-11-20 18:00:11,927 - INFO - 
Configuration s6_n241 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "8.34552477248499e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n241",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910566
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.19e-07
2024-11-20 18:00:11,928 - INFO - 
Starting training for config s6_n242:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:00:11,928 - INFO - Running command: ./train_gpt2cu -l 1.2825439936997361e-05 -o hyperband_runs_20241120_172038/run_s6_n242 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:00:21,731 - INFO - Training completed for config s6_n242:
  Training time: 0:00:09
  Final validation loss: 10.911438
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.83e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n242/checkpoint.bin
2024-11-20 18:00:21,731 - INFO - 
Configuration s6_n242 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.2825439936997361e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n242",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911438
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.83e-08
2024-11-20 18:00:21,731 - INFO - 
Starting training for config s6_n243:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:00:21,731 - INFO - Running command: ./train_gpt2cu -l 2.545321383573862e-05 -o hyperband_runs_20241120_172038/run_s6_n243 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:00:31,535 - INFO - Training completed for config s6_n243:
  Training time: 0:00:09
  Final validation loss: 10.911294
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.64e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n243/checkpoint.bin
2024-11-20 18:00:31,536 - INFO - 
Configuration s6_n243 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.545321383573862e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n243",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911294
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.64e-08
2024-11-20 18:00:31,536 - INFO - 
Starting training for config s6_n244:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:00:31,536 - INFO - Running command: ./train_gpt2cu -l 0.0002884967827666835 -o hyperband_runs_20241120_172038/run_s6_n244 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:00:41,339 - INFO - Training completed for config s6_n244:
  Training time: 0:00:09
  Final validation loss: 10.908033
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.12e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n244/checkpoint.bin
2024-11-20 18:00:41,339 - INFO - 
Configuration s6_n244 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002884967827666835",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n244",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908033
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.12e-07
2024-11-20 18:00:41,339 - INFO - 
Starting training for config s6_n245:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:00:41,340 - INFO - Running command: ./train_gpt2cu -l 3.8458487480844174e-05 -o hyperband_runs_20241120_172038/run_s6_n245 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:00:51,148 - INFO - Training completed for config s6_n245:
  Training time: 0:00:09
  Final validation loss: 10.911139
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.49e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n245/checkpoint.bin
2024-11-20 18:00:51,149 - INFO - 
Configuration s6_n245 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.8458487480844174e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n245",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911139
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.49e-08
2024-11-20 18:00:51,149 - INFO - 
Starting training for config s6_n246:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:00:51,149 - INFO - Running command: ./train_gpt2cu -l 7.263926146688439e-05 -o hyperband_runs_20241120_172038/run_s6_n246 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:01:00,935 - INFO - Training completed for config s6_n246:
  Training time: 0:00:09
  Final validation loss: 10.910700
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.04e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n246/checkpoint.bin
2024-11-20 18:01:00,935 - INFO - 
Configuration s6_n246 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.263926146688439e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n246",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910700
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.04e-07
2024-11-20 18:01:00,936 - INFO - 
Starting training for config s6_n247:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:01:00,936 - INFO - Running command: ./train_gpt2cu -l 0.00014223921450185655 -o hyperband_runs_20241120_172038/run_s6_n247 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:01:10,775 - INFO - Training completed for config s6_n247:
  Training time: 0:00:09
  Final validation loss: 10.909826
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.03e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n247/checkpoint.bin
2024-11-20 18:01:10,775 - INFO - 
Configuration s6_n247 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014223921450185655",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n247",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909826
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.03e-07
2024-11-20 18:01:10,776 - INFO - 
Starting training for config s6_n248:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:01:10,776 - INFO - Running command: ./train_gpt2cu -l 0.0002791246587083738 -o hyperband_runs_20241120_172038/run_s6_n248 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:01:20,575 - INFO - Training completed for config s6_n248:
  Training time: 0:00:09
  Final validation loss: 10.908149
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.99e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n248/checkpoint.bin
2024-11-20 18:01:20,575 - INFO - 
Configuration s6_n248 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002791246587083738",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n248",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908149
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.99e-07
2024-11-20 18:01:20,575 - INFO - 
Starting training for config s6_n249:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:01:20,575 - INFO - Running command: ./train_gpt2cu -l 2.0333633897577573e-05 -o hyperband_runs_20241120_172038/run_s6_n249 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:01:30,379 - INFO - Training completed for config s6_n249:
  Training time: 0:00:09
  Final validation loss: 10.911360
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.90e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n249/checkpoint.bin
2024-11-20 18:01:30,380 - INFO - 
Configuration s6_n249 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.0333633897577573e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n249",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911360
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.90e-08
2024-11-20 18:01:30,380 - INFO - 
Starting training for config s6_n250:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:01:30,380 - INFO - Running command: ./train_gpt2cu -l 0.00011295133492098326 -o hyperband_runs_20241120_172038/run_s6_n250 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:01:40,179 - INFO - Training completed for config s6_n250:
  Training time: 0:00:09
  Final validation loss: 10.910205
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.61e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n250/checkpoint.bin
2024-11-20 18:01:40,179 - INFO - 
Configuration s6_n250 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00011295133492098326",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n250",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910205
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.61e-07
2024-11-20 18:01:40,179 - INFO - 
Starting training for config s6_n251:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:01:40,179 - INFO - Running command: ./train_gpt2cu -l 0.0005047992540023229 -o hyperband_runs_20241120_172038/run_s6_n251 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:01:50,011 - INFO - Training completed for config s6_n251:
  Training time: 0:00:09
  Final validation loss: 10.905413
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.21e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n251/checkpoint.bin
2024-11-20 18:01:50,011 - INFO - 
Configuration s6_n251 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005047992540023229",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n251",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905413
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.21e-07
2024-11-20 18:01:50,011 - INFO - 
Starting training for config s6_n252:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:01:50,011 - INFO - Running command: ./train_gpt2cu -l 0.0003746451981679478 -o hyperband_runs_20241120_172038/run_s6_n252 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:01:59,846 - INFO - Training completed for config s6_n252:
  Training time: 0:00:09
  Final validation loss: 10.906990
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.35e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n252/checkpoint.bin
2024-11-20 18:01:59,846 - INFO - 
Configuration s6_n252 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003746451981679478",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n252",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906990
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.35e-07
2024-11-20 18:01:59,847 - INFO - 
Starting training for config s6_n253:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:01:59,847 - INFO - Running command: ./train_gpt2cu -l 0.000257224019894055 -o hyperband_runs_20241120_172038/run_s6_n253 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:02:09,679 - INFO - Training completed for config s6_n253:
  Training time: 0:00:09
  Final validation loss: 10.908422
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.67e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n253/checkpoint.bin
2024-11-20 18:02:09,679 - INFO - 
Configuration s6_n253 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000257224019894055",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n253",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908422
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.67e-07
2024-11-20 18:02:09,679 - INFO - 
Starting training for config s6_n254:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:02:09,680 - INFO - Running command: ./train_gpt2cu -l 0.00020585578755583794 -o hyperband_runs_20241120_172038/run_s6_n254 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:02:19,483 - INFO - Training completed for config s6_n254:
  Training time: 0:00:09
  Final validation loss: 10.909075
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.94e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n254/checkpoint.bin
2024-11-20 18:02:19,483 - INFO - 
Configuration s6_n254 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00020585578755583794",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n254",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909075
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.94e-07
2024-11-20 18:02:19,483 - INFO - 
Starting training for config s6_n255:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:02:19,483 - INFO - Running command: ./train_gpt2cu -l 1.642328359780165e-05 -o hyperband_runs_20241120_172038/run_s6_n255 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:02:29,282 - INFO - Training completed for config s6_n255:
  Training time: 0:00:09
  Final validation loss: 10.911402
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.35e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n255/checkpoint.bin
2024-11-20 18:02:29,283 - INFO - 
Configuration s6_n255 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.642328359780165e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n255",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911402
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.35e-08
2024-11-20 18:02:29,283 - INFO - 
Starting training for config s6_n256:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:02:29,283 - INFO - Running command: ./train_gpt2cu -l 0.00012061573719408668 -o hyperband_runs_20241120_172038/run_s6_n256 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:02:39,087 - INFO - Training completed for config s6_n256:
  Training time: 0:00:09
  Final validation loss: 10.910110
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.72e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n256/checkpoint.bin
2024-11-20 18:02:39,088 - INFO - 
Configuration s6_n256 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012061573719408668",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n256",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910110
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.72e-07
2024-11-20 18:02:39,088 - INFO - 
Starting training for config s6_n257:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:02:39,088 - INFO - Running command: ./train_gpt2cu -l 0.00013780923161945755 -o hyperband_runs_20241120_172038/run_s6_n257 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:02:48,904 - INFO - Training completed for config s6_n257:
  Training time: 0:00:09
  Final validation loss: 10.909887
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.97e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n257/checkpoint.bin
2024-11-20 18:02:48,904 - INFO - 
Configuration s6_n257 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013780923161945755",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n257",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909887
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.97e-07
2024-11-20 18:02:48,904 - INFO - 
Starting training for config s6_n258:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:02:48,904 - INFO - Running command: ./train_gpt2cu -l 0.0003793336210096167 -o hyperband_runs_20241120_172038/run_s6_n258 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:02:58,707 - INFO - Training completed for config s6_n258:
  Training time: 0:00:09
  Final validation loss: 10.906926
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.42e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n258/checkpoint.bin
2024-11-20 18:02:58,708 - INFO - 
Configuration s6_n258 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003793336210096167",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n258",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906926
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.42e-07
2024-11-20 18:02:58,708 - INFO - 
Starting training for config s6_n259:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:02:58,708 - INFO - Running command: ./train_gpt2cu -l 0.0008249355759153884 -o hyperband_runs_20241120_172038/run_s6_n259 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:03:08,517 - INFO - Training completed for config s6_n259:
  Training time: 0:00:09
  Final validation loss: 10.901492
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.18e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n259/checkpoint.bin
2024-11-20 18:03:08,517 - INFO - 
Configuration s6_n259 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008249355759153884",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n259",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901492
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.18e-06
2024-11-20 18:03:08,517 - INFO - 
Starting training for config s6_n260:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:03:08,518 - INFO - Running command: ./train_gpt2cu -l 0.00018184673279312609 -o hyperband_runs_20241120_172038/run_s6_n260 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:03:18,328 - INFO - Training completed for config s6_n260:
  Training time: 0:00:09
  Final validation loss: 10.909348
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.60e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n260/checkpoint.bin
2024-11-20 18:03:18,328 - INFO - 
Configuration s6_n260 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00018184673279312609",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n260",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909348
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.60e-07
2024-11-20 18:03:18,328 - INFO - 
Starting training for config s6_n261:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:03:18,328 - INFO - Running command: ./train_gpt2cu -l 5.8414460246101965e-05 -o hyperband_runs_20241120_172038/run_s6_n261 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:03:28,151 - INFO - Training completed for config s6_n261:
  Training time: 0:00:09
  Final validation loss: 10.910877
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.34e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n261/checkpoint.bin
2024-11-20 18:03:28,151 - INFO - 
Configuration s6_n261 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.8414460246101965e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n261",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910877
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.34e-08
2024-11-20 18:03:28,151 - INFO - 
Starting training for config s6_n262:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:03:28,152 - INFO - Running command: ./train_gpt2cu -l 1.593842466329478e-05 -o hyperband_runs_20241120_172038/run_s6_n262 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:03:37,963 - INFO - Training completed for config s6_n262:
  Training time: 0:00:09
  Final validation loss: 10.911418
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.28e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n262/checkpoint.bin
2024-11-20 18:03:37,963 - INFO - 
Configuration s6_n262 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.593842466329478e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n262",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911418
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.28e-08
2024-11-20 18:03:37,963 - INFO - 
Starting training for config s6_n263:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:03:37,964 - INFO - Running command: ./train_gpt2cu -l 0.00013814863276786818 -o hyperband_runs_20241120_172038/run_s6_n263 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:03:47,771 - INFO - Training completed for config s6_n263:
  Training time: 0:00:09
  Final validation loss: 10.909883
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.97e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n263/checkpoint.bin
2024-11-20 18:03:47,771 - INFO - 
Configuration s6_n263 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013814863276786818",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n263",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909883
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.97e-07
2024-11-20 18:03:47,771 - INFO - 
Starting training for config s6_n264:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:03:47,772 - INFO - Running command: ./train_gpt2cu -l 0.0006773380521221634 -o hyperband_runs_20241120_172038/run_s6_n264 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:03:57,580 - INFO - Training completed for config s6_n264:
  Training time: 0:00:09
  Final validation loss: 10.903292
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.68e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n264/checkpoint.bin
2024-11-20 18:03:57,580 - INFO - 
Configuration s6_n264 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006773380521221634",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n264",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.903292
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.68e-07
2024-11-20 18:03:57,581 - INFO - 
Starting training for config s6_n265:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:03:57,581 - INFO - Running command: ./train_gpt2cu -l 1.3254399743640721e-05 -o hyperband_runs_20241120_172038/run_s6_n265 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:04:07,386 - INFO - Training completed for config s6_n265:
  Training time: 0:00:09
  Final validation loss: 10.911448
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.89e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n265/checkpoint.bin
2024-11-20 18:04:07,386 - INFO - 
Configuration s6_n265 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.3254399743640721e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n265",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911448
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.89e-08
2024-11-20 18:04:07,386 - INFO - 
Starting training for config s6_n266:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:04:07,387 - INFO - Running command: ./train_gpt2cu -l 0.0001656666311048172 -o hyperband_runs_20241120_172038/run_s6_n266 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:04:17,189 - INFO - Training completed for config s6_n266:
  Training time: 0:00:09
  Final validation loss: 10.909552
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.37e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n266/checkpoint.bin
2024-11-20 18:04:17,189 - INFO - 
Configuration s6_n266 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001656666311048172",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n266",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909552
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.37e-07
2024-11-20 18:04:17,189 - INFO - 
Starting training for config s6_n267:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:04:17,189 - INFO - Running command: ./train_gpt2cu -l 2.6797057658918036e-05 -o hyperband_runs_20241120_172038/run_s6_n267 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:04:27,025 - INFO - Training completed for config s6_n267:
  Training time: 0:00:09
  Final validation loss: 10.911282
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.83e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n267/checkpoint.bin
2024-11-20 18:04:27,025 - INFO - 
Configuration s6_n267 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.6797057658918036e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n267",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911282
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.83e-08
2024-11-20 18:04:27,025 - INFO - 
Starting training for config s6_n268:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:04:27,025 - INFO - Running command: ./train_gpt2cu -l 0.0003144900106004761 -o hyperband_runs_20241120_172038/run_s6_n268 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:04:36,829 - INFO - Training completed for config s6_n268:
  Training time: 0:00:09
  Final validation loss: 10.907723
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.49e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n268/checkpoint.bin
2024-11-20 18:04:36,829 - INFO - 
Configuration s6_n268 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003144900106004761",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n268",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907723
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.49e-07
2024-11-20 18:04:36,829 - INFO - 
Starting training for config s6_n269:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:04:36,829 - INFO - Running command: ./train_gpt2cu -l 0.00025857628608913144 -o hyperband_runs_20241120_172038/run_s6_n269 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:04:46,639 - INFO - Training completed for config s6_n269:
  Training time: 0:00:09
  Final validation loss: 10.908403
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.69e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n269/checkpoint.bin
2024-11-20 18:04:46,640 - INFO - 
Configuration s6_n269 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00025857628608913144",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n269",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908403
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.69e-07
2024-11-20 18:04:46,640 - INFO - 
Starting training for config s6_n270:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:04:46,640 - INFO - Running command: ./train_gpt2cu -l 2.66792708939051e-05 -o hyperband_runs_20241120_172038/run_s6_n270 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:04:56,445 - INFO - Training completed for config s6_n270:
  Training time: 0:00:09
  Final validation loss: 10.911277
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.81e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n270/checkpoint.bin
2024-11-20 18:04:56,445 - INFO - 
Configuration s6_n270 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.66792708939051e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n270",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911277
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.81e-08
2024-11-20 18:04:56,446 - INFO - 
Starting training for config s6_n271:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:04:56,446 - INFO - Running command: ./train_gpt2cu -l 3.5141442233451466e-05 -o hyperband_runs_20241120_172038/run_s6_n271 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:05:06,267 - INFO - Training completed for config s6_n271:
  Training time: 0:00:09
  Final validation loss: 10.911174
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.02e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n271/checkpoint.bin
2024-11-20 18:05:06,267 - INFO - 
Configuration s6_n271 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.5141442233451466e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n271",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911174
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.02e-08
2024-11-20 18:05:06,267 - INFO - 
Starting training for config s6_n272:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:05:06,267 - INFO - Running command: ./train_gpt2cu -l 1.3620025385974222e-05 -o hyperband_runs_20241120_172038/run_s6_n272 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:05:16,075 - INFO - Training completed for config s6_n272:
  Training time: 0:00:09
  Final validation loss: 10.911445
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.95e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n272/checkpoint.bin
2024-11-20 18:05:16,075 - INFO - 
Configuration s6_n272 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.3620025385974222e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n272",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911445
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.95e-08
2024-11-20 18:05:16,075 - INFO - 
Starting training for config s6_n273:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:05:16,075 - INFO - Running command: ./train_gpt2cu -l 0.00017228543978783085 -o hyperband_runs_20241120_172038/run_s6_n273 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:05:25,877 - INFO - Training completed for config s6_n273:
  Training time: 0:00:09
  Final validation loss: 10.909479
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.46e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n273/checkpoint.bin
2024-11-20 18:05:25,877 - INFO - 
Configuration s6_n273 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00017228543978783085",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n273",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909479
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.46e-07
2024-11-20 18:05:25,878 - INFO - 
Starting training for config s6_n274:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:05:25,878 - INFO - Running command: ./train_gpt2cu -l 1.8139352817405595e-05 -o hyperband_runs_20241120_172038/run_s6_n274 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:05:35,688 - INFO - Training completed for config s6_n274:
  Training time: 0:00:09
  Final validation loss: 10.911375
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.59e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n274/checkpoint.bin
2024-11-20 18:05:35,688 - INFO - 
Configuration s6_n274 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.8139352817405595e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n274",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911375
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.59e-08
2024-11-20 18:05:35,688 - INFO - 
Starting training for config s6_n275:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:05:35,689 - INFO - Running command: ./train_gpt2cu -l 4.890780271993338e-05 -o hyperband_runs_20241120_172038/run_s6_n275 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:05:45,493 - INFO - Training completed for config s6_n275:
  Training time: 0:00:09
  Final validation loss: 10.911003
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.99e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n275/checkpoint.bin
2024-11-20 18:05:45,493 - INFO - 
Configuration s6_n275 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.890780271993338e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n275",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911003
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.99e-08
2024-11-20 18:05:45,493 - INFO - 
Starting training for config s6_n276:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:05:45,493 - INFO - Running command: ./train_gpt2cu -l 3.325017075329177e-05 -o hyperband_runs_20241120_172038/run_s6_n276 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:05:55,308 - INFO - Training completed for config s6_n276:
  Training time: 0:00:09
  Final validation loss: 10.911215
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.75e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n276/checkpoint.bin
2024-11-20 18:05:55,309 - INFO - 
Configuration s6_n276 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.325017075329177e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n276",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911215
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.75e-08
2024-11-20 18:05:55,309 - INFO - 
Starting training for config s6_n277:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:05:55,309 - INFO - Running command: ./train_gpt2cu -l 2.582442679677964e-05 -o hyperband_runs_20241120_172038/run_s6_n277 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:06:05,119 - INFO - Training completed for config s6_n277:
  Training time: 0:00:09
  Final validation loss: 10.911291
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.69e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n277/checkpoint.bin
2024-11-20 18:06:05,119 - INFO - 
Configuration s6_n277 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.582442679677964e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n277",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911291
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.69e-08
2024-11-20 18:06:05,119 - INFO - 
Starting training for config s6_n278:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:06:05,119 - INFO - Running command: ./train_gpt2cu -l 1.3225880764182476e-05 -o hyperband_runs_20241120_172038/run_s6_n278 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:06:14,933 - INFO - Training completed for config s6_n278:
  Training time: 0:00:09
  Final validation loss: 10.911456
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.89e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n278/checkpoint.bin
2024-11-20 18:06:14,933 - INFO - 
Configuration s6_n278 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.3225880764182476e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n278",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911456
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.89e-08
2024-11-20 18:06:14,933 - INFO - 
Starting training for config s6_n279:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:06:14,933 - INFO - Running command: ./train_gpt2cu -l 1.7194542671403072e-05 -o hyperband_runs_20241120_172038/run_s6_n279 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:06:24,765 - INFO - Training completed for config s6_n279:
  Training time: 0:00:09
  Final validation loss: 10.911386
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.46e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n279/checkpoint.bin
2024-11-20 18:06:24,765 - INFO - 
Configuration s6_n279 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.7194542671403072e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n279",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911386
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.46e-08
2024-11-20 18:06:24,765 - INFO - 
Starting training for config s6_n280:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:06:24,766 - INFO - Running command: ./train_gpt2cu -l 0.0008339139310003893 -o hyperband_runs_20241120_172038/run_s6_n280 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:06:34,573 - INFO - Training completed for config s6_n280:
  Training time: 0:00:09
  Final validation loss: 10.901381
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.19e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n280/checkpoint.bin
2024-11-20 18:06:34,573 - INFO - 
Configuration s6_n280 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008339139310003893",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n280",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901381
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.19e-06
2024-11-20 18:06:34,573 - INFO - 
Starting training for config s6_n281:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:06:34,574 - INFO - Running command: ./train_gpt2cu -l 2.0310669590522464e-05 -o hyperband_runs_20241120_172038/run_s6_n281 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:06:44,383 - INFO - Training completed for config s6_n281:
  Training time: 0:00:09
  Final validation loss: 10.911356
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.90e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n281/checkpoint.bin
2024-11-20 18:06:44,383 - INFO - 
Configuration s6_n281 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.0310669590522464e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n281",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911356
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.90e-08
2024-11-20 18:06:44,383 - INFO - 
Starting training for config s6_n282:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:06:44,383 - INFO - Running command: ./train_gpt2cu -l 0.0006673066269854008 -o hyperband_runs_20241120_172038/run_s6_n282 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:06:54,189 - INFO - Training completed for config s6_n282:
  Training time: 0:00:09
  Final validation loss: 10.903420
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.53e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n282/checkpoint.bin
2024-11-20 18:06:54,190 - INFO - 
Configuration s6_n282 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006673066269854008",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n282",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.903420
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.53e-07
2024-11-20 18:06:54,190 - INFO - 
Starting training for config s6_n283:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:06:54,190 - INFO - Running command: ./train_gpt2cu -l 0.00012309633200987264 -o hyperband_runs_20241120_172038/run_s6_n283 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:07:04,022 - INFO - Training completed for config s6_n283:
  Training time: 0:00:09
  Final validation loss: 10.910074
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.76e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n283/checkpoint.bin
2024-11-20 18:07:04,022 - INFO - 
Configuration s6_n283 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012309633200987264",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n283",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910074
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.76e-07
2024-11-20 18:07:04,022 - INFO - 
Starting training for config s6_n284:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:07:04,022 - INFO - Running command: ./train_gpt2cu -l 4.4343434305139085e-05 -o hyperband_runs_20241120_172038/run_s6_n284 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:07:13,825 - INFO - Training completed for config s6_n284:
  Training time: 0:00:09
  Final validation loss: 10.911077
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.33e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n284/checkpoint.bin
2024-11-20 18:07:13,826 - INFO - 
Configuration s6_n284 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.4343434305139085e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n284",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911077
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.33e-08
2024-11-20 18:07:13,826 - INFO - 
Starting training for config s6_n285:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:07:13,826 - INFO - Running command: ./train_gpt2cu -l 3.656086002184975e-05 -o hyperband_runs_20241120_172038/run_s6_n285 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:07:23,634 - INFO - Training completed for config s6_n285:
  Training time: 0:00:09
  Final validation loss: 10.911163
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.22e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n285/checkpoint.bin
2024-11-20 18:07:23,634 - INFO - 
Configuration s6_n285 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.656086002184975e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n285",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911163
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.22e-08
2024-11-20 18:07:23,634 - INFO - 
Starting training for config s6_n286:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:07:23,634 - INFO - Running command: ./train_gpt2cu -l 2.1323094451138793e-05 -o hyperband_runs_20241120_172038/run_s6_n286 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:07:33,434 - INFO - Training completed for config s6_n286:
  Training time: 0:00:09
  Final validation loss: 10.911346
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.05e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n286/checkpoint.bin
2024-11-20 18:07:33,435 - INFO - 
Configuration s6_n286 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.1323094451138793e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n286",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911346
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.05e-08
2024-11-20 18:07:33,435 - INFO - 
Starting training for config s6_n287:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:07:33,435 - INFO - Running command: ./train_gpt2cu -l 3.381292189269361e-05 -o hyperband_runs_20241120_172038/run_s6_n287 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:07:43,241 - INFO - Training completed for config s6_n287:
  Training time: 0:00:09
  Final validation loss: 10.911194
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.83e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n287/checkpoint.bin
2024-11-20 18:07:43,241 - INFO - 
Configuration s6_n287 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.381292189269361e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n287",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911194
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.83e-08
2024-11-20 18:07:43,241 - INFO - 
Starting training for config s6_n288:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:07:43,241 - INFO - Running command: ./train_gpt2cu -l 0.00015135613867803223 -o hyperband_runs_20241120_172038/run_s6_n288 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:07:53,063 - INFO - Training completed for config s6_n288:
  Training time: 0:00:09
  Final validation loss: 10.909727
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.16e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n288/checkpoint.bin
2024-11-20 18:07:53,063 - INFO - 
Configuration s6_n288 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00015135613867803223",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n288",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909727
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.16e-07
2024-11-20 18:07:53,063 - INFO - 
Starting training for config s6_n289:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:07:53,063 - INFO - Running command: ./train_gpt2cu -l 1.5880789872111386e-05 -o hyperband_runs_20241120_172038/run_s6_n289 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:08:02,876 - INFO - Training completed for config s6_n289:
  Training time: 0:00:09
  Final validation loss: 10.911402
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.27e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n289/checkpoint.bin
2024-11-20 18:08:02,876 - INFO - 
Configuration s6_n289 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.5880789872111386e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n289",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911402
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.27e-08
2024-11-20 18:08:02,876 - INFO - 
Starting training for config s6_n290:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:08:02,876 - INFO - Running command: ./train_gpt2cu -l 2.326708076309775e-05 -o hyperband_runs_20241120_172038/run_s6_n290 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:08:12,683 - INFO - Training completed for config s6_n290:
  Training time: 0:00:09
  Final validation loss: 10.911324
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.32e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n290/checkpoint.bin
2024-11-20 18:08:12,683 - INFO - 
Configuration s6_n290 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.326708076309775e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n290",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911324
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.32e-08
2024-11-20 18:08:12,683 - INFO - 
Starting training for config s6_n291:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:08:12,683 - INFO - Running command: ./train_gpt2cu -l 0.0006021443487263004 -o hyperband_runs_20241120_172038/run_s6_n291 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:08:22,509 - INFO - Training completed for config s6_n291:
  Training time: 0:00:09
  Final validation loss: 10.904208
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.60e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n291/checkpoint.bin
2024-11-20 18:08:22,510 - INFO - 
Configuration s6_n291 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006021443487263004",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n291",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904208
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.60e-07
2024-11-20 18:08:22,510 - INFO - 
Starting training for config s6_n292:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:08:22,510 - INFO - Running command: ./train_gpt2cu -l 0.0004787631009411304 -o hyperband_runs_20241120_172038/run_s6_n292 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:08:32,336 - INFO - Training completed for config s6_n292:
  Training time: 0:00:09
  Final validation loss: 10.905725
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.84e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n292/checkpoint.bin
2024-11-20 18:08:32,337 - INFO - 
Configuration s6_n292 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004787631009411304",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n292",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905725
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.84e-07
2024-11-20 18:08:32,337 - INFO - 
Starting training for config s6_n293:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:08:32,337 - INFO - Running command: ./train_gpt2cu -l 6.932114093854187e-05 -o hyperband_runs_20241120_172038/run_s6_n293 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:08:42,151 - INFO - Training completed for config s6_n293:
  Training time: 0:00:09
  Final validation loss: 10.910749
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.90e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n293/checkpoint.bin
2024-11-20 18:08:42,151 - INFO - 
Configuration s6_n293 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.932114093854187e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n293",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910749
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.90e-08
2024-11-20 18:08:42,151 - INFO - 
Starting training for config s6_n294:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:08:42,151 - INFO - Running command: ./train_gpt2cu -l 4.716482145092529e-05 -o hyperband_runs_20241120_172038/run_s6_n294 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:08:51,957 - INFO - Training completed for config s6_n294:
  Training time: 0:00:09
  Final validation loss: 10.911024
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.74e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n294/checkpoint.bin
2024-11-20 18:08:51,957 - INFO - 
Configuration s6_n294 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.716482145092529e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n294",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911024
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.74e-08
2024-11-20 18:08:51,957 - INFO - 
Starting training for config s6_n295:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:08:51,957 - INFO - Running command: ./train_gpt2cu -l 3.6431515770694035e-05 -o hyperband_runs_20241120_172038/run_s6_n295 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:09:01,768 - INFO - Training completed for config s6_n295:
  Training time: 0:00:09
  Final validation loss: 10.911169
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.20e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n295/checkpoint.bin
2024-11-20 18:09:01,768 - INFO - 
Configuration s6_n295 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.6431515770694035e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n295",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911169
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.20e-08
2024-11-20 18:09:01,768 - INFO - 
Starting training for config s6_n296:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:09:01,769 - INFO - Running command: ./train_gpt2cu -l 4.735642265355857e-05 -o hyperband_runs_20241120_172038/run_s6_n296 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:09:11,584 - INFO - Training completed for config s6_n296:
  Training time: 0:00:09
  Final validation loss: 10.911026
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.77e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n296/checkpoint.bin
2024-11-20 18:09:11,585 - INFO - 
Configuration s6_n296 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.735642265355857e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n296",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911026
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.77e-08
2024-11-20 18:09:11,585 - INFO - 
Starting training for config s6_n297:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:09:11,585 - INFO - Running command: ./train_gpt2cu -l 1.22949268509678e-05 -o hyperband_runs_20241120_172038/run_s6_n297 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:09:21,393 - INFO - Training completed for config s6_n297:
  Training time: 0:00:09
  Final validation loss: 10.911451
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.76e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n297/checkpoint.bin
2024-11-20 18:09:21,393 - INFO - 
Configuration s6_n297 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.22949268509678e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n297",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911451
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.76e-08
2024-11-20 18:09:21,393 - INFO - 
Starting training for config s6_n298:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:09:21,393 - INFO - Running command: ./train_gpt2cu -l 0.00013253597959595362 -o hyperband_runs_20241120_172038/run_s6_n298 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:09:31,199 - INFO - Training completed for config s6_n298:
  Training time: 0:00:09
  Final validation loss: 10.909972
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.89e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n298/checkpoint.bin
2024-11-20 18:09:31,199 - INFO - 
Configuration s6_n298 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013253597959595362",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n298",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909972
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.89e-07
2024-11-20 18:09:31,199 - INFO - 
Starting training for config s6_n299:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:09:31,199 - INFO - Running command: ./train_gpt2cu -l 8.33816660021095e-05 -o hyperband_runs_20241120_172038/run_s6_n299 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:09:41,009 - INFO - Training completed for config s6_n299:
  Training time: 0:00:09
  Final validation loss: 10.910578
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.19e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n299/checkpoint.bin
2024-11-20 18:09:41,010 - INFO - 
Configuration s6_n299 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "8.33816660021095e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n299",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910578
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.19e-07
2024-11-20 18:09:41,010 - INFO - 
Starting training for config s6_n300:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:09:41,010 - INFO - Running command: ./train_gpt2cu -l 2.5251779858327837e-05 -o hyperband_runs_20241120_172038/run_s6_n300 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:09:50,858 - INFO - Training completed for config s6_n300:
  Training time: 0:00:09
  Final validation loss: 10.911320
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.61e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n300/checkpoint.bin
2024-11-20 18:09:50,858 - INFO - 
Configuration s6_n300 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.5251779858327837e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n300",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911320
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.61e-08
2024-11-20 18:09:50,859 - INFO - 
Starting training for config s6_n301:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:09:50,859 - INFO - Running command: ./train_gpt2cu -l 6.747625339199909e-05 -o hyperband_runs_20241120_172038/run_s6_n301 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:10:00,666 - INFO - Training completed for config s6_n301:
  Training time: 0:00:09
  Final validation loss: 10.910769
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.64e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n301/checkpoint.bin
2024-11-20 18:10:00,666 - INFO - 
Configuration s6_n301 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.747625339199909e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n301",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910769
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.64e-08
2024-11-20 18:10:00,666 - INFO - 
Starting training for config s6_n302:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:10:00,667 - INFO - Running command: ./train_gpt2cu -l 0.0002480162625220691 -o hyperband_runs_20241120_172038/run_s6_n302 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:10:10,467 - INFO - Training completed for config s6_n302:
  Training time: 0:00:09
  Final validation loss: 10.908538
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.54e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n302/checkpoint.bin
2024-11-20 18:10:10,467 - INFO - 
Configuration s6_n302 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002480162625220691",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n302",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908538
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.54e-07
2024-11-20 18:10:10,467 - INFO - 
Starting training for config s6_n303:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:10:10,468 - INFO - Running command: ./train_gpt2cu -l 2.8466227726949434e-05 -o hyperband_runs_20241120_172038/run_s6_n303 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:10:20,275 - INFO - Training completed for config s6_n303:
  Training time: 0:00:09
  Final validation loss: 10.911263
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.07e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n303/checkpoint.bin
2024-11-20 18:10:20,275 - INFO - 
Configuration s6_n303 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.8466227726949434e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n303",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911263
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.07e-08
2024-11-20 18:10:20,276 - INFO - 
Starting training for config s6_n304:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:10:20,276 - INFO - Running command: ./train_gpt2cu -l 0.0004147521867486207 -o hyperband_runs_20241120_172038/run_s6_n304 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:10:30,082 - INFO - Training completed for config s6_n304:
  Training time: 0:00:09
  Final validation loss: 10.906485
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.93e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n304/checkpoint.bin
2024-11-20 18:10:30,083 - INFO - 
Configuration s6_n304 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004147521867486207",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n304",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906485
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.93e-07
2024-11-20 18:10:30,083 - INFO - 
Starting training for config s6_n305:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:10:30,083 - INFO - Running command: ./train_gpt2cu -l 2.3142115306207365e-05 -o hyperband_runs_20241120_172038/run_s6_n305 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:10:39,889 - INFO - Training completed for config s6_n305:
  Training time: 0:00:09
  Final validation loss: 10.911325
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.31e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n305/checkpoint.bin
2024-11-20 18:10:39,889 - INFO - 
Configuration s6_n305 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.3142115306207365e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n305",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911325
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.31e-08
2024-11-20 18:10:39,889 - INFO - 
Starting training for config s6_n306:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:10:39,889 - INFO - Running command: ./train_gpt2cu -l 0.0008099582756449049 -o hyperband_runs_20241120_172038/run_s6_n306 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:10:49,691 - INFO - Training completed for config s6_n306:
  Training time: 0:00:09
  Final validation loss: 10.901678
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.16e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n306/checkpoint.bin
2024-11-20 18:10:49,692 - INFO - 
Configuration s6_n306 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008099582756449049",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n306",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901678
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.16e-06
2024-11-20 18:10:49,692 - INFO - 
Starting training for config s6_n307:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:10:49,692 - INFO - Running command: ./train_gpt2cu -l 0.00015754130641696678 -o hyperband_runs_20241120_172038/run_s6_n307 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:10:59,504 - INFO - Training completed for config s6_n307:
  Training time: 0:00:09
  Final validation loss: 10.909648
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.25e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n307/checkpoint.bin
2024-11-20 18:10:59,504 - INFO - 
Configuration s6_n307 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00015754130641696678",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n307",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909648
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.25e-07
2024-11-20 18:10:59,504 - INFO - 
Starting training for config s6_n308:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:10:59,504 - INFO - Running command: ./train_gpt2cu -l 9.556900287713254e-05 -o hyperband_runs_20241120_172038/run_s6_n308 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:11:09,319 - INFO - Training completed for config s6_n308:
  Training time: 0:00:09
  Final validation loss: 10.910414
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.37e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n308/checkpoint.bin
2024-11-20 18:11:09,319 - INFO - 
Configuration s6_n308 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "9.556900287713254e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n308",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910414
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.37e-07
2024-11-20 18:11:09,319 - INFO - 
Starting training for config s6_n309:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:11:09,319 - INFO - Running command: ./train_gpt2cu -l 0.000830841442264205 -o hyperband_runs_20241120_172038/run_s6_n309 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:11:19,137 - INFO - Training completed for config s6_n309:
  Training time: 0:00:09
  Final validation loss: 10.901416
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.19e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n309/checkpoint.bin
2024-11-20 18:11:19,137 - INFO - 
Configuration s6_n309 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000830841442264205",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n309",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901416
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.19e-06
2024-11-20 18:11:19,137 - INFO - 
Starting training for config s6_n310:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:11:19,137 - INFO - Running command: ./train_gpt2cu -l 0.00027552934665632577 -o hyperband_runs_20241120_172038/run_s6_n310 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:11:28,933 - INFO - Training completed for config s6_n310:
  Training time: 0:00:09
  Final validation loss: 10.908200
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.94e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n310/checkpoint.bin
2024-11-20 18:11:28,933 - INFO - 
Configuration s6_n310 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00027552934665632577",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n310",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908200
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.94e-07
2024-11-20 18:11:28,933 - INFO - 
Starting training for config s6_n311:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:11:28,934 - INFO - Running command: ./train_gpt2cu -l 4.3795535972971344e-05 -o hyperband_runs_20241120_172038/run_s6_n311 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:11:38,766 - INFO - Training completed for config s6_n311:
  Training time: 0:00:09
  Final validation loss: 10.911080
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.26e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n311/checkpoint.bin
2024-11-20 18:11:38,766 - INFO - 
Configuration s6_n311 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.3795535972971344e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n311",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911080
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.26e-08
2024-11-20 18:11:38,766 - INFO - 
Starting training for config s6_n312:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:11:38,766 - INFO - Running command: ./train_gpt2cu -l 0.00028043710204923974 -o hyperband_runs_20241120_172038/run_s6_n312 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:11:48,578 - INFO - Training completed for config s6_n312:
  Training time: 0:00:09
  Final validation loss: 10.908127
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.01e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n312/checkpoint.bin
2024-11-20 18:11:48,578 - INFO - 
Configuration s6_n312 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00028043710204923974",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n312",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908127
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.01e-07
2024-11-20 18:11:48,578 - INFO - 
Starting training for config s6_n313:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:11:48,578 - INFO - Running command: ./train_gpt2cu -l 0.0008309356853545224 -o hyperband_runs_20241120_172038/run_s6_n313 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:11:58,394 - INFO - Training completed for config s6_n313:
  Training time: 0:00:09
  Final validation loss: 10.901423
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.19e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n313/checkpoint.bin
2024-11-20 18:11:58,395 - INFO - 
Configuration s6_n313 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008309356853545224",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n313",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901423
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.19e-06
2024-11-20 18:11:58,395 - INFO - 
Starting training for config s6_n314:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:11:58,395 - INFO - Running command: ./train_gpt2cu -l 0.00016908552434308932 -o hyperband_runs_20241120_172038/run_s6_n314 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:12:08,197 - INFO - Training completed for config s6_n314:
  Training time: 0:00:09
  Final validation loss: 10.909521
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.42e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n314/checkpoint.bin
2024-11-20 18:12:08,197 - INFO - 
Configuration s6_n314 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00016908552434308932",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n314",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909521
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.42e-07
2024-11-20 18:12:08,197 - INFO - 
Starting training for config s6_n315:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:12:08,198 - INFO - Running command: ./train_gpt2cu -l 4.714174687171792e-05 -o hyperband_runs_20241120_172038/run_s6_n315 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:12:18,002 - INFO - Training completed for config s6_n315:
  Training time: 0:00:09
  Final validation loss: 10.911043
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.73e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n315/checkpoint.bin
2024-11-20 18:12:18,002 - INFO - 
Configuration s6_n315 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.714174687171792e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n315",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911043
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.73e-08
2024-11-20 18:12:18,002 - INFO - 
Starting training for config s6_n316:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:12:18,003 - INFO - Running command: ./train_gpt2cu -l 0.00017423196170869958 -o hyperband_runs_20241120_172038/run_s6_n316 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:12:27,799 - INFO - Training completed for config s6_n316:
  Training time: 0:00:09
  Final validation loss: 10.909451
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.49e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n316/checkpoint.bin
2024-11-20 18:12:27,799 - INFO - 
Configuration s6_n316 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00017423196170869958",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n316",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909451
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.49e-07
2024-11-20 18:12:27,799 - INFO - 
Starting training for config s6_n317:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:12:27,800 - INFO - Running command: ./train_gpt2cu -l 2.2814056747773773e-05 -o hyperband_runs_20241120_172038/run_s6_n317 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:12:37,603 - INFO - Training completed for config s6_n317:
  Training time: 0:00:09
  Final validation loss: 10.911337
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.26e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n317/checkpoint.bin
2024-11-20 18:12:37,603 - INFO - 
Configuration s6_n317 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.2814056747773773e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n317",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911337
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.26e-08
2024-11-20 18:12:37,603 - INFO - 
Starting training for config s6_n318:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:12:37,603 - INFO - Running command: ./train_gpt2cu -l 7.773188218027952e-05 -o hyperband_runs_20241120_172038/run_s6_n318 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:12:47,402 - INFO - Training completed for config s6_n318:
  Training time: 0:00:09
  Final validation loss: 10.910647
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.11e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n318/checkpoint.bin
2024-11-20 18:12:47,403 - INFO - 
Configuration s6_n318 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.773188218027952e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n318",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910647
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.11e-07
2024-11-20 18:12:47,403 - INFO - 
Starting training for config s6_n319:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:12:47,403 - INFO - Running command: ./train_gpt2cu -l 0.00012024972963015373 -o hyperband_runs_20241120_172038/run_s6_n319 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:12:57,205 - INFO - Training completed for config s6_n319:
  Training time: 0:00:09
  Final validation loss: 10.910111
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.72e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n319/checkpoint.bin
2024-11-20 18:12:57,205 - INFO - 
Configuration s6_n319 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012024972963015373",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n319",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910111
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.72e-07
2024-11-20 18:12:57,205 - INFO - 
Starting training for config s6_n320:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:12:57,205 - INFO - Running command: ./train_gpt2cu -l 0.0001295997850488686 -o hyperband_runs_20241120_172038/run_s6_n320 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:13:07,018 - INFO - Training completed for config s6_n320:
  Training time: 0:00:09
  Final validation loss: 10.909986
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.85e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n320/checkpoint.bin
2024-11-20 18:13:07,018 - INFO - 
Configuration s6_n320 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001295997850488686",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n320",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909986
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.85e-07
2024-11-20 18:13:07,018 - INFO - 
Starting training for config s6_n321:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:13:07,018 - INFO - Running command: ./train_gpt2cu -l 2.687894819566958e-05 -o hyperband_runs_20241120_172038/run_s6_n321 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:13:16,833 - INFO - Training completed for config s6_n321:
  Training time: 0:00:09
  Final validation loss: 10.911276
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.84e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n321/checkpoint.bin
2024-11-20 18:13:16,834 - INFO - 
Configuration s6_n321 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.687894819566958e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n321",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911276
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.84e-08
2024-11-20 18:13:16,834 - INFO - 
Starting training for config s6_n322:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:13:16,834 - INFO - Running command: ./train_gpt2cu -l 0.0007535574287081613 -o hyperband_runs_20241120_172038/run_s6_n322 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:13:26,633 - INFO - Training completed for config s6_n322:
  Training time: 0:00:09
  Final validation loss: 10.902366
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.08e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n322/checkpoint.bin
2024-11-20 18:13:26,633 - INFO - 
Configuration s6_n322 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007535574287081613",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n322",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.902366
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.08e-06
2024-11-20 18:13:26,633 - INFO - 
Starting training for config s6_n323:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:13:26,633 - INFO - Running command: ./train_gpt2cu -l 5.287753704466903e-05 -o hyperband_runs_20241120_172038/run_s6_n323 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:13:36,428 - INFO - Training completed for config s6_n323:
  Training time: 0:00:09
  Final validation loss: 10.910959
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.55e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n323/checkpoint.bin
2024-11-20 18:13:36,428 - INFO - 
Configuration s6_n323 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.287753704466903e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n323",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910959
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.55e-08
2024-11-20 18:13:36,428 - INFO - 
Starting training for config s6_n324:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:13:36,428 - INFO - Running command: ./train_gpt2cu -l 1.1318319292832815e-05 -o hyperband_runs_20241120_172038/run_s6_n324 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:13:46,228 - INFO - Training completed for config s6_n324:
  Training time: 0:00:09
  Final validation loss: 10.911464
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.62e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n324/checkpoint.bin
2024-11-20 18:13:46,229 - INFO - 
Configuration s6_n324 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.1318319292832815e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n324",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911464
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.62e-08
2024-11-20 18:13:46,229 - INFO - 
Starting training for config s6_n325:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:13:46,229 - INFO - Running command: ./train_gpt2cu -l 0.0007107889545943217 -o hyperband_runs_20241120_172038/run_s6_n325 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:13:56,032 - INFO - Training completed for config s6_n325:
  Training time: 0:00:09
  Final validation loss: 10.902885
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.02e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n325/checkpoint.bin
2024-11-20 18:13:56,032 - INFO - 
Configuration s6_n325 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007107889545943217",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n325",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.902885
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-06
2024-11-20 18:13:56,032 - INFO - 
Starting training for config s6_n326:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:13:56,032 - INFO - Running command: ./train_gpt2cu -l 2.100841716300735e-05 -o hyperband_runs_20241120_172038/run_s6_n326 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:14:05,819 - INFO - Training completed for config s6_n326:
  Training time: 0:00:09
  Final validation loss: 10.911352
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.00e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n326/checkpoint.bin
2024-11-20 18:14:05,819 - INFO - 
Configuration s6_n326 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.100841716300735e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n326",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911352
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.00e-08
2024-11-20 18:14:05,820 - INFO - 
Starting training for config s6_n327:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:14:05,820 - INFO - Running command: ./train_gpt2cu -l 3.3137725202803053e-05 -o hyperband_runs_20241120_172038/run_s6_n327 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:14:15,638 - INFO - Training completed for config s6_n327:
  Training time: 0:00:09
  Final validation loss: 10.911211
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.73e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n327/checkpoint.bin
2024-11-20 18:14:15,638 - INFO - 
Configuration s6_n327 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.3137725202803053e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n327",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911211
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.73e-08
2024-11-20 18:14:15,638 - INFO - 
Starting training for config s6_n328:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:14:15,638 - INFO - Running command: ./train_gpt2cu -l 0.0001378333156062569 -o hyperband_runs_20241120_172038/run_s6_n328 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:14:25,441 - INFO - Training completed for config s6_n328:
  Training time: 0:00:09
  Final validation loss: 10.909886
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.97e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n328/checkpoint.bin
2024-11-20 18:14:25,441 - INFO - 
Configuration s6_n328 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001378333156062569",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n328",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909886
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.97e-07
2024-11-20 18:14:25,441 - INFO - 
Starting training for config s6_n329:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:14:25,441 - INFO - Running command: ./train_gpt2cu -l 1.6113551567265714e-05 -o hyperband_runs_20241120_172038/run_s6_n329 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:14:35,248 - INFO - Training completed for config s6_n329:
  Training time: 0:00:09
  Final validation loss: 10.911406
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.30e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n329/checkpoint.bin
2024-11-20 18:14:35,249 - INFO - 
Configuration s6_n329 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.6113551567265714e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n329",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911406
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.30e-08
2024-11-20 18:14:35,249 - INFO - 
Starting training for config s6_n330:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:14:35,250 - INFO - Running command: ./train_gpt2cu -l 0.00012440003373262492 -o hyperband_runs_20241120_172038/run_s6_n330 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:14:45,044 - INFO - Training completed for config s6_n330:
  Training time: 0:00:09
  Final validation loss: 10.910056
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.78e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n330/checkpoint.bin
2024-11-20 18:14:45,044 - INFO - 
Configuration s6_n330 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012440003373262492",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n330",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910056
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.78e-07
2024-11-20 18:14:45,044 - INFO - 
Starting training for config s6_n331:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:14:45,044 - INFO - Running command: ./train_gpt2cu -l 3.058504690053608e-05 -o hyperband_runs_20241120_172038/run_s6_n331 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:14:54,863 - INFO - Training completed for config s6_n331:
  Training time: 0:00:09
  Final validation loss: 10.911230
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.37e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n331/checkpoint.bin
2024-11-20 18:14:54,863 - INFO - 
Configuration s6_n331 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.058504690053608e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n331",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911230
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.37e-08
2024-11-20 18:14:54,864 - INFO - 
Starting training for config s6_n332:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:14:54,864 - INFO - Running command: ./train_gpt2cu -l 3.731855807400815e-05 -o hyperband_runs_20241120_172038/run_s6_n332 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:15:04,681 - INFO - Training completed for config s6_n332:
  Training time: 0:00:09
  Final validation loss: 10.911150
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.33e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n332/checkpoint.bin
2024-11-20 18:15:04,682 - INFO - 
Configuration s6_n332 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.731855807400815e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n332",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911150
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.33e-08
2024-11-20 18:15:04,682 - INFO - 
Starting training for config s6_n333:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:15:04,682 - INFO - Running command: ./train_gpt2cu -l 0.00090492595944296 -o hyperband_runs_20241120_172038/run_s6_n333 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:15:14,478 - INFO - Training completed for config s6_n333:
  Training time: 0:00:09
  Final validation loss: 10.900523
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.29e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n333/checkpoint.bin
2024-11-20 18:15:14,478 - INFO - 
Configuration s6_n333 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00090492595944296",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n333",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.900523
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.29e-06
2024-11-20 18:15:14,478 - INFO - 
Starting training for config s6_n334:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:15:14,478 - INFO - Running command: ./train_gpt2cu -l 0.00097968892904061 -o hyperband_runs_20241120_172038/run_s6_n334 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:15:24,284 - INFO - Training completed for config s6_n334:
  Training time: 0:00:09
  Final validation loss: 10.899619
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.40e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin
2024-11-20 18:15:24,285 - INFO - 
Configuration s6_n334 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00097968892904061",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n334",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.899619
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.40e-06
2024-11-20 18:15:24,285 - INFO - 
Starting training for config s6_n335:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:15:24,285 - INFO - Running command: ./train_gpt2cu -l 0.000246997336923326 -o hyperband_runs_20241120_172038/run_s6_n335 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:15:34,096 - INFO - Training completed for config s6_n335:
  Training time: 0:00:09
  Final validation loss: 10.908552
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.53e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n335/checkpoint.bin
2024-11-20 18:15:34,096 - INFO - 
Configuration s6_n335 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000246997336923326",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n335",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908552
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.53e-07
2024-11-20 18:15:34,096 - INFO - 
Starting training for config s6_n336:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:15:34,097 - INFO - Running command: ./train_gpt2cu -l 1.0459636021809759e-05 -o hyperband_runs_20241120_172038/run_s6_n336 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:15:43,914 - INFO - Training completed for config s6_n336:
  Training time: 0:00:09
  Final validation loss: 10.911471
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.49e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n336/checkpoint.bin
2024-11-20 18:15:43,914 - INFO - 
Configuration s6_n336 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.0459636021809759e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n336",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911471
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.49e-08
2024-11-20 18:15:43,914 - INFO - 
Starting training for config s6_n337:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:15:43,914 - INFO - Running command: ./train_gpt2cu -l 6.509873339272869e-05 -o hyperband_runs_20241120_172038/run_s6_n337 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:15:53,723 - INFO - Training completed for config s6_n337:
  Training time: 0:00:09
  Final validation loss: 10.910789
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.30e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n337/checkpoint.bin
2024-11-20 18:15:53,723 - INFO - 
Configuration s6_n337 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.509873339272869e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n337",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910789
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.30e-08
2024-11-20 18:15:53,723 - INFO - 
Starting training for config s6_n338:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:15:53,723 - INFO - Running command: ./train_gpt2cu -l 0.0008157981726792546 -o hyperband_runs_20241120_172038/run_s6_n338 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:16:03,529 - INFO - Training completed for config s6_n338:
  Training time: 0:00:09
  Final validation loss: 10.901600
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.17e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n338/checkpoint.bin
2024-11-20 18:16:03,529 - INFO - 
Configuration s6_n338 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008157981726792546",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n338",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901600
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.17e-06
2024-11-20 18:16:03,529 - INFO - 
Starting training for config s6_n339:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:16:03,529 - INFO - Running command: ./train_gpt2cu -l 0.0008881775390564398 -o hyperband_runs_20241120_172038/run_s6_n339 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:16:13,336 - INFO - Training completed for config s6_n339:
  Training time: 0:00:09
  Final validation loss: 10.900720
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.27e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n339/checkpoint.bin
2024-11-20 18:16:13,336 - INFO - 
Configuration s6_n339 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008881775390564398",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n339",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.900720
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.27e-06
2024-11-20 18:16:13,336 - INFO - 
Starting training for config s6_n340:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:16:13,336 - INFO - Running command: ./train_gpt2cu -l 1.5343323290330005e-05 -o hyperband_runs_20241120_172038/run_s6_n340 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:16:23,150 - INFO - Training completed for config s6_n340:
  Training time: 0:00:09
  Final validation loss: 10.911409
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.19e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n340/checkpoint.bin
2024-11-20 18:16:23,150 - INFO - 
Configuration s6_n340 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.5343323290330005e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n340",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911409
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.19e-08
2024-11-20 18:16:23,150 - INFO - 
Starting training for config s6_n341:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:16:23,150 - INFO - Running command: ./train_gpt2cu -l 0.00051494867892522 -o hyperband_runs_20241120_172038/run_s6_n341 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:16:32,964 - INFO - Training completed for config s6_n341:
  Training time: 0:00:09
  Final validation loss: 10.905282
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.36e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n341/checkpoint.bin
2024-11-20 18:16:32,964 - INFO - 
Configuration s6_n341 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00051494867892522",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n341",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905282
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.36e-07
2024-11-20 18:16:32,964 - INFO - 
Starting training for config s6_n342:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:16:32,964 - INFO - Running command: ./train_gpt2cu -l 4.37418963737997e-05 -o hyperband_runs_20241120_172038/run_s6_n342 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:16:42,765 - INFO - Training completed for config s6_n342:
  Training time: 0:00:09
  Final validation loss: 10.911075
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.25e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n342/checkpoint.bin
2024-11-20 18:16:42,765 - INFO - 
Configuration s6_n342 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.37418963737997e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n342",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911075
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.25e-08
2024-11-20 18:16:42,765 - INFO - 
Starting training for config s6_n343:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:16:42,765 - INFO - Running command: ./train_gpt2cu -l 0.0008029478952801089 -o hyperband_runs_20241120_172038/run_s6_n343 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:16:52,596 - INFO - Training completed for config s6_n343:
  Training time: 0:00:09
  Final validation loss: 10.901754
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.15e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n343/checkpoint.bin
2024-11-20 18:16:52,596 - INFO - 
Configuration s6_n343 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008029478952801089",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n343",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901754
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.15e-06
2024-11-20 18:16:52,596 - INFO - 
Starting training for config s6_n344:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:16:52,596 - INFO - Running command: ./train_gpt2cu -l 0.0003322864821178662 -o hyperband_runs_20241120_172038/run_s6_n344 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:17:02,422 - INFO - Training completed for config s6_n344:
  Training time: 0:00:09
  Final validation loss: 10.907499
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.75e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n344/checkpoint.bin
2024-11-20 18:17:02,423 - INFO - 
Configuration s6_n344 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003322864821178662",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n344",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907499
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.75e-07
2024-11-20 18:17:02,423 - INFO - 
Starting training for config s6_n345:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:17:02,423 - INFO - Running command: ./train_gpt2cu -l 1.15157164754941e-05 -o hyperband_runs_20241120_172038/run_s6_n345 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:17:12,242 - INFO - Training completed for config s6_n345:
  Training time: 0:00:09
  Final validation loss: 10.911467
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.65e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n345/checkpoint.bin
2024-11-20 18:17:12,242 - INFO - 
Configuration s6_n345 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.15157164754941e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n345",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911467
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.65e-08
2024-11-20 18:17:12,243 - INFO - 
Starting training for config s6_n346:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:17:12,243 - INFO - Running command: ./train_gpt2cu -l 0.0002670741282487934 -o hyperband_runs_20241120_172038/run_s6_n346 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:17:22,041 - INFO - Training completed for config s6_n346:
  Training time: 0:00:09
  Final validation loss: 10.908300
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.82e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n346/checkpoint.bin
2024-11-20 18:17:22,041 - INFO - 
Configuration s6_n346 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002670741282487934",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n346",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908300
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.82e-07
2024-11-20 18:17:22,041 - INFO - 
Starting training for config s6_n347:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:17:22,042 - INFO - Running command: ./train_gpt2cu -l 0.0001367156231897865 -o hyperband_runs_20241120_172038/run_s6_n347 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:17:31,847 - INFO - Training completed for config s6_n347:
  Training time: 0:00:09
  Final validation loss: 10.909904
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.95e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n347/checkpoint.bin
2024-11-20 18:17:31,848 - INFO - 
Configuration s6_n347 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001367156231897865",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n347",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909904
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.95e-07
2024-11-20 18:17:31,848 - INFO - 
Starting training for config s6_n348:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:17:31,848 - INFO - Running command: ./train_gpt2cu -l 3.1919328938179724e-05 -o hyperband_runs_20241120_172038/run_s6_n348 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:17:41,674 - INFO - Training completed for config s6_n348:
  Training time: 0:00:09
  Final validation loss: 10.911220
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.56e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n348/checkpoint.bin
2024-11-20 18:17:41,675 - INFO - 
Configuration s6_n348 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.1919328938179724e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n348",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911220
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.56e-08
2024-11-20 18:17:41,675 - INFO - 
Starting training for config s6_n349:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:17:41,675 - INFO - Running command: ./train_gpt2cu -l 0.000290227094127973 -o hyperband_runs_20241120_172038/run_s6_n349 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:17:51,495 - INFO - Training completed for config s6_n349:
  Training time: 0:00:09
  Final validation loss: 10.908013
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.15e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n349/checkpoint.bin
2024-11-20 18:17:51,495 - INFO - 
Configuration s6_n349 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000290227094127973",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n349",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908013
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.15e-07
2024-11-20 18:17:51,495 - INFO - 
Starting training for config s6_n350:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:17:51,495 - INFO - Running command: ./train_gpt2cu -l 4.588887630803111e-05 -o hyperband_runs_20241120_172038/run_s6_n350 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:18:01,288 - INFO - Training completed for config s6_n350:
  Training time: 0:00:09
  Final validation loss: 10.911043
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.56e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n350/checkpoint.bin
2024-11-20 18:18:01,288 - INFO - 
Configuration s6_n350 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.588887630803111e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n350",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911043
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.56e-08
2024-11-20 18:18:01,288 - INFO - 
Starting training for config s6_n351:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:18:01,288 - INFO - Running command: ./train_gpt2cu -l 0.00014314562198967294 -o hyperband_runs_20241120_172038/run_s6_n351 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:18:11,102 - INFO - Training completed for config s6_n351:
  Training time: 0:00:09
  Final validation loss: 10.909822
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.04e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n351/checkpoint.bin
2024-11-20 18:18:11,102 - INFO - 
Configuration s6_n351 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014314562198967294",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n351",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909822
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.04e-07
2024-11-20 18:18:11,102 - INFO - 
Starting training for config s6_n352:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:18:11,103 - INFO - Running command: ./train_gpt2cu -l 7.05783250116013e-05 -o hyperband_runs_20241120_172038/run_s6_n352 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:18:20,913 - INFO - Training completed for config s6_n352:
  Training time: 0:00:09
  Final validation loss: 10.910729
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.01e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n352/checkpoint.bin
2024-11-20 18:18:20,913 - INFO - 
Configuration s6_n352 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.05783250116013e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n352",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910729
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.01e-07
2024-11-20 18:18:20,913 - INFO - 
Starting training for config s6_n353:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:18:20,913 - INFO - Running command: ./train_gpt2cu -l 1.0838528234193024e-05 -o hyperband_runs_20241120_172038/run_s6_n353 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:18:30,718 - INFO - Training completed for config s6_n353:
  Training time: 0:00:09
  Final validation loss: 10.911466
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.55e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n353/checkpoint.bin
2024-11-20 18:18:30,719 - INFO - 
Configuration s6_n353 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.0838528234193024e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n353",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911466
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.55e-08
2024-11-20 18:18:30,719 - INFO - 
Starting training for config s6_n354:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:18:30,719 - INFO - Running command: ./train_gpt2cu -l 1.3517895619005685e-05 -o hyperband_runs_20241120_172038/run_s6_n354 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:18:40,524 - INFO - Training completed for config s6_n354:
  Training time: 0:00:09
  Final validation loss: 10.911445
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.93e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n354/checkpoint.bin
2024-11-20 18:18:40,524 - INFO - 
Configuration s6_n354 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.3517895619005685e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n354",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911445
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.93e-08
2024-11-20 18:18:40,524 - INFO - 
Starting training for config s6_n355:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:18:40,524 - INFO - Running command: ./train_gpt2cu -l 0.00019563461157272075 -o hyperband_runs_20241120_172038/run_s6_n355 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:18:50,326 - INFO - Training completed for config s6_n355:
  Training time: 0:00:09
  Final validation loss: 10.909185
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.79e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n355/checkpoint.bin
2024-11-20 18:18:50,326 - INFO - 
Configuration s6_n355 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00019563461157272075",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n355",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909185
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.79e-07
2024-11-20 18:18:50,326 - INFO - 
Starting training for config s6_n356:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:18:50,326 - INFO - Running command: ./train_gpt2cu -l 0.00012613073047830888 -o hyperband_runs_20241120_172038/run_s6_n356 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:19:00,135 - INFO - Training completed for config s6_n356:
  Training time: 0:00:09
  Final validation loss: 10.910028
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.80e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n356/checkpoint.bin
2024-11-20 18:19:00,136 - INFO - 
Configuration s6_n356 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012613073047830888",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n356",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910028
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.80e-07
2024-11-20 18:19:00,136 - INFO - 
Starting training for config s6_n357:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:19:00,136 - INFO - Running command: ./train_gpt2cu -l 2.1132582685080162e-05 -o hyperband_runs_20241120_172038/run_s6_n357 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:19:09,936 - INFO - Training completed for config s6_n357:
  Training time: 0:00:09
  Final validation loss: 10.911348
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.02e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n357/checkpoint.bin
2024-11-20 18:19:09,936 - INFO - 
Configuration s6_n357 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.1132582685080162e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n357",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911348
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.02e-08
2024-11-20 18:19:09,936 - INFO - 
Starting training for config s6_n358:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:19:09,937 - INFO - Running command: ./train_gpt2cu -l 5.796671236363848e-05 -o hyperband_runs_20241120_172038/run_s6_n358 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:19:19,734 - INFO - Training completed for config s6_n358:
  Training time: 0:00:09
  Final validation loss: 10.910894
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.28e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n358/checkpoint.bin
2024-11-20 18:19:19,734 - INFO - 
Configuration s6_n358 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.796671236363848e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n358",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910894
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.28e-08
2024-11-20 18:19:19,734 - INFO - 
Starting training for config s6_n359:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:19:19,735 - INFO - Running command: ./train_gpt2cu -l 7.938861341579324e-05 -o hyperband_runs_20241120_172038/run_s6_n359 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:19:29,532 - INFO - Training completed for config s6_n359:
  Training time: 0:00:09
  Final validation loss: 10.910628
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.13e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n359/checkpoint.bin
2024-11-20 18:19:29,532 - INFO - 
Configuration s6_n359 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.938861341579324e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n359",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910628
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.13e-07
2024-11-20 18:19:29,532 - INFO - 
Starting training for config s6_n360:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:19:29,532 - INFO - Running command: ./train_gpt2cu -l 4.086344519080409e-05 -o hyperband_runs_20241120_172038/run_s6_n360 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:19:39,358 - INFO - Training completed for config s6_n360:
  Training time: 0:00:09
  Final validation loss: 10.911108
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.84e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n360/checkpoint.bin
2024-11-20 18:19:39,358 - INFO - 
Configuration s6_n360 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.086344519080409e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n360",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911108
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.84e-08
2024-11-20 18:19:39,359 - INFO - 
Starting training for config s6_n361:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:19:39,359 - INFO - Running command: ./train_gpt2cu -l 0.00012278338398489199 -o hyperband_runs_20241120_172038/run_s6_n361 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:19:49,161 - INFO - Training completed for config s6_n361:
  Training time: 0:00:09
  Final validation loss: 10.910085
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.75e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n361/checkpoint.bin
2024-11-20 18:19:49,161 - INFO - 
Configuration s6_n361 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012278338398489199",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n361",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910085
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.75e-07
2024-11-20 18:19:49,161 - INFO - 
Starting training for config s6_n362:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:19:49,162 - INFO - Running command: ./train_gpt2cu -l 1.9311758780340757e-05 -o hyperband_runs_20241120_172038/run_s6_n362 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:19:58,960 - INFO - Training completed for config s6_n362:
  Training time: 0:00:09
  Final validation loss: 10.911364
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.76e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n362/checkpoint.bin
2024-11-20 18:19:58,960 - INFO - 
Configuration s6_n362 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.9311758780340757e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n362",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911364
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.76e-08
2024-11-20 18:19:58,961 - INFO - 
Starting training for config s6_n363:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:19:58,961 - INFO - Running command: ./train_gpt2cu -l 0.00012197404256915978 -o hyperband_runs_20241120_172038/run_s6_n363 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:20:08,773 - INFO - Training completed for config s6_n363:
  Training time: 0:00:09
  Final validation loss: 10.910083
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.74e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n363/checkpoint.bin
2024-11-20 18:20:08,774 - INFO - 
Configuration s6_n363 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012197404256915978",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n363",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910083
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.74e-07
2024-11-20 18:20:08,774 - INFO - 
Starting training for config s6_n364:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:20:08,774 - INFO - Running command: ./train_gpt2cu -l 0.0007960447614808076 -o hyperband_runs_20241120_172038/run_s6_n364 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:20:18,598 - INFO - Training completed for config s6_n364:
  Training time: 0:00:09
  Final validation loss: 10.901850
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.14e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n364/checkpoint.bin
2024-11-20 18:20:18,598 - INFO - 
Configuration s6_n364 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007960447614808076",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n364",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901850
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.14e-06
2024-11-20 18:20:18,598 - INFO - 
Starting training for config s6_n365:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:20:18,598 - INFO - Running command: ./train_gpt2cu -l 0.000357407200287514 -o hyperband_runs_20241120_172038/run_s6_n365 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:20:28,433 - INFO - Training completed for config s6_n365:
  Training time: 0:00:09
  Final validation loss: 10.907187
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.11e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n365/checkpoint.bin
2024-11-20 18:20:28,433 - INFO - 
Configuration s6_n365 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000357407200287514",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n365",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907187
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.11e-07
2024-11-20 18:20:28,434 - INFO - 
Starting training for config s6_n366:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:20:28,434 - INFO - Running command: ./train_gpt2cu -l 2.848609689351418e-05 -o hyperband_runs_20241120_172038/run_s6_n366 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:20:38,236 - INFO - Training completed for config s6_n366:
  Training time: 0:00:09
  Final validation loss: 10.911274
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.07e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n366/checkpoint.bin
2024-11-20 18:20:38,236 - INFO - 
Configuration s6_n366 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.848609689351418e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n366",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911274
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.07e-08
2024-11-20 18:20:38,236 - INFO - 
Starting training for config s6_n367:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:20:38,237 - INFO - Running command: ./train_gpt2cu -l 0.0004564735500034968 -o hyperband_runs_20241120_172038/run_s6_n367 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:20:48,047 - INFO - Training completed for config s6_n367:
  Training time: 0:00:09
  Final validation loss: 10.905989
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.52e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n367/checkpoint.bin
2024-11-20 18:20:48,047 - INFO - 
Configuration s6_n367 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004564735500034968",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n367",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905989
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.52e-07
2024-11-20 18:20:48,047 - INFO - 
Starting training for config s6_n368:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:20:48,047 - INFO - Running command: ./train_gpt2cu -l 9.990696858607197e-05 -o hyperband_runs_20241120_172038/run_s6_n368 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:20:57,863 - INFO - Training completed for config s6_n368:
  Training time: 0:00:09
  Final validation loss: 10.910357
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.43e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n368/checkpoint.bin
2024-11-20 18:20:57,863 - INFO - 
Configuration s6_n368 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "9.990696858607197e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n368",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910357
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.43e-07
2024-11-20 18:20:57,863 - INFO - 
Starting training for config s6_n369:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:20:57,863 - INFO - Running command: ./train_gpt2cu -l 7.783653127759239e-05 -o hyperband_runs_20241120_172038/run_s6_n369 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:21:07,673 - INFO - Training completed for config s6_n369:
  Training time: 0:00:09
  Final validation loss: 10.910647
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.11e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n369/checkpoint.bin
2024-11-20 18:21:07,674 - INFO - 
Configuration s6_n369 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.783653127759239e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n369",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910647
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.11e-07
2024-11-20 18:21:07,674 - INFO - 
Starting training for config s6_n370:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:21:07,674 - INFO - Running command: ./train_gpt2cu -l 3.751188544246121e-05 -o hyperband_runs_20241120_172038/run_s6_n370 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:21:17,475 - INFO - Training completed for config s6_n370:
  Training time: 0:00:09
  Final validation loss: 10.911154
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.36e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n370/checkpoint.bin
2024-11-20 18:21:17,475 - INFO - 
Configuration s6_n370 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.751188544246121e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n370",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911154
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.36e-08
2024-11-20 18:21:17,475 - INFO - 
Starting training for config s6_n371:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:21:17,475 - INFO - Running command: ./train_gpt2cu -l 0.0001970870781198133 -o hyperband_runs_20241120_172038/run_s6_n371 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:21:27,264 - INFO - Training completed for config s6_n371:
  Training time: 0:00:09
  Final validation loss: 10.909157
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.82e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n371/checkpoint.bin
2024-11-20 18:21:27,264 - INFO - 
Configuration s6_n371 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001970870781198133",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n371",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909157
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.82e-07
2024-11-20 18:21:27,265 - INFO - 
Starting training for config s6_n372:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:21:27,265 - INFO - Running command: ./train_gpt2cu -l 0.000158625873572474 -o hyperband_runs_20241120_172038/run_s6_n372 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:21:37,072 - INFO - Training completed for config s6_n372:
  Training time: 0:00:09
  Final validation loss: 10.909649
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.27e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n372/checkpoint.bin
2024-11-20 18:21:37,072 - INFO - 
Configuration s6_n372 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000158625873572474",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n372",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909649
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.27e-07
2024-11-20 18:21:37,072 - INFO - 
Starting training for config s6_n373:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:21:37,072 - INFO - Running command: ./train_gpt2cu -l 1.3238539821422258e-05 -o hyperband_runs_20241120_172038/run_s6_n373 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:21:46,887 - INFO - Training completed for config s6_n373:
  Training time: 0:00:09
  Final validation loss: 10.911445
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.89e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n373/checkpoint.bin
2024-11-20 18:21:46,887 - INFO - 
Configuration s6_n373 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.3238539821422258e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n373",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911445
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.89e-08
2024-11-20 18:21:46,887 - INFO - 
Starting training for config s6_n374:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:21:46,887 - INFO - Running command: ./train_gpt2cu -l 0.00040861558065735914 -o hyperband_runs_20241120_172038/run_s6_n374 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:21:56,678 - INFO - Training completed for config s6_n374:
  Training time: 0:00:09
  Final validation loss: 10.906569
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.84e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n374/checkpoint.bin
2024-11-20 18:21:56,678 - INFO - 
Configuration s6_n374 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00040861558065735914",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n374",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906569
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.84e-07
2024-11-20 18:21:56,679 - INFO - 
Starting training for config s6_n375:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:21:56,679 - INFO - Running command: ./train_gpt2cu -l 0.00018733388107123347 -o hyperband_runs_20241120_172038/run_s6_n375 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:22:06,480 - INFO - Training completed for config s6_n375:
  Training time: 0:00:09
  Final validation loss: 10.909290
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.68e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n375/checkpoint.bin
2024-11-20 18:22:06,481 - INFO - 
Configuration s6_n375 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00018733388107123347",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n375",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909290
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.68e-07
2024-11-20 18:22:06,481 - INFO - 
Starting training for config s6_n376:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:22:06,481 - INFO - Running command: ./train_gpt2cu -l 7.92237191872237e-05 -o hyperband_runs_20241120_172038/run_s6_n376 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:22:16,291 - INFO - Training completed for config s6_n376:
  Training time: 0:00:09
  Final validation loss: 10.910632
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.13e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n376/checkpoint.bin
2024-11-20 18:22:16,291 - INFO - 
Configuration s6_n376 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.92237191872237e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n376",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910632
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.13e-07
2024-11-20 18:22:16,291 - INFO - 
Starting training for config s6_n377:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:22:16,291 - INFO - Running command: ./train_gpt2cu -l 2.4189732673860728e-05 -o hyperband_runs_20241120_172038/run_s6_n377 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:22:26,106 - INFO - Training completed for config s6_n377:
  Training time: 0:00:09
  Final validation loss: 10.911310
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.46e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n377/checkpoint.bin
2024-11-20 18:22:26,106 - INFO - 
Configuration s6_n377 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.4189732673860728e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n377",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911310
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.46e-08
2024-11-20 18:22:26,106 - INFO - 
Starting training for config s6_n378:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:22:26,106 - INFO - Running command: ./train_gpt2cu -l 9.653022943174116e-05 -o hyperband_runs_20241120_172038/run_s6_n378 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:22:35,912 - INFO - Training completed for config s6_n378:
  Training time: 0:00:09
  Final validation loss: 10.910413
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.38e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n378/checkpoint.bin
2024-11-20 18:22:35,913 - INFO - 
Configuration s6_n378 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "9.653022943174116e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n378",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910413
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.38e-07
2024-11-20 18:22:35,913 - INFO - 
Starting training for config s6_n379:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:22:35,913 - INFO - Running command: ./train_gpt2cu -l 4.572948489477086e-05 -o hyperband_runs_20241120_172038/run_s6_n379 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:22:45,715 - INFO - Training completed for config s6_n379:
  Training time: 0:00:09
  Final validation loss: 10.911053
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.53e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n379/checkpoint.bin
2024-11-20 18:22:45,715 - INFO - 
Configuration s6_n379 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.572948489477086e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n379",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911053
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.53e-08
2024-11-20 18:22:45,716 - INFO - 
Starting training for config s6_n380:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:22:45,716 - INFO - Running command: ./train_gpt2cu -l 0.0008587527623389926 -o hyperband_runs_20241120_172038/run_s6_n380 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:22:55,520 - INFO - Training completed for config s6_n380:
  Training time: 0:00:09
  Final validation loss: 10.901081
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.23e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n380/checkpoint.bin
2024-11-20 18:22:55,521 - INFO - 
Configuration s6_n380 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008587527623389926",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n380",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901081
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.23e-06
2024-11-20 18:22:55,521 - INFO - 
Starting training for config s6_n381:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:22:55,521 - INFO - Running command: ./train_gpt2cu -l 0.0002189056788217684 -o hyperband_runs_20241120_172038/run_s6_n381 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:23:05,345 - INFO - Training completed for config s6_n381:
  Training time: 0:00:09
  Final validation loss: 10.908896
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.13e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n381/checkpoint.bin
2024-11-20 18:23:05,346 - INFO - 
Configuration s6_n381 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002189056788217684",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n381",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908896
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.13e-07
2024-11-20 18:23:05,346 - INFO - 
Starting training for config s6_n382:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:23:05,346 - INFO - Running command: ./train_gpt2cu -l 3.40803716308253e-05 -o hyperband_runs_20241120_172038/run_s6_n382 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:23:15,149 - INFO - Training completed for config s6_n382:
  Training time: 0:00:09
  Final validation loss: 10.911198
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.87e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n382/checkpoint.bin
2024-11-20 18:23:15,150 - INFO - 
Configuration s6_n382 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.40803716308253e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n382",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911198
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.87e-08
2024-11-20 18:23:15,150 - INFO - 
Starting training for config s6_n383:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:23:15,150 - INFO - Running command: ./train_gpt2cu -l 1.3944466928723285e-05 -o hyperband_runs_20241120_172038/run_s6_n383 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:23:24,958 - INFO - Training completed for config s6_n383:
  Training time: 0:00:09
  Final validation loss: 10.911428
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.99e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n383/checkpoint.bin
2024-11-20 18:23:24,959 - INFO - 
Configuration s6_n383 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.3944466928723285e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n383",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911428
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.99e-08
2024-11-20 18:23:24,959 - INFO - 
Starting training for config s6_n384:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:23:24,959 - INFO - Running command: ./train_gpt2cu -l 1.527824162768744e-05 -o hyperband_runs_20241120_172038/run_s6_n384 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:23:34,758 - INFO - Training completed for config s6_n384:
  Training time: 0:00:09
  Final validation loss: 10.911423
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.18e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n384/checkpoint.bin
2024-11-20 18:23:34,759 - INFO - 
Configuration s6_n384 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.527824162768744e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n384",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911423
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.18e-08
2024-11-20 18:23:34,759 - INFO - 
Starting training for config s6_n385:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:23:34,759 - INFO - Running command: ./train_gpt2cu -l 2.4652814041500932e-05 -o hyperband_runs_20241120_172038/run_s6_n385 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:23:44,568 - INFO - Training completed for config s6_n385:
  Training time: 0:00:09
  Final validation loss: 10.911305
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.52e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n385/checkpoint.bin
2024-11-20 18:23:44,568 - INFO - 
Configuration s6_n385 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.4652814041500932e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n385",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911305
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.52e-08
2024-11-20 18:23:44,568 - INFO - 
Starting training for config s6_n386:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:23:44,568 - INFO - Running command: ./train_gpt2cu -l 0.0002371423837007242 -o hyperband_runs_20241120_172038/run_s6_n386 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:23:54,366 - INFO - Training completed for config s6_n386:
  Training time: 0:00:09
  Final validation loss: 10.908679
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.39e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n386/checkpoint.bin
2024-11-20 18:23:54,367 - INFO - 
Configuration s6_n386 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002371423837007242",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n386",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908679
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.39e-07
2024-11-20 18:23:54,367 - INFO - 
Starting training for config s6_n387:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:23:54,367 - INFO - Running command: ./train_gpt2cu -l 0.0004902875342708506 -o hyperband_runs_20241120_172038/run_s6_n387 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:24:04,178 - INFO - Training completed for config s6_n387:
  Training time: 0:00:09
  Final validation loss: 10.905587
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.00e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n387/checkpoint.bin
2024-11-20 18:24:04,178 - INFO - 
Configuration s6_n387 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004902875342708506",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n387",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905587
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.00e-07
2024-11-20 18:24:04,178 - INFO - 
Starting training for config s6_n388:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:24:04,189 - INFO - Running command: ./train_gpt2cu -l 6.52222406806845e-05 -o hyperband_runs_20241120_172038/run_s6_n388 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:24:13,996 - INFO - Training completed for config s6_n388:
  Training time: 0:00:09
  Final validation loss: 10.910801
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.32e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n388/checkpoint.bin
2024-11-20 18:24:13,996 - INFO - 
Configuration s6_n388 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.52222406806845e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n388",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910801
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.32e-08
2024-11-20 18:24:13,996 - INFO - 
Starting training for config s6_n389:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:24:13,997 - INFO - Running command: ./train_gpt2cu -l 8.201067548190826e-05 -o hyperband_runs_20241120_172038/run_s6_n389 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:24:23,812 - INFO - Training completed for config s6_n389:
  Training time: 0:00:09
  Final validation loss: 10.910584
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.17e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n389/checkpoint.bin
2024-11-20 18:24:23,813 - INFO - 
Configuration s6_n389 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "8.201067548190826e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n389",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910584
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.17e-07
2024-11-20 18:24:23,813 - INFO - 
Starting training for config s6_n390:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:24:23,813 - INFO - Running command: ./train_gpt2cu -l 0.0002547555747597312 -o hyperband_runs_20241120_172038/run_s6_n390 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:24:33,604 - INFO - Training completed for config s6_n390:
  Training time: 0:00:09
  Final validation loss: 10.908457
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.64e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n390/checkpoint.bin
2024-11-20 18:24:33,605 - INFO - 
Configuration s6_n390 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002547555747597312",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n390",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908457
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.64e-07
2024-11-20 18:24:33,605 - INFO - 
Starting training for config s6_n391:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:24:33,605 - INFO - Running command: ./train_gpt2cu -l 1.4179673151583458e-05 -o hyperband_runs_20241120_172038/run_s6_n391 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:24:43,416 - INFO - Training completed for config s6_n391:
  Training time: 0:00:09
  Final validation loss: 10.911431
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.03e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n391/checkpoint.bin
2024-11-20 18:24:43,416 - INFO - 
Configuration s6_n391 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.4179673151583458e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n391",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911431
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.03e-08
2024-11-20 18:24:43,416 - INFO - 
Starting training for config s6_n392:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:24:43,416 - INFO - Running command: ./train_gpt2cu -l 0.00036508471329559046 -o hyperband_runs_20241120_172038/run_s6_n392 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:24:53,205 - INFO - Training completed for config s6_n392:
  Training time: 0:00:09
  Final validation loss: 10.907102
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.22e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n392/checkpoint.bin
2024-11-20 18:24:53,205 - INFO - 
Configuration s6_n392 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00036508471329559046",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n392",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907102
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.22e-07
2024-11-20 18:24:53,205 - INFO - 
Starting training for config s6_n393:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:24:53,205 - INFO - Running command: ./train_gpt2cu -l 1.0690400444133503e-05 -o hyperband_runs_20241120_172038/run_s6_n393 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:25:03,022 - INFO - Training completed for config s6_n393:
  Training time: 0:00:09
  Final validation loss: 10.911469
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.53e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n393/checkpoint.bin
2024-11-20 18:25:03,022 - INFO - 
Configuration s6_n393 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.0690400444133503e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n393",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911469
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.53e-08
2024-11-20 18:25:03,022 - INFO - 
Starting training for config s6_n394:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:25:03,023 - INFO - Running command: ./train_gpt2cu -l 2.6762562087675807e-05 -o hyperband_runs_20241120_172038/run_s6_n394 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:25:12,828 - INFO - Training completed for config s6_n394:
  Training time: 0:00:09
  Final validation loss: 10.911277
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.82e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n394/checkpoint.bin
2024-11-20 18:25:12,828 - INFO - 
Configuration s6_n394 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.6762562087675807e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n394",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911277
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.82e-08
2024-11-20 18:25:12,828 - INFO - 
Starting training for config s6_n395:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:25:12,828 - INFO - Running command: ./train_gpt2cu -l 0.0002483092861627605 -o hyperband_runs_20241120_172038/run_s6_n395 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:25:22,630 - INFO - Training completed for config s6_n395:
  Training time: 0:00:09
  Final validation loss: 10.908533
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.55e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n395/checkpoint.bin
2024-11-20 18:25:22,630 - INFO - 
Configuration s6_n395 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002483092861627605",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n395",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908533
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.55e-07
2024-11-20 18:25:22,630 - INFO - 
Starting training for config s6_n396:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:25:22,631 - INFO - Running command: ./train_gpt2cu -l 0.00012159216787154719 -o hyperband_runs_20241120_172038/run_s6_n396 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:25:32,435 - INFO - Training completed for config s6_n396:
  Training time: 0:00:09
  Final validation loss: 10.910100
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.74e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n396/checkpoint.bin
2024-11-20 18:25:32,435 - INFO - 
Configuration s6_n396 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012159216787154719",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n396",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910100
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.74e-07
2024-11-20 18:25:32,435 - INFO - 
Starting training for config s6_n397:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:25:32,435 - INFO - Running command: ./train_gpt2cu -l 4.463010732364632e-05 -o hyperband_runs_20241120_172038/run_s6_n397 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:25:42,265 - INFO - Training completed for config s6_n397:
  Training time: 0:00:09
  Final validation loss: 10.911066
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.38e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n397/checkpoint.bin
2024-11-20 18:25:42,265 - INFO - 
Configuration s6_n397 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.463010732364632e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n397",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911066
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.38e-08
2024-11-20 18:25:42,265 - INFO - 
Starting training for config s6_n398:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:25:42,265 - INFO - Running command: ./train_gpt2cu -l 0.0003102432609873989 -o hyperband_runs_20241120_172038/run_s6_n398 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:25:52,066 - INFO - Training completed for config s6_n398:
  Training time: 0:00:09
  Final validation loss: 10.907771
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.43e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n398/checkpoint.bin
2024-11-20 18:25:52,066 - INFO - 
Configuration s6_n398 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003102432609873989",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n398",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907771
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.43e-07
2024-11-20 18:25:52,066 - INFO - 
Starting training for config s6_n399:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:25:52,066 - INFO - Running command: ./train_gpt2cu -l 0.00028722599305629486 -o hyperband_runs_20241120_172038/run_s6_n399 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:26:01,880 - INFO - Training completed for config s6_n399:
  Training time: 0:00:09
  Final validation loss: 10.908062
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.10e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n399/checkpoint.bin
2024-11-20 18:26:01,881 - INFO - 
Configuration s6_n399 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00028722599305629486",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n399",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908062
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.10e-07
2024-11-20 18:26:01,881 - INFO - 
Starting training for config s6_n400:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:26:01,881 - INFO - Running command: ./train_gpt2cu -l 0.0005195453314618219 -o hyperband_runs_20241120_172038/run_s6_n400 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:26:11,701 - INFO - Training completed for config s6_n400:
  Training time: 0:00:09
  Final validation loss: 10.905227
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.42e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n400/checkpoint.bin
2024-11-20 18:26:11,701 - INFO - 
Configuration s6_n400 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005195453314618219",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n400",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905227
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.42e-07
2024-11-20 18:26:11,701 - INFO - 
Starting training for config s6_n401:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:26:11,702 - INFO - Running command: ./train_gpt2cu -l 0.0004431113889646486 -o hyperband_runs_20241120_172038/run_s6_n401 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:26:21,518 - INFO - Training completed for config s6_n401:
  Training time: 0:00:09
  Final validation loss: 10.906140
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.33e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n401/checkpoint.bin
2024-11-20 18:26:21,518 - INFO - 
Configuration s6_n401 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004431113889646486",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n401",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906140
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.33e-07
2024-11-20 18:26:21,519 - INFO - 
Starting training for config s6_n402:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:26:21,519 - INFO - Running command: ./train_gpt2cu -l 0.0003034703728821797 -o hyperband_runs_20241120_172038/run_s6_n402 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:26:31,319 - INFO - Training completed for config s6_n402:
  Training time: 0:00:09
  Final validation loss: 10.907849
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.34e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n402/checkpoint.bin
2024-11-20 18:26:31,319 - INFO - 
Configuration s6_n402 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003034703728821797",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n402",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907849
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.34e-07
2024-11-20 18:26:31,320 - INFO - 
Starting training for config s6_n403:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:26:31,320 - INFO - Running command: ./train_gpt2cu -l 3.0680606445603016e-05 -o hyperband_runs_20241120_172038/run_s6_n403 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:26:41,117 - INFO - Training completed for config s6_n403:
  Training time: 0:00:09
  Final validation loss: 10.911238
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.38e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n403/checkpoint.bin
2024-11-20 18:26:41,117 - INFO - 
Configuration s6_n403 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.0680606445603016e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n403",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911238
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.38e-08
2024-11-20 18:26:41,118 - INFO - 
Starting training for config s6_n404:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:26:41,118 - INFO - Running command: ./train_gpt2cu -l 0.00038586900970915026 -o hyperband_runs_20241120_172038/run_s6_n404 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:26:50,920 - INFO - Training completed for config s6_n404:
  Training time: 0:00:09
  Final validation loss: 10.906840
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.51e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n404/checkpoint.bin
2024-11-20 18:26:50,920 - INFO - 
Configuration s6_n404 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00038586900970915026",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n404",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906840
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.51e-07
2024-11-20 18:26:50,920 - INFO - 
Starting training for config s6_n405:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:26:50,921 - INFO - Running command: ./train_gpt2cu -l 1.9229973308895345e-05 -o hyperband_runs_20241120_172038/run_s6_n405 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:27:00,732 - INFO - Training completed for config s6_n405:
  Training time: 0:00:09
  Final validation loss: 10.911375
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.75e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n405/checkpoint.bin
2024-11-20 18:27:00,733 - INFO - 
Configuration s6_n405 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.9229973308895345e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n405",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911375
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.75e-08
2024-11-20 18:27:00,733 - INFO - 
Starting training for config s6_n406:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:27:00,733 - INFO - Running command: ./train_gpt2cu -l 0.0005246202568201113 -o hyperband_runs_20241120_172038/run_s6_n406 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:27:10,532 - INFO - Training completed for config s6_n406:
  Training time: 0:00:09
  Final validation loss: 10.905169
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.49e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n406/checkpoint.bin
2024-11-20 18:27:10,532 - INFO - 
Configuration s6_n406 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005246202568201113",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n406",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905169
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.49e-07
2024-11-20 18:27:10,532 - INFO - 
Starting training for config s6_n407:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:27:10,532 - INFO - Running command: ./train_gpt2cu -l 0.00033122926843914244 -o hyperband_runs_20241120_172038/run_s6_n407 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:27:20,334 - INFO - Training completed for config s6_n407:
  Training time: 0:00:09
  Final validation loss: 10.907512
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.73e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n407/checkpoint.bin
2024-11-20 18:27:20,334 - INFO - 
Configuration s6_n407 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00033122926843914244",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n407",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907512
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.73e-07
2024-11-20 18:27:20,334 - INFO - 
Starting training for config s6_n408:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:27:20,334 - INFO - Running command: ./train_gpt2cu -l 5.665307094113682e-05 -o hyperband_runs_20241120_172038/run_s6_n408 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:27:30,134 - INFO - Training completed for config s6_n408:
  Training time: 0:00:09
  Final validation loss: 10.910906
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.09e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n408/checkpoint.bin
2024-11-20 18:27:30,135 - INFO - 
Configuration s6_n408 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.665307094113682e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n408",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910906
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.09e-08
2024-11-20 18:27:30,135 - INFO - 
Starting training for config s6_n409:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:27:30,135 - INFO - Running command: ./train_gpt2cu -l 2.634423986752093e-05 -o hyperband_runs_20241120_172038/run_s6_n409 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:27:39,926 - INFO - Training completed for config s6_n409:
  Training time: 0:00:09
  Final validation loss: 10.911295
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.76e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n409/checkpoint.bin
2024-11-20 18:27:39,926 - INFO - 
Configuration s6_n409 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.634423986752093e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n409",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911295
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.76e-08
2024-11-20 18:27:39,927 - INFO - 
Starting training for config s6_n410:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:27:39,927 - INFO - Running command: ./train_gpt2cu -l 1.4059803256640399e-05 -o hyperband_runs_20241120_172038/run_s6_n410 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:27:49,714 - INFO - Training completed for config s6_n410:
  Training time: 0:00:09
  Final validation loss: 10.911424
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.01e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n410/checkpoint.bin
2024-11-20 18:27:49,714 - INFO - 
Configuration s6_n410 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.4059803256640399e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n410",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911424
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.01e-08
2024-11-20 18:27:49,714 - INFO - 
Starting training for config s6_n411:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:27:49,714 - INFO - Running command: ./train_gpt2cu -l 0.00015585882013859512 -o hyperband_runs_20241120_172038/run_s6_n411 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:27:59,533 - INFO - Training completed for config s6_n411:
  Training time: 0:00:09
  Final validation loss: 10.909674
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.23e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n411/checkpoint.bin
2024-11-20 18:27:59,533 - INFO - 
Configuration s6_n411 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00015585882013859512",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n411",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909674
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.23e-07
2024-11-20 18:27:59,533 - INFO - 
Starting training for config s6_n412:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:27:59,533 - INFO - Running command: ./train_gpt2cu -l 1.9481955045359432e-05 -o hyperband_runs_20241120_172038/run_s6_n412 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:28:09,339 - INFO - Training completed for config s6_n412:
  Training time: 0:00:09
  Final validation loss: 10.911366
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.78e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n412/checkpoint.bin
2024-11-20 18:28:09,339 - INFO - 
Configuration s6_n412 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.9481955045359432e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n412",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911366
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.78e-08
2024-11-20 18:28:09,339 - INFO - 
Starting training for config s6_n413:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:28:09,340 - INFO - Running command: ./train_gpt2cu -l 3.3917124986804754e-05 -o hyperband_runs_20241120_172038/run_s6_n413 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:28:19,137 - INFO - Training completed for config s6_n413:
  Training time: 0:00:09
  Final validation loss: 10.911201
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.85e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n413/checkpoint.bin
2024-11-20 18:28:19,137 - INFO - 
Configuration s6_n413 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.3917124986804754e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n413",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911201
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.85e-08
2024-11-20 18:28:19,137 - INFO - 
Starting training for config s6_n414:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:28:19,137 - INFO - Running command: ./train_gpt2cu -l 6.229113339191556e-05 -o hyperband_runs_20241120_172038/run_s6_n414 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:28:28,954 - INFO - Training completed for config s6_n414:
  Training time: 0:00:09
  Final validation loss: 10.910833
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.90e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n414/checkpoint.bin
2024-11-20 18:28:28,955 - INFO - 
Configuration s6_n414 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.229113339191556e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n414",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910833
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.90e-08
2024-11-20 18:28:28,955 - INFO - 
Starting training for config s6_n415:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:28:28,955 - INFO - Running command: ./train_gpt2cu -l 0.00034849607054646895 -o hyperband_runs_20241120_172038/run_s6_n415 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:28:38,762 - INFO - Training completed for config s6_n415:
  Training time: 0:00:09
  Final validation loss: 10.907297
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.98e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n415/checkpoint.bin
2024-11-20 18:28:38,763 - INFO - 
Configuration s6_n415 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00034849607054646895",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n415",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907297
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.98e-07
2024-11-20 18:28:38,763 - INFO - 
Starting training for config s6_n416:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:28:38,763 - INFO - Running command: ./train_gpt2cu -l 3.614996687496933e-05 -o hyperband_runs_20241120_172038/run_s6_n416 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:28:48,582 - INFO - Training completed for config s6_n416:
  Training time: 0:00:09
  Final validation loss: 10.911178
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.16e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n416/checkpoint.bin
2024-11-20 18:28:48,582 - INFO - 
Configuration s6_n416 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.614996687496933e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n416",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911178
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.16e-08
2024-11-20 18:28:48,582 - INFO - 
Starting training for config s6_n417:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:28:48,582 - INFO - Running command: ./train_gpt2cu -l 0.0001486207886031576 -o hyperband_runs_20241120_172038/run_s6_n417 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:28:58,397 - INFO - Training completed for config s6_n417:
  Training time: 0:00:09
  Final validation loss: 10.909762
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.12e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n417/checkpoint.bin
2024-11-20 18:28:58,397 - INFO - 
Configuration s6_n417 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001486207886031576",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n417",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909762
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.12e-07
2024-11-20 18:28:58,397 - INFO - 
Starting training for config s6_n418:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:28:58,398 - INFO - Running command: ./train_gpt2cu -l 1.0722570006130163e-05 -o hyperband_runs_20241120_172038/run_s6_n418 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:29:08,200 - INFO - Training completed for config s6_n418:
  Training time: 0:00:09
  Final validation loss: 10.911470
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.53e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n418/checkpoint.bin
2024-11-20 18:29:08,200 - INFO - 
Configuration s6_n418 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.0722570006130163e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n418",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911470
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.53e-08
2024-11-20 18:29:08,200 - INFO - 
Starting training for config s6_n419:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:29:08,200 - INFO - Running command: ./train_gpt2cu -l 2.784753442713612e-05 -o hyperband_runs_20241120_172038/run_s6_n419 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:29:18,007 - INFO - Training completed for config s6_n419:
  Training time: 0:00:09
  Final validation loss: 10.911257
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.98e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n419/checkpoint.bin
2024-11-20 18:29:18,007 - INFO - 
Configuration s6_n419 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.784753442713612e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n419",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911257
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.98e-08
2024-11-20 18:29:18,007 - INFO - 
Starting training for config s6_n420:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:29:18,008 - INFO - Running command: ./train_gpt2cu -l 0.0008560188308167667 -o hyperband_runs_20241120_172038/run_s6_n420 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:29:27,820 - INFO - Training completed for config s6_n420:
  Training time: 0:00:09
  Final validation loss: 10.901102
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.22e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n420/checkpoint.bin
2024-11-20 18:29:27,821 - INFO - 
Configuration s6_n420 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008560188308167667",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n420",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901102
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.22e-06
2024-11-20 18:29:27,821 - INFO - 
Starting training for config s6_n421:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:29:27,821 - INFO - Running command: ./train_gpt2cu -l 0.00046384683602221924 -o hyperband_runs_20241120_172038/run_s6_n421 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:29:37,635 - INFO - Training completed for config s6_n421:
  Training time: 0:00:09
  Final validation loss: 10.905903
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.63e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n421/checkpoint.bin
2024-11-20 18:29:37,635 - INFO - 
Configuration s6_n421 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00046384683602221924",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n421",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905903
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.63e-07
2024-11-20 18:29:37,635 - INFO - 
Starting training for config s6_n422:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:29:37,636 - INFO - Running command: ./train_gpt2cu -l 0.0005657697041682562 -o hyperband_runs_20241120_172038/run_s6_n422 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:29:47,446 - INFO - Training completed for config s6_n422:
  Training time: 0:00:09
  Final validation loss: 10.904649
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.08e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n422/checkpoint.bin
2024-11-20 18:29:47,446 - INFO - 
Configuration s6_n422 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005657697041682562",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n422",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904649
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.08e-07
2024-11-20 18:29:47,446 - INFO - 
Starting training for config s6_n423:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:29:47,446 - INFO - Running command: ./train_gpt2cu -l 1.2529639359152637e-05 -o hyperband_runs_20241120_172038/run_s6_n423 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:29:57,259 - INFO - Training completed for config s6_n423:
  Training time: 0:00:09
  Final validation loss: 10.911455
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.79e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n423/checkpoint.bin
2024-11-20 18:29:57,259 - INFO - 
Configuration s6_n423 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.2529639359152637e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n423",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911455
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.79e-08
2024-11-20 18:29:57,259 - INFO - 
Starting training for config s6_n424:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:29:57,260 - INFO - Running command: ./train_gpt2cu -l 2.9028928292918368e-05 -o hyperband_runs_20241120_172038/run_s6_n424 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:30:07,081 - INFO - Training completed for config s6_n424:
  Training time: 0:00:09
  Final validation loss: 10.911253
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.15e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n424/checkpoint.bin
2024-11-20 18:30:07,082 - INFO - 
Configuration s6_n424 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.9028928292918368e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n424",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911253
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.15e-08
2024-11-20 18:30:07,082 - INFO - 
Starting training for config s6_n425:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:30:07,082 - INFO - Running command: ./train_gpt2cu -l 3.3971035052427395e-05 -o hyperband_runs_20241120_172038/run_s6_n425 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:30:16,895 - INFO - Training completed for config s6_n425:
  Training time: 0:00:09
  Final validation loss: 10.911203
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.85e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n425/checkpoint.bin
2024-11-20 18:30:16,896 - INFO - 
Configuration s6_n425 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.3971035052427395e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n425",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911203
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.85e-08
2024-11-20 18:30:16,896 - INFO - 
Starting training for config s6_n426:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:30:16,896 - INFO - Running command: ./train_gpt2cu -l 4.8970948390397215e-05 -o hyperband_runs_20241120_172038/run_s6_n426 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:30:26,688 - INFO - Training completed for config s6_n426:
  Training time: 0:00:09
  Final validation loss: 10.911000
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.00e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n426/checkpoint.bin
2024-11-20 18:30:26,688 - INFO - 
Configuration s6_n426 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.8970948390397215e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n426",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911000
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.00e-08
2024-11-20 18:30:26,688 - INFO - 
Starting training for config s6_n427:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:30:26,688 - INFO - Running command: ./train_gpt2cu -l 0.00038297557085632084 -o hyperband_runs_20241120_172038/run_s6_n427 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:30:36,489 - INFO - Training completed for config s6_n427:
  Training time: 0:00:09
  Final validation loss: 10.906883
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.47e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n427/checkpoint.bin
2024-11-20 18:30:36,489 - INFO - 
Configuration s6_n427 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00038297557085632084",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n427",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906883
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.47e-07
2024-11-20 18:30:36,489 - INFO - 
Starting training for config s6_n428:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:30:36,490 - INFO - Running command: ./train_gpt2cu -l 6.819508962165395e-05 -o hyperband_runs_20241120_172038/run_s6_n428 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:30:46,282 - INFO - Training completed for config s6_n428:
  Training time: 0:00:09
  Final validation loss: 10.910759
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.74e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n428/checkpoint.bin
2024-11-20 18:30:46,283 - INFO - 
Configuration s6_n428 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.819508962165395e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n428",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910759
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.74e-08
2024-11-20 18:30:46,283 - INFO - 
Starting training for config s6_n429:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:30:46,283 - INFO - Running command: ./train_gpt2cu -l 0.0003309639900497035 -o hyperband_runs_20241120_172038/run_s6_n429 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:30:56,080 - INFO - Training completed for config s6_n429:
  Training time: 0:00:09
  Final validation loss: 10.907521
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.73e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n429/checkpoint.bin
2024-11-20 18:30:56,081 - INFO - 
Configuration s6_n429 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003309639900497035",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n429",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907521
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.73e-07
2024-11-20 18:30:56,081 - INFO - 
Starting training for config s6_n430:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:30:56,081 - INFO - Running command: ./train_gpt2cu -l 0.0002296818293942336 -o hyperband_runs_20241120_172038/run_s6_n430 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:31:05,871 - INFO - Training completed for config s6_n430:
  Training time: 0:00:09
  Final validation loss: 10.908775
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.28e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n430/checkpoint.bin
2024-11-20 18:31:05,871 - INFO - 
Configuration s6_n430 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002296818293942336",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n430",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908775
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.28e-07
2024-11-20 18:31:05,872 - INFO - 
Starting training for config s6_n431:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:31:05,872 - INFO - Running command: ./train_gpt2cu -l 1.9444547741816543e-05 -o hyperband_runs_20241120_172038/run_s6_n431 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:31:15,678 - INFO - Training completed for config s6_n431:
  Training time: 0:00:09
  Final validation loss: 10.911363
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.78e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n431/checkpoint.bin
2024-11-20 18:31:15,678 - INFO - 
Configuration s6_n431 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.9444547741816543e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n431",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911363
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.78e-08
2024-11-20 18:31:15,678 - INFO - 
Starting training for config s6_n432:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:31:15,678 - INFO - Running command: ./train_gpt2cu -l 0.0005718735354629053 -o hyperband_runs_20241120_172038/run_s6_n432 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:31:25,485 - INFO - Training completed for config s6_n432:
  Training time: 0:00:09
  Final validation loss: 10.904581
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.17e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n432/checkpoint.bin
2024-11-20 18:31:25,486 - INFO - 
Configuration s6_n432 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005718735354629053",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n432",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904581
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.17e-07
2024-11-20 18:31:25,486 - INFO - 
Starting training for config s6_n433:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:31:25,486 - INFO - Running command: ./train_gpt2cu -l 0.00042028372685650475 -o hyperband_runs_20241120_172038/run_s6_n433 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:31:35,294 - INFO - Training completed for config s6_n433:
  Training time: 0:00:09
  Final validation loss: 10.906436
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.00e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n433/checkpoint.bin
2024-11-20 18:31:35,294 - INFO - 
Configuration s6_n433 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00042028372685650475",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n433",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906436
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.00e-07
2024-11-20 18:31:35,294 - INFO - 
Starting training for config s6_n434:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:31:35,294 - INFO - Running command: ./train_gpt2cu -l 2.0418769471250216e-05 -o hyperband_runs_20241120_172038/run_s6_n434 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:31:45,090 - INFO - Training completed for config s6_n434:
  Training time: 0:00:09
  Final validation loss: 10.911356
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.92e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n434/checkpoint.bin
2024-11-20 18:31:45,090 - INFO - 
Configuration s6_n434 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.0418769471250216e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n434",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911356
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.92e-08
2024-11-20 18:31:45,090 - INFO - 
Starting training for config s6_n435:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:31:45,091 - INFO - Running command: ./train_gpt2cu -l 0.0002565539092773649 -o hyperband_runs_20241120_172038/run_s6_n435 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:31:54,894 - INFO - Training completed for config s6_n435:
  Training time: 0:00:09
  Final validation loss: 10.908429
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.67e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n435/checkpoint.bin
2024-11-20 18:31:54,894 - INFO - 
Configuration s6_n435 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002565539092773649",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n435",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908429
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.67e-07
2024-11-20 18:31:54,894 - INFO - 
Starting training for config s6_n436:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:31:54,894 - INFO - Running command: ./train_gpt2cu -l 1.676887353814895e-05 -o hyperband_runs_20241120_172038/run_s6_n436 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:32:04,692 - INFO - Training completed for config s6_n436:
  Training time: 0:00:09
  Final validation loss: 10.911405
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.40e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n436/checkpoint.bin
2024-11-20 18:32:04,693 - INFO - 
Configuration s6_n436 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.676887353814895e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n436",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911405
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.40e-08
2024-11-20 18:32:04,693 - INFO - 
Starting training for config s6_n437:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:32:04,693 - INFO - Running command: ./train_gpt2cu -l 3.386613787750546e-05 -o hyperband_runs_20241120_172038/run_s6_n437 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:32:14,487 - INFO - Training completed for config s6_n437:
  Training time: 0:00:09
  Final validation loss: 10.911203
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.84e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n437/checkpoint.bin
2024-11-20 18:32:14,487 - INFO - 
Configuration s6_n437 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.386613787750546e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n437",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911203
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.84e-08
2024-11-20 18:32:14,487 - INFO - 
Starting training for config s6_n438:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:32:14,488 - INFO - Running command: ./train_gpt2cu -l 0.00014131194490944586 -o hyperband_runs_20241120_172038/run_s6_n438 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:32:24,276 - INFO - Training completed for config s6_n438:
  Training time: 0:00:09
  Final validation loss: 10.909849
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.02e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n438/checkpoint.bin
2024-11-20 18:32:24,276 - INFO - 
Configuration s6_n438 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014131194490944586",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n438",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909849
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.02e-07
2024-11-20 18:32:24,276 - INFO - 
Starting training for config s6_n439:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:32:24,277 - INFO - Running command: ./train_gpt2cu -l 1.161865174278245e-05 -o hyperband_runs_20241120_172038/run_s6_n439 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:32:34,082 - INFO - Training completed for config s6_n439:
  Training time: 0:00:09
  Final validation loss: 10.911463
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.66e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n439/checkpoint.bin
2024-11-20 18:32:34,082 - INFO - 
Configuration s6_n439 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.161865174278245e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n439",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911463
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.66e-08
2024-11-20 18:32:34,082 - INFO - 
Starting training for config s6_n440:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:32:34,082 - INFO - Running command: ./train_gpt2cu -l 0.0004883898403137743 -o hyperband_runs_20241120_172038/run_s6_n440 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:32:43,882 - INFO - Training completed for config s6_n440:
  Training time: 0:00:09
  Final validation loss: 10.905588
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.98e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n440/checkpoint.bin
2024-11-20 18:32:43,883 - INFO - 
Configuration s6_n440 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004883898403137743",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n440",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905588
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.98e-07
2024-11-20 18:32:43,883 - INFO - 
Starting training for config s6_n441:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:32:43,883 - INFO - Running command: ./train_gpt2cu -l 0.00012886325512728833 -o hyperband_runs_20241120_172038/run_s6_n441 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:32:53,707 - INFO - Training completed for config s6_n441:
  Training time: 0:00:09
  Final validation loss: 10.910004
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.84e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n441/checkpoint.bin
2024-11-20 18:32:53,707 - INFO - 
Configuration s6_n441 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012886325512728833",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n441",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910004
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.84e-07
2024-11-20 18:32:53,707 - INFO - 
Starting training for config s6_n442:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:32:53,707 - INFO - Running command: ./train_gpt2cu -l 1.1206385547822435e-05 -o hyperband_runs_20241120_172038/run_s6_n442 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:33:03,515 - INFO - Training completed for config s6_n442:
  Training time: 0:00:09
  Final validation loss: 10.911467
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.60e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n442/checkpoint.bin
2024-11-20 18:33:03,515 - INFO - 
Configuration s6_n442 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.1206385547822435e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n442",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911467
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.60e-08
2024-11-20 18:33:03,515 - INFO - 
Starting training for config s6_n443:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:33:03,515 - INFO - Running command: ./train_gpt2cu -l 9.22449097277122e-05 -o hyperband_runs_20241120_172038/run_s6_n443 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:33:13,336 - INFO - Training completed for config s6_n443:
  Training time: 0:00:09
  Final validation loss: 10.910463
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.32e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n443/checkpoint.bin
2024-11-20 18:33:13,336 - INFO - 
Configuration s6_n443 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "9.22449097277122e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n443",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910463
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.32e-07
2024-11-20 18:33:13,336 - INFO - 
Starting training for config s6_n444:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:33:13,337 - INFO - Running command: ./train_gpt2cu -l 1.4762126986935927e-05 -o hyperband_runs_20241120_172038/run_s6_n444 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:33:23,133 - INFO - Training completed for config s6_n444:
  Training time: 0:00:09
  Final validation loss: 10.911427
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.11e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n444/checkpoint.bin
2024-11-20 18:33:23,133 - INFO - 
Configuration s6_n444 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.4762126986935927e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n444",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911427
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.11e-08
2024-11-20 18:33:23,133 - INFO - 
Starting training for config s6_n445:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:33:23,134 - INFO - Running command: ./train_gpt2cu -l 1.8471678655739112e-05 -o hyperband_runs_20241120_172038/run_s6_n445 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:33:32,947 - INFO - Training completed for config s6_n445:
  Training time: 0:00:09
  Final validation loss: 10.911366
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.64e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n445/checkpoint.bin
2024-11-20 18:33:32,947 - INFO - 
Configuration s6_n445 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.8471678655739112e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n445",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911366
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.64e-08
2024-11-20 18:33:32,947 - INFO - 
Starting training for config s6_n446:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:33:32,947 - INFO - Running command: ./train_gpt2cu -l 2.5478275802358845e-05 -o hyperband_runs_20241120_172038/run_s6_n446 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:33:42,740 - INFO - Training completed for config s6_n446:
  Training time: 0:00:09
  Final validation loss: 10.911291
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.64e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n446/checkpoint.bin
2024-11-20 18:33:42,740 - INFO - 
Configuration s6_n446 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.5478275802358845e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n446",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911291
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.64e-08
2024-11-20 18:33:42,740 - INFO - 
Starting training for config s6_n447:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:33:42,740 - INFO - Running command: ./train_gpt2cu -l 7.092807326932441e-05 -o hyperband_runs_20241120_172038/run_s6_n447 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:33:52,545 - INFO - Training completed for config s6_n447:
  Training time: 0:00:09
  Final validation loss: 10.910737
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.01e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n447/checkpoint.bin
2024-11-20 18:33:52,545 - INFO - 
Configuration s6_n447 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.092807326932441e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n447",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910737
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.01e-07
2024-11-20 18:33:52,545 - INFO - 
Starting training for config s6_n448:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:33:52,546 - INFO - Running command: ./train_gpt2cu -l 0.0003632056056840295 -o hyperband_runs_20241120_172038/run_s6_n448 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:34:02,354 - INFO - Training completed for config s6_n448:
  Training time: 0:00:09
  Final validation loss: 10.907140
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.19e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n448/checkpoint.bin
2024-11-20 18:34:02,354 - INFO - 
Configuration s6_n448 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003632056056840295",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n448",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907140
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.19e-07
2024-11-20 18:34:02,354 - INFO - 
Starting training for config s6_n449:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:34:02,355 - INFO - Running command: ./train_gpt2cu -l 0.0004225362112947988 -o hyperband_runs_20241120_172038/run_s6_n449 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:34:12,183 - INFO - Training completed for config s6_n449:
  Training time: 0:00:09
  Final validation loss: 10.906408
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.04e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n449/checkpoint.bin
2024-11-20 18:34:12,183 - INFO - 
Configuration s6_n449 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004225362112947988",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n449",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906408
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.04e-07
2024-11-20 18:34:12,184 - INFO - 
Starting training for config s6_n450:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:34:12,184 - INFO - Running command: ./train_gpt2cu -l 0.0002611813617550704 -o hyperband_runs_20241120_172038/run_s6_n450 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:34:21,973 - INFO - Training completed for config s6_n450:
  Training time: 0:00:09
  Final validation loss: 10.908381
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.73e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n450/checkpoint.bin
2024-11-20 18:34:21,974 - INFO - 
Configuration s6_n450 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002611813617550704",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n450",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908381
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.73e-07
2024-11-20 18:34:21,974 - INFO - 
Starting training for config s6_n451:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:34:21,974 - INFO - Running command: ./train_gpt2cu -l 0.00020862529536761073 -o hyperband_runs_20241120_172038/run_s6_n451 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:34:31,784 - INFO - Training completed for config s6_n451:
  Training time: 0:00:09
  Final validation loss: 10.909035
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.98e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n451/checkpoint.bin
2024-11-20 18:34:31,784 - INFO - 
Configuration s6_n451 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00020862529536761073",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n451",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909035
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.98e-07
2024-11-20 18:34:31,784 - INFO - 
Starting training for config s6_n452:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:34:31,785 - INFO - Running command: ./train_gpt2cu -l 0.0009894839327752709 -o hyperband_runs_20241120_172038/run_s6_n452 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:34:41,616 - INFO - Training completed for config s6_n452:
  Training time: 0:00:09
  Final validation loss: 10.899497
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.41e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin
2024-11-20 18:34:41,616 - INFO - 
Configuration s6_n452 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009894839327752709",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n452",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.899497
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.41e-06
2024-11-20 18:34:41,616 - INFO - 
Starting training for config s6_n453:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:34:41,616 - INFO - Running command: ./train_gpt2cu -l 0.00014976604465973602 -o hyperband_runs_20241120_172038/run_s6_n453 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:34:51,444 - INFO - Training completed for config s6_n453:
  Training time: 0:00:09
  Final validation loss: 10.909746
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.14e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n453/checkpoint.bin
2024-11-20 18:34:51,444 - INFO - 
Configuration s6_n453 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014976604465973602",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n453",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909746
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.14e-07
2024-11-20 18:34:51,444 - INFO - 
Starting training for config s6_n454:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:34:51,445 - INFO - Running command: ./train_gpt2cu -l 0.00019839720733761578 -o hyperband_runs_20241120_172038/run_s6_n454 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:35:01,257 - INFO - Training completed for config s6_n454:
  Training time: 0:00:09
  Final validation loss: 10.909159
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.83e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n454/checkpoint.bin
2024-11-20 18:35:01,257 - INFO - 
Configuration s6_n454 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00019839720733761578",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n454",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909159
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.83e-07
2024-11-20 18:35:01,257 - INFO - 
Starting training for config s6_n455:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:35:01,257 - INFO - Running command: ./train_gpt2cu -l 7.591971791476671e-05 -o hyperband_runs_20241120_172038/run_s6_n455 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:35:11,080 - INFO - Training completed for config s6_n455:
  Training time: 0:00:09
  Final validation loss: 10.910660
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.08e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n455/checkpoint.bin
2024-11-20 18:35:11,080 - INFO - 
Configuration s6_n455 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.591971791476671e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n455",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910660
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.08e-07
2024-11-20 18:35:11,080 - INFO - 
Starting training for config s6_n456:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:35:11,081 - INFO - Running command: ./train_gpt2cu -l 1.4688499008804864e-05 -o hyperband_runs_20241120_172038/run_s6_n456 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:35:20,907 - INFO - Training completed for config s6_n456:
  Training time: 0:00:09
  Final validation loss: 10.911429
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.10e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n456/checkpoint.bin
2024-11-20 18:35:20,907 - INFO - 
Configuration s6_n456 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.4688499008804864e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n456",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911429
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.10e-08
2024-11-20 18:35:20,908 - INFO - 
Starting training for config s6_n457:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:35:20,908 - INFO - Running command: ./train_gpt2cu -l 0.00030734427374176496 -o hyperband_runs_20241120_172038/run_s6_n457 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:35:30,721 - INFO - Training completed for config s6_n457:
  Training time: 0:00:09
  Final validation loss: 10.907814
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.39e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n457/checkpoint.bin
2024-11-20 18:35:30,721 - INFO - 
Configuration s6_n457 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00030734427374176496",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n457",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907814
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.39e-07
2024-11-20 18:35:30,721 - INFO - 
Starting training for config s6_n458:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:35:30,721 - INFO - Running command: ./train_gpt2cu -l 4.8434821442473034e-05 -o hyperband_runs_20241120_172038/run_s6_n458 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:35:40,534 - INFO - Training completed for config s6_n458:
  Training time: 0:00:09
  Final validation loss: 10.911014
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.92e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n458/checkpoint.bin
2024-11-20 18:35:40,534 - INFO - 
Configuration s6_n458 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.8434821442473034e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n458",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911014
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.92e-08
2024-11-20 18:35:40,534 - INFO - 
Starting training for config s6_n459:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:35:40,534 - INFO - Running command: ./train_gpt2cu -l 1.9975100641970355e-05 -o hyperband_runs_20241120_172038/run_s6_n459 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:35:50,348 - INFO - Training completed for config s6_n459:
  Training time: 0:00:09
  Final validation loss: 10.911368
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.85e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n459/checkpoint.bin
2024-11-20 18:35:50,349 - INFO - 
Configuration s6_n459 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.9975100641970355e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n459",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911368
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.85e-08
2024-11-20 18:35:50,349 - INFO - 
Starting training for config s6_n460:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:35:50,349 - INFO - Running command: ./train_gpt2cu -l 0.0008650173683974301 -o hyperband_runs_20241120_172038/run_s6_n460 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:36:00,184 - INFO - Training completed for config s6_n460:
  Training time: 0:00:09
  Final validation loss: 10.900998
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.24e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n460/checkpoint.bin
2024-11-20 18:36:00,184 - INFO - 
Configuration s6_n460 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008650173683974301",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n460",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.900998
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.24e-06
2024-11-20 18:36:00,184 - INFO - 
Starting training for config s6_n461:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:36:00,184 - INFO - Running command: ./train_gpt2cu -l 0.0003298083299883571 -o hyperband_runs_20241120_172038/run_s6_n461 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:36:10,006 - INFO - Training completed for config s6_n461:
  Training time: 0:00:09
  Final validation loss: 10.907528
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.71e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n461/checkpoint.bin
2024-11-20 18:36:10,006 - INFO - 
Configuration s6_n461 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003298083299883571",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n461",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907528
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.71e-07
2024-11-20 18:36:10,006 - INFO - 
Starting training for config s6_n462:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:36:10,006 - INFO - Running command: ./train_gpt2cu -l 0.00037437965100357444 -o hyperband_runs_20241120_172038/run_s6_n462 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:36:19,816 - INFO - Training completed for config s6_n462:
  Training time: 0:00:09
  Final validation loss: 10.906984
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.35e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n462/checkpoint.bin
2024-11-20 18:36:19,816 - INFO - 
Configuration s6_n462 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00037437965100357444",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n462",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906984
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.35e-07
2024-11-20 18:36:19,816 - INFO - 
Starting training for config s6_n463:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:36:19,817 - INFO - Running command: ./train_gpt2cu -l 8.43419687199634e-05 -o hyperband_runs_20241120_172038/run_s6_n463 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:36:29,622 - INFO - Training completed for config s6_n463:
  Training time: 0:00:09
  Final validation loss: 10.910559
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.20e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n463/checkpoint.bin
2024-11-20 18:36:29,622 - INFO - 
Configuration s6_n463 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "8.43419687199634e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n463",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910559
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.20e-07
2024-11-20 18:36:29,622 - INFO - 
Starting training for config s6_n464:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:36:29,623 - INFO - Running command: ./train_gpt2cu -l 0.00028254598780360767 -o hyperband_runs_20241120_172038/run_s6_n464 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:36:39,439 - INFO - Training completed for config s6_n464:
  Training time: 0:00:09
  Final validation loss: 10.908113
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.04e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n464/checkpoint.bin
2024-11-20 18:36:39,439 - INFO - 
Configuration s6_n464 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00028254598780360767",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n464",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908113
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.04e-07
2024-11-20 18:36:39,439 - INFO - 
Starting training for config s6_n465:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:36:39,439 - INFO - Running command: ./train_gpt2cu -l 0.0004596267992803697 -o hyperband_runs_20241120_172038/run_s6_n465 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:36:49,248 - INFO - Training completed for config s6_n465:
  Training time: 0:00:09
  Final validation loss: 10.905952
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.57e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n465/checkpoint.bin
2024-11-20 18:36:49,248 - INFO - 
Configuration s6_n465 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004596267992803697",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n465",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905952
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.57e-07
2024-11-20 18:36:49,248 - INFO - 
Starting training for config s6_n466:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:36:49,249 - INFO - Running command: ./train_gpt2cu -l 4.9386469528398384e-05 -o hyperband_runs_20241120_172038/run_s6_n466 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:36:59,045 - INFO - Training completed for config s6_n466:
  Training time: 0:00:09
  Final validation loss: 10.911007
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.06e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n466/checkpoint.bin
2024-11-20 18:36:59,046 - INFO - 
Configuration s6_n466 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.9386469528398384e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n466",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911007
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.06e-08
2024-11-20 18:36:59,046 - INFO - 
Starting training for config s6_n467:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:36:59,046 - INFO - Running command: ./train_gpt2cu -l 0.0007548680660404933 -o hyperband_runs_20241120_172038/run_s6_n467 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:37:08,867 - INFO - Training completed for config s6_n467:
  Training time: 0:00:09
  Final validation loss: 10.902349
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.08e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n467/checkpoint.bin
2024-11-20 18:37:08,868 - INFO - 
Configuration s6_n467 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007548680660404933",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n467",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.902349
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.08e-06
2024-11-20 18:37:08,868 - INFO - 
Starting training for config s6_n468:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:37:08,868 - INFO - Running command: ./train_gpt2cu -l 9.259400087664964e-05 -o hyperband_runs_20241120_172038/run_s6_n468 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:37:18,667 - INFO - Training completed for config s6_n468:
  Training time: 0:00:09
  Final validation loss: 10.910454
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.32e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n468/checkpoint.bin
2024-11-20 18:37:18,667 - INFO - 
Configuration s6_n468 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "9.259400087664964e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n468",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910454
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.32e-07
2024-11-20 18:37:18,668 - INFO - 
Starting training for config s6_n469:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:37:18,668 - INFO - Running command: ./train_gpt2cu -l 6.953047293710421e-05 -o hyperband_runs_20241120_172038/run_s6_n469 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:37:28,476 - INFO - Training completed for config s6_n469:
  Training time: 0:00:09
  Final validation loss: 10.910739
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.93e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n469/checkpoint.bin
2024-11-20 18:37:28,476 - INFO - 
Configuration s6_n469 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.953047293710421e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n469",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910739
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.93e-08
2024-11-20 18:37:28,476 - INFO - 
Starting training for config s6_n470:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:37:28,477 - INFO - Running command: ./train_gpt2cu -l 8.877986820521167e-05 -o hyperband_runs_20241120_172038/run_s6_n470 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:37:38,279 - INFO - Training completed for config s6_n470:
  Training time: 0:00:09
  Final validation loss: 10.910505
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.27e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n470/checkpoint.bin
2024-11-20 18:37:38,279 - INFO - 
Configuration s6_n470 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "8.877986820521167e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n470",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910505
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.27e-07
2024-11-20 18:37:38,279 - INFO - 
Starting training for config s6_n471:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:37:38,280 - INFO - Running command: ./train_gpt2cu -l 7.107191850371225e-05 -o hyperband_runs_20241120_172038/run_s6_n471 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:37:48,087 - INFO - Training completed for config s6_n471:
  Training time: 0:00:09
  Final validation loss: 10.910719
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.02e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n471/checkpoint.bin
2024-11-20 18:37:48,087 - INFO - 
Configuration s6_n471 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.107191850371225e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n471",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910719
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-07
2024-11-20 18:37:48,087 - INFO - 
Starting training for config s6_n472:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:37:48,087 - INFO - Running command: ./train_gpt2cu -l 0.0006271523394724145 -o hyperband_runs_20241120_172038/run_s6_n472 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:37:57,891 - INFO - Training completed for config s6_n472:
  Training time: 0:00:09
  Final validation loss: 10.903894
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.96e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n472/checkpoint.bin
2024-11-20 18:37:57,891 - INFO - 
Configuration s6_n472 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006271523394724145",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n472",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.903894
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.96e-07
2024-11-20 18:37:57,891 - INFO - 
Starting training for config s6_n473:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:37:57,892 - INFO - Running command: ./train_gpt2cu -l 0.0001575651004260464 -o hyperband_runs_20241120_172038/run_s6_n473 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:38:07,696 - INFO - Training completed for config s6_n473:
  Training time: 0:00:09
  Final validation loss: 10.909643
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.25e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n473/checkpoint.bin
2024-11-20 18:38:07,696 - INFO - 
Configuration s6_n473 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001575651004260464",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n473",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909643
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.25e-07
2024-11-20 18:38:07,697 - INFO - 
Starting training for config s6_n474:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:38:07,697 - INFO - Running command: ./train_gpt2cu -l 1.2340719829425106e-05 -o hyperband_runs_20241120_172038/run_s6_n474 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:38:17,511 - INFO - Training completed for config s6_n474:
  Training time: 0:00:09
  Final validation loss: 10.911455
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.76e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n474/checkpoint.bin
2024-11-20 18:38:17,512 - INFO - 
Configuration s6_n474 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.2340719829425106e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n474",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911455
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.76e-08
2024-11-20 18:38:17,512 - INFO - 
Starting training for config s6_n475:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:38:17,512 - INFO - Running command: ./train_gpt2cu -l 0.0005673052098845844 -o hyperband_runs_20241120_172038/run_s6_n475 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:38:27,318 - INFO - Training completed for config s6_n475:
  Training time: 0:00:09
  Final validation loss: 10.904643
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.10e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n475/checkpoint.bin
2024-11-20 18:38:27,318 - INFO - 
Configuration s6_n475 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005673052098845844",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n475",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904643
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.10e-07
2024-11-20 18:38:27,318 - INFO - 
Starting training for config s6_n476:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:38:27,318 - INFO - Running command: ./train_gpt2cu -l 3.074918551129432e-05 -o hyperband_runs_20241120_172038/run_s6_n476 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:38:37,119 - INFO - Training completed for config s6_n476:
  Training time: 0:00:09
  Final validation loss: 10.911227
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.39e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n476/checkpoint.bin
2024-11-20 18:38:37,119 - INFO - 
Configuration s6_n476 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.074918551129432e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n476",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911227
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.39e-08
2024-11-20 18:38:37,119 - INFO - 
Starting training for config s6_n477:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:38:37,119 - INFO - Running command: ./train_gpt2cu -l 6.402280236502774e-05 -o hyperband_runs_20241120_172038/run_s6_n477 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:38:46,933 - INFO - Training completed for config s6_n477:
  Training time: 0:00:09
  Final validation loss: 10.910814
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.15e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n477/checkpoint.bin
2024-11-20 18:38:46,933 - INFO - 
Configuration s6_n477 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.402280236502774e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n477",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910814
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.15e-08
2024-11-20 18:38:46,933 - INFO - 
Starting training for config s6_n478:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:38:46,933 - INFO - Running command: ./train_gpt2cu -l 0.00020014217262087663 -o hyperband_runs_20241120_172038/run_s6_n478 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:38:56,726 - INFO - Training completed for config s6_n478:
  Training time: 0:00:09
  Final validation loss: 10.909124
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.86e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n478/checkpoint.bin
2024-11-20 18:38:56,726 - INFO - 
Configuration s6_n478 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00020014217262087663",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n478",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909124
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.86e-07
2024-11-20 18:38:56,726 - INFO - 
Starting training for config s6_n479:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:38:56,726 - INFO - Running command: ./train_gpt2cu -l 0.0003052601124736334 -o hyperband_runs_20241120_172038/run_s6_n479 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:39:06,526 - INFO - Training completed for config s6_n479:
  Training time: 0:00:09
  Final validation loss: 10.907827
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.36e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n479/checkpoint.bin
2024-11-20 18:39:06,527 - INFO - 
Configuration s6_n479 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003052601124736334",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n479",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907827
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.36e-07
2024-11-20 18:39:06,527 - INFO - 
Starting training for config s6_n480:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:39:06,527 - INFO - Running command: ./train_gpt2cu -l 3.0216166843053533e-05 -o hyperband_runs_20241120_172038/run_s6_n480 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:39:16,323 - INFO - Training completed for config s6_n480:
  Training time: 0:00:09
  Final validation loss: 10.911251
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.32e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n480/checkpoint.bin
2024-11-20 18:39:16,324 - INFO - 
Configuration s6_n480 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.0216166843053533e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n480",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911251
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.32e-08
2024-11-20 18:39:16,324 - INFO - 
Starting training for config s6_n481:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:39:16,324 - INFO - Running command: ./train_gpt2cu -l 1.5185339628806665e-05 -o hyperband_runs_20241120_172038/run_s6_n481 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:39:26,148 - INFO - Training completed for config s6_n481:
  Training time: 0:00:09
  Final validation loss: 10.911411
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.17e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n481/checkpoint.bin
2024-11-20 18:39:26,148 - INFO - 
Configuration s6_n481 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.5185339628806665e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n481",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911411
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.17e-08
2024-11-20 18:39:26,148 - INFO - 
Starting training for config s6_n482:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:39:26,148 - INFO - Running command: ./train_gpt2cu -l 6.910490017977749e-05 -o hyperband_runs_20241120_172038/run_s6_n482 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:39:35,946 - INFO - Training completed for config s6_n482:
  Training time: 0:00:09
  Final validation loss: 10.910758
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.87e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n482/checkpoint.bin
2024-11-20 18:39:35,947 - INFO - 
Configuration s6_n482 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.910490017977749e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n482",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910758
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.87e-08
2024-11-20 18:39:35,947 - INFO - 
Starting training for config s6_n483:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:39:35,947 - INFO - Running command: ./train_gpt2cu -l 0.00014728703238723286 -o hyperband_runs_20241120_172038/run_s6_n483 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:39:45,753 - INFO - Training completed for config s6_n483:
  Training time: 0:00:09
  Final validation loss: 10.909775
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.10e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n483/checkpoint.bin
2024-11-20 18:39:45,753 - INFO - 
Configuration s6_n483 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014728703238723286",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n483",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909775
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.10e-07
2024-11-20 18:39:45,753 - INFO - 
Starting training for config s6_n484:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:39:45,753 - INFO - Running command: ./train_gpt2cu -l 1.755147736253365e-05 -o hyperband_runs_20241120_172038/run_s6_n484 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:39:55,572 - INFO - Training completed for config s6_n484:
  Training time: 0:00:09
  Final validation loss: 10.911385
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.51e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n484/checkpoint.bin
2024-11-20 18:39:55,573 - INFO - 
Configuration s6_n484 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.755147736253365e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n484",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911385
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.51e-08
2024-11-20 18:39:55,573 - INFO - 
Starting training for config s6_n485:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:39:55,573 - INFO - Running command: ./train_gpt2cu -l 3.3112839367109466e-05 -o hyperband_runs_20241120_172038/run_s6_n485 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:40:05,406 - INFO - Training completed for config s6_n485:
  Training time: 0:00:09
  Final validation loss: 10.911219
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.73e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n485/checkpoint.bin
2024-11-20 18:40:05,406 - INFO - 
Configuration s6_n485 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.3112839367109466e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n485",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911219
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.73e-08
2024-11-20 18:40:05,406 - INFO - 
Starting training for config s6_n486:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:40:05,406 - INFO - Running command: ./train_gpt2cu -l 0.00015286893660043896 -o hyperband_runs_20241120_172038/run_s6_n486 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:40:15,222 - INFO - Training completed for config s6_n486:
  Training time: 0:00:09
  Final validation loss: 10.909719
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.18e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n486/checkpoint.bin
2024-11-20 18:40:15,222 - INFO - 
Configuration s6_n486 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00015286893660043896",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n486",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909719
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.18e-07
2024-11-20 18:40:15,222 - INFO - 
Starting training for config s6_n487:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:40:15,222 - INFO - Running command: ./train_gpt2cu -l 0.00026011422853031846 -o hyperband_runs_20241120_172038/run_s6_n487 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:40:25,031 - INFO - Training completed for config s6_n487:
  Training time: 0:00:09
  Final validation loss: 10.908387
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.72e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n487/checkpoint.bin
2024-11-20 18:40:25,031 - INFO - 
Configuration s6_n487 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00026011422853031846",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n487",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908387
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.72e-07
2024-11-20 18:40:25,031 - INFO - 
Starting training for config s6_n488:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:40:25,032 - INFO - Running command: ./train_gpt2cu -l 0.0001342860025942153 -o hyperband_runs_20241120_172038/run_s6_n488 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:40:34,866 - INFO - Training completed for config s6_n488:
  Training time: 0:00:09
  Final validation loss: 10.909932
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.92e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n488/checkpoint.bin
2024-11-20 18:40:34,866 - INFO - 
Configuration s6_n488 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001342860025942153",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n488",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909932
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.92e-07
2024-11-20 18:40:34,866 - INFO - 
Starting training for config s6_n489:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:40:34,866 - INFO - Running command: ./train_gpt2cu -l 5.673275969797488e-05 -o hyperband_runs_20241120_172038/run_s6_n489 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:40:44,677 - INFO - Training completed for config s6_n489:
  Training time: 0:00:09
  Final validation loss: 10.910925
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.10e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n489/checkpoint.bin
2024-11-20 18:40:44,677 - INFO - 
Configuration s6_n489 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.673275969797488e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n489",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910925
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.10e-08
2024-11-20 18:40:44,677 - INFO - 
Starting training for config s6_n490:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:40:44,677 - INFO - Running command: ./train_gpt2cu -l 0.0009437860734729266 -o hyperband_runs_20241120_172038/run_s6_n490 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:40:54,474 - INFO - Training completed for config s6_n490:
  Training time: 0:00:09
  Final validation loss: 10.900056
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.35e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n490/checkpoint.bin
2024-11-20 18:40:54,474 - INFO - 
Configuration s6_n490 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009437860734729266",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n490",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.900056
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.35e-06
2024-11-20 18:40:54,474 - INFO - 
Starting training for config s6_n491:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:40:54,474 - INFO - Running command: ./train_gpt2cu -l 0.00010283472415028277 -o hyperband_runs_20241120_172038/run_s6_n491 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:41:04,264 - INFO - Training completed for config s6_n491:
  Training time: 0:00:09
  Final validation loss: 10.910322
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.47e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n491/checkpoint.bin
2024-11-20 18:41:04,264 - INFO - 
Configuration s6_n491 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010283472415028277",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n491",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910322
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.47e-07
2024-11-20 18:41:04,264 - INFO - 
Starting training for config s6_n492:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:41:04,264 - INFO - Running command: ./train_gpt2cu -l 1.0849703482675717e-05 -o hyperband_runs_20241120_172038/run_s6_n492 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:41:14,093 - INFO - Training completed for config s6_n492:
  Training time: 0:00:09
  Final validation loss: 10.911463
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.55e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n492/checkpoint.bin
2024-11-20 18:41:14,094 - INFO - 
Configuration s6_n492 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.0849703482675717e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n492",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911463
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.55e-08
2024-11-20 18:41:14,094 - INFO - 
Starting training for config s6_n493:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:41:14,094 - INFO - Running command: ./train_gpt2cu -l 1.1408428315522926e-05 -o hyperband_runs_20241120_172038/run_s6_n493 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:41:23,898 - INFO - Training completed for config s6_n493:
  Training time: 0:00:09
  Final validation loss: 10.911458
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.63e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n493/checkpoint.bin
2024-11-20 18:41:23,898 - INFO - 
Configuration s6_n493 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.1408428315522926e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n493",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911458
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.63e-08
2024-11-20 18:41:23,898 - INFO - 
Starting training for config s6_n494:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:41:23,898 - INFO - Running command: ./train_gpt2cu -l 1.1466894158237282e-05 -o hyperband_runs_20241120_172038/run_s6_n494 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:41:33,691 - INFO - Training completed for config s6_n494:
  Training time: 0:00:09
  Final validation loss: 10.911461
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.64e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n494/checkpoint.bin
2024-11-20 18:41:33,692 - INFO - 
Configuration s6_n494 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.1466894158237282e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n494",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911461
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.64e-08
2024-11-20 18:41:33,692 - INFO - 
Starting training for config s6_n495:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:41:33,692 - INFO - Running command: ./train_gpt2cu -l 0.00017941582293922763 -o hyperband_runs_20241120_172038/run_s6_n495 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:41:43,499 - INFO - Training completed for config s6_n495:
  Training time: 0:00:09
  Final validation loss: 10.909381
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.56e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n495/checkpoint.bin
2024-11-20 18:41:43,499 - INFO - 
Configuration s6_n495 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00017941582293922763",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n495",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909381
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.56e-07
2024-11-20 18:41:43,499 - INFO - 
Starting training for config s6_n496:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:41:43,500 - INFO - Running command: ./train_gpt2cu -l 0.0009743088881485038 -o hyperband_runs_20241120_172038/run_s6_n496 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:41:53,306 - INFO - Training completed for config s6_n496:
  Training time: 0:00:09
  Final validation loss: 10.899687
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.39e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin
2024-11-20 18:41:53,307 - INFO - 
Configuration s6_n496 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009743088881485038",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n496",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.899687
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.39e-06
2024-11-20 18:41:53,307 - INFO - 
Starting training for config s6_n497:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:41:53,307 - INFO - Running command: ./train_gpt2cu -l 0.00044103078901548763 -o hyperband_runs_20241120_172038/run_s6_n497 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:42:03,114 - INFO - Training completed for config s6_n497:
  Training time: 0:00:09
  Final validation loss: 10.906164
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.30e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n497/checkpoint.bin
2024-11-20 18:42:03,115 - INFO - 
Configuration s6_n497 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00044103078901548763",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n497",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906164
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.30e-07
2024-11-20 18:42:03,115 - INFO - 
Starting training for config s6_n498:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:42:03,115 - INFO - Running command: ./train_gpt2cu -l 5.670939503151214e-05 -o hyperband_runs_20241120_172038/run_s6_n498 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:42:12,929 - INFO - Training completed for config s6_n498:
  Training time: 0:00:09
  Final validation loss: 10.910902
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.10e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n498/checkpoint.bin
2024-11-20 18:42:12,929 - INFO - 
Configuration s6_n498 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.670939503151214e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n498",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910902
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.10e-08
2024-11-20 18:42:12,929 - INFO - 
Starting training for config s6_n499:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:42:12,930 - INFO - Running command: ./train_gpt2cu -l 8.2303890194231e-05 -o hyperband_runs_20241120_172038/run_s6_n499 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:42:22,734 - INFO - Training completed for config s6_n499:
  Training time: 0:00:09
  Final validation loss: 10.910579
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.18e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n499/checkpoint.bin
2024-11-20 18:42:22,734 - INFO - 
Configuration s6_n499 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "8.2303890194231e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n499",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910579
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.18e-07
2024-11-20 18:42:22,734 - INFO - 
Starting training for config s6_n500:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:42:22,734 - INFO - Running command: ./train_gpt2cu -l 1.69794677662123e-05 -o hyperband_runs_20241120_172038/run_s6_n500 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:42:32,527 - INFO - Training completed for config s6_n500:
  Training time: 0:00:09
  Final validation loss: 10.911391
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.43e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n500/checkpoint.bin
2024-11-20 18:42:32,527 - INFO - 
Configuration s6_n500 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.69794677662123e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n500",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911391
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.43e-08
2024-11-20 18:42:32,527 - INFO - 
Starting training for config s6_n501:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:42:32,527 - INFO - Running command: ./train_gpt2cu -l 4.86562495254897e-05 -o hyperband_runs_20241120_172038/run_s6_n501 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:42:42,325 - INFO - Training completed for config s6_n501:
  Training time: 0:00:09
  Final validation loss: 10.911005
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.95e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n501/checkpoint.bin
2024-11-20 18:42:42,325 - INFO - 
Configuration s6_n501 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.86562495254897e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n501",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911005
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.95e-08
2024-11-20 18:42:42,325 - INFO - 
Starting training for config s6_n502:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:42:42,326 - INFO - Running command: ./train_gpt2cu -l 0.00021886629442122976 -o hyperband_runs_20241120_172038/run_s6_n502 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:42:52,121 - INFO - Training completed for config s6_n502:
  Training time: 0:00:09
  Final validation loss: 10.908903
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.13e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n502/checkpoint.bin
2024-11-20 18:42:52,121 - INFO - 
Configuration s6_n502 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00021886629442122976",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n502",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908903
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.13e-07
2024-11-20 18:42:52,121 - INFO - 
Starting training for config s6_n503:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:42:52,121 - INFO - Running command: ./train_gpt2cu -l 1.898160413483254e-05 -o hyperband_runs_20241120_172038/run_s6_n503 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:43:01,924 - INFO - Training completed for config s6_n503:
  Training time: 0:00:09
  Final validation loss: 10.911373
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.71e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n503/checkpoint.bin
2024-11-20 18:43:01,924 - INFO - 
Configuration s6_n503 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.898160413483254e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n503",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911373
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.71e-08
2024-11-20 18:43:01,924 - INFO - 
Starting training for config s6_n504:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:43:01,924 - INFO - Running command: ./train_gpt2cu -l 1.806051993122544e-05 -o hyperband_runs_20241120_172038/run_s6_n504 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:43:11,735 - INFO - Training completed for config s6_n504:
  Training time: 0:00:09
  Final validation loss: 10.911385
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.58e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n504/checkpoint.bin
2024-11-20 18:43:11,735 - INFO - 
Configuration s6_n504 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.806051993122544e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n504",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911385
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.58e-08
2024-11-20 18:43:11,735 - INFO - 
Starting training for config s6_n505:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:43:11,735 - INFO - Running command: ./train_gpt2cu -l 0.0002292244764947636 -o hyperband_runs_20241120_172038/run_s6_n505 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:43:21,534 - INFO - Training completed for config s6_n505:
  Training time: 0:00:09
  Final validation loss: 10.908778
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.27e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n505/checkpoint.bin
2024-11-20 18:43:21,534 - INFO - 
Configuration s6_n505 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002292244764947636",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n505",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908778
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.27e-07
2024-11-20 18:43:21,534 - INFO - 
Starting training for config s6_n506:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:43:21,534 - INFO - Running command: ./train_gpt2cu -l 2.9068816245306063e-05 -o hyperband_runs_20241120_172038/run_s6_n506 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:43:31,310 - INFO - Training completed for config s6_n506:
  Training time: 0:00:09
  Final validation loss: 10.911249
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.15e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n506/checkpoint.bin
2024-11-20 18:43:31,311 - INFO - 
Configuration s6_n506 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.9068816245306063e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n506",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911249
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.15e-08
2024-11-20 18:43:31,311 - INFO - 
Starting training for config s6_n507:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:43:31,311 - INFO - Running command: ./train_gpt2cu -l 3.056744716309168e-05 -o hyperband_runs_20241120_172038/run_s6_n507 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:43:41,116 - INFO - Training completed for config s6_n507:
  Training time: 0:00:09
  Final validation loss: 10.911236
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.37e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n507/checkpoint.bin
2024-11-20 18:43:41,116 - INFO - 
Configuration s6_n507 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.056744716309168e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n507",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911236
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.37e-08
2024-11-20 18:43:41,117 - INFO - 
Starting training for config s6_n508:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:43:41,117 - INFO - Running command: ./train_gpt2cu -l 8.388123679936628e-05 -o hyperband_runs_20241120_172038/run_s6_n508 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:43:50,925 - INFO - Training completed for config s6_n508:
  Training time: 0:00:09
  Final validation loss: 10.910560
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.20e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n508/checkpoint.bin
2024-11-20 18:43:50,926 - INFO - 
Configuration s6_n508 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "8.388123679936628e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n508",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910560
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.20e-07
2024-11-20 18:43:50,926 - INFO - 
Starting training for config s6_n509:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:43:50,926 - INFO - Running command: ./train_gpt2cu -l 1.5571932217272492e-05 -o hyperband_runs_20241120_172038/run_s6_n509 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:44:00,750 - INFO - Training completed for config s6_n509:
  Training time: 0:00:09
  Final validation loss: 10.911418
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.22e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n509/checkpoint.bin
2024-11-20 18:44:00,750 - INFO - 
Configuration s6_n509 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.5571932217272492e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n509",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911418
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.22e-08
2024-11-20 18:44:00,750 - INFO - 
Starting training for config s6_n510:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:44:00,750 - INFO - Running command: ./train_gpt2cu -l 0.000574514524099536 -o hyperband_runs_20241120_172038/run_s6_n510 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:44:10,563 - INFO - Training completed for config s6_n510:
  Training time: 0:00:09
  Final validation loss: 10.904540
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.21e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n510/checkpoint.bin
2024-11-20 18:44:10,563 - INFO - 
Configuration s6_n510 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000574514524099536",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n510",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904540
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.21e-07
2024-11-20 18:44:10,563 - INFO - 
Starting training for config s6_n511:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:44:10,563 - INFO - Running command: ./train_gpt2cu -l 1.4445503275739688e-05 -o hyperband_runs_20241120_172038/run_s6_n511 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:44:20,380 - INFO - Training completed for config s6_n511:
  Training time: 0:00:09
  Final validation loss: 10.911427
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.06e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n511/checkpoint.bin
2024-11-20 18:44:20,380 - INFO - 
Configuration s6_n511 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.4445503275739688e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n511",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911427
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.06e-08
2024-11-20 18:44:20,380 - INFO - 
Starting training for config s6_n512:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:44:20,381 - INFO - Running command: ./train_gpt2cu -l 0.0004282236002425996 -o hyperband_runs_20241120_172038/run_s6_n512 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:44:30,217 - INFO - Training completed for config s6_n512:
  Training time: 0:00:09
  Final validation loss: 10.906335
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.12e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n512/checkpoint.bin
2024-11-20 18:44:30,217 - INFO - 
Configuration s6_n512 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004282236002425996",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n512",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906335
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.12e-07
2024-11-20 18:44:30,218 - INFO - 
Starting training for config s6_n513:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:44:30,218 - INFO - Running command: ./train_gpt2cu -l 7.306581333145128e-05 -o hyperband_runs_20241120_172038/run_s6_n513 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:44:40,045 - INFO - Training completed for config s6_n513:
  Training time: 0:00:09
  Final validation loss: 10.910699
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.04e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n513/checkpoint.bin
2024-11-20 18:44:40,045 - INFO - 
Configuration s6_n513 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.306581333145128e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n513",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910699
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.04e-07
2024-11-20 18:44:40,045 - INFO - 
Starting training for config s6_n514:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:44:40,046 - INFO - Running command: ./train_gpt2cu -l 4.1155729622356105e-05 -o hyperband_runs_20241120_172038/run_s6_n514 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:44:49,857 - INFO - Training completed for config s6_n514:
  Training time: 0:00:09
  Final validation loss: 10.911112
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.88e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n514/checkpoint.bin
2024-11-20 18:44:49,857 - INFO - 
Configuration s6_n514 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.1155729622356105e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n514",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911112
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.88e-08
2024-11-20 18:44:49,857 - INFO - 
Starting training for config s6_n515:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:44:49,857 - INFO - Running command: ./train_gpt2cu -l 1.2026988738705591e-05 -o hyperband_runs_20241120_172038/run_s6_n515 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:44:59,671 - INFO - Training completed for config s6_n515:
  Training time: 0:00:09
  Final validation loss: 10.911466
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.72e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n515/checkpoint.bin
2024-11-20 18:44:59,672 - INFO - 
Configuration s6_n515 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.2026988738705591e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n515",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911466
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.72e-08
2024-11-20 18:44:59,672 - INFO - 
Starting training for config s6_n516:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:44:59,672 - INFO - Running command: ./train_gpt2cu -l 0.0006409848656735655 -o hyperband_runs_20241120_172038/run_s6_n516 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:45:09,489 - INFO - Training completed for config s6_n516:
  Training time: 0:00:09
  Final validation loss: 10.903734
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.16e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n516/checkpoint.bin
2024-11-20 18:45:09,490 - INFO - 
Configuration s6_n516 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006409848656735655",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n516",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.903734
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.16e-07
2024-11-20 18:45:09,490 - INFO - 
Starting training for config s6_n517:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:45:09,490 - INFO - Running command: ./train_gpt2cu -l 4.927329939039188e-05 -o hyperband_runs_20241120_172038/run_s6_n517 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:45:19,300 - INFO - Training completed for config s6_n517:
  Training time: 0:00:09
  Final validation loss: 10.911015
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.04e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n517/checkpoint.bin
2024-11-20 18:45:19,300 - INFO - 
Configuration s6_n517 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.927329939039188e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n517",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911015
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.04e-08
2024-11-20 18:45:19,300 - INFO - 
Starting training for config s6_n518:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:45:19,300 - INFO - Running command: ./train_gpt2cu -l 0.0001988154731887732 -o hyperband_runs_20241120_172038/run_s6_n518 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:45:29,103 - INFO - Training completed for config s6_n518:
  Training time: 0:00:09
  Final validation loss: 10.909149
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.84e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n518/checkpoint.bin
2024-11-20 18:45:29,103 - INFO - 
Configuration s6_n518 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001988154731887732",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n518",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909149
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.84e-07
2024-11-20 18:45:29,103 - INFO - 
Starting training for config s6_n519:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:45:29,104 - INFO - Running command: ./train_gpt2cu -l 0.00040540489309619183 -o hyperband_runs_20241120_172038/run_s6_n519 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:45:38,927 - INFO - Training completed for config s6_n519:
  Training time: 0:00:09
  Final validation loss: 10.906599
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.79e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n519/checkpoint.bin
2024-11-20 18:45:38,927 - INFO - 
Configuration s6_n519 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00040540489309619183",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n519",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906599
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.79e-07
2024-11-20 18:45:38,927 - INFO - 
Starting training for config s6_n520:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:45:38,928 - INFO - Running command: ./train_gpt2cu -l 0.0007030878468635916 -o hyperband_runs_20241120_172038/run_s6_n520 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:45:48,737 - INFO - Training completed for config s6_n520:
  Training time: 0:00:09
  Final validation loss: 10.902978
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.00e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n520/checkpoint.bin
2024-11-20 18:45:48,738 - INFO - 
Configuration s6_n520 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007030878468635916",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n520",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.902978
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.00e-06
2024-11-20 18:45:48,738 - INFO - 
Starting training for config s6_n521:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:45:48,738 - INFO - Running command: ./train_gpt2cu -l 0.0001000131036640262 -o hyperband_runs_20241120_172038/run_s6_n521 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:45:58,553 - INFO - Training completed for config s6_n521:
  Training time: 0:00:09
  Final validation loss: 10.910360
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.43e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n521/checkpoint.bin
2024-11-20 18:45:58,553 - INFO - 
Configuration s6_n521 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001000131036640262",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n521",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910360
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.43e-07
2024-11-20 18:45:58,553 - INFO - 
Starting training for config s6_n522:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:45:58,554 - INFO - Running command: ./train_gpt2cu -l 0.000671880458880737 -o hyperband_runs_20241120_172038/run_s6_n522 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:46:08,358 - INFO - Training completed for config s6_n522:
  Training time: 0:00:09
  Final validation loss: 10.903358
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.60e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n522/checkpoint.bin
2024-11-20 18:46:08,358 - INFO - 
Configuration s6_n522 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000671880458880737",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n522",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.903358
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.60e-07
2024-11-20 18:46:08,358 - INFO - 
Starting training for config s6_n523:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:46:08,358 - INFO - Running command: ./train_gpt2cu -l 0.0006721463416277697 -o hyperband_runs_20241120_172038/run_s6_n523 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:46:18,163 - INFO - Training completed for config s6_n523:
  Training time: 0:00:09
  Final validation loss: 10.903358
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.60e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n523/checkpoint.bin
2024-11-20 18:46:18,164 - INFO - 
Configuration s6_n523 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006721463416277697",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n523",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.903358
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.60e-07
2024-11-20 18:46:18,164 - INFO - 
Starting training for config s6_n524:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:46:18,164 - INFO - Running command: ./train_gpt2cu -l 1.9430927440445804e-05 -o hyperband_runs_20241120_172038/run_s6_n524 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:46:27,988 - INFO - Training completed for config s6_n524:
  Training time: 0:00:09
  Final validation loss: 10.911364
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.78e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n524/checkpoint.bin
2024-11-20 18:46:27,988 - INFO - 
Configuration s6_n524 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.9430927440445804e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n524",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911364
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.78e-08
2024-11-20 18:46:27,988 - INFO - 
Starting training for config s6_n525:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:46:27,988 - INFO - Running command: ./train_gpt2cu -l 1.845789720082558e-05 -o hyperband_runs_20241120_172038/run_s6_n525 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:46:37,791 - INFO - Training completed for config s6_n525:
  Training time: 0:00:09
  Final validation loss: 10.911377
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.64e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n525/checkpoint.bin
2024-11-20 18:46:37,791 - INFO - 
Configuration s6_n525 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.845789720082558e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n525",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911377
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.64e-08
2024-11-20 18:46:37,791 - INFO - 
Starting training for config s6_n526:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:46:37,791 - INFO - Running command: ./train_gpt2cu -l 1.5677038243657724e-05 -o hyperband_runs_20241120_172038/run_s6_n526 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:46:47,594 - INFO - Training completed for config s6_n526:
  Training time: 0:00:09
  Final validation loss: 10.911407
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.24e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n526/checkpoint.bin
2024-11-20 18:46:47,594 - INFO - 
Configuration s6_n526 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.5677038243657724e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n526",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911407
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.24e-08
2024-11-20 18:46:47,594 - INFO - 
Starting training for config s6_n527:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:46:47,594 - INFO - Running command: ./train_gpt2cu -l 0.00013097049786896294 -o hyperband_runs_20241120_172038/run_s6_n527 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:46:57,395 - INFO - Training completed for config s6_n527:
  Training time: 0:00:09
  Final validation loss: 10.909987
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.87e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n527/checkpoint.bin
2024-11-20 18:46:57,395 - INFO - 
Configuration s6_n527 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013097049786896294",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n527",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909987
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.87e-07
2024-11-20 18:46:57,395 - INFO - 
Starting training for config s6_n528:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:46:57,395 - INFO - Running command: ./train_gpt2cu -l 4.995962645354262e-05 -o hyperband_runs_20241120_172038/run_s6_n528 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:47:07,243 - INFO - Training completed for config s6_n528:
  Training time: 0:00:09
  Final validation loss: 10.911003
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.14e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n528/checkpoint.bin
2024-11-20 18:47:07,243 - INFO - 
Configuration s6_n528 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.995962645354262e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n528",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911003
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.14e-08
2024-11-20 18:47:07,243 - INFO - 
Starting training for config s6_n529:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:47:07,243 - INFO - Running command: ./train_gpt2cu -l 1.139747452310268e-05 -o hyperband_runs_20241120_172038/run_s6_n529 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:47:17,039 - INFO - Training completed for config s6_n529:
  Training time: 0:00:09
  Final validation loss: 10.911465
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.63e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n529/checkpoint.bin
2024-11-20 18:47:17,039 - INFO - 
Configuration s6_n529 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.139747452310268e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n529",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911465
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.63e-08
2024-11-20 18:47:17,039 - INFO - 
Starting training for config s6_n530:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:47:17,040 - INFO - Running command: ./train_gpt2cu -l 1.8549917939404458e-05 -o hyperband_runs_20241120_172038/run_s6_n530 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:47:26,839 - INFO - Training completed for config s6_n530:
  Training time: 0:00:09
  Final validation loss: 10.911373
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.65e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n530/checkpoint.bin
2024-11-20 18:47:26,839 - INFO - 
Configuration s6_n530 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.8549917939404458e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n530",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911373
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.65e-08
2024-11-20 18:47:26,839 - INFO - 
Starting training for config s6_n531:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:47:26,840 - INFO - Running command: ./train_gpt2cu -l 0.0005692004594422224 -o hyperband_runs_20241120_172038/run_s6_n531 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:47:36,643 - INFO - Training completed for config s6_n531:
  Training time: 0:00:09
  Final validation loss: 10.904619
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.13e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n531/checkpoint.bin
2024-11-20 18:47:36,645 - INFO - 
Configuration s6_n531 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005692004594422224",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n531",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904619
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.13e-07
2024-11-20 18:47:36,645 - INFO - 
Starting training for config s6_n532:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:47:36,645 - INFO - Running command: ./train_gpt2cu -l 3.3404739502288046e-05 -o hyperband_runs_20241120_172038/run_s6_n532 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:47:46,463 - INFO - Training completed for config s6_n532:
  Training time: 0:00:09
  Final validation loss: 10.911207
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.77e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n532/checkpoint.bin
2024-11-20 18:47:46,463 - INFO - 
Configuration s6_n532 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.3404739502288046e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n532",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911207
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.77e-08
2024-11-20 18:47:46,463 - INFO - 
Starting training for config s6_n533:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:47:46,464 - INFO - Running command: ./train_gpt2cu -l 0.0005995598841000959 -o hyperband_runs_20241120_172038/run_s6_n533 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:47:56,255 - INFO - Training completed for config s6_n533:
  Training time: 0:00:09
  Final validation loss: 10.904239
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.57e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n533/checkpoint.bin
2024-11-20 18:47:56,255 - INFO - 
Configuration s6_n533 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005995598841000959",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n533",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904239
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.57e-07
2024-11-20 18:47:56,255 - INFO - 
Starting training for config s6_n534:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:47:56,255 - INFO - Running command: ./train_gpt2cu -l 0.0005220175259161493 -o hyperband_runs_20241120_172038/run_s6_n534 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:48:06,048 - INFO - Training completed for config s6_n534:
  Training time: 0:00:09
  Final validation loss: 10.905205
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.46e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n534/checkpoint.bin
2024-11-20 18:48:06,048 - INFO - 
Configuration s6_n534 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005220175259161493",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n534",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905205
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.46e-07
2024-11-20 18:48:06,048 - INFO - 
Starting training for config s6_n535:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:48:06,048 - INFO - Running command: ./train_gpt2cu -l 7.815937293632705e-05 -o hyperband_runs_20241120_172038/run_s6_n535 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:48:15,857 - INFO - Training completed for config s6_n535:
  Training time: 0:00:09
  Final validation loss: 10.910640
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.12e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n535/checkpoint.bin
2024-11-20 18:48:15,857 - INFO - 
Configuration s6_n535 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.815937293632705e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n535",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910640
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.12e-07
2024-11-20 18:48:15,857 - INFO - 
Starting training for config s6_n536:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:48:15,857 - INFO - Running command: ./train_gpt2cu -l 8.583304116315378e-05 -o hyperband_runs_20241120_172038/run_s6_n536 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:48:25,662 - INFO - Training completed for config s6_n536:
  Training time: 0:00:09
  Final validation loss: 10.910540
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.23e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n536/checkpoint.bin
2024-11-20 18:48:25,662 - INFO - 
Configuration s6_n536 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "8.583304116315378e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n536",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910540
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.23e-07
2024-11-20 18:48:25,662 - INFO - 
Starting training for config s6_n537:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:48:25,662 - INFO - Running command: ./train_gpt2cu -l 5.04219984060511e-05 -o hyperband_runs_20241120_172038/run_s6_n537 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:48:35,480 - INFO - Training completed for config s6_n537:
  Training time: 0:00:09
  Final validation loss: 10.910990
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.20e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n537/checkpoint.bin
2024-11-20 18:48:35,480 - INFO - 
Configuration s6_n537 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.04219984060511e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n537",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910990
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.20e-08
2024-11-20 18:48:35,480 - INFO - 
Starting training for config s6_n538:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:48:35,480 - INFO - Running command: ./train_gpt2cu -l 0.00018331040681790627 -o hyperband_runs_20241120_172038/run_s6_n538 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:48:45,283 - INFO - Training completed for config s6_n538:
  Training time: 0:00:09
  Final validation loss: 10.909332
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.62e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n538/checkpoint.bin
2024-11-20 18:48:45,283 - INFO - 
Configuration s6_n538 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00018331040681790627",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n538",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909332
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.62e-07
2024-11-20 18:48:45,283 - INFO - 
Starting training for config s6_n539:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:48:45,284 - INFO - Running command: ./train_gpt2cu -l 8.18124107807958e-05 -o hyperband_runs_20241120_172038/run_s6_n539 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:48:55,096 - INFO - Training completed for config s6_n539:
  Training time: 0:00:09
  Final validation loss: 10.910589
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.17e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n539/checkpoint.bin
2024-11-20 18:48:55,096 - INFO - 
Configuration s6_n539 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "8.18124107807958e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n539",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910589
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.17e-07
2024-11-20 18:48:55,096 - INFO - 
Starting training for config s6_n540:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:48:55,096 - INFO - Running command: ./train_gpt2cu -l 0.0008554037131933193 -o hyperband_runs_20241120_172038/run_s6_n540 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:49:04,910 - INFO - Training completed for config s6_n540:
  Training time: 0:00:09
  Final validation loss: 10.901110
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.22e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n540/checkpoint.bin
2024-11-20 18:49:04,910 - INFO - 
Configuration s6_n540 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008554037131933193",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n540",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901110
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.22e-06
2024-11-20 18:49:04,910 - INFO - 
Starting training for config s6_n541:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:49:04,910 - INFO - Running command: ./train_gpt2cu -l 5.6328391503752005e-05 -o hyperband_runs_20241120_172038/run_s6_n541 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:49:14,732 - INFO - Training completed for config s6_n541:
  Training time: 0:00:09
  Final validation loss: 10.910912
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.05e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n541/checkpoint.bin
2024-11-20 18:49:14,733 - INFO - 
Configuration s6_n541 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.6328391503752005e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n541",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910912
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.05e-08
2024-11-20 18:49:14,733 - INFO - 
Starting training for config s6_n542:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:49:14,733 - INFO - Running command: ./train_gpt2cu -l 3.5048461145307955e-05 -o hyperband_runs_20241120_172038/run_s6_n542 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:49:24,532 - INFO - Training completed for config s6_n542:
  Training time: 0:00:09
  Final validation loss: 10.911177
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.01e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n542/checkpoint.bin
2024-11-20 18:49:24,532 - INFO - 
Configuration s6_n542 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.5048461145307955e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n542",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911177
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.01e-08
2024-11-20 18:49:24,532 - INFO - 
Starting training for config s6_n543:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:49:24,532 - INFO - Running command: ./train_gpt2cu -l 6.909659971987748e-05 -o hyperband_runs_20241120_172038/run_s6_n543 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:49:34,357 - INFO - Training completed for config s6_n543:
  Training time: 0:00:09
  Final validation loss: 10.910755
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.87e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n543/checkpoint.bin
2024-11-20 18:49:34,357 - INFO - 
Configuration s6_n543 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.909659971987748e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n543",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910755
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.87e-08
2024-11-20 18:49:34,357 - INFO - 
Starting training for config s6_n544:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:49:34,357 - INFO - Running command: ./train_gpt2cu -l 1.3926986455041506e-05 -o hyperband_runs_20241120_172038/run_s6_n544 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:49:44,191 - INFO - Training completed for config s6_n544:
  Training time: 0:00:09
  Final validation loss: 10.911444
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.99e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n544/checkpoint.bin
2024-11-20 18:49:44,191 - INFO - 
Configuration s6_n544 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.3926986455041506e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n544",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911444
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.99e-08
2024-11-20 18:49:44,192 - INFO - 
Starting training for config s6_n545:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:49:44,192 - INFO - Running command: ./train_gpt2cu -l 3.595179343437779e-05 -o hyperband_runs_20241120_172038/run_s6_n545 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:49:53,991 - INFO - Training completed for config s6_n545:
  Training time: 0:00:09
  Final validation loss: 10.911173
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.14e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n545/checkpoint.bin
2024-11-20 18:49:53,991 - INFO - 
Configuration s6_n545 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.595179343437779e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n545",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911173
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.14e-08
2024-11-20 18:49:53,991 - INFO - 
Starting training for config s6_n546:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:49:53,991 - INFO - Running command: ./train_gpt2cu -l 0.00028776902883485405 -o hyperband_runs_20241120_172038/run_s6_n546 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:50:03,795 - INFO - Training completed for config s6_n546:
  Training time: 0:00:09
  Final validation loss: 10.908037
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.11e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n546/checkpoint.bin
2024-11-20 18:50:03,796 - INFO - 
Configuration s6_n546 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00028776902883485405",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n546",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908037
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.11e-07
2024-11-20 18:50:03,796 - INFO - 
Starting training for config s6_n547:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:50:03,796 - INFO - Running command: ./train_gpt2cu -l 3.496465324938545e-05 -o hyperband_runs_20241120_172038/run_s6_n547 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:50:13,596 - INFO - Training completed for config s6_n547:
  Training time: 0:00:09
  Final validation loss: 10.911181
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.99e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n547/checkpoint.bin
2024-11-20 18:50:13,596 - INFO - 
Configuration s6_n547 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.496465324938545e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n547",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911181
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.99e-08
2024-11-20 18:50:13,596 - INFO - 
Starting training for config s6_n548:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:50:13,596 - INFO - Running command: ./train_gpt2cu -l 9.07219820199334e-05 -o hyperband_runs_20241120_172038/run_s6_n548 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:50:23,395 - INFO - Training completed for config s6_n548:
  Training time: 0:00:09
  Final validation loss: 10.910471
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.30e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n548/checkpoint.bin
2024-11-20 18:50:23,395 - INFO - 
Configuration s6_n548 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "9.07219820199334e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n548",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910471
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.30e-07
2024-11-20 18:50:23,395 - INFO - 
Starting training for config s6_n549:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:50:23,395 - INFO - Running command: ./train_gpt2cu -l 0.00010655235446836722 -o hyperband_runs_20241120_172038/run_s6_n549 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:50:33,200 - INFO - Training completed for config s6_n549:
  Training time: 0:00:09
  Final validation loss: 10.910287
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.52e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n549/checkpoint.bin
2024-11-20 18:50:33,201 - INFO - 
Configuration s6_n549 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010655235446836722",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n549",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910287
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.52e-07
2024-11-20 18:50:33,201 - INFO - 
Starting training for config s6_n550:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:50:33,201 - INFO - Running command: ./train_gpt2cu -l 0.00019233428023629321 -o hyperband_runs_20241120_172038/run_s6_n550 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:50:42,995 - INFO - Training completed for config s6_n550:
  Training time: 0:00:09
  Final validation loss: 10.909216
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.75e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n550/checkpoint.bin
2024-11-20 18:50:42,995 - INFO - 
Configuration s6_n550 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00019233428023629321",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n550",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909216
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.75e-07
2024-11-20 18:50:42,995 - INFO - 
Starting training for config s6_n551:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:50:42,995 - INFO - Running command: ./train_gpt2cu -l 0.0007833672223959862 -o hyperband_runs_20241120_172038/run_s6_n551 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:50:52,806 - INFO - Training completed for config s6_n551:
  Training time: 0:00:09
  Final validation loss: 10.901995
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.12e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n551/checkpoint.bin
2024-11-20 18:50:52,806 - INFO - 
Configuration s6_n551 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007833672223959862",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n551",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901995
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.12e-06
2024-11-20 18:50:52,806 - INFO - 
Starting training for config s6_n552:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:50:52,806 - INFO - Running command: ./train_gpt2cu -l 1.986812777687916e-05 -o hyperband_runs_20241120_172038/run_s6_n552 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:51:02,621 - INFO - Training completed for config s6_n552:
  Training time: 0:00:09
  Final validation loss: 10.911361
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.84e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n552/checkpoint.bin
2024-11-20 18:51:02,621 - INFO - 
Configuration s6_n552 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.986812777687916e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n552",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911361
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.84e-08
2024-11-20 18:51:02,621 - INFO - 
Starting training for config s6_n553:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:51:02,621 - INFO - Running command: ./train_gpt2cu -l 0.0009757562917808082 -o hyperband_runs_20241120_172038/run_s6_n553 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:51:12,426 - INFO - Training completed for config s6_n553:
  Training time: 0:00:09
  Final validation loss: 10.899650
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.39e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin
2024-11-20 18:51:12,426 - INFO - 
Configuration s6_n553 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009757562917808082",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n553",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.899650
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.39e-06
2024-11-20 18:51:12,427 - INFO - 
Starting training for config s6_n554:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:51:12,427 - INFO - Running command: ./train_gpt2cu -l 0.0003554550371310786 -o hyperband_runs_20241120_172038/run_s6_n554 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:51:22,240 - INFO - Training completed for config s6_n554:
  Training time: 0:00:09
  Final validation loss: 10.907217
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.08e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n554/checkpoint.bin
2024-11-20 18:51:22,240 - INFO - 
Configuration s6_n554 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003554550371310786",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n554",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907217
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.08e-07
2024-11-20 18:51:22,240 - INFO - 
Starting training for config s6_n555:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:51:22,241 - INFO - Running command: ./train_gpt2cu -l 0.0003492934199555555 -o hyperband_runs_20241120_172038/run_s6_n555 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:51:32,057 - INFO - Training completed for config s6_n555:
  Training time: 0:00:09
  Final validation loss: 10.907293
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.99e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n555/checkpoint.bin
2024-11-20 18:51:32,057 - INFO - 
Configuration s6_n555 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003492934199555555",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n555",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907293
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.99e-07
2024-11-20 18:51:32,057 - INFO - 
Starting training for config s6_n556:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:51:32,057 - INFO - Running command: ./train_gpt2cu -l 2.1964872607413094e-05 -o hyperband_runs_20241120_172038/run_s6_n556 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:51:41,863 - INFO - Training completed for config s6_n556:
  Training time: 0:00:09
  Final validation loss: 10.911334
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.14e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n556/checkpoint.bin
2024-11-20 18:51:41,863 - INFO - 
Configuration s6_n556 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.1964872607413094e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n556",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911334
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.14e-08
2024-11-20 18:51:41,863 - INFO - 
Starting training for config s6_n557:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:51:41,863 - INFO - Running command: ./train_gpt2cu -l 0.00022731174184442617 -o hyperband_runs_20241120_172038/run_s6_n557 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:51:51,676 - INFO - Training completed for config s6_n557:
  Training time: 0:00:09
  Final validation loss: 10.908811
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.25e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n557/checkpoint.bin
2024-11-20 18:51:51,676 - INFO - 
Configuration s6_n557 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00022731174184442617",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n557",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908811
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.25e-07
2024-11-20 18:51:51,676 - INFO - 
Starting training for config s6_n558:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:51:51,677 - INFO - Running command: ./train_gpt2cu -l 0.00058046999043979 -o hyperband_runs_20241120_172038/run_s6_n558 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:52:01,487 - INFO - Training completed for config s6_n558:
  Training time: 0:00:09
  Final validation loss: 10.904474
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.29e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n558/checkpoint.bin
2024-11-20 18:52:01,488 - INFO - 
Configuration s6_n558 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00058046999043979",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n558",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904474
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.29e-07
2024-11-20 18:52:01,488 - INFO - 
Starting training for config s6_n559:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:52:01,488 - INFO - Running command: ./train_gpt2cu -l 9.223728868535986e-05 -o hyperband_runs_20241120_172038/run_s6_n559 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:52:11,286 - INFO - Training completed for config s6_n559:
  Training time: 0:00:09
  Final validation loss: 10.910460
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.32e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n559/checkpoint.bin
2024-11-20 18:52:11,287 - INFO - 
Configuration s6_n559 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "9.223728868535986e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n559",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910460
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.32e-07
2024-11-20 18:52:11,287 - INFO - 
Starting training for config s6_n560:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:52:11,287 - INFO - Running command: ./train_gpt2cu -l 2.480903349391704e-05 -o hyperband_runs_20241120_172038/run_s6_n560 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:52:21,106 - INFO - Training completed for config s6_n560:
  Training time: 0:00:09
  Final validation loss: 10.911304
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.54e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n560/checkpoint.bin
2024-11-20 18:52:21,106 - INFO - 
Configuration s6_n560 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.480903349391704e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n560",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911304
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.54e-08
2024-11-20 18:52:21,107 - INFO - 
Starting training for config s6_n561:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:52:21,107 - INFO - Running command: ./train_gpt2cu -l 0.0009466935556371588 -o hyperband_runs_20241120_172038/run_s6_n561 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:52:30,928 - INFO - Training completed for config s6_n561:
  Training time: 0:00:09
  Final validation loss: 10.900011
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.35e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin
2024-11-20 18:52:30,929 - INFO - 
Configuration s6_n561 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009466935556371588",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n561",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.900011
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.35e-06
2024-11-20 18:52:30,929 - INFO - 
Starting training for config s6_n562:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:52:30,929 - INFO - Running command: ./train_gpt2cu -l 0.00014907410234385945 -o hyperband_runs_20241120_172038/run_s6_n562 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:52:40,733 - INFO - Training completed for config s6_n562:
  Training time: 0:00:09
  Final validation loss: 10.909758
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.13e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n562/checkpoint.bin
2024-11-20 18:52:40,733 - INFO - 
Configuration s6_n562 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014907410234385945",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n562",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909758
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.13e-07
2024-11-20 18:52:40,733 - INFO - 
Starting training for config s6_n563:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:52:40,733 - INFO - Running command: ./train_gpt2cu -l 3.690306811508817e-05 -o hyperband_runs_20241120_172038/run_s6_n563 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:52:50,539 - INFO - Training completed for config s6_n563:
  Training time: 0:00:09
  Final validation loss: 10.911170
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.27e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n563/checkpoint.bin
2024-11-20 18:52:50,539 - INFO - 
Configuration s6_n563 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.690306811508817e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n563",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911170
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.27e-08
2024-11-20 18:52:50,539 - INFO - 
Starting training for config s6_n564:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:52:50,539 - INFO - Running command: ./train_gpt2cu -l 0.0002712212807866951 -o hyperband_runs_20241120_172038/run_s6_n564 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:53:00,350 - INFO - Training completed for config s6_n564:
  Training time: 0:00:09
  Final validation loss: 10.908243
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.87e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n564/checkpoint.bin
2024-11-20 18:53:00,351 - INFO - 
Configuration s6_n564 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002712212807866951",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n564",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908243
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.87e-07
2024-11-20 18:53:00,351 - INFO - 
Starting training for config s6_n565:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:53:00,351 - INFO - Running command: ./train_gpt2cu -l 1.4326111444539855e-05 -o hyperband_runs_20241120_172038/run_s6_n565 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:53:10,161 - INFO - Training completed for config s6_n565:
  Training time: 0:00:09
  Final validation loss: 10.911417
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.05e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n565/checkpoint.bin
2024-11-20 18:53:10,161 - INFO - 
Configuration s6_n565 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.4326111444539855e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n565",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911417
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.05e-08
2024-11-20 18:53:10,161 - INFO - 
Starting training for config s6_n566:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:53:10,161 - INFO - Running command: ./train_gpt2cu -l 3.7481983009161635e-05 -o hyperband_runs_20241120_172038/run_s6_n566 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:53:19,952 - INFO - Training completed for config s6_n566:
  Training time: 0:00:09
  Final validation loss: 10.911157
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.35e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n566/checkpoint.bin
2024-11-20 18:53:19,952 - INFO - 
Configuration s6_n566 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.7481983009161635e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n566",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911157
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.35e-08
2024-11-20 18:53:19,952 - INFO - 
Starting training for config s6_n567:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:53:19,952 - INFO - Running command: ./train_gpt2cu -l 0.0004519172519548599 -o hyperband_runs_20241120_172038/run_s6_n567 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:53:29,765 - INFO - Training completed for config s6_n567:
  Training time: 0:00:09
  Final validation loss: 10.906050
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.46e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n567/checkpoint.bin
2024-11-20 18:53:29,765 - INFO - 
Configuration s6_n567 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004519172519548599",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n567",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906050
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.46e-07
2024-11-20 18:53:29,765 - INFO - 
Starting training for config s6_n568:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:53:29,765 - INFO - Running command: ./train_gpt2cu -l 0.00016284683034833164 -o hyperband_runs_20241120_172038/run_s6_n568 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:53:39,581 - INFO - Training completed for config s6_n568:
  Training time: 0:00:09
  Final validation loss: 10.909593
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.33e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n568/checkpoint.bin
2024-11-20 18:53:39,582 - INFO - 
Configuration s6_n568 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00016284683034833164",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n568",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909593
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.33e-07
2024-11-20 18:53:39,582 - INFO - 
Starting training for config s6_n569:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:53:39,582 - INFO - Running command: ./train_gpt2cu -l 0.0002543057599428018 -o hyperband_runs_20241120_172038/run_s6_n569 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:53:49,388 - INFO - Training completed for config s6_n569:
  Training time: 0:00:09
  Final validation loss: 10.908461
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.63e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n569/checkpoint.bin
2024-11-20 18:53:49,388 - INFO - 
Configuration s6_n569 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002543057599428018",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n569",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908461
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.63e-07
2024-11-20 18:53:49,389 - INFO - 
Starting training for config s6_n570:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:53:49,389 - INFO - Running command: ./train_gpt2cu -l 0.000419370131555939 -o hyperband_runs_20241120_172038/run_s6_n570 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:53:59,187 - INFO - Training completed for config s6_n570:
  Training time: 0:00:09
  Final validation loss: 10.906443
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.99e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n570/checkpoint.bin
2024-11-20 18:53:59,188 - INFO - 
Configuration s6_n570 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000419370131555939",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n570",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906443
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.99e-07
2024-11-20 18:53:59,188 - INFO - 
Starting training for config s6_n571:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:53:59,188 - INFO - Running command: ./train_gpt2cu -l 0.0002457066908035236 -o hyperband_runs_20241120_172038/run_s6_n571 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:54:08,996 - INFO - Training completed for config s6_n571:
  Training time: 0:00:09
  Final validation loss: 10.908572
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.51e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n571/checkpoint.bin
2024-11-20 18:54:08,997 - INFO - 
Configuration s6_n571 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002457066908035236",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n571",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908572
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.51e-07
2024-11-20 18:54:08,997 - INFO - 
Starting training for config s6_n572:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:54:08,997 - INFO - Running command: ./train_gpt2cu -l 0.0006692136504312971 -o hyperband_runs_20241120_172038/run_s6_n572 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:54:18,804 - INFO - Training completed for config s6_n572:
  Training time: 0:00:09
  Final validation loss: 10.903395
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.56e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n572/checkpoint.bin
2024-11-20 18:54:18,804 - INFO - 
Configuration s6_n572 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006692136504312971",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n572",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.903395
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.56e-07
2024-11-20 18:54:18,804 - INFO - 
Starting training for config s6_n573:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:54:18,805 - INFO - Running command: ./train_gpt2cu -l 2.250836483368876e-05 -o hyperband_runs_20241120_172038/run_s6_n573 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:54:28,620 - INFO - Training completed for config s6_n573:
  Training time: 0:00:09
  Final validation loss: 10.911333
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.22e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n573/checkpoint.bin
2024-11-20 18:54:28,620 - INFO - 
Configuration s6_n573 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.250836483368876e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n573",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911333
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.22e-08
2024-11-20 18:54:28,620 - INFO - 
Starting training for config s6_n574:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:54:28,620 - INFO - Running command: ./train_gpt2cu -l 3.5539079661307214e-05 -o hyperband_runs_20241120_172038/run_s6_n574 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:54:38,419 - INFO - Training completed for config s6_n574:
  Training time: 0:00:09
  Final validation loss: 10.911171
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.08e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n574/checkpoint.bin
2024-11-20 18:54:38,419 - INFO - 
Configuration s6_n574 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.5539079661307214e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n574",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911171
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.08e-08
2024-11-20 18:54:38,419 - INFO - 
Starting training for config s6_n575:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:54:38,420 - INFO - Running command: ./train_gpt2cu -l 1.5841230189722165e-05 -o hyperband_runs_20241120_172038/run_s6_n575 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:54:48,227 - INFO - Training completed for config s6_n575:
  Training time: 0:00:09
  Final validation loss: 10.911417
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.26e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n575/checkpoint.bin
2024-11-20 18:54:48,227 - INFO - 
Configuration s6_n575 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.5841230189722165e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n575",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911417
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.26e-08
2024-11-20 18:54:48,227 - INFO - 
Starting training for config s6_n576:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:54:48,227 - INFO - Running command: ./train_gpt2cu -l 2.536396507539455e-05 -o hyperband_runs_20241120_172038/run_s6_n576 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:54:58,044 - INFO - Training completed for config s6_n576:
  Training time: 0:00:09
  Final validation loss: 10.911288
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.62e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n576/checkpoint.bin
2024-11-20 18:54:58,044 - INFO - 
Configuration s6_n576 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.536396507539455e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n576",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911288
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.62e-08
2024-11-20 18:54:58,045 - INFO - 
Starting training for config s6_n577:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:54:58,045 - INFO - Running command: ./train_gpt2cu -l 8.217114898237529e-05 -o hyperband_runs_20241120_172038/run_s6_n577 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:55:07,856 - INFO - Training completed for config s6_n577:
  Training time: 0:00:09
  Final validation loss: 10.910589
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.17e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n577/checkpoint.bin
2024-11-20 18:55:07,856 - INFO - 
Configuration s6_n577 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "8.217114898237529e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n577",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910589
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.17e-07
2024-11-20 18:55:07,856 - INFO - 
Starting training for config s6_n578:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:55:07,856 - INFO - Running command: ./train_gpt2cu -l 3.8568407229042724e-05 -o hyperband_runs_20241120_172038/run_s6_n578 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:55:17,662 - INFO - Training completed for config s6_n578:
  Training time: 0:00:09
  Final validation loss: 10.911142
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.51e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n578/checkpoint.bin
2024-11-20 18:55:17,662 - INFO - 
Configuration s6_n578 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.8568407229042724e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n578",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911142
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.51e-08
2024-11-20 18:55:17,662 - INFO - 
Starting training for config s6_n579:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:55:17,663 - INFO - Running command: ./train_gpt2cu -l 0.00031134527897074547 -o hyperband_runs_20241120_172038/run_s6_n579 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:55:27,478 - INFO - Training completed for config s6_n579:
  Training time: 0:00:09
  Final validation loss: 10.907753
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.45e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n579/checkpoint.bin
2024-11-20 18:55:27,478 - INFO - 
Configuration s6_n579 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00031134527897074547",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n579",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907753
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.45e-07
2024-11-20 18:55:27,478 - INFO - 
Starting training for config s6_n580:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:55:27,479 - INFO - Running command: ./train_gpt2cu -l 9.015360018826086e-05 -o hyperband_runs_20241120_172038/run_s6_n580 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:55:37,294 - INFO - Training completed for config s6_n580:
  Training time: 0:00:09
  Final validation loss: 10.910485
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.29e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n580/checkpoint.bin
2024-11-20 18:55:37,294 - INFO - 
Configuration s6_n580 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "9.015360018826086e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n580",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910485
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.29e-07
2024-11-20 18:55:37,294 - INFO - 
Starting training for config s6_n581:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:55:37,294 - INFO - Running command: ./train_gpt2cu -l 1.8653951563625485e-05 -o hyperband_runs_20241120_172038/run_s6_n581 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:55:47,108 - INFO - Training completed for config s6_n581:
  Training time: 0:00:09
  Final validation loss: 10.911375
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.66e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n581/checkpoint.bin
2024-11-20 18:55:47,108 - INFO - 
Configuration s6_n581 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.8653951563625485e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n581",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911375
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.66e-08
2024-11-20 18:55:47,108 - INFO - 
Starting training for config s6_n582:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:55:47,108 - INFO - Running command: ./train_gpt2cu -l 1.1692341832760991e-05 -o hyperband_runs_20241120_172038/run_s6_n582 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:55:56,901 - INFO - Training completed for config s6_n582:
  Training time: 0:00:09
  Final validation loss: 10.911463
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.67e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n582/checkpoint.bin
2024-11-20 18:55:56,902 - INFO - 
Configuration s6_n582 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.1692341832760991e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n582",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911463
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.67e-08
2024-11-20 18:55:56,902 - INFO - 
Starting training for config s6_n583:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:55:56,902 - INFO - Running command: ./train_gpt2cu -l 6.159858989533202e-05 -o hyperband_runs_20241120_172038/run_s6_n583 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:56:06,725 - INFO - Training completed for config s6_n583:
  Training time: 0:00:09
  Final validation loss: 10.910848
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.80e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n583/checkpoint.bin
2024-11-20 18:56:06,725 - INFO - 
Configuration s6_n583 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.159858989533202e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n583",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910848
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.80e-08
2024-11-20 18:56:06,725 - INFO - 
Starting training for config s6_n584:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:56:06,726 - INFO - Running command: ./train_gpt2cu -l 0.0005278182574572715 -o hyperband_runs_20241120_172038/run_s6_n584 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:56:16,520 - INFO - Training completed for config s6_n584:
  Training time: 0:00:09
  Final validation loss: 10.905138
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.54e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n584/checkpoint.bin
2024-11-20 18:56:16,520 - INFO - 
Configuration s6_n584 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005278182574572715",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n584",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905138
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.54e-07
2024-11-20 18:56:16,520 - INFO - 
Starting training for config s6_n585:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:56:16,520 - INFO - Running command: ./train_gpt2cu -l 0.00047600113579342206 -o hyperband_runs_20241120_172038/run_s6_n585 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:56:26,324 - INFO - Training completed for config s6_n585:
  Training time: 0:00:09
  Final validation loss: 10.905740
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.80e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n585/checkpoint.bin
2024-11-20 18:56:26,325 - INFO - 
Configuration s6_n585 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00047600113579342206",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n585",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905740
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.80e-07
2024-11-20 18:56:26,325 - INFO - 
Starting training for config s6_n586:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:56:26,325 - INFO - Running command: ./train_gpt2cu -l 4.113861432234419e-05 -o hyperband_runs_20241120_172038/run_s6_n586 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:56:36,134 - INFO - Training completed for config s6_n586:
  Training time: 0:00:09
  Final validation loss: 10.911109
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.88e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n586/checkpoint.bin
2024-11-20 18:56:36,134 - INFO - 
Configuration s6_n586 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.113861432234419e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n586",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911109
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.88e-08
2024-11-20 18:56:36,134 - INFO - 
Starting training for config s6_n587:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:56:36,134 - INFO - Running command: ./train_gpt2cu -l 4.837075520229896e-05 -o hyperband_runs_20241120_172038/run_s6_n587 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:56:45,952 - INFO - Training completed for config s6_n587:
  Training time: 0:00:09
  Final validation loss: 10.911013
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.91e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n587/checkpoint.bin
2024-11-20 18:56:45,952 - INFO - 
Configuration s6_n587 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.837075520229896e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n587",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911013
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.91e-08
2024-11-20 18:56:45,952 - INFO - 
Starting training for config s6_n588:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:56:45,953 - INFO - Running command: ./train_gpt2cu -l 0.0007278567127169047 -o hyperband_runs_20241120_172038/run_s6_n588 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:56:55,752 - INFO - Training completed for config s6_n588:
  Training time: 0:00:09
  Final validation loss: 10.902682
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.04e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n588/checkpoint.bin
2024-11-20 18:56:55,752 - INFO - 
Configuration s6_n588 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007278567127169047",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n588",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.902682
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.04e-06
2024-11-20 18:56:55,752 - INFO - 
Starting training for config s6_n589:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:56:55,753 - INFO - Running command: ./train_gpt2cu -l 0.00022371115865239027 -o hyperband_runs_20241120_172038/run_s6_n589 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:57:05,546 - INFO - Training completed for config s6_n589:
  Training time: 0:00:09
  Final validation loss: 10.908843
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.20e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n589/checkpoint.bin
2024-11-20 18:57:05,546 - INFO - 
Configuration s6_n589 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00022371115865239027",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n589",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908843
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.20e-07
2024-11-20 18:57:05,546 - INFO - 
Starting training for config s6_n590:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:57:05,547 - INFO - Running command: ./train_gpt2cu -l 5.464498357858356e-05 -o hyperband_runs_20241120_172038/run_s6_n590 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:57:15,349 - INFO - Training completed for config s6_n590:
  Training time: 0:00:09
  Final validation loss: 10.910940
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.81e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n590/checkpoint.bin
2024-11-20 18:57:15,349 - INFO - 
Configuration s6_n590 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.464498357858356e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n590",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910940
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.81e-08
2024-11-20 18:57:15,349 - INFO - 
Starting training for config s6_n591:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:57:15,349 - INFO - Running command: ./train_gpt2cu -l 0.0008079629767133919 -o hyperband_runs_20241120_172038/run_s6_n591 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:57:25,150 - INFO - Training completed for config s6_n591:
  Training time: 0:00:09
  Final validation loss: 10.901706
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.15e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n591/checkpoint.bin
2024-11-20 18:57:25,150 - INFO - 
Configuration s6_n591 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008079629767133919",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n591",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901706
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.15e-06
2024-11-20 18:57:25,150 - INFO - 
Starting training for config s6_n592:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:57:25,150 - INFO - Running command: ./train_gpt2cu -l 2.1341357544714167e-05 -o hyperband_runs_20241120_172038/run_s6_n592 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:57:34,963 - INFO - Training completed for config s6_n592:
  Training time: 0:00:09
  Final validation loss: 10.911343
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.05e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n592/checkpoint.bin
2024-11-20 18:57:34,963 - INFO - 
Configuration s6_n592 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.1341357544714167e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n592",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911343
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.05e-08
2024-11-20 18:57:34,964 - INFO - 
Starting training for config s6_n593:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:57:34,964 - INFO - Running command: ./train_gpt2cu -l 1.3764014650004214e-05 -o hyperband_runs_20241120_172038/run_s6_n593 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:57:44,781 - INFO - Training completed for config s6_n593:
  Training time: 0:00:09
  Final validation loss: 10.911436
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.97e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n593/checkpoint.bin
2024-11-20 18:57:44,782 - INFO - 
Configuration s6_n593 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.3764014650004214e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n593",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911436
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.97e-08
2024-11-20 18:57:44,782 - INFO - 
Starting training for config s6_n594:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:57:44,782 - INFO - Running command: ./train_gpt2cu -l 5.118728164395129e-05 -o hyperband_runs_20241120_172038/run_s6_n594 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:57:54,583 - INFO - Training completed for config s6_n594:
  Training time: 0:00:09
  Final validation loss: 10.910982
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.31e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n594/checkpoint.bin
2024-11-20 18:57:54,583 - INFO - 
Configuration s6_n594 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.118728164395129e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n594",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910982
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.31e-08
2024-11-20 18:57:54,583 - INFO - 
Starting training for config s6_n595:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:57:54,584 - INFO - Running command: ./train_gpt2cu -l 2.0009912111400956e-05 -o hyperband_runs_20241120_172038/run_s6_n595 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:58:04,406 - INFO - Training completed for config s6_n595:
  Training time: 0:00:09
  Final validation loss: 10.911357
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.86e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n595/checkpoint.bin
2024-11-20 18:58:04,412 - INFO - 
Configuration s6_n595 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.0009912111400956e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n595",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911357
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.86e-08
2024-11-20 18:58:04,412 - INFO - 
Starting training for config s6_n596:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:58:04,436 - INFO - Running command: ./train_gpt2cu -l 2.7760779197823518e-05 -o hyperband_runs_20241120_172038/run_s6_n596 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:58:14,235 - INFO - Training completed for config s6_n596:
  Training time: 0:00:09
  Final validation loss: 10.911264
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.97e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n596/checkpoint.bin
2024-11-20 18:58:14,236 - INFO - 
Configuration s6_n596 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.7760779197823518e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n596",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911264
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.97e-08
2024-11-20 18:58:14,236 - INFO - 
Starting training for config s6_n597:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:58:14,236 - INFO - Running command: ./train_gpt2cu -l 0.0001248549548186002 -o hyperband_runs_20241120_172038/run_s6_n597 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:58:24,053 - INFO - Training completed for config s6_n597:
  Training time: 0:00:09
  Final validation loss: 10.910056
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.78e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n597/checkpoint.bin
2024-11-20 18:58:24,053 - INFO - 
Configuration s6_n597 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001248549548186002",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n597",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910056
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.78e-07
2024-11-20 18:58:24,053 - INFO - 
Starting training for config s6_n598:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:58:24,054 - INFO - Running command: ./train_gpt2cu -l 0.00047945366371818075 -o hyperband_runs_20241120_172038/run_s6_n598 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:58:33,860 - INFO - Training completed for config s6_n598:
  Training time: 0:00:09
  Final validation loss: 10.905706
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.85e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n598/checkpoint.bin
2024-11-20 18:58:33,860 - INFO - 
Configuration s6_n598 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00047945366371818075",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n598",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905706
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.85e-07
2024-11-20 18:58:33,860 - INFO - 
Starting training for config s6_n599:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:58:33,860 - INFO - Running command: ./train_gpt2cu -l 4.69594408343588e-05 -o hyperband_runs_20241120_172038/run_s6_n599 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:58:43,669 - INFO - Training completed for config s6_n599:
  Training time: 0:00:09
  Final validation loss: 10.911024
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.71e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n599/checkpoint.bin
2024-11-20 18:58:43,669 - INFO - 
Configuration s6_n599 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.69594408343588e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n599",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911024
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.71e-08
2024-11-20 18:58:43,669 - INFO - 
Starting training for config s6_n600:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:58:43,669 - INFO - Running command: ./train_gpt2cu -l 3.2419121211567234e-05 -o hyperband_runs_20241120_172038/run_s6_n600 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:58:53,501 - INFO - Training completed for config s6_n600:
  Training time: 0:00:09
  Final validation loss: 10.911212
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.63e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n600/checkpoint.bin
2024-11-20 18:58:53,501 - INFO - 
Configuration s6_n600 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.2419121211567234e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n600",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911212
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.63e-08
2024-11-20 18:58:53,501 - INFO - 
Starting training for config s6_n601:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:58:53,502 - INFO - Running command: ./train_gpt2cu -l 0.0007221173134528555 -o hyperband_runs_20241120_172038/run_s6_n601 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:59:03,318 - INFO - Training completed for config s6_n601:
  Training time: 0:00:09
  Final validation loss: 10.902760
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.03e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n601/checkpoint.bin
2024-11-20 18:59:03,319 - INFO - 
Configuration s6_n601 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007221173134528555",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n601",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.902760
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.03e-06
2024-11-20 18:59:03,319 - INFO - 
Starting training for config s6_n602:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:59:03,319 - INFO - Running command: ./train_gpt2cu -l 8.537053382825846e-05 -o hyperband_runs_20241120_172038/run_s6_n602 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:59:13,129 - INFO - Training completed for config s6_n602:
  Training time: 0:00:09
  Final validation loss: 10.910553
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.22e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n602/checkpoint.bin
2024-11-20 18:59:13,129 - INFO - 
Configuration s6_n602 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "8.537053382825846e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n602",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910553
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.22e-07
2024-11-20 18:59:13,129 - INFO - 
Starting training for config s6_n603:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:59:13,130 - INFO - Running command: ./train_gpt2cu -l 0.0002188003149396116 -o hyperband_runs_20241120_172038/run_s6_n603 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:59:22,938 - INFO - Training completed for config s6_n603:
  Training time: 0:00:09
  Final validation loss: 10.908902
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.13e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n603/checkpoint.bin
2024-11-20 18:59:22,938 - INFO - 
Configuration s6_n603 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002188003149396116",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n603",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908902
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.13e-07
2024-11-20 18:59:22,939 - INFO - 
Starting training for config s6_n604:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:59:22,939 - INFO - Running command: ./train_gpt2cu -l 0.00010818197682333904 -o hyperband_runs_20241120_172038/run_s6_n604 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:59:32,747 - INFO - Training completed for config s6_n604:
  Training time: 0:00:09
  Final validation loss: 10.910254
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.55e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n604/checkpoint.bin
2024-11-20 18:59:32,747 - INFO - 
Configuration s6_n604 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010818197682333904",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n604",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910254
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.55e-07
2024-11-20 18:59:32,747 - INFO - 
Starting training for config s6_n605:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:59:32,747 - INFO - Running command: ./train_gpt2cu -l 2.063662913647307e-05 -o hyperband_runs_20241120_172038/run_s6_n605 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:59:42,556 - INFO - Training completed for config s6_n605:
  Training time: 0:00:09
  Final validation loss: 10.911357
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.95e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n605/checkpoint.bin
2024-11-20 18:59:42,556 - INFO - 
Configuration s6_n605 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.063662913647307e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n605",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911357
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.95e-08
2024-11-20 18:59:42,556 - INFO - 
Starting training for config s6_n606:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:59:42,556 - INFO - Running command: ./train_gpt2cu -l 1.90023454720959e-05 -o hyperband_runs_20241120_172038/run_s6_n606 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 18:59:52,358 - INFO - Training completed for config s6_n606:
  Training time: 0:00:09
  Final validation loss: 10.911369
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.71e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n606/checkpoint.bin
2024-11-20 18:59:52,359 - INFO - 
Configuration s6_n606 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.90023454720959e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n606",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911369
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.71e-08
2024-11-20 18:59:52,359 - INFO - 
Starting training for config s6_n607:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 18:59:52,359 - INFO - Running command: ./train_gpt2cu -l 0.000765146304141897 -o hyperband_runs_20241120_172038/run_s6_n607 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:00:02,167 - INFO - Training completed for config s6_n607:
  Training time: 0:00:09
  Final validation loss: 10.902229
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.09e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n607/checkpoint.bin
2024-11-20 19:00:02,167 - INFO - 
Configuration s6_n607 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000765146304141897",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n607",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.902229
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.09e-06
2024-11-20 19:00:02,167 - INFO - 
Starting training for config s6_n608:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:00:02,167 - INFO - Running command: ./train_gpt2cu -l 0.00010648358418437476 -o hyperband_runs_20241120_172038/run_s6_n608 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:00:11,973 - INFO - Training completed for config s6_n608:
  Training time: 0:00:09
  Final validation loss: 10.910282
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.52e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n608/checkpoint.bin
2024-11-20 19:00:11,974 - INFO - 
Configuration s6_n608 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010648358418437476",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n608",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910282
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.52e-07
2024-11-20 19:00:11,974 - INFO - 
Starting training for config s6_n609:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:00:11,974 - INFO - Running command: ./train_gpt2cu -l 1.3209445450376663e-05 -o hyperband_runs_20241120_172038/run_s6_n609 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:00:21,814 - INFO - Training completed for config s6_n609:
  Training time: 0:00:09
  Final validation loss: 10.911445
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.89e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n609/checkpoint.bin
2024-11-20 19:00:21,814 - INFO - 
Configuration s6_n609 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.3209445450376663e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n609",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911445
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.89e-08
2024-11-20 19:00:21,814 - INFO - 
Starting training for config s6_n610:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:00:21,814 - INFO - Running command: ./train_gpt2cu -l 0.0009840193661966614 -o hyperband_runs_20241120_172038/run_s6_n610 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:00:31,605 - INFO - Training completed for config s6_n610:
  Training time: 0:00:09
  Final validation loss: 10.899554
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.41e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin
2024-11-20 19:00:31,606 - INFO - 
Configuration s6_n610 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009840193661966614",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n610",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.899554
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.41e-06
2024-11-20 19:00:31,606 - INFO - 
Starting training for config s6_n611:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:00:31,606 - INFO - Running command: ./train_gpt2cu -l 0.00016470947779637405 -o hyperband_runs_20241120_172038/run_s6_n611 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:00:41,432 - INFO - Training completed for config s6_n611:
  Training time: 0:00:09
  Final validation loss: 10.909567
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.35e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n611/checkpoint.bin
2024-11-20 19:00:41,432 - INFO - 
Configuration s6_n611 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00016470947779637405",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n611",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909567
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.35e-07
2024-11-20 19:00:41,432 - INFO - 
Starting training for config s6_n612:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:00:41,433 - INFO - Running command: ./train_gpt2cu -l 0.0002037514937249855 -o hyperband_runs_20241120_172038/run_s6_n612 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:00:51,234 - INFO - Training completed for config s6_n612:
  Training time: 0:00:09
  Final validation loss: 10.909088
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.91e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n612/checkpoint.bin
2024-11-20 19:00:51,235 - INFO - 
Configuration s6_n612 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002037514937249855",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n612",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909088
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.91e-07
2024-11-20 19:00:51,235 - INFO - 
Starting training for config s6_n613:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:00:51,235 - INFO - Running command: ./train_gpt2cu -l 2.0846959513545142e-05 -o hyperband_runs_20241120_172038/run_s6_n613 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:01:01,042 - INFO - Training completed for config s6_n613:
  Training time: 0:00:09
  Final validation loss: 10.911361
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.98e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n613/checkpoint.bin
2024-11-20 19:01:01,042 - INFO - 
Configuration s6_n613 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.0846959513545142e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n613",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911361
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.98e-08
2024-11-20 19:01:01,042 - INFO - 
Starting training for config s6_n614:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:01:01,042 - INFO - Running command: ./train_gpt2cu -l 1.4727003649976319e-05 -o hyperband_runs_20241120_172038/run_s6_n614 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:01:10,848 - INFO - Training completed for config s6_n614:
  Training time: 0:00:09
  Final validation loss: 10.911417
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.10e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n614/checkpoint.bin
2024-11-20 19:01:10,848 - INFO - 
Configuration s6_n614 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.4727003649976319e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n614",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911417
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.10e-08
2024-11-20 19:01:10,848 - INFO - 
Starting training for config s6_n615:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:01:10,848 - INFO - Running command: ./train_gpt2cu -l 0.0007505781567021048 -o hyperband_runs_20241120_172038/run_s6_n615 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:01:20,662 - INFO - Training completed for config s6_n615:
  Training time: 0:00:09
  Final validation loss: 10.902408
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.07e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n615/checkpoint.bin
2024-11-20 19:01:20,663 - INFO - 
Configuration s6_n615 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007505781567021048",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n615",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.902408
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.07e-06
2024-11-20 19:01:20,663 - INFO - 
Starting training for config s6_n616:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:01:20,663 - INFO - Running command: ./train_gpt2cu -l 1.477494772183291e-05 -o hyperband_runs_20241120_172038/run_s6_n616 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:01:30,468 - INFO - Training completed for config s6_n616:
  Training time: 0:00:09
  Final validation loss: 10.911412
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.11e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n616/checkpoint.bin
2024-11-20 19:01:30,468 - INFO - 
Configuration s6_n616 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.477494772183291e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n616",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911412
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.11e-08
2024-11-20 19:01:30,468 - INFO - 
Starting training for config s6_n617:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:01:30,468 - INFO - Running command: ./train_gpt2cu -l 0.0008822222688470273 -o hyperband_runs_20241120_172038/run_s6_n617 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:01:40,272 - INFO - Training completed for config s6_n617:
  Training time: 0:00:09
  Final validation loss: 10.900793
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.26e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n617/checkpoint.bin
2024-11-20 19:01:40,272 - INFO - 
Configuration s6_n617 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008822222688470273",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n617",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.900793
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.26e-06
2024-11-20 19:01:40,272 - INFO - 
Starting training for config s6_n618:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:01:40,272 - INFO - Running command: ./train_gpt2cu -l 5.4268249713120735e-05 -o hyperband_runs_20241120_172038/run_s6_n618 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:01:50,078 - INFO - Training completed for config s6_n618:
  Training time: 0:00:09
  Final validation loss: 10.910948
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.75e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n618/checkpoint.bin
2024-11-20 19:01:50,078 - INFO - 
Configuration s6_n618 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.4268249713120735e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n618",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910948
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.75e-08
2024-11-20 19:01:50,078 - INFO - 
Starting training for config s6_n619:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:01:50,078 - INFO - Running command: ./train_gpt2cu -l 4.0078210146832144e-05 -o hyperband_runs_20241120_172038/run_s6_n619 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:01:59,895 - INFO - Training completed for config s6_n619:
  Training time: 0:00:09
  Final validation loss: 10.911112
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.73e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n619/checkpoint.bin
2024-11-20 19:01:59,895 - INFO - 
Configuration s6_n619 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.0078210146832144e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n619",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911112
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.73e-08
2024-11-20 19:01:59,895 - INFO - 
Starting training for config s6_n620:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:01:59,895 - INFO - Running command: ./train_gpt2cu -l 1.3345314902695581e-05 -o hyperband_runs_20241120_172038/run_s6_n620 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:02:09,712 - INFO - Training completed for config s6_n620:
  Training time: 0:00:09
  Final validation loss: 10.911437
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.91e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n620/checkpoint.bin
2024-11-20 19:02:09,712 - INFO - 
Configuration s6_n620 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.3345314902695581e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n620",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911437
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.91e-08
2024-11-20 19:02:09,712 - INFO - 
Starting training for config s6_n621:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:02:09,712 - INFO - Running command: ./train_gpt2cu -l 4.0258364831641886e-05 -o hyperband_runs_20241120_172038/run_s6_n621 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:02:19,542 - INFO - Training completed for config s6_n621:
  Training time: 0:00:09
  Final validation loss: 10.911121
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.75e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n621/checkpoint.bin
2024-11-20 19:02:19,542 - INFO - 
Configuration s6_n621 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.0258364831641886e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n621",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911121
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.75e-08
2024-11-20 19:02:19,542 - INFO - 
Starting training for config s6_n622:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:02:19,543 - INFO - Running command: ./train_gpt2cu -l 2.618229930214731e-05 -o hyperband_runs_20241120_172038/run_s6_n622 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:02:29,337 - INFO - Training completed for config s6_n622:
  Training time: 0:00:09
  Final validation loss: 10.911295
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.74e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n622/checkpoint.bin
2024-11-20 19:02:29,337 - INFO - 
Configuration s6_n622 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.618229930214731e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n622",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911295
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.74e-08
2024-11-20 19:02:29,337 - INFO - 
Starting training for config s6_n623:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:02:29,338 - INFO - Running command: ./train_gpt2cu -l 1.9897740386266733e-05 -o hyperband_runs_20241120_172038/run_s6_n623 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:02:39,168 - INFO - Training completed for config s6_n623:
  Training time: 0:00:09
  Final validation loss: 10.911360
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.84e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n623/checkpoint.bin
2024-11-20 19:02:39,168 - INFO - 
Configuration s6_n623 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.9897740386266733e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n623",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911360
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.84e-08
2024-11-20 19:02:39,168 - INFO - 
Starting training for config s6_n624:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:02:39,168 - INFO - Running command: ./train_gpt2cu -l 0.0002870835626005401 -o hyperband_runs_20241120_172038/run_s6_n624 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:02:48,969 - INFO - Training completed for config s6_n624:
  Training time: 0:00:09
  Final validation loss: 10.908050
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.10e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n624/checkpoint.bin
2024-11-20 19:02:48,970 - INFO - 
Configuration s6_n624 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002870835626005401",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n624",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908050
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.10e-07
2024-11-20 19:02:48,970 - INFO - 
Starting training for config s6_n625:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:02:48,970 - INFO - Running command: ./train_gpt2cu -l 0.0005005296956902601 -o hyperband_runs_20241120_172038/run_s6_n625 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:02:58,777 - INFO - Training completed for config s6_n625:
  Training time: 0:00:09
  Final validation loss: 10.905466
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.15e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n625/checkpoint.bin
2024-11-20 19:02:58,778 - INFO - 
Configuration s6_n625 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005005296956902601",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n625",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905466
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.15e-07
2024-11-20 19:02:58,778 - INFO - 
Starting training for config s6_n626:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:02:58,778 - INFO - Running command: ./train_gpt2cu -l 5.472800770001521e-05 -o hyperband_runs_20241120_172038/run_s6_n626 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:03:08,566 - INFO - Training completed for config s6_n626:
  Training time: 0:00:09
  Final validation loss: 10.910933
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.82e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n626/checkpoint.bin
2024-11-20 19:03:08,566 - INFO - 
Configuration s6_n626 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.472800770001521e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n626",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910933
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.82e-08
2024-11-20 19:03:08,566 - INFO - 
Starting training for config s6_n627:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:03:08,567 - INFO - Running command: ./train_gpt2cu -l 0.0004982092352823935 -o hyperband_runs_20241120_172038/run_s6_n627 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:03:18,385 - INFO - Training completed for config s6_n627:
  Training time: 0:00:09
  Final validation loss: 10.905491
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.12e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n627/checkpoint.bin
2024-11-20 19:03:18,385 - INFO - 
Configuration s6_n627 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004982092352823935",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n627",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905491
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.12e-07
2024-11-20 19:03:18,386 - INFO - 
Starting training for config s6_n628:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:03:18,386 - INFO - Running command: ./train_gpt2cu -l 7.465361678327396e-05 -o hyperband_runs_20241120_172038/run_s6_n628 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:03:28,200 - INFO - Training completed for config s6_n628:
  Training time: 0:00:09
  Final validation loss: 10.910676
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.07e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n628/checkpoint.bin
2024-11-20 19:03:28,201 - INFO - 
Configuration s6_n628 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.465361678327396e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n628",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910676
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.07e-07
2024-11-20 19:03:28,201 - INFO - 
Starting training for config s6_n629:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:03:28,201 - INFO - Running command: ./train_gpt2cu -l 0.00040127141098263787 -o hyperband_runs_20241120_172038/run_s6_n629 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:03:38,003 - INFO - Training completed for config s6_n629:
  Training time: 0:00:09
  Final validation loss: 10.906653
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.73e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n629/checkpoint.bin
2024-11-20 19:03:38,003 - INFO - 
Configuration s6_n629 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00040127141098263787",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n629",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906653
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.73e-07
2024-11-20 19:03:38,003 - INFO - 
Starting training for config s6_n630:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:03:38,003 - INFO - Running command: ./train_gpt2cu -l 0.00023223131815253126 -o hyperband_runs_20241120_172038/run_s6_n630 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:03:47,799 - INFO - Training completed for config s6_n630:
  Training time: 0:00:09
  Final validation loss: 10.908731
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.32e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n630/checkpoint.bin
2024-11-20 19:03:47,799 - INFO - 
Configuration s6_n630 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00023223131815253126",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n630",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908731
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.32e-07
2024-11-20 19:03:47,799 - INFO - 
Starting training for config s6_n631:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:03:47,800 - INFO - Running command: ./train_gpt2cu -l 5.8171587768090244e-05 -o hyperband_runs_20241120_172038/run_s6_n631 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:03:57,618 - INFO - Training completed for config s6_n631:
  Training time: 0:00:09
  Final validation loss: 10.910890
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.31e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n631/checkpoint.bin
2024-11-20 19:03:57,618 - INFO - 
Configuration s6_n631 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.8171587768090244e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n631",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910890
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.31e-08
2024-11-20 19:03:57,619 - INFO - 
Starting training for config s6_n632:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:03:57,619 - INFO - Running command: ./train_gpt2cu -l 0.0007609596504620381 -o hyperband_runs_20241120_172038/run_s6_n632 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:04:07,421 - INFO - Training completed for config s6_n632:
  Training time: 0:00:09
  Final validation loss: 10.902279
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.09e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n632/checkpoint.bin
2024-11-20 19:04:07,421 - INFO - 
Configuration s6_n632 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007609596504620381",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n632",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.902279
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.09e-06
2024-11-20 19:04:07,421 - INFO - 
Starting training for config s6_n633:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:04:07,421 - INFO - Running command: ./train_gpt2cu -l 0.00025661277038928684 -o hyperband_runs_20241120_172038/run_s6_n633 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:04:17,230 - INFO - Training completed for config s6_n633:
  Training time: 0:00:09
  Final validation loss: 10.908436
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.67e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n633/checkpoint.bin
2024-11-20 19:04:17,230 - INFO - 
Configuration s6_n633 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00025661277038928684",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n633",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908436
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.67e-07
2024-11-20 19:04:17,230 - INFO - 
Starting training for config s6_n634:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:04:17,230 - INFO - Running command: ./train_gpt2cu -l 1.1976227994996558e-05 -o hyperband_runs_20241120_172038/run_s6_n634 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:04:27,038 - INFO - Training completed for config s6_n634:
  Training time: 0:00:09
  Final validation loss: 10.911458
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.71e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n634/checkpoint.bin
2024-11-20 19:04:27,038 - INFO - 
Configuration s6_n634 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.1976227994996558e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n634",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911458
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.71e-08
2024-11-20 19:04:27,039 - INFO - 
Starting training for config s6_n635:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:04:27,039 - INFO - Running command: ./train_gpt2cu -l 3.609271612367347e-05 -o hyperband_runs_20241120_172038/run_s6_n635 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:04:36,863 - INFO - Training completed for config s6_n635:
  Training time: 0:00:09
  Final validation loss: 10.911164
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.16e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n635/checkpoint.bin
2024-11-20 19:04:36,864 - INFO - 
Configuration s6_n635 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.609271612367347e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n635",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911164
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.16e-08
2024-11-20 19:04:36,864 - INFO - 
Starting training for config s6_n636:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:04:36,864 - INFO - Running command: ./train_gpt2cu -l 2.2413124226811814e-05 -o hyperband_runs_20241120_172038/run_s6_n636 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:04:46,671 - INFO - Training completed for config s6_n636:
  Training time: 0:00:09
  Final validation loss: 10.911329
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.20e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n636/checkpoint.bin
2024-11-20 19:04:46,672 - INFO - 
Configuration s6_n636 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.2413124226811814e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n636",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911329
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.20e-08
2024-11-20 19:04:46,672 - INFO - 
Starting training for config s6_n637:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:04:46,672 - INFO - Running command: ./train_gpt2cu -l 2.4763338315283713e-05 -o hyperband_runs_20241120_172038/run_s6_n637 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:04:56,488 - INFO - Training completed for config s6_n637:
  Training time: 0:00:09
  Final validation loss: 10.911304
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.54e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n637/checkpoint.bin
2024-11-20 19:04:56,488 - INFO - 
Configuration s6_n637 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.4763338315283713e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n637",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911304
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.54e-08
2024-11-20 19:04:56,488 - INFO - 
Starting training for config s6_n638:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:04:56,488 - INFO - Running command: ./train_gpt2cu -l 0.0007915379022221989 -o hyperband_runs_20241120_172038/run_s6_n638 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:05:06,292 - INFO - Training completed for config s6_n638:
  Training time: 0:00:09
  Final validation loss: 10.901899
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.13e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n638/checkpoint.bin
2024-11-20 19:05:06,292 - INFO - 
Configuration s6_n638 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007915379022221989",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n638",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901899
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.13e-06
2024-11-20 19:05:06,292 - INFO - 
Starting training for config s6_n639:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:05:06,292 - INFO - Running command: ./train_gpt2cu -l 1.7508382416180288e-05 -o hyperband_runs_20241120_172038/run_s6_n639 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:05:16,114 - INFO - Training completed for config s6_n639:
  Training time: 0:00:09
  Final validation loss: 10.911380
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.50e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n639/checkpoint.bin
2024-11-20 19:05:16,114 - INFO - 
Configuration s6_n639 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.7508382416180288e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n639",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911380
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.50e-08
2024-11-20 19:05:16,115 - INFO - 
Starting training for config s6_n640:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:05:16,115 - INFO - Running command: ./train_gpt2cu -l 3.99195061784802e-05 -o hyperband_runs_20241120_172038/run_s6_n640 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:05:25,960 - INFO - Training completed for config s6_n640:
  Training time: 0:00:09
  Final validation loss: 10.911123
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.70e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n640/checkpoint.bin
2024-11-20 19:05:25,960 - INFO - 
Configuration s6_n640 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.99195061784802e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n640",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911123
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.70e-08
2024-11-20 19:05:25,960 - INFO - 
Starting training for config s6_n641:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:05:25,960 - INFO - Running command: ./train_gpt2cu -l 2.125819243612928e-05 -o hyperband_runs_20241120_172038/run_s6_n641 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:05:35,768 - INFO - Training completed for config s6_n641:
  Training time: 0:00:09
  Final validation loss: 10.911341
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.04e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n641/checkpoint.bin
2024-11-20 19:05:35,768 - INFO - 
Configuration s6_n641 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.125819243612928e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n641",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911341
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.04e-08
2024-11-20 19:05:35,769 - INFO - 
Starting training for config s6_n642:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:05:35,770 - INFO - Running command: ./train_gpt2cu -l 2.214422303294427e-05 -o hyperband_runs_20241120_172038/run_s6_n642 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:05:45,581 - INFO - Training completed for config s6_n642:
  Training time: 0:00:09
  Final validation loss: 10.911324
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.16e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n642/checkpoint.bin
2024-11-20 19:05:45,581 - INFO - 
Configuration s6_n642 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.214422303294427e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n642",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911324
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.16e-08
2024-11-20 19:05:45,581 - INFO - 
Starting training for config s6_n643:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:05:45,581 - INFO - Running command: ./train_gpt2cu -l 0.0005720172163291692 -o hyperband_runs_20241120_172038/run_s6_n643 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:05:55,424 - INFO - Training completed for config s6_n643:
  Training time: 0:00:09
  Final validation loss: 10.904593
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.17e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n643/checkpoint.bin
2024-11-20 19:05:55,424 - INFO - 
Configuration s6_n643 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005720172163291692",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n643",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904593
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.17e-07
2024-11-20 19:05:55,424 - INFO - 
Starting training for config s6_n644:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:05:55,424 - INFO - Running command: ./train_gpt2cu -l 1.4046269688907319e-05 -o hyperband_runs_20241120_172038/run_s6_n644 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:06:05,237 - INFO - Training completed for config s6_n644:
  Training time: 0:00:09
  Final validation loss: 10.911429
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.01e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n644/checkpoint.bin
2024-11-20 19:06:05,237 - INFO - 
Configuration s6_n644 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.4046269688907319e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n644",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911429
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.01e-08
2024-11-20 19:06:05,237 - INFO - 
Starting training for config s6_n645:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:06:05,237 - INFO - Running command: ./train_gpt2cu -l 5.810657016497294e-05 -o hyperband_runs_20241120_172038/run_s6_n645 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:06:15,052 - INFO - Training completed for config s6_n645:
  Training time: 0:00:09
  Final validation loss: 10.910887
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.30e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n645/checkpoint.bin
2024-11-20 19:06:15,053 - INFO - 
Configuration s6_n645 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.810657016497294e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n645",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910887
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.30e-08
2024-11-20 19:06:15,053 - INFO - 
Starting training for config s6_n646:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:06:15,053 - INFO - Running command: ./train_gpt2cu -l 0.0004027082254989879 -o hyperband_runs_20241120_172038/run_s6_n646 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:06:24,869 - INFO - Training completed for config s6_n646:
  Training time: 0:00:09
  Final validation loss: 10.906633
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.75e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n646/checkpoint.bin
2024-11-20 19:06:24,869 - INFO - 
Configuration s6_n646 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004027082254989879",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n646",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906633
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.75e-07
2024-11-20 19:06:24,869 - INFO - 
Starting training for config s6_n647:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:06:24,869 - INFO - Running command: ./train_gpt2cu -l 0.0003642664166407205 -o hyperband_runs_20241120_172038/run_s6_n647 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:06:34,683 - INFO - Training completed for config s6_n647:
  Training time: 0:00:09
  Final validation loss: 10.907109
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.20e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n647/checkpoint.bin
2024-11-20 19:06:34,684 - INFO - 
Configuration s6_n647 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003642664166407205",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n647",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907109
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.20e-07
2024-11-20 19:06:34,684 - INFO - 
Starting training for config s6_n648:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:06:34,684 - INFO - Running command: ./train_gpt2cu -l 0.00014369669328027261 -o hyperband_runs_20241120_172038/run_s6_n648 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:06:44,489 - INFO - Training completed for config s6_n648:
  Training time: 0:00:09
  Final validation loss: 10.909819
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.05e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n648/checkpoint.bin
2024-11-20 19:06:44,489 - INFO - 
Configuration s6_n648 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014369669328027261",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n648",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909819
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.05e-07
2024-11-20 19:06:44,489 - INFO - 
Starting training for config s6_n649:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:06:44,489 - INFO - Running command: ./train_gpt2cu -l 0.00040113875039152864 -o hyperband_runs_20241120_172038/run_s6_n649 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:06:54,302 - INFO - Training completed for config s6_n649:
  Training time: 0:00:09
  Final validation loss: 10.906658
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.73e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n649/checkpoint.bin
2024-11-20 19:06:54,302 - INFO - 
Configuration s6_n649 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00040113875039152864",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n649",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906658
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.73e-07
2024-11-20 19:06:54,302 - INFO - 
Starting training for config s6_n650:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:06:54,302 - INFO - Running command: ./train_gpt2cu -l 2.833870803771944e-05 -o hyperband_runs_20241120_172038/run_s6_n650 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:07:04,109 - INFO - Training completed for config s6_n650:
  Training time: 0:00:09
  Final validation loss: 10.911267
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.05e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n650/checkpoint.bin
2024-11-20 19:07:04,109 - INFO - 
Configuration s6_n650 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.833870803771944e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n650",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911267
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.05e-08
2024-11-20 19:07:04,109 - INFO - 
Starting training for config s6_n651:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:07:04,109 - INFO - Running command: ./train_gpt2cu -l 1.1383504915563191e-05 -o hyperband_runs_20241120_172038/run_s6_n651 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:07:13,929 - INFO - Training completed for config s6_n651:
  Training time: 0:00:09
  Final validation loss: 10.911462
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.63e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n651/checkpoint.bin
2024-11-20 19:07:13,930 - INFO - 
Configuration s6_n651 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.1383504915563191e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n651",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911462
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.63e-08
2024-11-20 19:07:13,930 - INFO - 
Starting training for config s6_n652:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:07:13,930 - INFO - Running command: ./train_gpt2cu -l 0.00081477193361014 -o hyperband_runs_20241120_172038/run_s6_n652 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:07:23,728 - INFO - Training completed for config s6_n652:
  Training time: 0:00:09
  Final validation loss: 10.901621
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.16e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n652/checkpoint.bin
2024-11-20 19:07:23,728 - INFO - 
Configuration s6_n652 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00081477193361014",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n652",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.901621
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.16e-06
2024-11-20 19:07:23,729 - INFO - 
Starting training for config s6_n653:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:07:23,729 - INFO - Running command: ./train_gpt2cu -l 0.0005074096433030957 -o hyperband_runs_20241120_172038/run_s6_n653 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:07:33,553 - INFO - Training completed for config s6_n653:
  Training time: 0:00:09
  Final validation loss: 10.905370
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.25e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n653/checkpoint.bin
2024-11-20 19:07:33,554 - INFO - 
Configuration s6_n653 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005074096433030957",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n653",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905370
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.25e-07
2024-11-20 19:07:33,554 - INFO - 
Starting training for config s6_n654:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:07:33,554 - INFO - Running command: ./train_gpt2cu -l 0.0001679851852726962 -o hyperband_runs_20241120_172038/run_s6_n654 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:07:43,354 - INFO - Training completed for config s6_n654:
  Training time: 0:00:09
  Final validation loss: 10.909521
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.40e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n654/checkpoint.bin
2024-11-20 19:07:43,354 - INFO - 
Configuration s6_n654 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001679851852726962",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n654",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909521
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.40e-07
2024-11-20 19:07:43,354 - INFO - 
Starting training for config s6_n655:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:07:43,355 - INFO - Running command: ./train_gpt2cu -l 0.000573822404641857 -o hyperband_runs_20241120_172038/run_s6_n655 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:07:53,156 - INFO - Training completed for config s6_n655:
  Training time: 0:00:09
  Final validation loss: 10.904554
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.20e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n655/checkpoint.bin
2024-11-20 19:07:53,156 - INFO - 
Configuration s6_n655 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000573822404641857",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n655",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904554
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.20e-07
2024-11-20 19:07:53,156 - INFO - 
Starting training for config s6_n656:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:07:53,156 - INFO - Running command: ./train_gpt2cu -l 4.533204515863054e-05 -o hyperband_runs_20241120_172038/run_s6_n656 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:08:02,960 - INFO - Training completed for config s6_n656:
  Training time: 0:00:09
  Final validation loss: 10.911056
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.48e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n656/checkpoint.bin
2024-11-20 19:08:02,960 - INFO - 
Configuration s6_n656 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.533204515863054e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n656",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911056
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.48e-08
2024-11-20 19:08:02,960 - INFO - 
Starting training for config s6_n657:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:08:02,960 - INFO - Running command: ./train_gpt2cu -l 0.0004283293388778901 -o hyperband_runs_20241120_172038/run_s6_n657 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:08:12,762 - INFO - Training completed for config s6_n657:
  Training time: 0:00:09
  Final validation loss: 10.906323
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.12e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n657/checkpoint.bin
2024-11-20 19:08:12,763 - INFO - 
Configuration s6_n657 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004283293388778901",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n657",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906323
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.12e-07
2024-11-20 19:08:12,763 - INFO - 
Starting training for config s6_n658:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:08:12,763 - INFO - Running command: ./train_gpt2cu -l 5.052063123298024e-05 -o hyperband_runs_20241120_172038/run_s6_n658 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:08:22,554 - INFO - Training completed for config s6_n658:
  Training time: 0:00:09
  Final validation loss: 10.910983
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.22e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n658/checkpoint.bin
2024-11-20 19:08:22,554 - INFO - 
Configuration s6_n658 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.052063123298024e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n658",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910983
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.22e-08
2024-11-20 19:08:22,554 - INFO - 
Starting training for config s6_n659:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:08:22,554 - INFO - Running command: ./train_gpt2cu -l 6.891924031605632e-05 -o hyperband_runs_20241120_172038/run_s6_n659 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:08:32,360 - INFO - Training completed for config s6_n659:
  Training time: 0:00:09
  Final validation loss: 10.910742
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.85e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n659/checkpoint.bin
2024-11-20 19:08:32,360 - INFO - 
Configuration s6_n659 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.891924031605632e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n659",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910742
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.85e-08
2024-11-20 19:08:32,360 - INFO - 
Starting training for config s6_n660:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:08:32,360 - INFO - Running command: ./train_gpt2cu -l 2.4615135676650183e-05 -o hyperband_runs_20241120_172038/run_s6_n660 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:08:42,168 - INFO - Training completed for config s6_n660:
  Training time: 0:00:09
  Final validation loss: 10.911299
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.52e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n660/checkpoint.bin
2024-11-20 19:08:42,168 - INFO - 
Configuration s6_n660 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.4615135676650183e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n660",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911299
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.52e-08
2024-11-20 19:08:42,168 - INFO - 
Starting training for config s6_n661:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:08:42,169 - INFO - Running command: ./train_gpt2cu -l 5.413666108890476e-05 -o hyperband_runs_20241120_172038/run_s6_n661 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:08:51,974 - INFO - Training completed for config s6_n661:
  Training time: 0:00:09
  Final validation loss: 10.910941
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.73e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n661/checkpoint.bin
2024-11-20 19:08:51,974 - INFO - 
Configuration s6_n661 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.413666108890476e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n661",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910941
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.73e-08
2024-11-20 19:08:51,974 - INFO - 
Starting training for config s6_n662:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:08:51,974 - INFO - Running command: ./train_gpt2cu -l 2.1789525523583005e-05 -o hyperband_runs_20241120_172038/run_s6_n662 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:09:01,775 - INFO - Training completed for config s6_n662:
  Training time: 0:00:09
  Final validation loss: 10.911341
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.11e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n662/checkpoint.bin
2024-11-20 19:09:01,775 - INFO - 
Configuration s6_n662 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.1789525523583005e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n662",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911341
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.11e-08
2024-11-20 19:09:01,775 - INFO - 
Starting training for config s6_n663:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:09:01,775 - INFO - Running command: ./train_gpt2cu -l 4.0908741915302165e-05 -o hyperband_runs_20241120_172038/run_s6_n663 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:09:11,600 - INFO - Training completed for config s6_n663:
  Training time: 0:00:09
  Final validation loss: 10.911104
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.84e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n663/checkpoint.bin
2024-11-20 19:09:11,601 - INFO - 
Configuration s6_n663 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.0908741915302165e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n663",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911104
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.84e-08
2024-11-20 19:09:11,601 - INFO - 
Starting training for config s6_n664:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:09:11,601 - INFO - Running command: ./train_gpt2cu -l 3.404638689794727e-05 -o hyperband_runs_20241120_172038/run_s6_n664 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:09:21,417 - INFO - Training completed for config s6_n664:
  Training time: 0:00:09
  Final validation loss: 10.911200
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.86e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n664/checkpoint.bin
2024-11-20 19:09:21,417 - INFO - 
Configuration s6_n664 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.404638689794727e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n664",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911200
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.86e-08
2024-11-20 19:09:21,417 - INFO - 
Starting training for config s6_n665:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:09:21,417 - INFO - Running command: ./train_gpt2cu -l 0.00021237975136107032 -o hyperband_runs_20241120_172038/run_s6_n665 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:09:31,225 - INFO - Training completed for config s6_n665:
  Training time: 0:00:09
  Final validation loss: 10.908983
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.03e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n665/checkpoint.bin
2024-11-20 19:09:31,225 - INFO - 
Configuration s6_n665 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00021237975136107032",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n665",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908983
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.03e-07
2024-11-20 19:09:31,225 - INFO - 
Starting training for config s6_n666:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:09:31,225 - INFO - Running command: ./train_gpt2cu -l 0.00034027257651389703 -o hyperband_runs_20241120_172038/run_s6_n666 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:09:41,044 - INFO - Training completed for config s6_n666:
  Training time: 0:00:09
  Final validation loss: 10.907404
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.86e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n666/checkpoint.bin
2024-11-20 19:09:41,044 - INFO - 
Configuration s6_n666 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00034027257651389703",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n666",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907404
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.86e-07
2024-11-20 19:09:41,044 - INFO - 
Starting training for config s6_n667:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:09:41,045 - INFO - Running command: ./train_gpt2cu -l 0.0007052164516636011 -o hyperband_runs_20241120_172038/run_s6_n667 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:09:50,855 - INFO - Training completed for config s6_n667:
  Training time: 0:00:09
  Final validation loss: 10.902952
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.01e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n667/checkpoint.bin
2024-11-20 19:09:50,855 - INFO - 
Configuration s6_n667 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007052164516636011",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n667",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.902952
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.01e-06
2024-11-20 19:09:50,855 - INFO - 
Starting training for config s6_n668:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:09:50,855 - INFO - Running command: ./train_gpt2cu -l 4.689355535916641e-05 -o hyperband_runs_20241120_172038/run_s6_n668 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:10:00,673 - INFO - Training completed for config s6_n668:
  Training time: 0:00:09
  Final validation loss: 10.911037
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.70e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n668/checkpoint.bin
2024-11-20 19:10:00,673 - INFO - 
Configuration s6_n668 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.689355535916641e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n668",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911037
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.70e-08
2024-11-20 19:10:00,674 - INFO - 
Starting training for config s6_n669:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:10:00,674 - INFO - Running command: ./train_gpt2cu -l 0.0005269083413840958 -o hyperband_runs_20241120_172038/run_s6_n669 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:10:10,495 - INFO - Training completed for config s6_n669:
  Training time: 0:00:09
  Final validation loss: 10.905139
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.53e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n669/checkpoint.bin
2024-11-20 19:10:10,495 - INFO - 
Configuration s6_n669 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005269083413840958",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n669",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.905139
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.53e-07
2024-11-20 19:10:10,495 - INFO - 
Starting training for config s6_n670:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:10:10,495 - INFO - Running command: ./train_gpt2cu -l 0.00011970574293899663 -o hyperband_runs_20241120_172038/run_s6_n670 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:10:20,299 - INFO - Training completed for config s6_n670:
  Training time: 0:00:09
  Final validation loss: 10.910116
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.71e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n670/checkpoint.bin
2024-11-20 19:10:20,299 - INFO - 
Configuration s6_n670 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00011970574293899663",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n670",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910116
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.71e-07
2024-11-20 19:10:20,299 - INFO - 
Starting training for config s6_n671:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:10:20,299 - INFO - Running command: ./train_gpt2cu -l 3.3428680613685236e-05 -o hyperband_runs_20241120_172038/run_s6_n671 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:10:30,116 - INFO - Training completed for config s6_n671:
  Training time: 0:00:09
  Final validation loss: 10.911209
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.78e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n671/checkpoint.bin
2024-11-20 19:10:30,116 - INFO - 
Configuration s6_n671 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.3428680613685236e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n671",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911209
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.78e-08
2024-11-20 19:10:30,116 - INFO - 
Starting training for config s6_n672:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:10:30,117 - INFO - Running command: ./train_gpt2cu -l 0.0004255953434304252 -o hyperband_runs_20241120_172038/run_s6_n672 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:10:39,942 - INFO - Training completed for config s6_n672:
  Training time: 0:00:09
  Final validation loss: 10.906363
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.08e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n672/checkpoint.bin
2024-11-20 19:10:39,943 - INFO - 
Configuration s6_n672 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004255953434304252",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n672",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906363
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.08e-07
2024-11-20 19:10:39,943 - INFO - 
Starting training for config s6_n673:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:10:39,943 - INFO - Running command: ./train_gpt2cu -l 4.078510284103951e-05 -o hyperband_runs_20241120_172038/run_s6_n673 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:10:49,746 - INFO - Training completed for config s6_n673:
  Training time: 0:00:09
  Final validation loss: 10.911110
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.83e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n673/checkpoint.bin
2024-11-20 19:10:49,747 - INFO - 
Configuration s6_n673 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.078510284103951e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n673",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911110
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.83e-08
2024-11-20 19:10:49,747 - INFO - 
Starting training for config s6_n674:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:10:49,747 - INFO - Running command: ./train_gpt2cu -l 6.929710869336622e-05 -o hyperband_runs_20241120_172038/run_s6_n674 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:10:59,583 - INFO - Training completed for config s6_n674:
  Training time: 0:00:09
  Final validation loss: 10.910746
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.90e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n674/checkpoint.bin
2024-11-20 19:10:59,583 - INFO - 
Configuration s6_n674 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.929710869336622e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n674",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910746
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.90e-08
2024-11-20 19:10:59,583 - INFO - 
Starting training for config s6_n675:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:10:59,583 - INFO - Running command: ./train_gpt2cu -l 0.00018232189218803354 -o hyperband_runs_20241120_172038/run_s6_n675 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:11:09,420 - INFO - Training completed for config s6_n675:
  Training time: 0:00:09
  Final validation loss: 10.909352
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.60e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n675/checkpoint.bin
2024-11-20 19:11:09,421 - INFO - 
Configuration s6_n675 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00018232189218803354",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n675",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909352
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.60e-07
2024-11-20 19:11:09,421 - INFO - 
Starting training for config s6_n676:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:11:09,421 - INFO - Running command: ./train_gpt2cu -l 1.8988086142650574e-05 -o hyperband_runs_20241120_172038/run_s6_n676 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:11:19,221 - INFO - Training completed for config s6_n676:
  Training time: 0:00:09
  Final validation loss: 10.911366
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.71e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n676/checkpoint.bin
2024-11-20 19:11:19,222 - INFO - 
Configuration s6_n676 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.8988086142650574e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n676",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911366
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.71e-08
2024-11-20 19:11:19,222 - INFO - 
Starting training for config s6_n677:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:11:19,222 - INFO - Running command: ./train_gpt2cu -l 0.0007683502023562 -o hyperband_runs_20241120_172038/run_s6_n677 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:11:29,036 - INFO - Training completed for config s6_n677:
  Training time: 0:00:09
  Final validation loss: 10.902189
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.10e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n677/checkpoint.bin
2024-11-20 19:11:29,036 - INFO - 
Configuration s6_n677 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007683502023562",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n677",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.902189
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-06
2024-11-20 19:11:29,036 - INFO - 
Starting training for config s6_n678:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:11:29,036 - INFO - Running command: ./train_gpt2cu -l 2.2073375735644282e-05 -o hyperband_runs_20241120_172038/run_s6_n678 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:11:38,834 - INFO - Training completed for config s6_n678:
  Training time: 0:00:09
  Final validation loss: 10.911333
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.15e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n678/checkpoint.bin
2024-11-20 19:11:38,834 - INFO - 
Configuration s6_n678 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.2073375735644282e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n678",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911333
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.15e-08
2024-11-20 19:11:38,834 - INFO - 
Starting training for config s6_n679:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:11:38,834 - INFO - Running command: ./train_gpt2cu -l 5.600307796325918e-05 -o hyperband_runs_20241120_172038/run_s6_n679 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:11:48,638 - INFO - Training completed for config s6_n679:
  Training time: 0:00:09
  Final validation loss: 10.910912
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.00e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n679/checkpoint.bin
2024-11-20 19:11:48,638 - INFO - 
Configuration s6_n679 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "5.600307796325918e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n679",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910912
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.00e-08
2024-11-20 19:11:48,638 - INFO - 
Starting training for config s6_n680:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:11:48,639 - INFO - Running command: ./train_gpt2cu -l 0.00033916528330383026 -o hyperband_runs_20241120_172038/run_s6_n680 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:11:58,454 - INFO - Training completed for config s6_n680:
  Training time: 0:00:09
  Final validation loss: 10.907420
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.85e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n680/checkpoint.bin
2024-11-20 19:11:58,454 - INFO - 
Configuration s6_n680 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00033916528330383026",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n680",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907420
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.85e-07
2024-11-20 19:11:58,454 - INFO - 
Starting training for config s6_n681:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:11:58,454 - INFO - Running command: ./train_gpt2cu -l 0.00020648832026337472 -o hyperband_runs_20241120_172038/run_s6_n681 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:12:08,265 - INFO - Training completed for config s6_n681:
  Training time: 0:00:09
  Final validation loss: 10.909060
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.95e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n681/checkpoint.bin
2024-11-20 19:12:08,265 - INFO - 
Configuration s6_n681 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00020648832026337472",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n681",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909060
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.95e-07
2024-11-20 19:12:08,265 - INFO - 
Starting training for config s6_n682:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:12:08,265 - INFO - Running command: ./train_gpt2cu -l 1.92172488726427e-05 -o hyperband_runs_20241120_172038/run_s6_n682 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:12:18,065 - INFO - Training completed for config s6_n682:
  Training time: 0:00:09
  Final validation loss: 10.911376
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.75e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n682/checkpoint.bin
2024-11-20 19:12:18,066 - INFO - 
Configuration s6_n682 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.92172488726427e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n682",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911376
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.75e-08
2024-11-20 19:12:18,066 - INFO - 
Starting training for config s6_n683:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:12:18,066 - INFO - Running command: ./train_gpt2cu -l 0.00013757619572047418 -o hyperband_runs_20241120_172038/run_s6_n683 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:12:27,866 - INFO - Training completed for config s6_n683:
  Training time: 0:00:09
  Final validation loss: 10.909893
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.97e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n683/checkpoint.bin
2024-11-20 19:12:27,866 - INFO - 
Configuration s6_n683 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013757619572047418",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n683",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909893
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.97e-07
2024-11-20 19:12:27,867 - INFO - 
Starting training for config s6_n684:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:12:27,867 - INFO - Running command: ./train_gpt2cu -l 3.08800119082644e-05 -o hyperband_runs_20241120_172038/run_s6_n684 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:12:37,677 - INFO - Training completed for config s6_n684:
  Training time: 0:00:09
  Final validation loss: 10.911226
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.41e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n684/checkpoint.bin
2024-11-20 19:12:37,677 - INFO - 
Configuration s6_n684 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.08800119082644e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n684",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911226
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.41e-08
2024-11-20 19:12:37,677 - INFO - 
Starting training for config s6_n685:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:12:37,678 - INFO - Running command: ./train_gpt2cu -l 0.00012078149946818566 -o hyperband_runs_20241120_172038/run_s6_n685 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:12:47,489 - INFO - Training completed for config s6_n685:
  Training time: 0:00:09
  Final validation loss: 10.910107
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.73e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n685/checkpoint.bin
2024-11-20 19:12:47,489 - INFO - 
Configuration s6_n685 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012078149946818566",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n685",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910107
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.73e-07
2024-11-20 19:12:47,489 - INFO - 
Starting training for config s6_n686:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:12:47,489 - INFO - Running command: ./train_gpt2cu -l 4.090010202926255e-05 -o hyperband_runs_20241120_172038/run_s6_n686 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:12:57,277 - INFO - Training completed for config s6_n686:
  Training time: 0:00:09
  Final validation loss: 10.911100
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.84e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n686/checkpoint.bin
2024-11-20 19:12:57,278 - INFO - 
Configuration s6_n686 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.090010202926255e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n686",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911100
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.84e-08
2024-11-20 19:12:57,278 - INFO - 
Starting training for config s6_n687:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:12:57,278 - INFO - Running command: ./train_gpt2cu -l 1.4048399763139695e-05 -o hyperband_runs_20241120_172038/run_s6_n687 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:13:07,087 - INFO - Training completed for config s6_n687:
  Training time: 0:00:09
  Final validation loss: 10.911437
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.01e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n687/checkpoint.bin
2024-11-20 19:13:07,087 - INFO - 
Configuration s6_n687 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.4048399763139695e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n687",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911437
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.01e-08
2024-11-20 19:13:07,087 - INFO - 
Starting training for config s6_n688:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:13:07,088 - INFO - Running command: ./train_gpt2cu -l 0.00015086047669819316 -o hyperband_runs_20241120_172038/run_s6_n688 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:13:16,910 - INFO - Training completed for config s6_n688:
  Training time: 0:00:09
  Final validation loss: 10.909737
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.16e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n688/checkpoint.bin
2024-11-20 19:13:16,910 - INFO - 
Configuration s6_n688 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00015086047669819316",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n688",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.909737
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.16e-07
2024-11-20 19:13:16,910 - INFO - 
Starting training for config s6_n689:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:13:16,911 - INFO - Running command: ./train_gpt2cu -l 0.0003215587431981187 -o hyperband_runs_20241120_172038/run_s6_n689 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:13:26,712 - INFO - Training completed for config s6_n689:
  Training time: 0:00:09
  Final validation loss: 10.907622
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.59e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n689/checkpoint.bin
2024-11-20 19:13:26,713 - INFO - 
Configuration s6_n689 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003215587431981187",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n689",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907622
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.59e-07
2024-11-20 19:13:26,713 - INFO - 
Starting training for config s6_n690:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:13:26,713 - INFO - Running command: ./train_gpt2cu -l 0.00038928301499258745 -o hyperband_runs_20241120_172038/run_s6_n690 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:13:36,521 - INFO - Training completed for config s6_n690:
  Training time: 0:00:09
  Final validation loss: 10.906786
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.56e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n690/checkpoint.bin
2024-11-20 19:13:36,521 - INFO - 
Configuration s6_n690 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00038928301499258745",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n690",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906786
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.56e-07
2024-11-20 19:13:36,521 - INFO - 
Starting training for config s6_n691:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:13:36,522 - INFO - Running command: ./train_gpt2cu -l 0.0001262126298901507 -o hyperband_runs_20241120_172038/run_s6_n691 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:13:46,339 - INFO - Training completed for config s6_n691:
  Training time: 0:00:09
  Final validation loss: 10.910032
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.80e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n691/checkpoint.bin
2024-11-20 19:13:46,339 - INFO - 
Configuration s6_n691 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001262126298901507",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n691",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910032
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.80e-07
2024-11-20 19:13:46,339 - INFO - 
Starting training for config s6_n692:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:13:46,340 - INFO - Running command: ./train_gpt2cu -l 7.975863834032993e-05 -o hyperband_runs_20241120_172038/run_s6_n692 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:13:56,160 - INFO - Training completed for config s6_n692:
  Training time: 0:00:09
  Final validation loss: 10.910620
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.14e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n692/checkpoint.bin
2024-11-20 19:13:56,160 - INFO - 
Configuration s6_n692 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "7.975863834032993e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n692",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910620
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.14e-07
2024-11-20 19:13:56,160 - INFO - 
Starting training for config s6_n693:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:13:56,160 - INFO - Running command: ./train_gpt2cu -l 0.00028270003811761056 -o hyperband_runs_20241120_172038/run_s6_n693 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:14:05,982 - INFO - Training completed for config s6_n693:
  Training time: 0:00:09
  Final validation loss: 10.908113
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.04e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n693/checkpoint.bin
2024-11-20 19:14:05,983 - INFO - 
Configuration s6_n693 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00028270003811761056",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n693",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908113
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.04e-07
2024-11-20 19:14:05,983 - INFO - 
Starting training for config s6_n694:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:14:05,983 - INFO - Running command: ./train_gpt2cu -l 0.0005785577817493396 -o hyperband_runs_20241120_172038/run_s6_n694 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:14:15,796 - INFO - Training completed for config s6_n694:
  Training time: 0:00:09
  Final validation loss: 10.904501
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 8.27e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n694/checkpoint.bin
2024-11-20 19:14:15,797 - INFO - 
Configuration s6_n694 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005785577817493396",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n694",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904501
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.27e-07
2024-11-20 19:14:15,797 - INFO - 
Starting training for config s6_n695:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:14:15,797 - INFO - Running command: ./train_gpt2cu -l 0.00023770609386476307 -o hyperband_runs_20241120_172038/run_s6_n695 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:14:25,627 - INFO - Training completed for config s6_n695:
  Training time: 0:00:09
  Final validation loss: 10.908674
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.40e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n695/checkpoint.bin
2024-11-20 19:14:25,628 - INFO - 
Configuration s6_n695 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00023770609386476307",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n695",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908674
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.40e-07
2024-11-20 19:14:25,628 - INFO - 
Starting training for config s6_n696:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:14:25,628 - INFO - Running command: ./train_gpt2cu -l 0.00026874093015523577 -o hyperband_runs_20241120_172038/run_s6_n696 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:14:35,446 - INFO - Training completed for config s6_n696:
  Training time: 0:00:09
  Final validation loss: 10.908287
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.84e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n696/checkpoint.bin
2024-11-20 19:14:35,446 - INFO - 
Configuration s6_n696 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00026874093015523577",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n696",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908287
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.84e-07
2024-11-20 19:14:35,447 - INFO - 
Starting training for config s6_n697:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:14:35,447 - INFO - Running command: ./train_gpt2cu -l 1.0293593321050873e-05 -o hyperband_runs_20241120_172038/run_s6_n697 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:14:45,256 - INFO - Training completed for config s6_n697:
  Training time: 0:00:09
  Final validation loss: 10.911466
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.47e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n697/checkpoint.bin
2024-11-20 19:14:45,257 - INFO - 
Configuration s6_n697 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.0293593321050873e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n697",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911466
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.47e-08
2024-11-20 19:14:45,257 - INFO - 
Starting training for config s6_n698:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:14:45,257 - INFO - Running command: ./train_gpt2cu -l 0.00011813733966184564 -o hyperband_runs_20241120_172038/run_s6_n698 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:14:55,056 - INFO - Training completed for config s6_n698:
  Training time: 0:00:09
  Final validation loss: 10.910138
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.69e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n698/checkpoint.bin
2024-11-20 19:14:55,056 - INFO - 
Configuration s6_n698 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00011813733966184564",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n698",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910138
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.69e-07
2024-11-20 19:14:55,056 - INFO - 
Starting training for config s6_n699:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:14:55,056 - INFO - Running command: ./train_gpt2cu -l 6.51875322853796e-05 -o hyperband_runs_20241120_172038/run_s6_n699 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:15:04,860 - INFO - Training completed for config s6_n699:
  Training time: 0:00:09
  Final validation loss: 10.910795
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.31e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n699/checkpoint.bin
2024-11-20 19:15:04,861 - INFO - 
Configuration s6_n699 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "6.51875322853796e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n699",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910795
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.31e-08
2024-11-20 19:15:04,861 - INFO - 
Starting training for config s6_n700:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:15:04,861 - INFO - Running command: ./train_gpt2cu -l 0.0006951122926882169 -o hyperband_runs_20241120_172038/run_s6_n700 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:15:14,677 - INFO - Training completed for config s6_n700:
  Training time: 0:00:09
  Final validation loss: 10.903079
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 9.93e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n700/checkpoint.bin
2024-11-20 19:15:14,678 - INFO - 
Configuration s6_n700 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006951122926882169",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n700",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.903079
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.93e-07
2024-11-20 19:15:14,678 - INFO - 
Starting training for config s6_n701:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:15:14,678 - INFO - Running command: ./train_gpt2cu -l 1.5093754995041652e-05 -o hyperband_runs_20241120_172038/run_s6_n701 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:15:24,489 - INFO - Training completed for config s6_n701:
  Training time: 0:00:09
  Final validation loss: 10.911421
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.16e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n701/checkpoint.bin
2024-11-20 19:15:24,489 - INFO - 
Configuration s6_n701 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.5093754995041652e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n701",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911421
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.16e-08
2024-11-20 19:15:24,489 - INFO - 
Starting training for config s6_n702:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:15:24,489 - INFO - Running command: ./train_gpt2cu -l 3.0551491966287525e-05 -o hyperband_runs_20241120_172038/run_s6_n702 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:15:34,304 - INFO - Training completed for config s6_n702:
  Training time: 0:00:09
  Final validation loss: 10.911235
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.36e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n702/checkpoint.bin
2024-11-20 19:15:34,305 - INFO - 
Configuration s6_n702 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.0551491966287525e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n702",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911235
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.36e-08
2024-11-20 19:15:34,305 - INFO - 
Starting training for config s6_n703:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:15:34,305 - INFO - Running command: ./train_gpt2cu -l 2.3601601086749784e-05 -o hyperband_runs_20241120_172038/run_s6_n703 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:15:44,144 - INFO - Training completed for config s6_n703:
  Training time: 0:00:09
  Final validation loss: 10.911331
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.37e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n703/checkpoint.bin
2024-11-20 19:15:44,144 - INFO - 
Configuration s6_n703 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.3601601086749784e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n703",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911331
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.37e-08
2024-11-20 19:15:44,144 - INFO - 
Starting training for config s6_n704:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:15:44,144 - INFO - Running command: ./train_gpt2cu -l 3.194448999896041e-05 -o hyperband_runs_20241120_172038/run_s6_n704 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:15:53,956 - INFO - Training completed for config s6_n704:
  Training time: 0:00:09
  Final validation loss: 10.911226
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.56e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n704/checkpoint.bin
2024-11-20 19:15:53,956 - INFO - 
Configuration s6_n704 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.194448999896041e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n704",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911226
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.56e-08
2024-11-20 19:15:53,956 - INFO - 
Starting training for config s6_n705:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:15:53,956 - INFO - Running command: ./train_gpt2cu -l 0.0007045014359961428 -o hyperband_runs_20241120_172038/run_s6_n705 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:16:03,782 - INFO - Training completed for config s6_n705:
  Training time: 0:00:09
  Final validation loss: 10.902961
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.01e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n705/checkpoint.bin
2024-11-20 19:16:03,783 - INFO - 
Configuration s6_n705 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007045014359961428",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n705",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.902961
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.01e-06
2024-11-20 19:16:03,783 - INFO - 
Starting training for config s6_n706:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:16:03,783 - INFO - Running command: ./train_gpt2cu -l 1.1315507944221985e-05 -o hyperband_runs_20241120_172038/run_s6_n706 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:16:13,589 - INFO - Training completed for config s6_n706:
  Training time: 0:00:09
  Final validation loss: 10.911464
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.62e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n706/checkpoint.bin
2024-11-20 19:16:13,589 - INFO - 
Configuration s6_n706 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.1315507944221985e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n706",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911464
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.62e-08
2024-11-20 19:16:13,589 - INFO - 
Starting training for config s6_n707:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:16:13,590 - INFO - Running command: ./train_gpt2cu -l 3.6854613667030884e-05 -o hyperband_runs_20241120_172038/run_s6_n707 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:16:23,406 - INFO - Training completed for config s6_n707:
  Training time: 0:00:09
  Final validation loss: 10.911169
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.26e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n707/checkpoint.bin
2024-11-20 19:16:23,406 - INFO - 
Configuration s6_n707 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "3.6854613667030884e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n707",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911169
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.26e-08
2024-11-20 19:16:23,407 - INFO - 
Starting training for config s6_n708:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:16:23,407 - INFO - Running command: ./train_gpt2cu -l 0.00012231392378853138 -o hyperband_runs_20241120_172038/run_s6_n708 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:16:33,231 - INFO - Training completed for config s6_n708:
  Training time: 0:00:09
  Final validation loss: 10.910091
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.75e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n708/checkpoint.bin
2024-11-20 19:16:33,231 - INFO - 
Configuration s6_n708 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012231392378853138",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n708",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910091
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.75e-07
2024-11-20 19:16:33,231 - INFO - 
Starting training for config s6_n709:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:16:33,231 - INFO - Running command: ./train_gpt2cu -l 1.648719888079006e-05 -o hyperband_runs_20241120_172038/run_s6_n709 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:16:43,041 - INFO - Training completed for config s6_n709:
  Training time: 0:00:09
  Final validation loss: 10.911409
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.36e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n709/checkpoint.bin
2024-11-20 19:16:43,041 - INFO - 
Configuration s6_n709 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.648719888079006e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n709",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911409
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.36e-08
2024-11-20 19:16:43,041 - INFO - 
Starting training for config s6_n710:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:16:43,041 - INFO - Running command: ./train_gpt2cu -l 2.5827505635930866e-05 -o hyperband_runs_20241120_172038/run_s6_n710 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:16:52,867 - INFO - Training completed for config s6_n710:
  Training time: 0:00:09
  Final validation loss: 10.911301
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.69e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n710/checkpoint.bin
2024-11-20 19:16:52,868 - INFO - 
Configuration s6_n710 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.5827505635930866e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n710",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911301
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.69e-08
2024-11-20 19:16:52,868 - INFO - 
Starting training for config s6_n711:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:16:52,868 - INFO - Running command: ./train_gpt2cu -l 2.4267606006815547e-05 -o hyperband_runs_20241120_172038/run_s6_n711 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:17:02,684 - INFO - Training completed for config s6_n711:
  Training time: 0:00:09
  Final validation loss: 10.911307
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.47e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n711/checkpoint.bin
2024-11-20 19:17:02,684 - INFO - 
Configuration s6_n711 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.4267606006815547e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n711",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911307
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.47e-08
2024-11-20 19:17:02,684 - INFO - 
Starting training for config s6_n712:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:17:02,684 - INFO - Running command: ./train_gpt2cu -l 4.564252819084777e-05 -o hyperband_runs_20241120_172038/run_s6_n712 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:17:12,504 - INFO - Training completed for config s6_n712:
  Training time: 0:00:09
  Final validation loss: 10.911054
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.52e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n712/checkpoint.bin
2024-11-20 19:17:12,504 - INFO - 
Configuration s6_n712 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.564252819084777e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n712",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911054
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.52e-08
2024-11-20 19:17:12,504 - INFO - 
Starting training for config s6_n713:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:17:12,504 - INFO - Running command: ./train_gpt2cu -l 0.0005499121239166275 -o hyperband_runs_20241120_172038/run_s6_n713 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:17:22,320 - INFO - Training completed for config s6_n713:
  Training time: 0:00:09
  Final validation loss: 10.904837
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 7.86e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n713/checkpoint.bin
2024-11-20 19:17:22,320 - INFO - 
Configuration s6_n713 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005499121239166275",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n713",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.904837
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.86e-07
2024-11-20 19:17:22,320 - INFO - 
Starting training for config s6_n714:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:17:22,321 - INFO - Running command: ./train_gpt2cu -l 0.000303366850837294 -o hyperband_runs_20241120_172038/run_s6_n714 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:17:32,118 - INFO - Training completed for config s6_n714:
  Training time: 0:00:09
  Final validation loss: 10.907847
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.33e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n714/checkpoint.bin
2024-11-20 19:17:32,119 - INFO - 
Configuration s6_n714 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.000303366850837294",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n714",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907847
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.33e-07
2024-11-20 19:17:32,119 - INFO - 
Starting training for config s6_n715:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:17:32,119 - INFO - Running command: ./train_gpt2cu -l 1.9072807475805305e-05 -o hyperband_runs_20241120_172038/run_s6_n715 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:17:41,928 - INFO - Training completed for config s6_n715:
  Training time: 0:00:09
  Final validation loss: 10.911366
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.72e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n715/checkpoint.bin
2024-11-20 19:17:41,929 - INFO - 
Configuration s6_n715 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.9072807475805305e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n715",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911366
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.72e-08
2024-11-20 19:17:41,929 - INFO - 
Starting training for config s6_n716:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:17:41,929 - INFO - Running command: ./train_gpt2cu -l 1.0652628954181153e-05 -o hyperband_runs_20241120_172038/run_s6_n716 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:17:51,748 - INFO - Training completed for config s6_n716:
  Training time: 0:00:09
  Final validation loss: 10.911468
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.52e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n716/checkpoint.bin
2024-11-20 19:17:51,748 - INFO - 
Configuration s6_n716 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.0652628954181153e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n716",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911468
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.52e-08
2024-11-20 19:17:51,748 - INFO - 
Starting training for config s6_n717:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:17:51,748 - INFO - Running command: ./train_gpt2cu -l 1.6466792141352934e-05 -o hyperband_runs_20241120_172038/run_s6_n717 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:18:01,548 - INFO - Training completed for config s6_n717:
  Training time: 0:00:09
  Final validation loss: 10.911397
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.35e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n717/checkpoint.bin
2024-11-20 19:18:01,548 - INFO - 
Configuration s6_n717 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.6466792141352934e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n717",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911397
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.35e-08
2024-11-20 19:18:01,548 - INFO - 
Starting training for config s6_n718:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:18:01,549 - INFO - Running command: ./train_gpt2cu -l 0.00011338928510603157 -o hyperband_runs_20241120_172038/run_s6_n718 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:18:11,342 - INFO - Training completed for config s6_n718:
  Training time: 0:00:09
  Final validation loss: 10.910193
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.62e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n718/checkpoint.bin
2024-11-20 19:18:11,342 - INFO - 
Configuration s6_n718 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00011338928510603157",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n718",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910193
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.62e-07
2024-11-20 19:18:11,342 - INFO - 
Starting training for config s6_n719:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:18:11,342 - INFO - Running command: ./train_gpt2cu -l 0.00010676199353415503 -o hyperband_runs_20241120_172038/run_s6_n719 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:18:21,142 - INFO - Training completed for config s6_n719:
  Training time: 0:00:09
  Final validation loss: 10.910277
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.53e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n719/checkpoint.bin
2024-11-20 19:18:21,142 - INFO - 
Configuration s6_n719 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010676199353415503",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n719",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910277
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.53e-07
2024-11-20 19:18:21,142 - INFO - 
Starting training for config s6_n720:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:18:21,142 - INFO - Running command: ./train_gpt2cu -l 2.0354889228149053e-05 -o hyperband_runs_20241120_172038/run_s6_n720 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:18:30,966 - INFO - Training completed for config s6_n720:
  Training time: 0:00:09
  Final validation loss: 10.911355
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.91e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n720/checkpoint.bin
2024-11-20 19:18:30,966 - INFO - 
Configuration s6_n720 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "2.0354889228149053e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n720",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911355
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.91e-08
2024-11-20 19:18:30,966 - INFO - 
Starting training for config s6_n721:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:18:30,966 - INFO - Running command: ./train_gpt2cu -l 1.183900728007317e-05 -o hyperband_runs_20241120_172038/run_s6_n721 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:18:40,793 - INFO - Training completed for config s6_n721:
  Training time: 0:00:09
  Final validation loss: 10.911464
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.69e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n721/checkpoint.bin
2024-11-20 19:18:40,794 - INFO - 
Configuration s6_n721 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.183900728007317e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n721",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911464
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.69e-08
2024-11-20 19:18:40,794 - INFO - 
Starting training for config s6_n722:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:18:40,794 - INFO - Running command: ./train_gpt2cu -l 0.00029966062628708696 -o hyperband_runs_20241120_172038/run_s6_n722 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:18:50,600 - INFO - Training completed for config s6_n722:
  Training time: 0:00:09
  Final validation loss: 10.907899
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 4.28e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n722/checkpoint.bin
2024-11-20 19:18:50,601 - INFO - 
Configuration s6_n722 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00029966062628708696",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n722",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.907899
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.28e-07
2024-11-20 19:18:50,601 - INFO - 
Starting training for config s6_n723:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:18:50,601 - INFO - Running command: ./train_gpt2cu -l 1.6391935275852858e-05 -o hyperband_runs_20241120_172038/run_s6_n723 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:19:00,410 - INFO - Training completed for config s6_n723:
  Training time: 0:00:09
  Final validation loss: 10.911405
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 2.34e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n723/checkpoint.bin
2024-11-20 19:19:00,410 - INFO - 
Configuration s6_n723 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.6391935275852858e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n723",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911405
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.34e-08
2024-11-20 19:19:00,410 - INFO - 
Starting training for config s6_n724:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:19:00,411 - INFO - Running command: ./train_gpt2cu -l 0.00027035664094511645 -o hyperband_runs_20241120_172038/run_s6_n724 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:19:10,226 - INFO - Training completed for config s6_n724:
  Training time: 0:00:09
  Final validation loss: 10.908257
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 3.86e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n724/checkpoint.bin
2024-11-20 19:19:10,226 - INFO - 
Configuration s6_n724 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00027035664094511645",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n724",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.908257
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.86e-07
2024-11-20 19:19:10,226 - INFO - 
Starting training for config s6_n725:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:19:10,227 - INFO - Running command: ./train_gpt2cu -l 8.861334212887578e-05 -o hyperband_runs_20241120_172038/run_s6_n725 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:19:20,050 - INFO - Training completed for config s6_n725:
  Training time: 0:00:09
  Final validation loss: 10.910504
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.27e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n725/checkpoint.bin
2024-11-20 19:19:20,051 - INFO - 
Configuration s6_n725 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "8.861334212887578e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n725",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.910504
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.27e-07
2024-11-20 19:19:20,051 - INFO - 
Starting training for config s6_n726:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:19:20,051 - INFO - Running command: ./train_gpt2cu -l 1.1937128143630463e-05 -o hyperband_runs_20241120_172038/run_s6_n726 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:19:29,862 - INFO - Training completed for config s6_n726:
  Training time: 0:00:09
  Final validation loss: 10.911460
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 1.71e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n726/checkpoint.bin
2024-11-20 19:19:29,862 - INFO - 
Configuration s6_n726 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "1.1937128143630463e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n726",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911460
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.71e-08
2024-11-20 19:19:29,862 - INFO - 
Starting training for config s6_n727:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:19:29,862 - INFO - Running command: ./train_gpt2cu -l 4.402106374819876e-05 -o hyperband_runs_20241120_172038/run_s6_n727 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:19:39,675 - INFO - Training completed for config s6_n727:
  Training time: 0:00:09
  Final validation loss: 10.911067
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 6.29e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n727/checkpoint.bin
2024-11-20 19:19:39,676 - INFO - 
Configuration s6_n727 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "4.402106374819876e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n727",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.911067
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.29e-08
2024-11-20 19:19:39,676 - INFO - 
Starting training for config s6_n728:
  Iterations: 1
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 19:19:39,676 - INFO - Running command: ./train_gpt2cu -l 0.00037467572481081286 -o hyperband_runs_20241120_172038/run_s6_n728 -x 1 -n 1 -y 0 -b 64 -d 524288 -h 0
2024-11-20 19:19:49,489 - INFO - Training completed for config s6_n728:
  Training time: 0:00:09
  Final validation loss: 10.906987
  Hellaswag accuracy: 0.00%
  Total iterations: 1
  Maximum learning rate: 5.35e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n728/checkpoint.bin
2024-11-20 19:19:49,489 - INFO - 
Configuration s6_n728 (bracket_6_round_0):
  Hyperparameters: {
  "learning_rate": "0.00037467572481081286",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n728",
  "max_steps": "1",
  "checkpoint_every": "1",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 1
  Total iterations: 1
  Training time: 0:00:09
  Validation Loss: 10.906987
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.35e-07
2024-11-20 19:19:49,490 - INFO - 
Eliminating 486 configurations:
  Surviving: 243
2024-11-20 19:19:55,546 - INFO - 
Bracket 6, Round 1:
  Active configs: 243
  Iterations: 3
2024-11-20 19:19:55,546 - INFO - 
Starting training for config s6_n0:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin
2024-11-20 19:19:55,546 - INFO - Running command: ./train_gpt2cu -l 0.0009977479607140977 -o hyperband_runs_20241120_172038/run_s6_n0 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:20:05,077 - INFO - Training completed for config s6_n0:
  Training time: 0:00:09
  Final validation loss: 10.839233
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.28e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin
2024-11-20 19:20:05,077 - INFO - 
Configuration s6_n0 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009977479607140977",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n0",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:09
  Validation Loss: 10.839233
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.28e-06
2024-11-20 19:20:05,077 - INFO - 
New best configuration found!
  Config ID: s6_n0
  Validation Loss: 10.839233
  Hellaswag Accuracy: 0.00%
  Training Time: 0:00:09
2024-11-20 19:20:05,077 - INFO - 
Starting training for config s6_n452:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin
2024-11-20 19:20:05,077 - INFO - Running command: ./train_gpt2cu -l 0.0009894839327752709 -o hyperband_runs_20241120_172038/run_s6_n452 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:20:16,142 - INFO - Training completed for config s6_n452:
  Training time: 0:00:11
  Final validation loss: 10.839821
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.24e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin
2024-11-20 19:20:16,142 - INFO - 
Configuration s6_n452 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009894839327752709",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n452",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.839821
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.24e-06
2024-11-20 19:20:16,143 - INFO - 
Starting training for config s6_n610:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin
2024-11-20 19:20:16,143 - INFO - Running command: ./train_gpt2cu -l 0.0009840193661966614 -o hyperband_runs_20241120_172038/run_s6_n610 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:20:27,192 - INFO - Training completed for config s6_n610:
  Training time: 0:00:11
  Final validation loss: 10.840207
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.22e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin
2024-11-20 19:20:27,193 - INFO - 
Configuration s6_n610 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009840193661966614",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n610",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.840207
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.22e-06
2024-11-20 19:20:27,193 - INFO - 
Starting training for config s6_n334:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin
2024-11-20 19:20:27,193 - INFO - Running command: ./train_gpt2cu -l 0.00097968892904061 -o hyperband_runs_20241120_172038/run_s6_n334 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:20:38,256 - INFO - Training completed for config s6_n334:
  Training time: 0:00:11
  Final validation loss: 10.840517
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.20e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin
2024-11-20 19:20:38,256 - INFO - 
Configuration s6_n334 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00097968892904061",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n334",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.840517
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.20e-06
2024-11-20 19:20:38,256 - INFO - 
Starting training for config s6_n553:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin
2024-11-20 19:20:38,256 - INFO - Running command: ./train_gpt2cu -l 0.0009757562917808082 -o hyperband_runs_20241120_172038/run_s6_n553 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:20:50,281 - INFO - Training completed for config s6_n553:
  Training time: 0:00:12
  Final validation loss: 10.840788
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.18e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin
2024-11-20 19:20:50,281 - INFO - 
Configuration s6_n553 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009757562917808082",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n553",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.840788
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.18e-06
2024-11-20 19:20:50,281 - INFO - 
Starting training for config s6_n37:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin
2024-11-20 19:20:50,281 - INFO - Running command: ./train_gpt2cu -l 0.0009748120712873382 -o hyperband_runs_20241120_172038/run_s6_n37 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:21:03,087 - INFO - Training completed for config s6_n37:
  Training time: 0:00:12
  Final validation loss: 10.840858
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.18e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin
2024-11-20 19:21:03,087 - INFO - 
Configuration s6_n37 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009748120712873382",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n37",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.840858
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.18e-06
2024-11-20 19:21:03,087 - INFO - 
Starting training for config s6_n496:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin
2024-11-20 19:21:03,087 - INFO - Running command: ./train_gpt2cu -l 0.0009743088881485038 -o hyperband_runs_20241120_172038/run_s6_n496 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:21:14,143 - INFO - Training completed for config s6_n496:
  Training time: 0:00:11
  Final validation loss: 10.840891
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.18e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin
2024-11-20 19:21:14,143 - INFO - 
Configuration s6_n496 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009743088881485038",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n496",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.840891
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.18e-06
2024-11-20 19:21:14,143 - INFO - 
Starting training for config s6_n3:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin
2024-11-20 19:21:14,144 - INFO - Running command: ./train_gpt2cu -l 0.0009583333644205056 -o hyperband_runs_20241120_172038/run_s6_n3 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:21:23,584 - INFO - Training completed for config s6_n3:
  Training time: 0:00:09
  Final validation loss: 10.842016
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.11e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin
2024-11-20 19:21:23,584 - INFO - 
Configuration s6_n3 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009583333644205056",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n3",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:09
  Validation Loss: 10.842016
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.11e-06
2024-11-20 19:21:23,584 - INFO - 
Starting training for config s6_n561:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin
2024-11-20 19:21:23,585 - INFO - Running command: ./train_gpt2cu -l 0.0009466935556371588 -o hyperband_runs_20241120_172038/run_s6_n561 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:21:36,008 - INFO - Training completed for config s6_n561:
  Training time: 0:00:12
  Final validation loss: 10.842843
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.06e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin
2024-11-20 19:21:36,009 - INFO - 
Configuration s6_n561 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009466935556371588",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n561",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.842843
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.06e-06
2024-11-20 19:21:36,009 - INFO - 
Starting training for config s6_n490:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n490/checkpoint.bin
2024-11-20 19:21:36,009 - INFO - Running command: ./train_gpt2cu -l 0.0009437860734729266 -o hyperband_runs_20241120_172038/run_s6_n490 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n490/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:21:49,644 - INFO - Training completed for config s6_n490:
  Training time: 0:00:13
  Final validation loss: 10.843041
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.04e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n490/checkpoint.bin
2024-11-20 19:21:49,644 - INFO - 
Configuration s6_n490 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009437860734729266",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n490",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n490/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:13
  Validation Loss: 10.843041
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.04e-06
2024-11-20 19:21:49,644 - INFO - 
Starting training for config s6_n122:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n122/checkpoint.bin
2024-11-20 19:21:49,644 - INFO - Running command: ./train_gpt2cu -l 0.0009278776931084436 -o hyperband_runs_20241120_172038/run_s6_n122 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n122/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:22:00,710 - INFO - Training completed for config s6_n122:
  Training time: 0:00:11
  Final validation loss: 10.844192
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.98e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n122/checkpoint.bin
2024-11-20 19:22:00,710 - INFO - 
Configuration s6_n122 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009278776931084436",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n122",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n122/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.844192
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.98e-06
2024-11-20 19:22:00,710 - INFO - 
Starting training for config s6_n147:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n147/checkpoint.bin
2024-11-20 19:22:00,710 - INFO - Running command: ./train_gpt2cu -l 0.0009244094155573718 -o hyperband_runs_20241120_172038/run_s6_n147 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n147/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:22:11,771 - INFO - Training completed for config s6_n147:
  Training time: 0:00:11
  Final validation loss: 10.844432
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.96e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n147/checkpoint.bin
2024-11-20 19:22:11,771 - INFO - 
Configuration s6_n147 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009244094155573718",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n147",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n147/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.844432
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.96e-06
2024-11-20 19:22:11,771 - INFO - 
Starting training for config s6_n333:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n333/checkpoint.bin
2024-11-20 19:22:11,771 - INFO - Running command: ./train_gpt2cu -l 0.00090492595944296 -o hyperband_runs_20241120_172038/run_s6_n333 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n333/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:22:22,836 - INFO - Training completed for config s6_n333:
  Training time: 0:00:11
  Final validation loss: 10.845852
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.88e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n333/checkpoint.bin
2024-11-20 19:22:22,837 - INFO - 
Configuration s6_n333 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00090492595944296",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n333",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n333/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.845852
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.88e-06
2024-11-20 19:22:22,837 - INFO - 
Starting training for config s6_n146:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n146/checkpoint.bin
2024-11-20 19:22:22,837 - INFO - Running command: ./train_gpt2cu -l 0.0008942480821014569 -o hyperband_runs_20241120_172038/run_s6_n146 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n146/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:22:34,776 - INFO - Training completed for config s6_n146:
  Training time: 0:00:11
  Final validation loss: 10.846624
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.83e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n146/checkpoint.bin
2024-11-20 19:22:34,776 - INFO - 
Configuration s6_n146 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008942480821014569",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n146",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n146/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.846624
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.83e-06
2024-11-20 19:22:34,776 - INFO - 
Starting training for config s6_n339:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n339/checkpoint.bin
2024-11-20 19:22:34,776 - INFO - Running command: ./train_gpt2cu -l 0.0008881775390564398 -o hyperband_runs_20241120_172038/run_s6_n339 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n339/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:22:47,539 - INFO - Training completed for config s6_n339:
  Training time: 0:00:12
  Final validation loss: 10.847065
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.81e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n339/checkpoint.bin
2024-11-20 19:22:47,539 - INFO - 
Configuration s6_n339 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008881775390564398",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n339",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n339/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.847065
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.81e-06
2024-11-20 19:22:47,539 - INFO - 
Starting training for config s6_n85:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n85/checkpoint.bin
2024-11-20 19:22:47,539 - INFO - Running command: ./train_gpt2cu -l 0.0008833451139763101 -o hyperband_runs_20241120_172038/run_s6_n85 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n85/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:22:58,593 - INFO - Training completed for config s6_n85:
  Training time: 0:00:11
  Final validation loss: 10.847404
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.79e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n85/checkpoint.bin
2024-11-20 19:22:58,593 - INFO - 
Configuration s6_n85 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008833451139763101",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n85",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n85/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.847404
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.79e-06
2024-11-20 19:22:58,593 - INFO - 
Starting training for config s6_n617:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n617/checkpoint.bin
2024-11-20 19:22:58,593 - INFO - Running command: ./train_gpt2cu -l 0.0008822222688470273 -o hyperband_runs_20241120_172038/run_s6_n617 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n617/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:23:09,662 - INFO - Training completed for config s6_n617:
  Training time: 0:00:11
  Final validation loss: 10.847486
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.78e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n617/checkpoint.bin
2024-11-20 19:23:09,662 - INFO - 
Configuration s6_n617 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008822222688470273",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n617",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n617/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.847486
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.78e-06
2024-11-20 19:23:09,662 - INFO - 
Starting training for config s6_n460:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n460/checkpoint.bin
2024-11-20 19:23:09,662 - INFO - Running command: ./train_gpt2cu -l 0.0008650173683974301 -o hyperband_runs_20241120_172038/run_s6_n460 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n460/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:23:21,847 - INFO - Training completed for config s6_n460:
  Training time: 0:00:12
  Final validation loss: 10.848708
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.71e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n460/checkpoint.bin
2024-11-20 19:23:21,847 - INFO - 
Configuration s6_n460 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008650173683974301",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n460",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n460/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.848708
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.71e-06
2024-11-20 19:23:21,847 - INFO - 
Starting training for config s6_n22:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n22/checkpoint.bin
2024-11-20 19:23:21,848 - INFO - Running command: ./train_gpt2cu -l 0.000859266840585978 -o hyperband_runs_20241120_172038/run_s6_n22 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n22/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:23:34,646 - INFO - Training completed for config s6_n22:
  Training time: 0:00:12
  Final validation loss: 10.849123
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.68e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n22/checkpoint.bin
2024-11-20 19:23:34,646 - INFO - 
Configuration s6_n22 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000859266840585978",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n22",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n22/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.849123
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.68e-06
2024-11-20 19:23:34,646 - INFO - 
Starting training for config s6_n380:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n380/checkpoint.bin
2024-11-20 19:23:34,646 - INFO - Running command: ./train_gpt2cu -l 0.0008587527623389926 -o hyperband_runs_20241120_172038/run_s6_n380 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n380/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:23:45,687 - INFO - Training completed for config s6_n380:
  Training time: 0:00:11
  Final validation loss: 10.849157
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.68e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n380/checkpoint.bin
2024-11-20 19:23:45,687 - INFO - 
Configuration s6_n380 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008587527623389926",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n380",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n380/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.849157
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.68e-06
2024-11-20 19:23:45,687 - INFO - 
Starting training for config s6_n420:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n420/checkpoint.bin
2024-11-20 19:23:45,687 - INFO - Running command: ./train_gpt2cu -l 0.0008560188308167667 -o hyperband_runs_20241120_172038/run_s6_n420 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n420/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:23:56,748 - INFO - Training completed for config s6_n420:
  Training time: 0:00:11
  Final validation loss: 10.849351
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.67e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n420/checkpoint.bin
2024-11-20 19:23:56,748 - INFO - 
Configuration s6_n420 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008560188308167667",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n420",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n420/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.849351
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.67e-06
2024-11-20 19:23:56,748 - INFO - 
Starting training for config s6_n154:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n154/checkpoint.bin
2024-11-20 19:23:56,748 - INFO - Running command: ./train_gpt2cu -l 0.0008562517308020131 -o hyperband_runs_20241120_172038/run_s6_n154 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n154/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:24:08,956 - INFO - Training completed for config s6_n154:
  Training time: 0:00:12
  Final validation loss: 10.849329
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.67e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n154/checkpoint.bin
2024-11-20 19:24:08,957 - INFO - 
Configuration s6_n154 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008562517308020131",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n154",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n154/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.849329
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.67e-06
2024-11-20 19:24:08,957 - INFO - 
Starting training for config s6_n540:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n540/checkpoint.bin
2024-11-20 19:24:08,957 - INFO - Running command: ./train_gpt2cu -l 0.0008554037131933193 -o hyperband_runs_20241120_172038/run_s6_n540 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n540/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:24:21,756 - INFO - Training completed for config s6_n540:
  Training time: 0:00:12
  Final validation loss: 10.849399
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.67e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n540/checkpoint.bin
2024-11-20 19:24:21,756 - INFO - 
Configuration s6_n540 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008554037131933193",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n540",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n540/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.849399
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.67e-06
2024-11-20 19:24:21,756 - INFO - 
Starting training for config s6_n234:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n234/checkpoint.bin
2024-11-20 19:24:21,756 - INFO - Running command: ./train_gpt2cu -l 0.000853428541786053 -o hyperband_runs_20241120_172038/run_s6_n234 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n234/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:24:32,826 - INFO - Training completed for config s6_n234:
  Training time: 0:00:11
  Final validation loss: 10.849543
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.66e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n234/checkpoint.bin
2024-11-20 19:24:32,826 - INFO - 
Configuration s6_n234 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000853428541786053",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n234",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n234/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.849543
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.66e-06
2024-11-20 19:24:32,827 - INFO - 
Starting training for config s6_n167:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n167/checkpoint.bin
2024-11-20 19:24:32,827 - INFO - Running command: ./train_gpt2cu -l 0.0008525192676792822 -o hyperband_runs_20241120_172038/run_s6_n167 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n167/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:24:43,933 - INFO - Training completed for config s6_n167:
  Training time: 0:00:11
  Final validation loss: 10.849609
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.65e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n167/checkpoint.bin
2024-11-20 19:24:43,933 - INFO - 
Configuration s6_n167 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008525192676792822",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n167",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n167/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.849609
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.65e-06
2024-11-20 19:24:43,933 - INFO - 
Starting training for config s6_n42:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n42/checkpoint.bin
2024-11-20 19:24:43,933 - INFO - Running command: ./train_gpt2cu -l 0.0008427581488465726 -o hyperband_runs_20241120_172038/run_s6_n42 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n42/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:24:56,098 - INFO - Training completed for config s6_n42:
  Training time: 0:00:12
  Final validation loss: 10.850302
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.61e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n42/checkpoint.bin
2024-11-20 19:24:56,099 - INFO - 
Configuration s6_n42 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008427581488465726",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n42",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n42/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.850302
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.61e-06
2024-11-20 19:24:56,099 - INFO - 
Starting training for config s6_n173:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n173/checkpoint.bin
2024-11-20 19:24:56,099 - INFO - Running command: ./train_gpt2cu -l 0.0008431900534300434 -o hyperband_runs_20241120_172038/run_s6_n173 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n173/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:25:08,857 - INFO - Training completed for config s6_n173:
  Training time: 0:00:12
  Final validation loss: 10.850271
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.61e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n173/checkpoint.bin
2024-11-20 19:25:08,857 - INFO - 
Configuration s6_n173 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008431900534300434",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n173",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n173/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.850271
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.61e-06
2024-11-20 19:25:08,858 - INFO - 
Starting training for config s6_n15:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n15/checkpoint.bin
2024-11-20 19:25:08,858 - INFO - Running command: ./train_gpt2cu -l 0.0008401301724146576 -o hyperband_runs_20241120_172038/run_s6_n15 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n15/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:25:19,924 - INFO - Training completed for config s6_n15:
  Training time: 0:00:11
  Final validation loss: 10.850492
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.60e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n15/checkpoint.bin
2024-11-20 19:25:19,924 - INFO - 
Configuration s6_n15 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008401301724146576",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n15",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n15/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.850492
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.60e-06
2024-11-20 19:25:19,924 - INFO - 
Starting training for config s6_n280:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n280/checkpoint.bin
2024-11-20 19:25:19,924 - INFO - Running command: ./train_gpt2cu -l 0.0008339139310003893 -o hyperband_runs_20241120_172038/run_s6_n280 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n280/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:25:30,971 - INFO - Training completed for config s6_n280:
  Training time: 0:00:11
  Final validation loss: 10.850937
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.57e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n280/checkpoint.bin
2024-11-20 19:25:30,972 - INFO - 
Configuration s6_n280 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008339139310003893",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n280",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n280/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.850937
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.57e-06
2024-11-20 19:25:30,972 - INFO - 
Starting training for config s6_n309:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n309/checkpoint.bin
2024-11-20 19:25:30,972 - INFO - Running command: ./train_gpt2cu -l 0.000830841442264205 -o hyperband_runs_20241120_172038/run_s6_n309 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n309/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:25:43,151 - INFO - Training completed for config s6_n309:
  Training time: 0:00:12
  Final validation loss: 10.851172
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.56e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n309/checkpoint.bin
2024-11-20 19:25:43,152 - INFO - 
Configuration s6_n309 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000830841442264205",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n309",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n309/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.851172
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.56e-06
2024-11-20 19:25:43,152 - INFO - 
Starting training for config s6_n313:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n313/checkpoint.bin
2024-11-20 19:25:43,152 - INFO - Running command: ./train_gpt2cu -l 0.0008309356853545224 -o hyperband_runs_20241120_172038/run_s6_n313 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n313/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:25:55,981 - INFO - Training completed for config s6_n313:
  Training time: 0:00:12
  Final validation loss: 10.851155
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.56e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n313/checkpoint.bin
2024-11-20 19:25:55,981 - INFO - 
Configuration s6_n313 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008309356853545224",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n313",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n313/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.851155
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.56e-06
2024-11-20 19:25:55,981 - INFO - 
Starting training for config s6_n259:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n259/checkpoint.bin
2024-11-20 19:25:55,981 - INFO - Running command: ./train_gpt2cu -l 0.0008249355759153884 -o hyperband_runs_20241120_172038/run_s6_n259 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n259/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:26:07,036 - INFO - Training completed for config s6_n259:
  Training time: 0:00:11
  Final validation loss: 10.851578
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.54e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n259/checkpoint.bin
2024-11-20 19:26:07,036 - INFO - 
Configuration s6_n259 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008249355759153884",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n259",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n259/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.851578
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.54e-06
2024-11-20 19:26:07,036 - INFO - 
Starting training for config s6_n152:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n152/checkpoint.bin
2024-11-20 19:26:07,036 - INFO - Running command: ./train_gpt2cu -l 0.0008225875504756807 -o hyperband_runs_20241120_172038/run_s6_n152 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n152/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:26:18,111 - INFO - Training completed for config s6_n152:
  Training time: 0:00:11
  Final validation loss: 10.851740
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.53e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n152/checkpoint.bin
2024-11-20 19:26:18,111 - INFO - 
Configuration s6_n152 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008225875504756807",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n152",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n152/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.851740
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.53e-06
2024-11-20 19:26:18,111 - INFO - 
Starting training for config s6_n338:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n338/checkpoint.bin
2024-11-20 19:26:18,111 - INFO - Running command: ./train_gpt2cu -l 0.0008157981726792546 -o hyperband_runs_20241120_172038/run_s6_n338 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n338/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:26:30,265 - INFO - Training completed for config s6_n338:
  Training time: 0:00:12
  Final validation loss: 10.852234
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.50e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n338/checkpoint.bin
2024-11-20 19:26:30,266 - INFO - 
Configuration s6_n338 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008157981726792546",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n338",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n338/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.852234
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.50e-06
2024-11-20 19:26:30,266 - INFO - 
Starting training for config s6_n652:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n652/checkpoint.bin
2024-11-20 19:26:30,266 - INFO - Running command: ./train_gpt2cu -l 0.00081477193361014 -o hyperband_runs_20241120_172038/run_s6_n652 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n652/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:26:43,069 - INFO - Training completed for config s6_n652:
  Training time: 0:00:12
  Final validation loss: 10.852300
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.49e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n652/checkpoint.bin
2024-11-20 19:26:43,069 - INFO - 
Configuration s6_n652 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00081477193361014",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n652",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n652/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.852300
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.49e-06
2024-11-20 19:26:43,070 - INFO - 
Starting training for config s6_n306:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n306/checkpoint.bin
2024-11-20 19:26:43,070 - INFO - Running command: ./train_gpt2cu -l 0.0008099582756449049 -o hyperband_runs_20241120_172038/run_s6_n306 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n306/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:26:54,154 - INFO - Training completed for config s6_n306:
  Training time: 0:00:11
  Final validation loss: 10.852644
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.47e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n306/checkpoint.bin
2024-11-20 19:26:54,154 - INFO - 
Configuration s6_n306 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008099582756449049",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n306",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n306/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.852644
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.47e-06
2024-11-20 19:26:54,154 - INFO - 
Starting training for config s6_n591:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n591/checkpoint.bin
2024-11-20 19:26:54,154 - INFO - Running command: ./train_gpt2cu -l 0.0008079629767133919 -o hyperband_runs_20241120_172038/run_s6_n591 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n591/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:27:05,219 - INFO - Training completed for config s6_n591:
  Training time: 0:00:11
  Final validation loss: 10.852788
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.46e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n591/checkpoint.bin
2024-11-20 19:27:05,219 - INFO - 
Configuration s6_n591 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008079629767133919",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n591",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n591/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.852788
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.46e-06
2024-11-20 19:27:05,220 - INFO - 
Starting training for config s6_n343:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n343/checkpoint.bin
2024-11-20 19:27:05,220 - INFO - Running command: ./train_gpt2cu -l 0.0008029478952801089 -o hyperband_runs_20241120_172038/run_s6_n343 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n343/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:27:17,390 - INFO - Training completed for config s6_n343:
  Training time: 0:00:12
  Final validation loss: 10.853130
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.44e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n343/checkpoint.bin
2024-11-20 19:27:17,390 - INFO - 
Configuration s6_n343 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008029478952801089",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n343",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n343/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.853130
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.44e-06
2024-11-20 19:27:17,390 - INFO - 
Starting training for config s6_n53:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n53/checkpoint.bin
2024-11-20 19:27:17,390 - INFO - Running command: ./train_gpt2cu -l 0.0007988992971993117 -o hyperband_runs_20241120_172038/run_s6_n53 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n53/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:27:30,172 - INFO - Training completed for config s6_n53:
  Training time: 0:00:12
  Final validation loss: 10.853424
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.42e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n53/checkpoint.bin
2024-11-20 19:27:30,172 - INFO - 
Configuration s6_n53 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007988992971993117",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n53",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n53/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.853424
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.42e-06
2024-11-20 19:27:30,172 - INFO - 
Starting training for config s6_n116:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n116/checkpoint.bin
2024-11-20 19:27:30,172 - INFO - Running command: ./train_gpt2cu -l 0.0007975447996901649 -o hyperband_runs_20241120_172038/run_s6_n116 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n116/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:27:41,235 - INFO - Training completed for config s6_n116:
  Training time: 0:00:11
  Final validation loss: 10.853514
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.42e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n116/checkpoint.bin
2024-11-20 19:27:41,236 - INFO - 
Configuration s6_n116 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007975447996901649",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n116",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n116/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.853514
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.42e-06
2024-11-20 19:27:41,236 - INFO - 
Starting training for config s6_n210:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n210/checkpoint.bin
2024-11-20 19:27:41,236 - INFO - Running command: ./train_gpt2cu -l 0.000796614898741513 -o hyperband_runs_20241120_172038/run_s6_n210 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n210/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:27:52,303 - INFO - Training completed for config s6_n210:
  Training time: 0:00:11
  Final validation loss: 10.853595
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.41e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n210/checkpoint.bin
2024-11-20 19:27:52,303 - INFO - 
Configuration s6_n210 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000796614898741513",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n210",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n210/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.853595
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.41e-06
2024-11-20 19:27:52,303 - INFO - 
Starting training for config s6_n364:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n364/checkpoint.bin
2024-11-20 19:27:52,303 - INFO - Running command: ./train_gpt2cu -l 0.0007960447614808076 -o hyperband_runs_20241120_172038/run_s6_n364 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n364/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:28:04,474 - INFO - Training completed for config s6_n364:
  Training time: 0:00:12
  Final validation loss: 10.853629
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.41e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n364/checkpoint.bin
2024-11-20 19:28:04,474 - INFO - 
Configuration s6_n364 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007960447614808076",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n364",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n364/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.853629
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.41e-06
2024-11-20 19:28:04,475 - INFO - 
Starting training for config s6_n229:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n229/checkpoint.bin
2024-11-20 19:28:04,475 - INFO - Running command: ./train_gpt2cu -l 0.00079540403785159 -o hyperband_runs_20241120_172038/run_s6_n229 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n229/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:28:17,266 - INFO - Training completed for config s6_n229:
  Training time: 0:00:12
  Final validation loss: 10.853673
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.41e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n229/checkpoint.bin
2024-11-20 19:28:17,266 - INFO - 
Configuration s6_n229 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00079540403785159",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n229",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n229/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.853673
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.41e-06
2024-11-20 19:28:17,266 - INFO - 
Starting training for config s6_n28:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n28/checkpoint.bin
2024-11-20 19:28:17,267 - INFO - Running command: ./train_gpt2cu -l 0.0007944460308724998 -o hyperband_runs_20241120_172038/run_s6_n28 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n28/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:28:28,322 - INFO - Training completed for config s6_n28:
  Training time: 0:00:11
  Final validation loss: 10.853750
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.40e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n28/checkpoint.bin
2024-11-20 19:28:28,322 - INFO - 
Configuration s6_n28 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007944460308724998",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n28",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n28/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.853750
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.40e-06
2024-11-20 19:28:28,322 - INFO - 
Starting training for config s6_n638:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n638/checkpoint.bin
2024-11-20 19:28:28,322 - INFO - Running command: ./train_gpt2cu -l 0.0007915379022221989 -o hyperband_runs_20241120_172038/run_s6_n638 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n638/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:28:39,381 - INFO - Training completed for config s6_n638:
  Training time: 0:00:11
  Final validation loss: 10.853941
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.39e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n638/checkpoint.bin
2024-11-20 19:28:39,381 - INFO - 
Configuration s6_n638 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007915379022221989",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n638",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n638/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.853941
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.39e-06
2024-11-20 19:28:39,381 - INFO - 
Starting training for config s6_n551:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n551/checkpoint.bin
2024-11-20 19:28:39,381 - INFO - Running command: ./train_gpt2cu -l 0.0007833672223959862 -o hyperband_runs_20241120_172038/run_s6_n551 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n551/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:28:51,581 - INFO - Training completed for config s6_n551:
  Training time: 0:00:12
  Final validation loss: 10.854538
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.36e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n551/checkpoint.bin
2024-11-20 19:28:51,582 - INFO - 
Configuration s6_n551 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007833672223959862",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n551",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n551/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.854538
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.36e-06
2024-11-20 19:28:51,582 - INFO - 
Starting training for config s6_n100:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n100/checkpoint.bin
2024-11-20 19:28:51,582 - INFO - Running command: ./train_gpt2cu -l 0.0007748331409407934 -o hyperband_runs_20241120_172038/run_s6_n100 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n100/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:29:04,400 - INFO - Training completed for config s6_n100:
  Training time: 0:00:12
  Final validation loss: 10.855147
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.32e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n100/checkpoint.bin
2024-11-20 19:29:04,400 - INFO - 
Configuration s6_n100 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007748331409407934",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n100",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n100/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.855147
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.32e-06
2024-11-20 19:29:04,400 - INFO - 
Starting training for config s6_n677:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n677/checkpoint.bin
2024-11-20 19:29:04,400 - INFO - Running command: ./train_gpt2cu -l 0.0007683502023562 -o hyperband_runs_20241120_172038/run_s6_n677 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n677/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:29:15,492 - INFO - Training completed for config s6_n677:
  Training time: 0:00:11
  Final validation loss: 10.855604
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.29e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n677/checkpoint.bin
2024-11-20 19:29:15,492 - INFO - 
Configuration s6_n677 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007683502023562",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n677",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n677/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.855604
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.29e-06
2024-11-20 19:29:15,492 - INFO - 
Starting training for config s6_n607:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n607/checkpoint.bin
2024-11-20 19:29:15,492 - INFO - Running command: ./train_gpt2cu -l 0.000765146304141897 -o hyperband_runs_20241120_172038/run_s6_n607 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n607/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:29:26,550 - INFO - Training completed for config s6_n607:
  Training time: 0:00:11
  Final validation loss: 10.855837
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.28e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n607/checkpoint.bin
2024-11-20 19:29:26,551 - INFO - 
Configuration s6_n607 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000765146304141897",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n607",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n607/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.855837
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.28e-06
2024-11-20 19:29:26,551 - INFO - 
Starting training for config s6_n632:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n632/checkpoint.bin
2024-11-20 19:29:26,551 - INFO - Running command: ./train_gpt2cu -l 0.0007609596504620381 -o hyperband_runs_20241120_172038/run_s6_n632 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n632/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:29:38,766 - INFO - Training completed for config s6_n632:
  Training time: 0:00:12
  Final validation loss: 10.856140
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.26e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n632/checkpoint.bin
2024-11-20 19:29:38,766 - INFO - 
Configuration s6_n632 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007609596504620381",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n632",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n632/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.856140
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.26e-06
2024-11-20 19:29:38,766 - INFO - 
Starting training for config s6_n467:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n467/checkpoint.bin
2024-11-20 19:29:38,766 - INFO - Running command: ./train_gpt2cu -l 0.0007548680660404933 -o hyperband_runs_20241120_172038/run_s6_n467 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n467/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:29:51,528 - INFO - Training completed for config s6_n467:
  Training time: 0:00:12
  Final validation loss: 10.856577
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.24e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n467/checkpoint.bin
2024-11-20 19:29:51,529 - INFO - 
Configuration s6_n467 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007548680660404933",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n467",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n467/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.856577
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.24e-06
2024-11-20 19:29:51,529 - INFO - 
Starting training for config s6_n322:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n322/checkpoint.bin
2024-11-20 19:29:51,529 - INFO - Running command: ./train_gpt2cu -l 0.0007535574287081613 -o hyperband_runs_20241120_172038/run_s6_n322 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n322/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:30:02,567 - INFO - Training completed for config s6_n322:
  Training time: 0:00:11
  Final validation loss: 10.856680
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.23e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n322/checkpoint.bin
2024-11-20 19:30:02,567 - INFO - 
Configuration s6_n322 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007535574287081613",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n322",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n322/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.856680
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.23e-06
2024-11-20 19:30:02,567 - INFO - 
Starting training for config s6_n615:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n615/checkpoint.bin
2024-11-20 19:30:02,568 - INFO - Running command: ./train_gpt2cu -l 0.0007505781567021048 -o hyperband_runs_20241120_172038/run_s6_n615 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n615/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:30:13,615 - INFO - Training completed for config s6_n615:
  Training time: 0:00:11
  Final validation loss: 10.856892
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.22e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n615/checkpoint.bin
2024-11-20 19:30:13,615 - INFO - 
Configuration s6_n615 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007505781567021048",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n615",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n615/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.856892
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.22e-06
2024-11-20 19:30:13,615 - INFO - 
Starting training for config s6_n588:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n588/checkpoint.bin
2024-11-20 19:30:13,615 - INFO - Running command: ./train_gpt2cu -l 0.0007278567127169047 -o hyperband_runs_20241120_172038/run_s6_n588 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n588/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:30:25,803 - INFO - Training completed for config s6_n588:
  Training time: 0:00:12
  Final validation loss: 10.858515
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.12e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n588/checkpoint.bin
2024-11-20 19:30:25,803 - INFO - 
Configuration s6_n588 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007278567127169047",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n588",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n588/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.858515
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.12e-06
2024-11-20 19:30:25,804 - INFO - 
Starting training for config s6_n236:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n236/checkpoint.bin
2024-11-20 19:30:25,804 - INFO - Running command: ./train_gpt2cu -l 0.0007215956007704206 -o hyperband_runs_20241120_172038/run_s6_n236 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n236/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:30:38,578 - INFO - Training completed for config s6_n236:
  Training time: 0:00:12
  Final validation loss: 10.858981
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.09e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n236/checkpoint.bin
2024-11-20 19:30:38,579 - INFO - 
Configuration s6_n236 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007215956007704206",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n236",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n236/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.858981
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.09e-06
2024-11-20 19:30:38,579 - INFO - 
Starting training for config s6_n601:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n601/checkpoint.bin
2024-11-20 19:30:38,579 - INFO - Running command: ./train_gpt2cu -l 0.0007221173134528555 -o hyperband_runs_20241120_172038/run_s6_n601 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n601/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:30:49,634 - INFO - Training completed for config s6_n601:
  Training time: 0:00:11
  Final validation loss: 10.858954
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.09e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n601/checkpoint.bin
2024-11-20 19:30:49,635 - INFO - 
Configuration s6_n601 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007221173134528555",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n601",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n601/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.858954
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.09e-06
2024-11-20 19:30:49,635 - INFO - 
Starting training for config s6_n325:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n325/checkpoint.bin
2024-11-20 19:30:49,635 - INFO - Running command: ./train_gpt2cu -l 0.0007107889545943217 -o hyperband_runs_20241120_172038/run_s6_n325 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n325/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:31:00,697 - INFO - Training completed for config s6_n325:
  Training time: 0:00:11
  Final validation loss: 10.859774
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.05e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n325/checkpoint.bin
2024-11-20 19:31:00,697 - INFO - 
Configuration s6_n325 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007107889545943217",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n325",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n325/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.859774
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.05e-06
2024-11-20 19:31:00,697 - INFO - 
Starting training for config s6_n667:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n667/checkpoint.bin
2024-11-20 19:31:00,698 - INFO - Running command: ./train_gpt2cu -l 0.0007052164516636011 -o hyperband_runs_20241120_172038/run_s6_n667 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n667/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:31:12,913 - INFO - Training completed for config s6_n667:
  Training time: 0:00:12
  Final validation loss: 10.860167
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.02e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n667/checkpoint.bin
2024-11-20 19:31:12,914 - INFO - 
Configuration s6_n667 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007052164516636011",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n667",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n667/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.860167
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.02e-06
2024-11-20 19:31:12,914 - INFO - 
Starting training for config s6_n705:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n705/checkpoint.bin
2024-11-20 19:31:12,914 - INFO - Running command: ./train_gpt2cu -l 0.0007045014359961428 -o hyperband_runs_20241120_172038/run_s6_n705 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n705/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:31:25,686 - INFO - Training completed for config s6_n705:
  Training time: 0:00:12
  Final validation loss: 10.860220
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.02e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n705/checkpoint.bin
2024-11-20 19:31:25,686 - INFO - 
Configuration s6_n705 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007045014359961428",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n705",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n705/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.860220
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.02e-06
2024-11-20 19:31:25,686 - INFO - 
Starting training for config s6_n520:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n520/checkpoint.bin
2024-11-20 19:31:25,687 - INFO - Running command: ./train_gpt2cu -l 0.0007030878468635916 -o hyperband_runs_20241120_172038/run_s6_n520 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n520/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:31:36,739 - INFO - Training completed for config s6_n520:
  Training time: 0:00:11
  Final validation loss: 10.860308
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.01e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n520/checkpoint.bin
2024-11-20 19:31:36,740 - INFO - 
Configuration s6_n520 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007030878468635916",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n520",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n520/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.860308
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.01e-06
2024-11-20 19:31:36,740 - INFO - 
Starting training for config s6_n700:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n700/checkpoint.bin
2024-11-20 19:31:36,740 - INFO - Running command: ./train_gpt2cu -l 0.0006951122926882169 -o hyperband_runs_20241120_172038/run_s6_n700 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n700/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:31:47,796 - INFO - Training completed for config s6_n700:
  Training time: 0:00:11
  Final validation loss: 10.860886
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.98e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n700/checkpoint.bin
2024-11-20 19:31:47,796 - INFO - 
Configuration s6_n700 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006951122926882169",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n700",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n700/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.860886
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.98e-06
2024-11-20 19:31:47,796 - INFO - 
Starting training for config s6_n235:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n235/checkpoint.bin
2024-11-20 19:31:47,796 - INFO - Running command: ./train_gpt2cu -l 0.0006851603833257309 -o hyperband_runs_20241120_172038/run_s6_n235 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n235/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:31:59,997 - INFO - Training completed for config s6_n235:
  Training time: 0:00:12
  Final validation loss: 10.861635
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.94e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n235/checkpoint.bin
2024-11-20 19:31:59,998 - INFO - 
Configuration s6_n235 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006851603833257309",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n235",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n235/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.861635
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.94e-06
2024-11-20 19:31:59,998 - INFO - 
Starting training for config s6_n264:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n264/checkpoint.bin
2024-11-20 19:31:59,998 - INFO - Running command: ./train_gpt2cu -l 0.0006773380521221634 -o hyperband_runs_20241120_172038/run_s6_n264 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n264/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:32:12,785 - INFO - Training completed for config s6_n264:
  Training time: 0:00:12
  Final validation loss: 10.862196
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.90e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n264/checkpoint.bin
2024-11-20 19:32:12,785 - INFO - 
Configuration s6_n264 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006773380521221634",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n264",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n264/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.862196
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.90e-06
2024-11-20 19:32:12,786 - INFO - 
Starting training for config s6_n522:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n522/checkpoint.bin
2024-11-20 19:32:12,786 - INFO - Running command: ./train_gpt2cu -l 0.000671880458880737 -o hyperband_runs_20241120_172038/run_s6_n522 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n522/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:32:23,832 - INFO - Training completed for config s6_n522:
  Training time: 0:00:11
  Final validation loss: 10.862585
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.88e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n522/checkpoint.bin
2024-11-20 19:32:23,832 - INFO - 
Configuration s6_n522 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000671880458880737",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n522",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n522/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.862585
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.88e-06
2024-11-20 19:32:23,832 - INFO - 
Starting training for config s6_n523:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n523/checkpoint.bin
2024-11-20 19:32:23,832 - INFO - Running command: ./train_gpt2cu -l 0.0006721463416277697 -o hyperband_runs_20241120_172038/run_s6_n523 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n523/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:32:34,896 - INFO - Training completed for config s6_n523:
  Training time: 0:00:11
  Final validation loss: 10.862581
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.88e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n523/checkpoint.bin
2024-11-20 19:32:34,896 - INFO - 
Configuration s6_n523 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006721463416277697",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n523",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n523/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.862581
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.88e-06
2024-11-20 19:32:34,896 - INFO - 
Starting training for config s6_n572:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n572/checkpoint.bin
2024-11-20 19:32:34,896 - INFO - Running command: ./train_gpt2cu -l 0.0006692136504312971 -o hyperband_runs_20241120_172038/run_s6_n572 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n572/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:32:47,096 - INFO - Training completed for config s6_n572:
  Training time: 0:00:12
  Final validation loss: 10.862782
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.87e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n572/checkpoint.bin
2024-11-20 19:32:47,096 - INFO - 
Configuration s6_n572 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006692136504312971",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n572",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n572/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.862782
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.87e-06
2024-11-20 19:32:47,096 - INFO - 
Starting training for config s6_n191:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n191/checkpoint.bin
2024-11-20 19:32:47,096 - INFO - Running command: ./train_gpt2cu -l 0.0006673650168736646 -o hyperband_runs_20241120_172038/run_s6_n191 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n191/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:32:59,897 - INFO - Training completed for config s6_n191:
  Training time: 0:00:12
  Final validation loss: 10.862921
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.86e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n191/checkpoint.bin
2024-11-20 19:32:59,897 - INFO - 
Configuration s6_n191 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006673650168736646",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n191",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n191/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.862921
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.86e-06
2024-11-20 19:32:59,897 - INFO - 
Starting training for config s6_n282:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n282/checkpoint.bin
2024-11-20 19:32:59,897 - INFO - Running command: ./train_gpt2cu -l 0.0006673066269854008 -o hyperband_runs_20241120_172038/run_s6_n282 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n282/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:33:10,962 - INFO - Training completed for config s6_n282:
  Training time: 0:00:11
  Final validation loss: 10.862920
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.86e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n282/checkpoint.bin
2024-11-20 19:33:10,962 - INFO - 
Configuration s6_n282 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006673066269854008",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n282",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n282/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.862920
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.86e-06
2024-11-20 19:33:10,962 - INFO - 
Starting training for config s6_n34:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n34/checkpoint.bin
2024-11-20 19:33:10,962 - INFO - Running command: ./train_gpt2cu -l 0.000655179765012117 -o hyperband_runs_20241120_172038/run_s6_n34 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n34/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:33:22,020 - INFO - Training completed for config s6_n34:
  Training time: 0:00:11
  Final validation loss: 10.863779
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.81e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n34/checkpoint.bin
2024-11-20 19:33:22,020 - INFO - 
Configuration s6_n34 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000655179765012117",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n34",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n34/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.863779
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.81e-06
2024-11-20 19:33:22,020 - INFO - 
Starting training for config s6_n217:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n217/checkpoint.bin
2024-11-20 19:33:22,020 - INFO - Running command: ./train_gpt2cu -l 0.0006502089255387881 -o hyperband_runs_20241120_172038/run_s6_n217 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n217/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:33:34,216 - INFO - Training completed for config s6_n217:
  Training time: 0:00:12
  Final validation loss: 10.864138
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.79e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n217/checkpoint.bin
2024-11-20 19:33:34,217 - INFO - 
Configuration s6_n217 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006502089255387881",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n217",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n217/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.864138
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.79e-06
2024-11-20 19:33:34,217 - INFO - 
Starting training for config s6_n516:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n516/checkpoint.bin
2024-11-20 19:33:34,217 - INFO - Running command: ./train_gpt2cu -l 0.0006409848656735655 -o hyperband_runs_20241120_172038/run_s6_n516 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n516/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:33:47,017 - INFO - Training completed for config s6_n516:
  Training time: 0:00:12
  Final validation loss: 10.864820
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.75e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n516/checkpoint.bin
2024-11-20 19:33:47,017 - INFO - 
Configuration s6_n516 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006409848656735655",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n516",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n516/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.864820
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.75e-06
2024-11-20 19:33:47,017 - INFO - 
Starting training for config s6_n185:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n185/checkpoint.bin
2024-11-20 19:33:47,017 - INFO - Running command: ./train_gpt2cu -l 0.0006393198282527764 -o hyperband_runs_20241120_172038/run_s6_n185 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n185/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:33:58,077 - INFO - Training completed for config s6_n185:
  Training time: 0:00:11
  Final validation loss: 10.864949
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.74e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n185/checkpoint.bin
2024-11-20 19:33:58,077 - INFO - 
Configuration s6_n185 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006393198282527764",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n185",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n185/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.864949
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.74e-06
2024-11-20 19:33:58,077 - INFO - 
Starting training for config s6_n14:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n14/checkpoint.bin
2024-11-20 19:33:58,077 - INFO - Running command: ./train_gpt2cu -l 0.0006305830318046952 -o hyperband_runs_20241120_172038/run_s6_n14 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n14/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:34:09,132 - INFO - Training completed for config s6_n14:
  Training time: 0:00:11
  Final validation loss: 10.865570
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.70e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n14/checkpoint.bin
2024-11-20 19:34:09,132 - INFO - 
Configuration s6_n14 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006305830318046952",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n14",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n14/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.865570
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.70e-06
2024-11-20 19:34:09,133 - INFO - 
Starting training for config s6_n472:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n472/checkpoint.bin
2024-11-20 19:34:09,133 - INFO - Running command: ./train_gpt2cu -l 0.0006271523394724145 -o hyperband_runs_20241120_172038/run_s6_n472 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n472/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:34:21,298 - INFO - Training completed for config s6_n472:
  Training time: 0:00:12
  Final validation loss: 10.865822
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.69e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n472/checkpoint.bin
2024-11-20 19:34:21,298 - INFO - 
Configuration s6_n472 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006271523394724145",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n472",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n472/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.865822
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.69e-06
2024-11-20 19:34:21,299 - INFO - 
Starting training for config s6_n291:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n291/checkpoint.bin
2024-11-20 19:34:21,299 - INFO - Running command: ./train_gpt2cu -l 0.0006021443487263004 -o hyperband_runs_20241120_172038/run_s6_n291 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n291/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:34:34,097 - INFO - Training completed for config s6_n291:
  Training time: 0:00:12
  Final validation loss: 10.867643
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.58e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n291/checkpoint.bin
2024-11-20 19:34:34,097 - INFO - 
Configuration s6_n291 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006021443487263004",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n291",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n291/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.867643
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.58e-06
2024-11-20 19:34:34,097 - INFO - 
Starting training for config s6_n1:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n1/checkpoint.bin
2024-11-20 19:34:34,097 - INFO - Running command: ./train_gpt2cu -l 0.0006009494647743333 -o hyperband_runs_20241120_172038/run_s6_n1 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n1/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:34:43,500 - INFO - Training completed for config s6_n1:
  Training time: 0:00:09
  Final validation loss: 10.867731
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.58e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n1/checkpoint.bin
2024-11-20 19:34:43,500 - INFO - 
Configuration s6_n1 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006009494647743333",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n1",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n1/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:09
  Validation Loss: 10.867731
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.58e-06
2024-11-20 19:34:43,500 - INFO - 
Starting training for config s6_n533:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n533/checkpoint.bin
2024-11-20 19:34:43,500 - INFO - Running command: ./train_gpt2cu -l 0.0005995598841000959 -o hyperband_runs_20241120_172038/run_s6_n533 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n533/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:34:55,620 - INFO - Training completed for config s6_n533:
  Training time: 0:00:12
  Final validation loss: 10.867825
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.57e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n533/checkpoint.bin
2024-11-20 19:34:55,620 - INFO - 
Configuration s6_n533 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005995598841000959",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n533",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n533/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.867825
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.57e-06
2024-11-20 19:34:55,620 - INFO - 
Starting training for config s6_n206:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n206/checkpoint.bin
2024-11-20 19:34:55,621 - INFO - Running command: ./train_gpt2cu -l 0.0005960641560476585 -o hyperband_runs_20241120_172038/run_s6_n206 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n206/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:35:08,417 - INFO - Training completed for config s6_n206:
  Training time: 0:00:12
  Final validation loss: 10.868075
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.55e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n206/checkpoint.bin
2024-11-20 19:35:08,417 - INFO - 
Configuration s6_n206 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005960641560476585",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n206",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n206/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.868075
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.55e-06
2024-11-20 19:35:08,417 - INFO - 
Starting training for config s6_n558:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n558/checkpoint.bin
2024-11-20 19:35:08,417 - INFO - Running command: ./train_gpt2cu -l 0.00058046999043979 -o hyperband_runs_20241120_172038/run_s6_n558 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n558/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:35:21,314 - INFO - Training completed for config s6_n558:
  Training time: 0:00:12
  Final validation loss: 10.869190
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.49e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n558/checkpoint.bin
2024-11-20 19:35:21,314 - INFO - 
Configuration s6_n558 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00058046999043979",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n558",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n558/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.869190
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.49e-06
2024-11-20 19:35:21,315 - INFO - 
Starting training for config s6_n694:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n694/checkpoint.bin
2024-11-20 19:35:21,315 - INFO - Running command: ./train_gpt2cu -l 0.0005785577817493396 -o hyperband_runs_20241120_172038/run_s6_n694 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n694/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:35:34,969 - INFO - Training completed for config s6_n694:
  Training time: 0:00:13
  Final validation loss: 10.869328
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.48e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n694/checkpoint.bin
2024-11-20 19:35:34,969 - INFO - 
Configuration s6_n694 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005785577817493396",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n694",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n694/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:13
  Validation Loss: 10.869328
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.48e-06
2024-11-20 19:35:34,969 - INFO - 
Starting training for config s6_n88:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n88/checkpoint.bin
2024-11-20 19:35:34,969 - INFO - Running command: ./train_gpt2cu -l 0.0005770588695397528 -o hyperband_runs_20241120_172038/run_s6_n88 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n88/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:35:46,046 - INFO - Training completed for config s6_n88:
  Training time: 0:00:11
  Final validation loss: 10.869435
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.47e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n88/checkpoint.bin
2024-11-20 19:35:46,046 - INFO - 
Configuration s6_n88 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005770588695397528",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n88",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n88/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.869435
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.47e-06
2024-11-20 19:35:46,046 - INFO - 
Starting training for config s6_n510:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n510/checkpoint.bin
2024-11-20 19:35:46,047 - INFO - Running command: ./train_gpt2cu -l 0.000574514524099536 -o hyperband_runs_20241120_172038/run_s6_n510 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n510/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:35:57,113 - INFO - Training completed for config s6_n510:
  Training time: 0:00:11
  Final validation loss: 10.869621
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.46e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n510/checkpoint.bin
2024-11-20 19:35:57,114 - INFO - 
Configuration s6_n510 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000574514524099536",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n510",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n510/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.869621
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.46e-06
2024-11-20 19:35:57,114 - INFO - 
Starting training for config s6_n655:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n655/checkpoint.bin
2024-11-20 19:35:57,114 - INFO - Running command: ./train_gpt2cu -l 0.000573822404641857 -o hyperband_runs_20241120_172038/run_s6_n655 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n655/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:36:08,169 - INFO - Training completed for config s6_n655:
  Training time: 0:00:11
  Final validation loss: 10.869681
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.46e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n655/checkpoint.bin
2024-11-20 19:36:08,170 - INFO - 
Configuration s6_n655 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000573822404641857",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n655",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n655/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.869681
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.46e-06
2024-11-20 19:36:08,170 - INFO - 
Starting training for config s6_n432:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n432/checkpoint.bin
2024-11-20 19:36:08,170 - INFO - Running command: ./train_gpt2cu -l 0.0005718735354629053 -o hyperband_runs_20241120_172038/run_s6_n432 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n432/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:36:20,129 - INFO - Training completed for config s6_n432:
  Training time: 0:00:11
  Final validation loss: 10.869818
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.45e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n432/checkpoint.bin
2024-11-20 19:36:20,129 - INFO - 
Configuration s6_n432 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005718735354629053",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n432",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n432/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.869818
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.45e-06
2024-11-20 19:36:20,129 - INFO - 
Starting training for config s6_n643:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n643/checkpoint.bin
2024-11-20 19:36:20,129 - INFO - Running command: ./train_gpt2cu -l 0.0005720172163291692 -o hyperband_runs_20241120_172038/run_s6_n643 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n643/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:36:32,892 - INFO - Training completed for config s6_n643:
  Training time: 0:00:12
  Final validation loss: 10.869802
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.45e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n643/checkpoint.bin
2024-11-20 19:36:32,892 - INFO - 
Configuration s6_n643 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005720172163291692",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n643",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n643/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.869802
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.45e-06
2024-11-20 19:36:32,893 - INFO - 
Starting training for config s6_n531:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n531/checkpoint.bin
2024-11-20 19:36:32,893 - INFO - Running command: ./train_gpt2cu -l 0.0005692004594422224 -o hyperband_runs_20241120_172038/run_s6_n531 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n531/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:36:43,937 - INFO - Training completed for config s6_n531:
  Training time: 0:00:11
  Final validation loss: 10.870011
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.44e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n531/checkpoint.bin
2024-11-20 19:36:43,937 - INFO - 
Configuration s6_n531 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005692004594422224",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n531",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n531/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.870011
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.44e-06
2024-11-20 19:36:43,937 - INFO - 
Starting training for config s6_n475:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n475/checkpoint.bin
2024-11-20 19:36:43,938 - INFO - Running command: ./train_gpt2cu -l 0.0005673052098845844 -o hyperband_runs_20241120_172038/run_s6_n475 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n475/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:36:55,019 - INFO - Training completed for config s6_n475:
  Training time: 0:00:11
  Final validation loss: 10.870149
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.43e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n475/checkpoint.bin
2024-11-20 19:36:55,019 - INFO - 
Configuration s6_n475 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005673052098845844",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n475",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n475/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.870149
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.43e-06
2024-11-20 19:36:55,019 - INFO - 
Starting training for config s6_n422:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n422/checkpoint.bin
2024-11-20 19:36:55,019 - INFO - Running command: ./train_gpt2cu -l 0.0005657697041682562 -o hyperband_runs_20241120_172038/run_s6_n422 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n422/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:37:07,207 - INFO - Training completed for config s6_n422:
  Training time: 0:00:12
  Final validation loss: 10.870253
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.42e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n422/checkpoint.bin
2024-11-20 19:37:07,208 - INFO - 
Configuration s6_n422 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005657697041682562",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n422",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n422/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.870253
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.42e-06
2024-11-20 19:37:07,208 - INFO - 
Starting training for config s6_n142:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n142/checkpoint.bin
2024-11-20 19:37:07,208 - INFO - Running command: ./train_gpt2cu -l 0.0005665513189493892 -o hyperband_runs_20241120_172038/run_s6_n142 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n142/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:37:19,995 - INFO - Training completed for config s6_n142:
  Training time: 0:00:12
  Final validation loss: 10.870194
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.43e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n142/checkpoint.bin
2024-11-20 19:37:19,996 - INFO - 
Configuration s6_n142 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005665513189493892",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n142",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n142/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.870194
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.43e-06
2024-11-20 19:37:19,996 - INFO - 
Starting training for config s6_n183:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n183/checkpoint.bin
2024-11-20 19:37:19,996 - INFO - Running command: ./train_gpt2cu -l 0.0005536324926595919 -o hyperband_runs_20241120_172038/run_s6_n183 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n183/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:37:31,052 - INFO - Training completed for config s6_n183:
  Training time: 0:00:11
  Final validation loss: 10.871168
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.37e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n183/checkpoint.bin
2024-11-20 19:37:31,052 - INFO - 
Configuration s6_n183 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005536324926595919",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n183",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n183/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.871168
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.37e-06
2024-11-20 19:37:31,052 - INFO - 
Starting training for config s6_n713:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n713/checkpoint.bin
2024-11-20 19:37:31,053 - INFO - Running command: ./train_gpt2cu -l 0.0005499121239166275 -o hyperband_runs_20241120_172038/run_s6_n713 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n713/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:37:42,129 - INFO - Training completed for config s6_n713:
  Training time: 0:00:11
  Final validation loss: 10.871412
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.36e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n713/checkpoint.bin
2024-11-20 19:37:42,129 - INFO - 
Configuration s6_n713 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005499121239166275",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n713",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n713/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.871412
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.36e-06
2024-11-20 19:37:42,129 - INFO - 
Starting training for config s6_n83:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n83/checkpoint.bin
2024-11-20 19:37:42,129 - INFO - Running command: ./train_gpt2cu -l 0.000547532555846819 -o hyperband_runs_20241120_172038/run_s6_n83 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n83/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:37:54,310 - INFO - Training completed for config s6_n83:
  Training time: 0:00:12
  Final validation loss: 10.871599
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.35e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n83/checkpoint.bin
2024-11-20 19:37:54,310 - INFO - 
Configuration s6_n83 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000547532555846819",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n83",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n83/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.871599
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.35e-06
2024-11-20 19:37:54,310 - INFO - 
Starting training for config s6_n150:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n150/checkpoint.bin
2024-11-20 19:37:54,310 - INFO - Running command: ./train_gpt2cu -l 0.0005391268463780815 -o hyperband_runs_20241120_172038/run_s6_n150 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n150/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:38:07,120 - INFO - Training completed for config s6_n150:
  Training time: 0:00:12
  Final validation loss: 10.872209
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.31e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n150/checkpoint.bin
2024-11-20 19:38:07,120 - INFO - 
Configuration s6_n150 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005391268463780815",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n150",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n150/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.872209
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.31e-06
2024-11-20 19:38:07,120 - INFO - 
Starting training for config s6_n584:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n584/checkpoint.bin
2024-11-20 19:38:07,120 - INFO - Running command: ./train_gpt2cu -l 0.0005278182574572715 -o hyperband_runs_20241120_172038/run_s6_n584 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n584/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:38:18,233 - INFO - Training completed for config s6_n584:
  Training time: 0:00:11
  Final validation loss: 10.873015
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.26e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n584/checkpoint.bin
2024-11-20 19:38:18,234 - INFO - 
Configuration s6_n584 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005278182574572715",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n584",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n584/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.873015
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.26e-06
2024-11-20 19:38:18,234 - INFO - 
Starting training for config s6_n669:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n669/checkpoint.bin
2024-11-20 19:38:18,234 - INFO - Running command: ./train_gpt2cu -l 0.0005269083413840958 -o hyperband_runs_20241120_172038/run_s6_n669 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n669/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:38:29,264 - INFO - Training completed for config s6_n669:
  Training time: 0:00:11
  Final validation loss: 10.873080
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.26e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n669/checkpoint.bin
2024-11-20 19:38:29,264 - INFO - 
Configuration s6_n669 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005269083413840958",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n669",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n669/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.873080
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.26e-06
2024-11-20 19:38:29,264 - INFO - 
Starting training for config s6_n406:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n406/checkpoint.bin
2024-11-20 19:38:29,264 - INFO - Running command: ./train_gpt2cu -l 0.0005246202568201113 -o hyperband_runs_20241120_172038/run_s6_n406 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n406/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:38:41,399 - INFO - Training completed for config s6_n406:
  Training time: 0:00:12
  Final validation loss: 10.873251
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.25e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n406/checkpoint.bin
2024-11-20 19:38:41,399 - INFO - 
Configuration s6_n406 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005246202568201113",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n406",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n406/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.873251
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.25e-06
2024-11-20 19:38:41,400 - INFO - 
Starting training for config s6_n219:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n219/checkpoint.bin
2024-11-20 19:38:41,400 - INFO - Running command: ./train_gpt2cu -l 0.0005228506839588235 -o hyperband_runs_20241120_172038/run_s6_n219 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n219/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:38:54,192 - INFO - Training completed for config s6_n219:
  Training time: 0:00:12
  Final validation loss: 10.873383
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.24e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n219/checkpoint.bin
2024-11-20 19:38:54,192 - INFO - 
Configuration s6_n219 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005228506839588235",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n219",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n219/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.873383
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.24e-06
2024-11-20 19:38:54,192 - INFO - 
Starting training for config s6_n534:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n534/checkpoint.bin
2024-11-20 19:38:54,193 - INFO - Running command: ./train_gpt2cu -l 0.0005220175259161493 -o hyperband_runs_20241120_172038/run_s6_n534 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n534/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:39:05,235 - INFO - Training completed for config s6_n534:
  Training time: 0:00:11
  Final validation loss: 10.873446
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.24e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n534/checkpoint.bin
2024-11-20 19:39:05,235 - INFO - 
Configuration s6_n534 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005220175259161493",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n534",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n534/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.873446
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.24e-06
2024-11-20 19:39:05,235 - INFO - 
Starting training for config s6_n400:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n400/checkpoint.bin
2024-11-20 19:39:05,235 - INFO - Running command: ./train_gpt2cu -l 0.0005195453314618219 -o hyperband_runs_20241120_172038/run_s6_n400 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n400/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:39:16,300 - INFO - Training completed for config s6_n400:
  Training time: 0:00:11
  Final validation loss: 10.873620
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.23e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n400/checkpoint.bin
2024-11-20 19:39:16,300 - INFO - 
Configuration s6_n400 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005195453314618219",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n400",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n400/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.873620
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.23e-06
2024-11-20 19:39:16,300 - INFO - 
Starting training for config s6_n341:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n341/checkpoint.bin
2024-11-20 19:39:16,300 - INFO - Running command: ./train_gpt2cu -l 0.00051494867892522 -o hyperband_runs_20241120_172038/run_s6_n341 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n341/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:39:28,506 - INFO - Training completed for config s6_n341:
  Training time: 0:00:12
  Final validation loss: 10.873964
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.21e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n341/checkpoint.bin
2024-11-20 19:39:28,506 - INFO - 
Configuration s6_n341 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00051494867892522",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n341",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n341/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.873964
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.21e-06
2024-11-20 19:39:28,506 - INFO - 
Starting training for config s6_n653:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n653/checkpoint.bin
2024-11-20 19:39:28,506 - INFO - Running command: ./train_gpt2cu -l 0.0005074096433030957 -o hyperband_runs_20241120_172038/run_s6_n653 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n653/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:39:41,315 - INFO - Training completed for config s6_n653:
  Training time: 0:00:12
  Final validation loss: 10.874517
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.17e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n653/checkpoint.bin
2024-11-20 19:39:41,315 - INFO - 
Configuration s6_n653 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005074096433030957",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n653",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n653/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.874517
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.17e-06
2024-11-20 19:39:41,315 - INFO - 
Starting training for config s6_n251:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n251/checkpoint.bin
2024-11-20 19:39:41,315 - INFO - Running command: ./train_gpt2cu -l 0.0005047992540023229 -o hyperband_runs_20241120_172038/run_s6_n251 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n251/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:39:52,379 - INFO - Training completed for config s6_n251:
  Training time: 0:00:11
  Final validation loss: 10.874697
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.16e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n251/checkpoint.bin
2024-11-20 19:39:52,379 - INFO - 
Configuration s6_n251 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005047992540023229",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n251",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n251/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.874697
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.16e-06
2024-11-20 19:39:52,380 - INFO - 
Starting training for config s6_n625:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n625/checkpoint.bin
2024-11-20 19:39:52,380 - INFO - Running command: ./train_gpt2cu -l 0.0005005296956902601 -o hyperband_runs_20241120_172038/run_s6_n625 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n625/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:40:03,441 - INFO - Training completed for config s6_n625:
  Training time: 0:00:11
  Final validation loss: 10.874995
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.15e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n625/checkpoint.bin
2024-11-20 19:40:03,442 - INFO - 
Configuration s6_n625 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005005296956902601",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n625",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n625/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.874995
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.15e-06
2024-11-20 19:40:03,442 - INFO - 
Starting training for config s6_n627:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n627/checkpoint.bin
2024-11-20 19:40:03,442 - INFO - Running command: ./train_gpt2cu -l 0.0004982092352823935 -o hyperband_runs_20241120_172038/run_s6_n627 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n627/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:40:15,607 - INFO - Training completed for config s6_n627:
  Training time: 0:00:12
  Final validation loss: 10.875177
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.14e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n627/checkpoint.bin
2024-11-20 19:40:15,608 - INFO - 
Configuration s6_n627 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004982092352823935",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n627",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n627/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.875177
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.14e-06
2024-11-20 19:40:15,608 - INFO - 
Starting training for config s6_n16:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n16/checkpoint.bin
2024-11-20 19:40:15,608 - INFO - Running command: ./train_gpt2cu -l 0.0004914026159065427 -o hyperband_runs_20241120_172038/run_s6_n16 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n16/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:40:28,408 - INFO - Training completed for config s6_n16:
  Training time: 0:00:12
  Final validation loss: 10.875673
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.11e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n16/checkpoint.bin
2024-11-20 19:40:28,408 - INFO - 
Configuration s6_n16 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004914026159065427",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n16",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n16/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.875673
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.11e-06
2024-11-20 19:40:28,408 - INFO - 
Starting training for config s6_n74:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n74/checkpoint.bin
2024-11-20 19:40:28,408 - INFO - Running command: ./train_gpt2cu -l 0.000490991692094771 -o hyperband_runs_20241120_172038/run_s6_n74 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n74/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:40:39,462 - INFO - Training completed for config s6_n74:
  Training time: 0:00:11
  Final validation loss: 10.875689
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.10e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n74/checkpoint.bin
2024-11-20 19:40:39,462 - INFO - 
Configuration s6_n74 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000490991692094771",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n74",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n74/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.875689
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.10e-06
2024-11-20 19:40:39,462 - INFO - 
Starting training for config s6_n387:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n387/checkpoint.bin
2024-11-20 19:40:39,463 - INFO - Running command: ./train_gpt2cu -l 0.0004902875342708506 -o hyperband_runs_20241120_172038/run_s6_n387 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n387/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:40:50,522 - INFO - Training completed for config s6_n387:
  Training time: 0:00:11
  Final validation loss: 10.875751
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.10e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n387/checkpoint.bin
2024-11-20 19:40:50,522 - INFO - 
Configuration s6_n387 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004902875342708506",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n387",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n387/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.875751
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.10e-06
2024-11-20 19:40:50,522 - INFO - 
Starting training for config s6_n440:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n440/checkpoint.bin
2024-11-20 19:40:50,523 - INFO - Running command: ./train_gpt2cu -l 0.0004883898403137743 -o hyperband_runs_20241120_172038/run_s6_n440 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n440/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:41:02,704 - INFO - Training completed for config s6_n440:
  Training time: 0:00:12
  Final validation loss: 10.875887
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.09e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n440/checkpoint.bin
2024-11-20 19:41:02,704 - INFO - 
Configuration s6_n440 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004883898403137743",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n440",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n440/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.875887
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.09e-06
2024-11-20 19:41:02,704 - INFO - 
Starting training for config s6_n212:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n212/checkpoint.bin
2024-11-20 19:41:02,704 - INFO - Running command: ./train_gpt2cu -l 0.0004886431983043564 -o hyperband_runs_20241120_172038/run_s6_n212 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n212/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:41:15,533 - INFO - Training completed for config s6_n212:
  Training time: 0:00:12
  Final validation loss: 10.875867
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.09e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n212/checkpoint.bin
2024-11-20 19:41:15,533 - INFO - 
Configuration s6_n212 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004886431983043564",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n212",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n212/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.875867
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.09e-06
2024-11-20 19:41:15,533 - INFO - 
Starting training for config s6_n54:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n54/checkpoint.bin
2024-11-20 19:41:15,533 - INFO - Running command: ./train_gpt2cu -l 0.00048244579252361273 -o hyperband_runs_20241120_172038/run_s6_n54 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n54/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:41:26,593 - INFO - Training completed for config s6_n54:
  Training time: 0:00:11
  Final validation loss: 10.876307
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.07e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n54/checkpoint.bin
2024-11-20 19:41:26,594 - INFO - 
Configuration s6_n54 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00048244579252361273",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n54",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n54/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.876307
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.07e-06
2024-11-20 19:41:26,594 - INFO - 
Starting training for config s6_n598:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n598/checkpoint.bin
2024-11-20 19:41:26,594 - INFO - Running command: ./train_gpt2cu -l 0.00047945366371818075 -o hyperband_runs_20241120_172038/run_s6_n598 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n598/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:41:37,662 - INFO - Training completed for config s6_n598:
  Training time: 0:00:11
  Final validation loss: 10.876524
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.05e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n598/checkpoint.bin
2024-11-20 19:41:37,662 - INFO - 
Configuration s6_n598 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00047945366371818075",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n598",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n598/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.876524
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.05e-06
2024-11-20 19:41:37,662 - INFO - 
Starting training for config s6_n292:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n292/checkpoint.bin
2024-11-20 19:41:37,662 - INFO - Running command: ./train_gpt2cu -l 0.0004787631009411304 -o hyperband_runs_20241120_172038/run_s6_n292 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n292/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:41:49,822 - INFO - Training completed for config s6_n292:
  Training time: 0:00:12
  Final validation loss: 10.876577
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.05e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n292/checkpoint.bin
2024-11-20 19:41:49,822 - INFO - 
Configuration s6_n292 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004787631009411304",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n292",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n292/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.876577
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.05e-06
2024-11-20 19:41:49,822 - INFO - 
Starting training for config s6_n585:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n585/checkpoint.bin
2024-11-20 19:41:49,822 - INFO - Running command: ./train_gpt2cu -l 0.00047600113579342206 -o hyperband_runs_20241120_172038/run_s6_n585 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n585/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:42:02,622 - INFO - Training completed for config s6_n585:
  Training time: 0:00:12
  Final validation loss: 10.876768
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.04e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n585/checkpoint.bin
2024-11-20 19:42:02,623 - INFO - 
Configuration s6_n585 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00047600113579342206",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n585",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n585/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.876768
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.04e-06
2024-11-20 19:42:02,623 - INFO - 
Starting training for config s6_n134:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n134/checkpoint.bin
2024-11-20 19:42:02,623 - INFO - Running command: ./train_gpt2cu -l 0.0004676997157935328 -o hyperband_runs_20241120_172038/run_s6_n134 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n134/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:42:13,673 - INFO - Training completed for config s6_n134:
  Training time: 0:00:11
  Final validation loss: 10.877358
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.00e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n134/checkpoint.bin
2024-11-20 19:42:13,673 - INFO - 
Configuration s6_n134 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004676997157935328",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n134",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n134/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.877358
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.00e-06
2024-11-20 19:42:13,673 - INFO - 
Starting training for config s6_n421:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n421/checkpoint.bin
2024-11-20 19:42:13,673 - INFO - Running command: ./train_gpt2cu -l 0.00046384683602221924 -o hyperband_runs_20241120_172038/run_s6_n421 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n421/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:42:24,764 - INFO - Training completed for config s6_n421:
  Training time: 0:00:11
  Final validation loss: 10.877653
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.99e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n421/checkpoint.bin
2024-11-20 19:42:24,764 - INFO - 
Configuration s6_n421 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00046384683602221924",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n421",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n421/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.877653
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.99e-06
2024-11-20 19:42:24,765 - INFO - 
Starting training for config s6_n465:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n465/checkpoint.bin
2024-11-20 19:42:24,765 - INFO - Running command: ./train_gpt2cu -l 0.0004596267992803697 -o hyperband_runs_20241120_172038/run_s6_n465 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n465/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:42:36,929 - INFO - Training completed for config s6_n465:
  Training time: 0:00:12
  Final validation loss: 10.877947
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.97e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n465/checkpoint.bin
2024-11-20 19:42:36,930 - INFO - 
Configuration s6_n465 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004596267992803697",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n465",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n465/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.877947
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.97e-06
2024-11-20 19:42:36,930 - INFO - 
Starting training for config s6_n367:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n367/checkpoint.bin
2024-11-20 19:42:36,930 - INFO - Running command: ./train_gpt2cu -l 0.0004564735500034968 -o hyperband_runs_20241120_172038/run_s6_n367 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n367/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:42:49,722 - INFO - Training completed for config s6_n367:
  Training time: 0:00:12
  Final validation loss: 10.878182
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.96e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n367/checkpoint.bin
2024-11-20 19:42:49,722 - INFO - 
Configuration s6_n367 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004564735500034968",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n367",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n367/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.878182
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.96e-06
2024-11-20 19:42:49,722 - INFO - 
Starting training for config s6_n567:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n567/checkpoint.bin
2024-11-20 19:42:49,723 - INFO - Running command: ./train_gpt2cu -l 0.0004519172519548599 -o hyperband_runs_20241120_172038/run_s6_n567 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n567/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:43:00,780 - INFO - Training completed for config s6_n567:
  Training time: 0:00:11
  Final validation loss: 10.878519
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.94e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n567/checkpoint.bin
2024-11-20 19:43:00,780 - INFO - 
Configuration s6_n567 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004519172519548599",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n567",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n567/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.878519
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.94e-06
2024-11-20 19:43:00,780 - INFO - 
Starting training for config s6_n401:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n401/checkpoint.bin
2024-11-20 19:43:00,780 - INFO - Running command: ./train_gpt2cu -l 0.0004431113889646486 -o hyperband_runs_20241120_172038/run_s6_n401 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n401/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:43:11,829 - INFO - Training completed for config s6_n401:
  Training time: 0:00:11
  Final validation loss: 10.879163
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.90e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n401/checkpoint.bin
2024-11-20 19:43:11,830 - INFO - 
Configuration s6_n401 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004431113889646486",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n401",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n401/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.879163
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.90e-06
2024-11-20 19:43:11,830 - INFO - 
Starting training for config s6_n497:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n497/checkpoint.bin
2024-11-20 19:43:11,830 - INFO - Running command: ./train_gpt2cu -l 0.00044103078901548763 -o hyperband_runs_20241120_172038/run_s6_n497 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n497/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:43:24,042 - INFO - Training completed for config s6_n497:
  Training time: 0:00:12
  Final validation loss: 10.879291
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.89e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n497/checkpoint.bin
2024-11-20 19:43:24,042 - INFO - 
Configuration s6_n497 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00044103078901548763",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n497",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n497/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.879291
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.89e-06
2024-11-20 19:43:24,042 - INFO - 
Starting training for config s6_n163:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n163/checkpoint.bin
2024-11-20 19:43:24,042 - INFO - Running command: ./train_gpt2cu -l 0.0004359219869977251 -o hyperband_runs_20241120_172038/run_s6_n163 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n163/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:43:36,817 - INFO - Training completed for config s6_n163:
  Training time: 0:00:12
  Final validation loss: 10.879679
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.87e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n163/checkpoint.bin
2024-11-20 19:43:36,817 - INFO - 
Configuration s6_n163 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004359219869977251",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n163",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n163/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.879679
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.87e-06
2024-11-20 19:43:36,817 - INFO - 
Starting training for config s6_n107:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n107/checkpoint.bin
2024-11-20 19:43:36,817 - INFO - Running command: ./train_gpt2cu -l 0.0004308027030496864 -o hyperband_runs_20241120_172038/run_s6_n107 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n107/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:43:47,878 - INFO - Training completed for config s6_n107:
  Training time: 0:00:11
  Final validation loss: 10.880067
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.85e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n107/checkpoint.bin
2024-11-20 19:43:47,878 - INFO - 
Configuration s6_n107 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004308027030496864",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n107",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n107/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.880067
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.85e-06
2024-11-20 19:43:47,878 - INFO - 
Starting training for config s6_n214:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n214/checkpoint.bin
2024-11-20 19:43:47,878 - INFO - Running command: ./train_gpt2cu -l 0.00042994844931465285 -o hyperband_runs_20241120_172038/run_s6_n214 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n214/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:43:58,946 - INFO - Training completed for config s6_n214:
  Training time: 0:00:11
  Final validation loss: 10.880133
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.84e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n214/checkpoint.bin
2024-11-20 19:43:58,946 - INFO - 
Configuration s6_n214 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00042994844931465285",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n214",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n214/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.880133
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.84e-06
2024-11-20 19:43:58,946 - INFO - 
Starting training for config s6_n68:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n68/checkpoint.bin
2024-11-20 19:43:58,946 - INFO - Running command: ./train_gpt2cu -l 0.00043018629735312866 -o hyperband_runs_20241120_172038/run_s6_n68 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n68/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:44:11,144 - INFO - Training completed for config s6_n68:
  Training time: 0:00:12
  Final validation loss: 10.880107
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.84e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n68/checkpoint.bin
2024-11-20 19:44:11,144 - INFO - 
Configuration s6_n68 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00043018629735312866",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n68",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n68/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.880107
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.84e-06
2024-11-20 19:44:11,145 - INFO - 
Starting training for config s6_n657:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n657/checkpoint.bin
2024-11-20 19:44:11,145 - INFO - Running command: ./train_gpt2cu -l 0.0004283293388778901 -o hyperband_runs_20241120_172038/run_s6_n657 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n657/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:44:23,961 - INFO - Training completed for config s6_n657:
  Training time: 0:00:12
  Final validation loss: 10.880241
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.84e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n657/checkpoint.bin
2024-11-20 19:44:23,962 - INFO - 
Configuration s6_n657 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004283293388778901",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n657",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n657/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.880241
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.84e-06
2024-11-20 19:44:23,962 - INFO - 
Starting training for config s6_n512:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n512/checkpoint.bin
2024-11-20 19:44:23,962 - INFO - Running command: ./train_gpt2cu -l 0.0004282236002425996 -o hyperband_runs_20241120_172038/run_s6_n512 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n512/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:44:35,018 - INFO - Training completed for config s6_n512:
  Training time: 0:00:11
  Final validation loss: 10.880257
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.84e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n512/checkpoint.bin
2024-11-20 19:44:35,018 - INFO - 
Configuration s6_n512 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004282236002425996",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n512",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n512/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.880257
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.84e-06
2024-11-20 19:44:35,018 - INFO - 
Starting training for config s6_n672:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n672/checkpoint.bin
2024-11-20 19:44:35,018 - INFO - Running command: ./train_gpt2cu -l 0.0004255953434304252 -o hyperband_runs_20241120_172038/run_s6_n672 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n672/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:44:46,087 - INFO - Training completed for config s6_n672:
  Training time: 0:00:11
  Final validation loss: 10.880451
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.82e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n672/checkpoint.bin
2024-11-20 19:44:46,088 - INFO - 
Configuration s6_n672 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004255953434304252",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n672",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n672/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.880451
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.82e-06
2024-11-20 19:44:46,088 - INFO - 
Starting training for config s6_n77:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n77/checkpoint.bin
2024-11-20 19:44:46,088 - INFO - Running command: ./train_gpt2cu -l 0.0004225248406036559 -o hyperband_runs_20241120_172038/run_s6_n77 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n77/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:44:58,244 - INFO - Training completed for config s6_n77:
  Training time: 0:00:12
  Final validation loss: 10.880672
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.81e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n77/checkpoint.bin
2024-11-20 19:44:58,244 - INFO - 
Configuration s6_n77 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004225248406036559",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n77",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n77/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.880672
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.81e-06
2024-11-20 19:44:58,244 - INFO - 
Starting training for config s6_n6:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n6/checkpoint.bin
2024-11-20 19:44:58,244 - INFO - Running command: ./train_gpt2cu -l 0.0004231577128629817 -o hyperband_runs_20241120_172038/run_s6_n6 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n6/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:45:10,972 - INFO - Training completed for config s6_n6:
  Training time: 0:00:12
  Final validation loss: 10.880621
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.81e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n6/checkpoint.bin
2024-11-20 19:45:10,972 - INFO - 
Configuration s6_n6 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004231577128629817",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n6",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n6/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.880621
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.81e-06
2024-11-20 19:45:10,972 - INFO - 
Starting training for config s6_n449:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n449/checkpoint.bin
2024-11-20 19:45:10,972 - INFO - Running command: ./train_gpt2cu -l 0.0004225362112947988 -o hyperband_runs_20241120_172038/run_s6_n449 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n449/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:45:22,022 - INFO - Training completed for config s6_n449:
  Training time: 0:00:11
  Final validation loss: 10.880678
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.81e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n449/checkpoint.bin
2024-11-20 19:45:22,022 - INFO - 
Configuration s6_n449 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004225362112947988",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n449",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n449/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.880678
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.81e-06
2024-11-20 19:45:22,022 - INFO - 
Starting training for config s6_n433:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n433/checkpoint.bin
2024-11-20 19:45:22,022 - INFO - Running command: ./train_gpt2cu -l 0.00042028372685650475 -o hyperband_runs_20241120_172038/run_s6_n433 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n433/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:45:33,078 - INFO - Training completed for config s6_n433:
  Training time: 0:00:11
  Final validation loss: 10.880838
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.80e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n433/checkpoint.bin
2024-11-20 19:45:33,078 - INFO - 
Configuration s6_n433 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00042028372685650475",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n433",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n433/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.880838
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.80e-06
2024-11-20 19:45:33,078 - INFO - 
Starting training for config s6_n570:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n570/checkpoint.bin
2024-11-20 19:45:33,078 - INFO - Running command: ./train_gpt2cu -l 0.000419370131555939 -o hyperband_runs_20241120_172038/run_s6_n570 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n570/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:45:45,368 - INFO - Training completed for config s6_n570:
  Training time: 0:00:12
  Final validation loss: 10.880901
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.80e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n570/checkpoint.bin
2024-11-20 19:45:45,368 - INFO - 
Configuration s6_n570 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000419370131555939",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n570",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n570/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.880901
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.80e-06
2024-11-20 19:45:45,368 - INFO - 
Starting training for config s6_n155:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n155/checkpoint.bin
2024-11-20 19:45:45,368 - INFO - Running command: ./train_gpt2cu -l 0.00041716596685425323 -o hyperband_runs_20241120_172038/run_s6_n155 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n155/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:45:58,144 - INFO - Training completed for config s6_n155:
  Training time: 0:00:12
  Final validation loss: 10.881060
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.79e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n155/checkpoint.bin
2024-11-20 19:45:58,145 - INFO - 
Configuration s6_n155 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00041716596685425323",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n155",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n155/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.881060
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.79e-06
2024-11-20 19:45:58,145 - INFO - 
Starting training for config s6_n304:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n304/checkpoint.bin
2024-11-20 19:45:58,145 - INFO - Running command: ./train_gpt2cu -l 0.0004147521867486207 -o hyperband_runs_20241120_172038/run_s6_n304 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n304/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:46:09,211 - INFO - Training completed for config s6_n304:
  Training time: 0:00:11
  Final validation loss: 10.881240
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.78e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n304/checkpoint.bin
2024-11-20 19:46:09,212 - INFO - 
Configuration s6_n304 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004147521867486207",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n304",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n304/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.881240
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.78e-06
2024-11-20 19:46:09,212 - INFO - 
Starting training for config s6_n374:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n374/checkpoint.bin
2024-11-20 19:46:09,212 - INFO - Running command: ./train_gpt2cu -l 0.00040861558065735914 -o hyperband_runs_20241120_172038/run_s6_n374 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n374/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:46:20,262 - INFO - Training completed for config s6_n374:
  Training time: 0:00:11
  Final validation loss: 10.881711
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.75e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n374/checkpoint.bin
2024-11-20 19:46:20,263 - INFO - 
Configuration s6_n374 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00040861558065735914",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n374",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n374/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.881711
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.75e-06
2024-11-20 19:46:20,263 - INFO - 
Starting training for config s6_n519:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n519/checkpoint.bin
2024-11-20 19:46:20,263 - INFO - Running command: ./train_gpt2cu -l 0.00040540489309619183 -o hyperband_runs_20241120_172038/run_s6_n519 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n519/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:46:32,459 - INFO - Training completed for config s6_n519:
  Training time: 0:00:12
  Final validation loss: 10.881933
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.74e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n519/checkpoint.bin
2024-11-20 19:46:32,459 - INFO - 
Configuration s6_n519 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00040540489309619183",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n519",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n519/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.881933
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.74e-06
2024-11-20 19:46:32,459 - INFO - 
Starting training for config s6_n73:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n73/checkpoint.bin
2024-11-20 19:46:32,460 - INFO - Running command: ./train_gpt2cu -l 0.00040336605982500004 -o hyperband_runs_20241120_172038/run_s6_n73 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n73/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:46:45,266 - INFO - Training completed for config s6_n73:
  Training time: 0:00:12
  Final validation loss: 10.882067
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.73e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n73/checkpoint.bin
2024-11-20 19:46:45,266 - INFO - 
Configuration s6_n73 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00040336605982500004",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n73",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n73/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.882067
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.73e-06
2024-11-20 19:46:45,266 - INFO - 
Starting training for config s6_n646:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n646/checkpoint.bin
2024-11-20 19:46:45,266 - INFO - Running command: ./train_gpt2cu -l 0.0004027082254989879 -o hyperband_runs_20241120_172038/run_s6_n646 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n646/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:46:56,328 - INFO - Training completed for config s6_n646:
  Training time: 0:00:11
  Final validation loss: 10.882128
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.73e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n646/checkpoint.bin
2024-11-20 19:46:56,328 - INFO - 
Configuration s6_n646 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004027082254989879",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n646",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n646/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.882128
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.73e-06
2024-11-20 19:46:56,329 - INFO - 
Starting training for config s6_n629:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n629/checkpoint.bin
2024-11-20 19:46:56,329 - INFO - Running command: ./train_gpt2cu -l 0.00040127141098263787 -o hyperband_runs_20241120_172038/run_s6_n629 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n629/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:47:07,376 - INFO - Training completed for config s6_n629:
  Training time: 0:00:11
  Final validation loss: 10.882235
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.72e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n629/checkpoint.bin
2024-11-20 19:47:07,376 - INFO - 
Configuration s6_n629 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00040127141098263787",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n629",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n629/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.882235
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.72e-06
2024-11-20 19:47:07,376 - INFO - 
Starting training for config s6_n649:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n649/checkpoint.bin
2024-11-20 19:47:07,376 - INFO - Running command: ./train_gpt2cu -l 0.00040113875039152864 -o hyperband_runs_20241120_172038/run_s6_n649 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n649/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:47:19,551 - INFO - Training completed for config s6_n649:
  Training time: 0:00:12
  Final validation loss: 10.882245
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.72e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n649/checkpoint.bin
2024-11-20 19:47:19,551 - INFO - 
Configuration s6_n649 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00040113875039152864",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n649",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n649/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.882245
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.72e-06
2024-11-20 19:47:19,551 - INFO - 
Starting training for config s6_n690:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n690/checkpoint.bin
2024-11-20 19:47:19,551 - INFO - Running command: ./train_gpt2cu -l 0.00038928301499258745 -o hyperband_runs_20241120_172038/run_s6_n690 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n690/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:47:32,340 - INFO - Training completed for config s6_n690:
  Training time: 0:00:12
  Final validation loss: 10.883088
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.67e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n690/checkpoint.bin
2024-11-20 19:47:32,340 - INFO - 
Configuration s6_n690 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00038928301499258745",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n690",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n690/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.883088
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.67e-06
2024-11-20 19:47:32,340 - INFO - 
Starting training for config s6_n209:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n209/checkpoint.bin
2024-11-20 19:47:32,340 - INFO - Running command: ./train_gpt2cu -l 0.00038763793333230513 -o hyperband_runs_20241120_172038/run_s6_n209 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n209/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:47:43,404 - INFO - Training completed for config s6_n209:
  Training time: 0:00:11
  Final validation loss: 10.883215
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.66e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n209/checkpoint.bin
2024-11-20 19:47:43,404 - INFO - 
Configuration s6_n209 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00038763793333230513",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n209",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n209/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.883215
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.66e-06
2024-11-20 19:47:43,404 - INFO - 
Starting training for config s6_n404:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n404/checkpoint.bin
2024-11-20 19:47:43,404 - INFO - Running command: ./train_gpt2cu -l 0.00038586900970915026 -o hyperband_runs_20241120_172038/run_s6_n404 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n404/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:47:54,506 - INFO - Training completed for config s6_n404:
  Training time: 0:00:11
  Final validation loss: 10.883345
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.65e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n404/checkpoint.bin
2024-11-20 19:47:54,507 - INFO - 
Configuration s6_n404 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00038586900970915026",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n404",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n404/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.883345
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.65e-06
2024-11-20 19:47:54,507 - INFO - 
Starting training for config s6_n169:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n169/checkpoint.bin
2024-11-20 19:47:54,507 - INFO - Running command: ./train_gpt2cu -l 0.00038437001256041916 -o hyperband_runs_20241120_172038/run_s6_n169 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n169/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:48:06,644 - INFO - Training completed for config s6_n169:
  Training time: 0:00:12
  Final validation loss: 10.883454
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.65e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n169/checkpoint.bin
2024-11-20 19:48:06,644 - INFO - 
Configuration s6_n169 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00038437001256041916",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n169",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n169/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.883454
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.65e-06
2024-11-20 19:48:06,644 - INFO - 
Starting training for config s6_n427:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n427/checkpoint.bin
2024-11-20 19:48:06,645 - INFO - Running command: ./train_gpt2cu -l 0.00038297557085632084 -o hyperband_runs_20241120_172038/run_s6_n427 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n427/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:48:19,472 - INFO - Training completed for config s6_n427:
  Training time: 0:00:12
  Final validation loss: 10.883568
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.64e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n427/checkpoint.bin
2024-11-20 19:48:19,472 - INFO - 
Configuration s6_n427 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00038297557085632084",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n427",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n427/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.883568
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.64e-06
2024-11-20 19:48:19,472 - INFO - 
Starting training for config s6_n258:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n258/checkpoint.bin
2024-11-20 19:48:19,473 - INFO - Running command: ./train_gpt2cu -l 0.0003793336210096167 -o hyperband_runs_20241120_172038/run_s6_n258 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n258/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:48:30,529 - INFO - Training completed for config s6_n258:
  Training time: 0:00:11
  Final validation loss: 10.883821
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.63e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n258/checkpoint.bin
2024-11-20 19:48:30,530 - INFO - 
Configuration s6_n258 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003793336210096167",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n258",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n258/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.883821
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.63e-06
2024-11-20 19:48:30,530 - INFO - 
Starting training for config s6_n177:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n177/checkpoint.bin
2024-11-20 19:48:30,530 - INFO - Running command: ./train_gpt2cu -l 0.00037553337942508797 -o hyperband_runs_20241120_172038/run_s6_n177 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n177/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:48:41,592 - INFO - Training completed for config s6_n177:
  Training time: 0:00:11
  Final validation loss: 10.884100
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.61e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n177/checkpoint.bin
2024-11-20 19:48:41,593 - INFO - 
Configuration s6_n177 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00037553337942508797",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n177",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n177/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.884100
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.61e-06
2024-11-20 19:48:41,593 - INFO - 
Starting training for config s6_n462:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n462/checkpoint.bin
2024-11-20 19:48:41,593 - INFO - Running command: ./train_gpt2cu -l 0.00037437965100357444 -o hyperband_runs_20241120_172038/run_s6_n462 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n462/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:48:53,758 - INFO - Training completed for config s6_n462:
  Training time: 0:00:12
  Final validation loss: 10.884183
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.60e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n462/checkpoint.bin
2024-11-20 19:48:53,758 - INFO - 
Configuration s6_n462 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00037437965100357444",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n462",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n462/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.884183
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.60e-06
2024-11-20 19:48:53,758 - INFO - 
Starting training for config s6_n728:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n728/checkpoint.bin
2024-11-20 19:48:53,758 - INFO - Running command: ./train_gpt2cu -l 0.00037467572481081286 -o hyperband_runs_20241120_172038/run_s6_n728 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n728/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:49:06,540 - INFO - Training completed for config s6_n728:
  Training time: 0:00:12
  Final validation loss: 10.884164
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.61e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n728/checkpoint.bin
2024-11-20 19:49:06,541 - INFO - 
Configuration s6_n728 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00037467572481081286",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n728",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n728/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.884164
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.61e-06
2024-11-20 19:49:06,541 - INFO - 
Starting training for config s6_n252:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n252/checkpoint.bin
2024-11-20 19:49:06,541 - INFO - Running command: ./train_gpt2cu -l 0.0003746451981679478 -o hyperband_runs_20241120_172038/run_s6_n252 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n252/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:49:17,600 - INFO - Training completed for config s6_n252:
  Training time: 0:00:11
  Final validation loss: 10.884154
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.61e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n252/checkpoint.bin
2024-11-20 19:49:17,600 - INFO - 
Configuration s6_n252 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003746451981679478",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n252",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n252/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.884154
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.61e-06
2024-11-20 19:49:17,601 - INFO - 
Starting training for config s6_n30:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n30/checkpoint.bin
2024-11-20 19:49:17,601 - INFO - Running command: ./train_gpt2cu -l 0.0003700750868107223 -o hyperband_runs_20241120_172038/run_s6_n30 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n30/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:49:28,670 - INFO - Training completed for config s6_n30:
  Training time: 0:00:11
  Final validation loss: 10.884512
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.59e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n30/checkpoint.bin
2024-11-20 19:49:28,670 - INFO - 
Configuration s6_n30 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003700750868107223",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n30",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n30/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.884512
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.59e-06
2024-11-20 19:49:28,670 - INFO - 
Starting training for config s6_n392:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n392/checkpoint.bin
2024-11-20 19:49:28,670 - INFO - Running command: ./train_gpt2cu -l 0.00036508471329559046 -o hyperband_runs_20241120_172038/run_s6_n392 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n392/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:49:40,859 - INFO - Training completed for config s6_n392:
  Training time: 0:00:12
  Final validation loss: 10.884883
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.56e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n392/checkpoint.bin
2024-11-20 19:49:40,860 - INFO - 
Configuration s6_n392 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00036508471329559046",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n392",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n392/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.884883
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.56e-06
2024-11-20 19:49:40,860 - INFO - 
Starting training for config s6_n647:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n647/checkpoint.bin
2024-11-20 19:49:40,860 - INFO - Running command: ./train_gpt2cu -l 0.0003642664166407205 -o hyperband_runs_20241120_172038/run_s6_n647 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n647/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:49:53,660 - INFO - Training completed for config s6_n647:
  Training time: 0:00:12
  Final validation loss: 10.884940
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.56e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n647/checkpoint.bin
2024-11-20 19:49:53,660 - INFO - 
Configuration s6_n647 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003642664166407205",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n647",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n647/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.884940
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.56e-06
2024-11-20 19:49:53,660 - INFO - 
Starting training for config s6_n178:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n178/checkpoint.bin
2024-11-20 19:49:53,660 - INFO - Running command: ./train_gpt2cu -l 0.00036266275588751055 -o hyperband_runs_20241120_172038/run_s6_n178 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n178/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:50:04,706 - INFO - Training completed for config s6_n178:
  Training time: 0:00:11
  Final validation loss: 10.885061
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.55e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n178/checkpoint.bin
2024-11-20 19:50:04,706 - INFO - 
Configuration s6_n178 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00036266275588751055",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n178",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n178/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.885061
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.55e-06
2024-11-20 19:50:04,706 - INFO - 
Starting training for config s6_n448:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n448/checkpoint.bin
2024-11-20 19:50:04,706 - INFO - Running command: ./train_gpt2cu -l 0.0003632056056840295 -o hyperband_runs_20241120_172038/run_s6_n448 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n448/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:50:15,762 - INFO - Training completed for config s6_n448:
  Training time: 0:00:11
  Final validation loss: 10.885010
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.56e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n448/checkpoint.bin
2024-11-20 19:50:15,763 - INFO - 
Configuration s6_n448 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003632056056840295",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n448",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n448/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.885010
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.56e-06
2024-11-20 19:50:15,763 - INFO - 
Starting training for config s6_n121:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n121/checkpoint.bin
2024-11-20 19:50:15,763 - INFO - Running command: ./train_gpt2cu -l 0.0003615226741902246 -o hyperband_runs_20241120_172038/run_s6_n121 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n121/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:50:27,981 - INFO - Training completed for config s6_n121:
  Training time: 0:00:12
  Final validation loss: 10.885127
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.55e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n121/checkpoint.bin
2024-11-20 19:50:27,981 - INFO - 
Configuration s6_n121 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003615226741902246",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n121",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n121/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.885127
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.55e-06
2024-11-20 19:50:27,982 - INFO - 
Starting training for config s6_n80:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n80/checkpoint.bin
2024-11-20 19:50:27,982 - INFO - Running command: ./train_gpt2cu -l 0.00036069623181292457 -o hyperband_runs_20241120_172038/run_s6_n80 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n80/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:50:40,771 - INFO - Training completed for config s6_n80:
  Training time: 0:00:12
  Final validation loss: 10.885196
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.55e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n80/checkpoint.bin
2024-11-20 19:50:40,771 - INFO - 
Configuration s6_n80 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00036069623181292457",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n80",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n80/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.885196
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.55e-06
2024-11-20 19:50:40,772 - INFO - 
Starting training for config s6_n25:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n25/checkpoint.bin
2024-11-20 19:50:40,772 - INFO - Running command: ./train_gpt2cu -l 0.00036026954346696954 -o hyperband_runs_20241120_172038/run_s6_n25 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n25/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:50:51,824 - INFO - Training completed for config s6_n25:
  Training time: 0:00:11
  Final validation loss: 10.885237
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.54e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n25/checkpoint.bin
2024-11-20 19:50:51,824 - INFO - 
Configuration s6_n25 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00036026954346696954",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n25",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n25/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.885237
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.54e-06
2024-11-20 19:50:51,824 - INFO - 
Starting training for config s6_n365:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n365/checkpoint.bin
2024-11-20 19:50:51,824 - INFO - Running command: ./train_gpt2cu -l 0.000357407200287514 -o hyperband_runs_20241120_172038/run_s6_n365 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n365/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:51:02,901 - INFO - Training completed for config s6_n365:
  Training time: 0:00:11
  Final validation loss: 10.885428
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.53e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n365/checkpoint.bin
2024-11-20 19:51:02,901 - INFO - 
Configuration s6_n365 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000357407200287514",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n365",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n365/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.885428
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.53e-06
2024-11-20 19:51:02,901 - INFO - 
Starting training for config s6_n554:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n554/checkpoint.bin
2024-11-20 19:51:02,902 - INFO - Running command: ./train_gpt2cu -l 0.0003554550371310786 -o hyperband_runs_20241120_172038/run_s6_n554 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n554/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:51:15,069 - INFO - Training completed for config s6_n554:
  Training time: 0:00:12
  Final validation loss: 10.885592
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.52e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n554/checkpoint.bin
2024-11-20 19:51:15,069 - INFO - 
Configuration s6_n554 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003554550371310786",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n554",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n554/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.885592
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.52e-06
2024-11-20 19:51:15,069 - INFO - 
Starting training for config s6_n119:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n119/checkpoint.bin
2024-11-20 19:51:15,070 - INFO - Running command: ./train_gpt2cu -l 0.0003510213073172754 -o hyperband_runs_20241120_172038/run_s6_n119 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n119/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:51:27,868 - INFO - Training completed for config s6_n119:
  Training time: 0:00:12
  Final validation loss: 10.885917
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.50e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n119/checkpoint.bin
2024-11-20 19:51:27,868 - INFO - 
Configuration s6_n119 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003510213073172754",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n119",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n119/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.885917
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.50e-06
2024-11-20 19:51:27,868 - INFO - 
Starting training for config s6_n186:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n186/checkpoint.bin
2024-11-20 19:51:27,868 - INFO - Running command: ./train_gpt2cu -l 0.00035081501592460135 -o hyperband_runs_20241120_172038/run_s6_n186 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n186/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:51:38,973 - INFO - Training completed for config s6_n186:
  Training time: 0:00:11
  Final validation loss: 10.885932
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.50e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n186/checkpoint.bin
2024-11-20 19:51:38,973 - INFO - 
Configuration s6_n186 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00035081501592460135",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n186",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n186/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.885932
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.50e-06
2024-11-20 19:51:38,973 - INFO - 
Starting training for config s6_n555:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n555/checkpoint.bin
2024-11-20 19:51:38,973 - INFO - Running command: ./train_gpt2cu -l 0.0003492934199555555 -o hyperband_runs_20241120_172038/run_s6_n555 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n555/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:51:50,026 - INFO - Training completed for config s6_n555:
  Training time: 0:00:11
  Final validation loss: 10.886038
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.50e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n555/checkpoint.bin
2024-11-20 19:51:50,026 - INFO - 
Configuration s6_n555 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003492934199555555",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n555",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n555/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.886038
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.50e-06
2024-11-20 19:51:50,026 - INFO - 
Starting training for config s6_n415:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n415/checkpoint.bin
2024-11-20 19:51:50,026 - INFO - Running command: ./train_gpt2cu -l 0.00034849607054646895 -o hyperband_runs_20241120_172038/run_s6_n415 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n415/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:52:02,171 - INFO - Training completed for config s6_n415:
  Training time: 0:00:12
  Final validation loss: 10.886095
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.49e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n415/checkpoint.bin
2024-11-20 19:52:02,171 - INFO - 
Configuration s6_n415 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00034849607054646895",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n415",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n415/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.886095
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.49e-06
2024-11-20 19:52:02,171 - INFO - 
Starting training for config s6_n35:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n35/checkpoint.bin
2024-11-20 19:52:02,171 - INFO - Running command: ./train_gpt2cu -l 0.00034809604687483517 -o hyperband_runs_20241120_172038/run_s6_n35 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n35/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:52:14,967 - INFO - Training completed for config s6_n35:
  Training time: 0:00:12
  Final validation loss: 10.886128
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.49e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n35/checkpoint.bin
2024-11-20 19:52:14,967 - INFO - 
Configuration s6_n35 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00034809604687483517",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n35",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n35/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.886128
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.49e-06
2024-11-20 19:52:14,967 - INFO - 
Starting training for config s6_n230:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n230/checkpoint.bin
2024-11-20 19:52:14,967 - INFO - Running command: ./train_gpt2cu -l 0.000343445966883462 -o hyperband_runs_20241120_172038/run_s6_n230 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n230/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:52:26,045 - INFO - Training completed for config s6_n230:
  Training time: 0:00:11
  Final validation loss: 10.886446
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.47e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n230/checkpoint.bin
2024-11-20 19:52:26,045 - INFO - 
Configuration s6_n230 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000343445966883462",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n230",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n230/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.886446
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.47e-06
2024-11-20 19:52:26,046 - INFO - 
Starting training for config s6_n105:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n105/checkpoint.bin
2024-11-20 19:52:26,046 - INFO - Running command: ./train_gpt2cu -l 0.00034298991818401437 -o hyperband_runs_20241120_172038/run_s6_n105 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n105/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:52:37,108 - INFO - Training completed for config s6_n105:
  Training time: 0:00:11
  Final validation loss: 10.886487
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.47e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n105/checkpoint.bin
2024-11-20 19:52:37,109 - INFO - 
Configuration s6_n105 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00034298991818401437",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n105",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n105/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.886487
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.47e-06
2024-11-20 19:52:37,109 - INFO - 
Starting training for config s6_n218:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n218/checkpoint.bin
2024-11-20 19:52:37,109 - INFO - Running command: ./train_gpt2cu -l 0.0003412585211946685 -o hyperband_runs_20241120_172038/run_s6_n218 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n218/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:52:49,303 - INFO - Training completed for config s6_n218:
  Training time: 0:00:12
  Final validation loss: 10.886621
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.46e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n218/checkpoint.bin
2024-11-20 19:52:49,303 - INFO - 
Configuration s6_n218 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003412585211946685",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n218",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n218/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.886621
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.46e-06
2024-11-20 19:52:49,303 - INFO - 
Starting training for config s6_n666:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n666/checkpoint.bin
2024-11-20 19:52:49,303 - INFO - Running command: ./train_gpt2cu -l 0.00034027257651389703 -o hyperband_runs_20241120_172038/run_s6_n666 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n666/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:53:02,075 - INFO - Training completed for config s6_n666:
  Training time: 0:00:12
  Final validation loss: 10.886681
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.46e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n666/checkpoint.bin
2024-11-20 19:53:02,075 - INFO - 
Configuration s6_n666 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00034027257651389703",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n666",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n666/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.886681
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.46e-06
2024-11-20 19:53:02,076 - INFO - 
Starting training for config s6_n680:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n680/checkpoint.bin
2024-11-20 19:53:02,076 - INFO - Running command: ./train_gpt2cu -l 0.00033916528330383026 -o hyperband_runs_20241120_172038/run_s6_n680 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n680/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:53:13,137 - INFO - Training completed for config s6_n680:
  Training time: 0:00:11
  Final validation loss: 10.886774
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.45e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n680/checkpoint.bin
2024-11-20 19:53:13,137 - INFO - 
Configuration s6_n680 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00033916528330383026",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n680",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n680/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.886774
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.45e-06
2024-11-20 19:53:13,138 - INFO - 
Starting training for config s6_n170:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n170/checkpoint.bin
2024-11-20 19:53:13,138 - INFO - Running command: ./train_gpt2cu -l 0.0003338803294642336 -o hyperband_runs_20241120_172038/run_s6_n170 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n170/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:53:24,194 - INFO - Training completed for config s6_n170:
  Training time: 0:00:11
  Final validation loss: 10.887151
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.43e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n170/checkpoint.bin
2024-11-20 19:53:24,194 - INFO - 
Configuration s6_n170 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003338803294642336",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n170",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n170/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.887151
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.43e-06
2024-11-20 19:53:24,194 - INFO - 
Starting training for config s6_n344:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n344/checkpoint.bin
2024-11-20 19:53:24,194 - INFO - Running command: ./train_gpt2cu -l 0.0003322864821178662 -o hyperband_runs_20241120_172038/run_s6_n344 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n344/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:53:36,425 - INFO - Training completed for config s6_n344:
  Training time: 0:00:12
  Final validation loss: 10.887277
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.42e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n344/checkpoint.bin
2024-11-20 19:53:36,426 - INFO - 
Configuration s6_n344 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003322864821178662",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n344",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n344/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.887277
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.42e-06
2024-11-20 19:53:36,426 - INFO - 
Starting training for config s6_n45:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n45/checkpoint.bin
2024-11-20 19:53:36,426 - INFO - Running command: ./train_gpt2cu -l 0.0003320422942338955 -o hyperband_runs_20241120_172038/run_s6_n45 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n45/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:53:49,179 - INFO - Training completed for config s6_n45:
  Training time: 0:00:12
  Final validation loss: 10.887290
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.42e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n45/checkpoint.bin
2024-11-20 19:53:49,179 - INFO - 
Configuration s6_n45 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003320422942338955",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n45",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n45/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.887290
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.42e-06
2024-11-20 19:53:49,179 - INFO - 
Starting training for config s6_n407:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n407/checkpoint.bin
2024-11-20 19:53:49,179 - INFO - Running command: ./train_gpt2cu -l 0.00033122926843914244 -o hyperband_runs_20241120_172038/run_s6_n407 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n407/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:54:00,233 - INFO - Training completed for config s6_n407:
  Training time: 0:00:11
  Final validation loss: 10.887346
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.42e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n407/checkpoint.bin
2024-11-20 19:54:00,234 - INFO - 
Configuration s6_n407 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00033122926843914244",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n407",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n407/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.887346
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.42e-06
2024-11-20 19:54:00,234 - INFO - 
Starting training for config s6_n429:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n429/checkpoint.bin
2024-11-20 19:54:00,234 - INFO - Running command: ./train_gpt2cu -l 0.0003309639900497035 -o hyperband_runs_20241120_172038/run_s6_n429 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n429/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:54:11,287 - INFO - Training completed for config s6_n429:
  Training time: 0:00:11
  Final validation loss: 10.887364
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.42e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n429/checkpoint.bin
2024-11-20 19:54:11,287 - INFO - 
Configuration s6_n429 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003309639900497035",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n429",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n429/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.887364
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.42e-06
2024-11-20 19:54:11,288 - INFO - 
Starting training for config s6_n461:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n461/checkpoint.bin
2024-11-20 19:54:11,288 - INFO - Running command: ./train_gpt2cu -l 0.0003298083299883571 -o hyperband_runs_20241120_172038/run_s6_n461 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n461/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:54:23,495 - INFO - Training completed for config s6_n461:
  Training time: 0:00:12
  Final validation loss: 10.887460
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.41e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n461/checkpoint.bin
2024-11-20 19:54:23,495 - INFO - 
Configuration s6_n461 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003298083299883571",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n461",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n461/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.887460
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.41e-06
2024-11-20 19:54:23,495 - INFO - 
Starting training for config s6_n50:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n50/checkpoint.bin
2024-11-20 19:54:23,495 - INFO - Running command: ./train_gpt2cu -l 0.00032463130841415454 -o hyperband_runs_20241120_172038/run_s6_n50 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n50/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:54:36,272 - INFO - Training completed for config s6_n50:
  Training time: 0:00:12
  Final validation loss: 10.887834
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.39e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n50/checkpoint.bin
2024-11-20 19:54:36,272 - INFO - 
Configuration s6_n50 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00032463130841415454",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n50",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n50/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.887834
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.39e-06
2024-11-20 19:54:36,272 - INFO - 
Starting training for config s6_n689:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n689/checkpoint.bin
2024-11-20 19:54:36,272 - INFO - Running command: ./train_gpt2cu -l 0.0003215587431981187 -o hyperband_runs_20241120_172038/run_s6_n689 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n689/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:54:47,354 - INFO - Training completed for config s6_n689:
  Training time: 0:00:11
  Final validation loss: 10.888071
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.38e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n689/checkpoint.bin
2024-11-20 19:54:47,354 - INFO - 
Configuration s6_n689 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003215587431981187",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n689",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n689/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.888071
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.38e-06
2024-11-20 19:54:47,354 - INFO - 
Starting training for config s6_n268:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n268/checkpoint.bin
2024-11-20 19:54:47,354 - INFO - Running command: ./train_gpt2cu -l 0.0003144900106004761 -o hyperband_runs_20241120_172038/run_s6_n268 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n268/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:54:58,423 - INFO - Training completed for config s6_n268:
  Training time: 0:00:11
  Final validation loss: 10.888588
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.35e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n268/checkpoint.bin
2024-11-20 19:54:58,423 - INFO - 
Configuration s6_n268 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003144900106004761",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n268",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n268/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.888588
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.35e-06
2024-11-20 19:54:58,423 - INFO - 
Starting training for config s6_n190:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n190/checkpoint.bin
2024-11-20 19:54:58,423 - INFO - Running command: ./train_gpt2cu -l 0.00031228025979209253 -o hyperband_runs_20241120_172038/run_s6_n190 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n190/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:55:10,592 - INFO - Training completed for config s6_n190:
  Training time: 0:00:12
  Final validation loss: 10.888752
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.34e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n190/checkpoint.bin
2024-11-20 19:55:10,592 - INFO - 
Configuration s6_n190 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00031228025979209253",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n190",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n190/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.888752
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.34e-06
2024-11-20 19:55:10,592 - INFO - 
Starting training for config s6_n168:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n168/checkpoint.bin
2024-11-20 19:55:10,592 - INFO - Running command: ./train_gpt2cu -l 0.0003117980439479601 -o hyperband_runs_20241120_172038/run_s6_n168 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n168/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:55:23,378 - INFO - Training completed for config s6_n168:
  Training time: 0:00:12
  Final validation loss: 10.888792
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.34e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n168/checkpoint.bin
2024-11-20 19:55:23,378 - INFO - 
Configuration s6_n168 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003117980439479601",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n168",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n168/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.888792
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.34e-06
2024-11-20 19:55:23,378 - INFO - 
Starting training for config s6_n579:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n579/checkpoint.bin
2024-11-20 19:55:23,378 - INFO - Running command: ./train_gpt2cu -l 0.00031134527897074547 -o hyperband_runs_20241120_172038/run_s6_n579 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n579/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:55:34,449 - INFO - Training completed for config s6_n579:
  Training time: 0:00:11
  Final validation loss: 10.888813
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.33e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n579/checkpoint.bin
2024-11-20 19:55:34,449 - INFO - 
Configuration s6_n579 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00031134527897074547",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n579",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n579/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.888813
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.33e-06
2024-11-20 19:55:34,449 - INFO - 
Starting training for config s6_n398:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n398/checkpoint.bin
2024-11-20 19:55:34,449 - INFO - Running command: ./train_gpt2cu -l 0.0003102432609873989 -o hyperband_runs_20241120_172038/run_s6_n398 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n398/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:55:45,510 - INFO - Training completed for config s6_n398:
  Training time: 0:00:11
  Final validation loss: 10.888898
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.33e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n398/checkpoint.bin
2024-11-20 19:55:45,510 - INFO - 
Configuration s6_n398 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003102432609873989",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n398",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n398/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.888898
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.33e-06
2024-11-20 19:55:45,510 - INFO - 
Starting training for config s6_n148:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n148/checkpoint.bin
2024-11-20 19:55:45,511 - INFO - Running command: ./train_gpt2cu -l 0.00030713444107260913 -o hyperband_runs_20241120_172038/run_s6_n148 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n148/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:55:57,703 - INFO - Training completed for config s6_n148:
  Training time: 0:00:12
  Final validation loss: 10.889128
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.32e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n148/checkpoint.bin
2024-11-20 19:55:57,703 - INFO - 
Configuration s6_n148 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00030713444107260913",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n148",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n148/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.889128
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.32e-06
2024-11-20 19:55:57,703 - INFO - 
Starting training for config s6_n457:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n457/checkpoint.bin
2024-11-20 19:55:57,703 - INFO - Running command: ./train_gpt2cu -l 0.00030734427374176496 -o hyperband_runs_20241120_172038/run_s6_n457 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n457/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:56:10,492 - INFO - Training completed for config s6_n457:
  Training time: 0:00:12
  Final validation loss: 10.889116
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.32e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n457/checkpoint.bin
2024-11-20 19:56:10,492 - INFO - 
Configuration s6_n457 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00030734427374176496",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n457",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n457/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.889116
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.32e-06
2024-11-20 19:56:10,492 - INFO - 
Starting training for config s6_n479:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n479/checkpoint.bin
2024-11-20 19:56:10,493 - INFO - Running command: ./train_gpt2cu -l 0.0003052601124736334 -o hyperband_runs_20241120_172038/run_s6_n479 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n479/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:56:21,555 - INFO - Training completed for config s6_n479:
  Training time: 0:00:11
  Final validation loss: 10.889277
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.31e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n479/checkpoint.bin
2024-11-20 19:56:21,555 - INFO - 
Configuration s6_n479 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003052601124736334",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n479",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n479/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.889277
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.31e-06
2024-11-20 19:56:21,555 - INFO - 
Starting training for config s6_n714:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n714/checkpoint.bin
2024-11-20 19:56:21,556 - INFO - Running command: ./train_gpt2cu -l 0.000303366850837294 -o hyperband_runs_20241120_172038/run_s6_n714 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n714/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:56:32,612 - INFO - Training completed for config s6_n714:
  Training time: 0:00:11
  Final validation loss: 10.889414
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.30e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n714/checkpoint.bin
2024-11-20 19:56:32,612 - INFO - 
Configuration s6_n714 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000303366850837294",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n714",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n714/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.889414
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.30e-06
2024-11-20 19:56:32,612 - INFO - 
Starting training for config s6_n402:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n402/checkpoint.bin
2024-11-20 19:56:32,612 - INFO - Running command: ./train_gpt2cu -l 0.0003034703728821797 -o hyperband_runs_20241120_172038/run_s6_n402 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n402/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:56:44,802 - INFO - Training completed for config s6_n402:
  Training time: 0:00:12
  Final validation loss: 10.889394
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.30e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n402/checkpoint.bin
2024-11-20 19:56:44,803 - INFO - 
Configuration s6_n402 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003034703728821797",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n402",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n402/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.889394
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.30e-06
2024-11-20 19:56:44,803 - INFO - 
Starting training for config s6_n175:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n175/checkpoint.bin
2024-11-20 19:56:44,803 - INFO - Running command: ./train_gpt2cu -l 0.0003002626915241805 -o hyperband_runs_20241120_172038/run_s6_n175 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n175/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:56:57,595 - INFO - Training completed for config s6_n175:
  Training time: 0:00:12
  Final validation loss: 10.889619
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.29e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n175/checkpoint.bin
2024-11-20 19:56:57,595 - INFO - 
Configuration s6_n175 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003002626915241805",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n175",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n175/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.889619
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.29e-06
2024-11-20 19:56:57,596 - INFO - 
Starting training for config s6_n166:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n166/checkpoint.bin
2024-11-20 19:56:57,596 - INFO - Running command: ./train_gpt2cu -l 0.0003002284855912264 -o hyperband_runs_20241120_172038/run_s6_n166 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n166/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:57:08,656 - INFO - Training completed for config s6_n166:
  Training time: 0:00:11
  Final validation loss: 10.889624
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.29e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n166/checkpoint.bin
2024-11-20 19:57:08,656 - INFO - 
Configuration s6_n166 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003002284855912264",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n166",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n166/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.889624
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.29e-06
2024-11-20 19:57:08,656 - INFO - 
Starting training for config s6_n722:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n722/checkpoint.bin
2024-11-20 19:57:08,656 - INFO - Running command: ./train_gpt2cu -l 0.00029966062628708696 -o hyperband_runs_20241120_172038/run_s6_n722 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n722/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:57:19,729 - INFO - Training completed for config s6_n722:
  Training time: 0:00:11
  Final validation loss: 10.889673
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.28e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n722/checkpoint.bin
2024-11-20 19:57:19,729 - INFO - 
Configuration s6_n722 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00029966062628708696",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n722",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n722/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.889673
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.28e-06
2024-11-20 19:57:19,729 - INFO - 
Starting training for config s6_n164:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n164/checkpoint.bin
2024-11-20 19:57:19,729 - INFO - Running command: ./train_gpt2cu -l 0.00029850297884334483 -o hyperband_runs_20241120_172038/run_s6_n164 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n164/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:57:31,903 - INFO - Training completed for config s6_n164:
  Training time: 0:00:12
  Final validation loss: 10.889754
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.28e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n164/checkpoint.bin
2024-11-20 19:57:31,903 - INFO - 
Configuration s6_n164 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00029850297884334483",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n164",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n164/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.889754
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.28e-06
2024-11-20 19:57:31,903 - INFO - 
Starting training for config s6_n349:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n349/checkpoint.bin
2024-11-20 19:57:31,904 - INFO - Running command: ./train_gpt2cu -l 0.000290227094127973 -o hyperband_runs_20241120_172038/run_s6_n349 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n349/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:57:44,695 - INFO - Training completed for config s6_n349:
  Training time: 0:00:12
  Final validation loss: 10.890347
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.24e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n349/checkpoint.bin
2024-11-20 19:57:44,696 - INFO - 
Configuration s6_n349 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000290227094127973",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n349",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n349/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.890347
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.24e-06
2024-11-20 19:57:44,696 - INFO - 
Starting training for config s6_n239:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n239/checkpoint.bin
2024-11-20 19:57:44,696 - INFO - Running command: ./train_gpt2cu -l 0.00028939503137182925 -o hyperband_runs_20241120_172038/run_s6_n239 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n239/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:57:55,757 - INFO - Training completed for config s6_n239:
  Training time: 0:00:11
  Final validation loss: 10.890417
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.24e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n239/checkpoint.bin
2024-11-20 19:57:55,757 - INFO - 
Configuration s6_n239 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00028939503137182925",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n239",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n239/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.890417
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.24e-06
2024-11-20 19:57:55,757 - INFO - 
Starting training for config s6_n244:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n244/checkpoint.bin
2024-11-20 19:57:55,757 - INFO - Running command: ./train_gpt2cu -l 0.0002884967827666835 -o hyperband_runs_20241120_172038/run_s6_n244 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n244/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:58:06,853 - INFO - Training completed for config s6_n244:
  Training time: 0:00:11
  Final validation loss: 10.890480
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.24e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n244/checkpoint.bin
2024-11-20 19:58:06,853 - INFO - 
Configuration s6_n244 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002884967827666835",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n244",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n244/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.890480
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.24e-06
2024-11-20 19:58:06,853 - INFO - 
Starting training for config s6_n546:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n546/checkpoint.bin
2024-11-20 19:58:06,854 - INFO - Running command: ./train_gpt2cu -l 0.00028776902883485405 -o hyperband_runs_20241120_172038/run_s6_n546 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n546/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:58:18,996 - INFO - Training completed for config s6_n546:
  Training time: 0:00:12
  Final validation loss: 10.890540
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.23e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n546/checkpoint.bin
2024-11-20 19:58:18,996 - INFO - 
Configuration s6_n546 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00028776902883485405",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n546",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n546/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.890540
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.23e-06
2024-11-20 19:58:18,996 - INFO - 
Starting training for config s6_n624:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n624/checkpoint.bin
2024-11-20 19:58:18,996 - INFO - Running command: ./train_gpt2cu -l 0.0002870835626005401 -o hyperband_runs_20241120_172038/run_s6_n624 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n624/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:58:31,796 - INFO - Training completed for config s6_n624:
  Training time: 0:00:12
  Final validation loss: 10.890592
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.23e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n624/checkpoint.bin
2024-11-20 19:58:31,796 - INFO - 
Configuration s6_n624 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002870835626005401",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n624",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n624/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.890592
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.23e-06
2024-11-20 19:58:31,796 - INFO - 
Starting training for config s6_n399:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n399/checkpoint.bin
2024-11-20 19:58:31,797 - INFO - Running command: ./train_gpt2cu -l 0.00028722599305629486 -o hyperband_runs_20241120_172038/run_s6_n399 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n399/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:58:42,866 - INFO - Training completed for config s6_n399:
  Training time: 0:00:11
  Final validation loss: 10.890570
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.23e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n399/checkpoint.bin
2024-11-20 19:58:42,866 - INFO - 
Configuration s6_n399 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00028722599305629486",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n399",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n399/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.890570
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.23e-06
2024-11-20 19:58:42,866 - INFO - 
Starting training for config s6_n43:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n43/checkpoint.bin
2024-11-20 19:58:42,867 - INFO - Running command: ./train_gpt2cu -l 0.00028564306755181964 -o hyperband_runs_20241120_172038/run_s6_n43 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n43/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:58:53,947 - INFO - Training completed for config s6_n43:
  Training time: 0:00:11
  Final validation loss: 10.890682
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.22e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n43/checkpoint.bin
2024-11-20 19:58:53,947 - INFO - 
Configuration s6_n43 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00028564306755181964",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n43",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n43/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.890682
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.22e-06
2024-11-20 19:58:53,947 - INFO - 
Starting training for config s6_n12:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n12/checkpoint.bin
2024-11-20 19:58:53,948 - INFO - Running command: ./train_gpt2cu -l 0.00028311239031055744 -o hyperband_runs_20241120_172038/run_s6_n12 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n12/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:59:06,109 - INFO - Training completed for config s6_n12:
  Training time: 0:00:12
  Final validation loss: 10.890880
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.21e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n12/checkpoint.bin
2024-11-20 19:59:06,109 - INFO - 
Configuration s6_n12 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00028311239031055744",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n12",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n12/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.890880
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.21e-06
2024-11-20 19:59:06,109 - INFO - 
Starting training for config s6_n464:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n464/checkpoint.bin
2024-11-20 19:59:06,109 - INFO - Running command: ./train_gpt2cu -l 0.00028254598780360767 -o hyperband_runs_20241120_172038/run_s6_n464 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n464/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:59:18,908 - INFO - Training completed for config s6_n464:
  Training time: 0:00:12
  Final validation loss: 10.890917
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.21e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n464/checkpoint.bin
2024-11-20 19:59:18,909 - INFO - 
Configuration s6_n464 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00028254598780360767",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n464",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n464/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.890917
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.21e-06
2024-11-20 19:59:18,909 - INFO - 
Starting training for config s6_n693:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n693/checkpoint.bin
2024-11-20 19:59:18,909 - INFO - Running command: ./train_gpt2cu -l 0.00028270003811761056 -o hyperband_runs_20241120_172038/run_s6_n693 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n693/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:59:29,968 - INFO - Training completed for config s6_n693:
  Training time: 0:00:11
  Final validation loss: 10.890902
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.21e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n693/checkpoint.bin
2024-11-20 19:59:29,968 - INFO - 
Configuration s6_n693 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00028270003811761056",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n693",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n693/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.890902
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.21e-06
2024-11-20 19:59:29,968 - INFO - 
Starting training for config s6_n312:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n312/checkpoint.bin
2024-11-20 19:59:29,969 - INFO - Running command: ./train_gpt2cu -l 0.00028043710204923974 -o hyperband_runs_20241120_172038/run_s6_n312 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n312/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:59:41,028 - INFO - Training completed for config s6_n312:
  Training time: 0:00:11
  Final validation loss: 10.891078
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.20e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n312/checkpoint.bin
2024-11-20 19:59:41,028 - INFO - 
Configuration s6_n312 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00028043710204923974",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n312",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n312/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.891078
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.20e-06
2024-11-20 19:59:41,028 - INFO - 
Starting training for config s6_n195:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n195/checkpoint.bin
2024-11-20 19:59:41,028 - INFO - Running command: ./train_gpt2cu -l 0.0002802340153113612 -o hyperband_runs_20241120_172038/run_s6_n195 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n195/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 19:59:53,214 - INFO - Training completed for config s6_n195:
  Training time: 0:00:12
  Final validation loss: 10.891081
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.20e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n195/checkpoint.bin
2024-11-20 19:59:53,214 - INFO - 
Configuration s6_n195 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002802340153113612",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n195",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n195/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.891081
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.20e-06
2024-11-20 19:59:53,215 - INFO - 
Starting training for config s6_n248:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n248/checkpoint.bin
2024-11-20 19:59:53,215 - INFO - Running command: ./train_gpt2cu -l 0.0002791246587083738 -o hyperband_runs_20241120_172038/run_s6_n248 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n248/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:00:06,013 - INFO - Training completed for config s6_n248:
  Training time: 0:00:12
  Final validation loss: 10.891167
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.20e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n248/checkpoint.bin
2024-11-20 20:00:06,013 - INFO - 
Configuration s6_n248 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002791246587083738",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n248",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n248/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.891167
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.20e-06
2024-11-20 20:00:06,013 - INFO - 
Starting training for config s6_n128:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n128/checkpoint.bin
2024-11-20 20:00:06,013 - INFO - Running command: ./train_gpt2cu -l 0.000278819280235079 -o hyperband_runs_20241120_172038/run_s6_n128 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n128/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:00:17,027 - INFO - Training completed for config s6_n128:
  Training time: 0:00:11
  Final validation loss: 10.891193
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.19e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n128/checkpoint.bin
2024-11-20 20:00:17,028 - INFO - 
Configuration s6_n128 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000278819280235079",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n128",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n128/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.891193
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.19e-06
2024-11-20 20:00:17,028 - INFO - 
Starting training for config s6_n40:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n40/checkpoint.bin
2024-11-20 20:00:17,028 - INFO - Running command: ./train_gpt2cu -l 0.00027860859556582063 -o hyperband_runs_20241120_172038/run_s6_n40 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n40/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:00:28,069 - INFO - Training completed for config s6_n40:
  Training time: 0:00:11
  Final validation loss: 10.891199
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.19e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n40/checkpoint.bin
2024-11-20 20:00:28,069 - INFO - 
Configuration s6_n40 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00027860859556582063",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n40",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n40/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.891199
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.19e-06
2024-11-20 20:00:28,069 - INFO - 
Starting training for config s6_n310:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n310/checkpoint.bin
2024-11-20 20:00:28,069 - INFO - Running command: ./train_gpt2cu -l 0.00027552934665632577 -o hyperband_runs_20241120_172038/run_s6_n310 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n310/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:00:40,323 - INFO - Training completed for config s6_n310:
  Training time: 0:00:12
  Final validation loss: 10.891428
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.18e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n310/checkpoint.bin
2024-11-20 20:00:40,323 - INFO - 
Configuration s6_n310 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00027552934665632577",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n310",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n310/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.891428
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.18e-06
2024-11-20 20:00:40,323 - INFO - 
Starting training for config s6_n26:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n26/checkpoint.bin
2024-11-20 20:00:40,323 - INFO - Running command: ./train_gpt2cu -l 0.000274180833397406 -o hyperband_runs_20241120_172038/run_s6_n26 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n26/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:00:53,106 - INFO - Training completed for config s6_n26:
  Training time: 0:00:12
  Final validation loss: 10.891527
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.18e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n26/checkpoint.bin
2024-11-20 20:00:53,106 - INFO - 
Configuration s6_n26 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000274180833397406",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n26",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n26/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.891527
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.18e-06
2024-11-20 20:00:53,106 - INFO - 
Starting training for config s6_n156:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n156/checkpoint.bin
2024-11-20 20:00:53,106 - INFO - Running command: ./train_gpt2cu -l 0.0002729555936444007 -o hyperband_runs_20241120_172038/run_s6_n156 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n156/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:01:04,178 - INFO - Training completed for config s6_n156:
  Training time: 0:00:11
  Final validation loss: 10.891619
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.17e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n156/checkpoint.bin
2024-11-20 20:01:04,178 - INFO - 
Configuration s6_n156 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002729555936444007",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n156",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n156/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.891619
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.17e-06
2024-11-20 20:01:04,178 - INFO - 
Starting training for config s6_n564:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n564/checkpoint.bin
2024-11-20 20:01:04,178 - INFO - Running command: ./train_gpt2cu -l 0.0002712212807866951 -o hyperband_runs_20241120_172038/run_s6_n564 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n564/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:01:15,233 - INFO - Training completed for config s6_n564:
  Training time: 0:00:11
  Final validation loss: 10.891739
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.16e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n564/checkpoint.bin
2024-11-20 20:01:15,234 - INFO - 
Configuration s6_n564 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002712212807866951",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n564",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n564/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.891739
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.16e-06
2024-11-20 20:01:15,234 - INFO - 
Starting training for config s6_n5:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n5/checkpoint.bin
2024-11-20 20:01:15,234 - INFO - Running command: ./train_gpt2cu -l 0.0002710810617150556 -o hyperband_runs_20241120_172038/run_s6_n5 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n5/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:01:26,791 - INFO - Training completed for config s6_n5:
  Training time: 0:00:11
  Final validation loss: 10.891738
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.16e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n5/checkpoint.bin
2024-11-20 20:01:26,792 - INFO - 
Configuration s6_n5 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002710810617150556",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n5",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n5/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.891738
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.16e-06
2024-11-20 20:01:26,792 - INFO - 
Starting training for config s6_n724:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n724/checkpoint.bin
2024-11-20 20:01:26,792 - INFO - Running command: ./train_gpt2cu -l 0.00027035664094511645 -o hyperband_runs_20241120_172038/run_s6_n724 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n724/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:01:40,391 - INFO - Training completed for config s6_n724:
  Training time: 0:00:13
  Final validation loss: 10.891798
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.16e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n724/checkpoint.bin
2024-11-20 20:01:40,391 - INFO - 
Configuration s6_n724 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00027035664094511645",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n724",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n724/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:13
  Validation Loss: 10.891798
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.16e-06
2024-11-20 20:01:40,391 - INFO - 
Starting training for config s6_n184:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n184/checkpoint.bin
2024-11-20 20:01:40,391 - INFO - Running command: ./train_gpt2cu -l 0.0002693407255441648 -o hyperband_runs_20241120_172038/run_s6_n184 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n184/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:01:52,314 - INFO - Training completed for config s6_n184:
  Training time: 0:00:11
  Final validation loss: 10.891880
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.15e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n184/checkpoint.bin
2024-11-20 20:01:52,314 - INFO - 
Configuration s6_n184 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002693407255441648",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n184",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n184/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.891880
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.15e-06
2024-11-20 20:01:52,315 - INFO - 
Starting training for config s6_n696:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n696/checkpoint.bin
2024-11-20 20:01:52,315 - INFO - Running command: ./train_gpt2cu -l 0.00026874093015523577 -o hyperband_runs_20241120_172038/run_s6_n696 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n696/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:02:03,378 - INFO - Training completed for config s6_n696:
  Training time: 0:00:11
  Final validation loss: 10.891917
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.15e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n696/checkpoint.bin
2024-11-20 20:02:03,378 - INFO - 
Configuration s6_n696 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00026874093015523577",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n696",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n696/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.891917
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.15e-06
2024-11-20 20:02:03,378 - INFO - 
Starting training for config s6_n346:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n346/checkpoint.bin
2024-11-20 20:02:03,378 - INFO - Running command: ./train_gpt2cu -l 0.0002670741282487934 -o hyperband_runs_20241120_172038/run_s6_n346 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n346/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:02:14,419 - INFO - Training completed for config s6_n346:
  Training time: 0:00:11
  Final validation loss: 10.892042
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.14e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n346/checkpoint.bin
2024-11-20 20:02:14,419 - INFO - 
Configuration s6_n346 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002670741282487934",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n346",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n346/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.892042
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.14e-06
2024-11-20 20:02:14,419 - INFO - 
Starting training for config s6_n208:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n208/checkpoint.bin
2024-11-20 20:02:14,419 - INFO - Running command: ./train_gpt2cu -l 0.00026333300463007446 -o hyperband_runs_20241120_172038/run_s6_n208 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n208/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:02:25,473 - INFO - Training completed for config s6_n208:
  Training time: 0:00:11
  Final validation loss: 10.892312
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.13e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n208/checkpoint.bin
2024-11-20 20:02:25,473 - INFO - 
Configuration s6_n208 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00026333300463007446",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n208",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n208/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.892312
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.13e-06
2024-11-20 20:02:25,473 - INFO - 
Starting training for config s6_n104:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n104/checkpoint.bin
2024-11-20 20:02:25,473 - INFO - Running command: ./train_gpt2cu -l 0.0002630435518795737 -o hyperband_runs_20241120_172038/run_s6_n104 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n104/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:02:38,070 - INFO - Training completed for config s6_n104:
  Training time: 0:00:12
  Final validation loss: 10.892317
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.13e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n104/checkpoint.bin
2024-11-20 20:02:38,071 - INFO - 
Configuration s6_n104 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002630435518795737",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n104",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n104/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.892317
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.13e-06
2024-11-20 20:02:38,071 - INFO - 
Starting training for config s6_n450:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n450/checkpoint.bin
2024-11-20 20:02:38,071 - INFO - Running command: ./train_gpt2cu -l 0.0002611813617550704 -o hyperband_runs_20241120_172038/run_s6_n450 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n450/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:02:51,690 - INFO - Training completed for config s6_n450:
  Training time: 0:00:13
  Final validation loss: 10.892467
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.12e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n450/checkpoint.bin
2024-11-20 20:02:51,690 - INFO - 
Configuration s6_n450 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002611813617550704",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n450",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n450/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:13
  Validation Loss: 10.892467
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.12e-06
2024-11-20 20:02:51,690 - INFO - 
Starting training for config s6_n487:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n487/checkpoint.bin
2024-11-20 20:02:51,691 - INFO - Running command: ./train_gpt2cu -l 0.00026011422853031846 -o hyperband_runs_20241120_172038/run_s6_n487 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n487/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:03:03,516 - INFO - Training completed for config s6_n487:
  Training time: 0:00:11
  Final validation loss: 10.892550
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.11e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n487/checkpoint.bin
2024-11-20 20:03:03,516 - INFO - 
Configuration s6_n487 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00026011422853031846",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n487",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n487/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.892550
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.11e-06
2024-11-20 20:03:03,517 - INFO - 
Starting training for config s6_n215:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n215/checkpoint.bin
2024-11-20 20:03:03,517 - INFO - Running command: ./train_gpt2cu -l 0.000259642775094729 -o hyperband_runs_20241120_172038/run_s6_n215 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n215/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:03:14,572 - INFO - Training completed for config s6_n215:
  Training time: 0:00:11
  Final validation loss: 10.892575
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.11e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n215/checkpoint.bin
2024-11-20 20:03:14,572 - INFO - 
Configuration s6_n215 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000259642775094729",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n215",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n215/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.892575
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.11e-06
2024-11-20 20:03:14,572 - INFO - 
Starting training for config s6_n269:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n269/checkpoint.bin
2024-11-20 20:03:14,573 - INFO - Running command: ./train_gpt2cu -l 0.00025857628608913144 -o hyperband_runs_20241120_172038/run_s6_n269 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n269/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:03:25,667 - INFO - Training completed for config s6_n269:
  Training time: 0:00:11
  Final validation loss: 10.892673
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.11e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n269/checkpoint.bin
2024-11-20 20:03:25,668 - INFO - 
Configuration s6_n269 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00025857628608913144",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n269",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n269/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.892673
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.11e-06
2024-11-20 20:03:25,668 - INFO - 
Starting training for config s6_n253:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n253/checkpoint.bin
2024-11-20 20:03:25,668 - INFO - Running command: ./train_gpt2cu -l 0.000257224019894055 -o hyperband_runs_20241120_172038/run_s6_n253 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n253/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:03:36,724 - INFO - Training completed for config s6_n253:
  Training time: 0:00:11
  Final validation loss: 10.892764
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.10e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n253/checkpoint.bin
2024-11-20 20:03:36,724 - INFO - 
Configuration s6_n253 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000257224019894055",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n253",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n253/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.892764
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-06
2024-11-20 20:03:36,724 - INFO - 
Starting training for config s6_n435:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n435/checkpoint.bin
2024-11-20 20:03:36,724 - INFO - Running command: ./train_gpt2cu -l 0.0002565539092773649 -o hyperband_runs_20241120_172038/run_s6_n435 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n435/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:03:49,241 - INFO - Training completed for config s6_n435:
  Training time: 0:00:12
  Final validation loss: 10.892807
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.10e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n435/checkpoint.bin
2024-11-20 20:03:49,242 - INFO - 
Configuration s6_n435 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002565539092773649",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n435",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n435/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.892807
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-06
2024-11-20 20:03:49,242 - INFO - 
Starting training for config s6_n633:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n633/checkpoint.bin
2024-11-20 20:03:49,242 - INFO - Running command: ./train_gpt2cu -l 0.00025661277038928684 -o hyperband_runs_20241120_172038/run_s6_n633 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n633/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:04:02,816 - INFO - Training completed for config s6_n633:
  Training time: 0:00:13
  Final validation loss: 10.892805
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.10e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n633/checkpoint.bin
2024-11-20 20:04:02,817 - INFO - 
Configuration s6_n633 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00025661277038928684",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n633",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n633/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:13
  Validation Loss: 10.892805
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-06
2024-11-20 20:04:02,817 - INFO - 
Starting training for config s6_n390:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n390/checkpoint.bin
2024-11-20 20:04:02,817 - INFO - Running command: ./train_gpt2cu -l 0.0002547555747597312 -o hyperband_runs_20241120_172038/run_s6_n390 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n390/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:04:14,736 - INFO - Training completed for config s6_n390:
  Training time: 0:00:11
  Final validation loss: 10.892940
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.09e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n390/checkpoint.bin
2024-11-20 20:04:14,736 - INFO - 
Configuration s6_n390 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002547555747597312",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n390",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n390/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.892940
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.09e-06
2024-11-20 20:04:14,736 - INFO - 
Starting training for config s6_n569:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n569/checkpoint.bin
2024-11-20 20:04:14,736 - INFO - Running command: ./train_gpt2cu -l 0.0002543057599428018 -o hyperband_runs_20241120_172038/run_s6_n569 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n569/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:04:25,793 - INFO - Training completed for config s6_n569:
  Training time: 0:00:11
  Final validation loss: 10.892973
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.09e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n569/checkpoint.bin
2024-11-20 20:04:25,793 - INFO - 
Configuration s6_n569 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002543057599428018",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n569",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n569/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.892973
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.09e-06
2024-11-20 20:04:25,794 - INFO - 
Starting training for config s6_n395:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n395/checkpoint.bin
2024-11-20 20:04:25,794 - INFO - Running command: ./train_gpt2cu -l 0.0002483092861627605 -o hyperband_runs_20241120_172038/run_s6_n395 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n395/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:04:36,847 - INFO - Training completed for config s6_n395:
  Training time: 0:00:11
  Final validation loss: 10.893419
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.06e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n395/checkpoint.bin
2024-11-20 20:04:36,847 - INFO - 
Configuration s6_n395 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002483092861627605",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n395",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n395/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.893419
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.06e-06
2024-11-20 20:04:36,847 - INFO - 
Starting training for config s6_n302:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n302/checkpoint.bin
2024-11-20 20:04:36,847 - INFO - Running command: ./train_gpt2cu -l 0.0002480162625220691 -o hyperband_runs_20241120_172038/run_s6_n302 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n302/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:04:47,933 - INFO - Training completed for config s6_n302:
  Training time: 0:00:11
  Final validation loss: 10.893450
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.06e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n302/checkpoint.bin
2024-11-20 20:04:47,933 - INFO - 
Configuration s6_n302 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002480162625220691",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n302",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n302/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.893450
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.06e-06
2024-11-20 20:04:47,933 - INFO - 
Starting training for config s6_n335:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n335/checkpoint.bin
2024-11-20 20:04:47,933 - INFO - Running command: ./train_gpt2cu -l 0.000246997336923326 -o hyperband_runs_20241120_172038/run_s6_n335 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n335/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:05:00,427 - INFO - Training completed for config s6_n335:
  Training time: 0:00:12
  Final validation loss: 10.893521
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.06e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n335/checkpoint.bin
2024-11-20 20:05:00,427 - INFO - 
Configuration s6_n335 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.000246997336923326",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n335",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n335/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.893521
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.06e-06
2024-11-20 20:05:00,427 - INFO - 
Starting training for config s6_n571:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n571/checkpoint.bin
2024-11-20 20:05:00,427 - INFO - Running command: ./train_gpt2cu -l 0.0002457066908035236 -o hyperband_runs_20241120_172038/run_s6_n571 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n571/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:05:12,723 - INFO - Training completed for config s6_n571:
  Training time: 0:00:12
  Final validation loss: 10.893622
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.05e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n571/checkpoint.bin
2024-11-20 20:05:12,723 - INFO - 
Configuration s6_n571 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002457066908035236",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n571",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n571/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.893622
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.05e-06
2024-11-20 20:05:12,723 - INFO - 
Starting training for config s6_n125:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n125/checkpoint.bin
2024-11-20 20:05:12,723 - INFO - Running command: ./train_gpt2cu -l 0.0002446362076671156 -o hyperband_runs_20241120_172038/run_s6_n125 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n125/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:05:26,309 - INFO - Training completed for config s6_n125:
  Training time: 0:00:13
  Final validation loss: 10.893702
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.05e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n125/checkpoint.bin
2024-11-20 20:05:26,310 - INFO - 
Configuration s6_n125 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002446362076671156",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n125",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n125/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:13
  Validation Loss: 10.893702
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.05e-06
2024-11-20 20:05:26,310 - INFO - 
Starting training for config s6_n49:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n49/checkpoint.bin
2024-11-20 20:05:26,310 - INFO - Running command: ./train_gpt2cu -l 0.00024087829793111455 -o hyperband_runs_20241120_172038/run_s6_n49 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n49/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:05:37,368 - INFO - Training completed for config s6_n49:
  Training time: 0:00:11
  Final validation loss: 10.893976
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.03e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n49/checkpoint.bin
2024-11-20 20:05:37,368 - INFO - 
Configuration s6_n49 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00024087829793111455",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n49",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n49/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.893976
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.03e-06
2024-11-20 20:05:37,368 - INFO - 
Starting training for config s6_n695:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n695/checkpoint.bin
2024-11-20 20:05:37,368 - INFO - Running command: ./train_gpt2cu -l 0.00023770609386476307 -o hyperband_runs_20241120_172038/run_s6_n695 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n695/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:05:48,434 - INFO - Training completed for config s6_n695:
  Training time: 0:00:11
  Final validation loss: 10.894211
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.02e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n695/checkpoint.bin
2024-11-20 20:05:48,435 - INFO - 
Configuration s6_n695 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00023770609386476307",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n695",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n695/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.894211
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-06
2024-11-20 20:05:48,435 - INFO - 
Starting training for config s6_n386:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n386/checkpoint.bin
2024-11-20 20:05:48,435 - INFO - Running command: ./train_gpt2cu -l 0.0002371423837007242 -o hyperband_runs_20241120_172038/run_s6_n386 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n386/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:05:59,536 - INFO - Training completed for config s6_n386:
  Training time: 0:00:11
  Final validation loss: 10.894243
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.02e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n386/checkpoint.bin
2024-11-20 20:05:59,536 - INFO - 
Configuration s6_n386 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002371423837007242",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n386",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n386/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.894243
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-06
2024-11-20 20:05:59,536 - INFO - 
Starting training for config s6_n630:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n630/checkpoint.bin
2024-11-20 20:05:59,536 - INFO - Running command: ./train_gpt2cu -l 0.00023223131815253126 -o hyperband_runs_20241120_172038/run_s6_n630 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n630/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:06:11,088 - INFO - Training completed for config s6_n630:
  Training time: 0:00:11
  Final validation loss: 10.894604
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.95e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n630/checkpoint.bin
2024-11-20 20:06:11,088 - INFO - 
Configuration s6_n630 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00023223131815253126",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n630",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n630/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.894604
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.95e-07
2024-11-20 20:06:11,088 - INFO - 
Starting training for config s6_n430:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n430/checkpoint.bin
2024-11-20 20:06:11,088 - INFO - Running command: ./train_gpt2cu -l 0.0002296818293942336 -o hyperband_runs_20241120_172038/run_s6_n430 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n430/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:06:23,865 - INFO - Training completed for config s6_n430:
  Training time: 0:00:12
  Final validation loss: 10.894786
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.84e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n430/checkpoint.bin
2024-11-20 20:06:23,865 - INFO - 
Configuration s6_n430 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002296818293942336",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n430",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n430/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.894786
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.84e-07
2024-11-20 20:06:23,865 - INFO - 
Starting training for config s6_n505:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n505/checkpoint.bin
2024-11-20 20:06:23,865 - INFO - Running command: ./train_gpt2cu -l 0.0002292244764947636 -o hyperband_runs_20241120_172038/run_s6_n505 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n505/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:06:34,930 - INFO - Training completed for config s6_n505:
  Training time: 0:00:11
  Final validation loss: 10.894824
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.82e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n505/checkpoint.bin
2024-11-20 20:06:34,930 - INFO - 
Configuration s6_n505 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002292244764947636",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n505",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n505/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.894824
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.82e-07
2024-11-20 20:06:34,930 - INFO - 
Starting training for config s6_n189:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n189/checkpoint.bin
2024-11-20 20:06:34,930 - INFO - Running command: ./train_gpt2cu -l 0.00022589175006131897 -o hyperband_runs_20241120_172038/run_s6_n189 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n189/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:06:45,994 - INFO - Training completed for config s6_n189:
  Training time: 0:00:11
  Final validation loss: 10.895060
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.68e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n189/checkpoint.bin
2024-11-20 20:06:45,995 - INFO - 
Configuration s6_n189 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00022589175006131897",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n189",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n189/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.895060
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.68e-07
2024-11-20 20:06:45,995 - INFO - 
Starting training for config s6_n557:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n557/checkpoint.bin
2024-11-20 20:06:45,995 - INFO - Running command: ./train_gpt2cu -l 0.00022731174184442617 -o hyperband_runs_20241120_172038/run_s6_n557 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n557/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:06:58,212 - INFO - Training completed for config s6_n557:
  Training time: 0:00:12
  Final validation loss: 10.894958
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.74e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n557/checkpoint.bin
2024-11-20 20:06:58,212 - INFO - 
Configuration s6_n557 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00022731174184442617",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n557",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n557/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.894958
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.74e-07
2024-11-20 20:06:58,212 - INFO - 
Starting training for config s6_n181:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n181/checkpoint.bin
2024-11-20 20:06:58,212 - INFO - Running command: ./train_gpt2cu -l 0.00022520718065505214 -o hyperband_runs_20241120_172038/run_s6_n181 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n181/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:07:10,963 - INFO - Training completed for config s6_n181:
  Training time: 0:00:12
  Final validation loss: 10.895116
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.65e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n181/checkpoint.bin
2024-11-20 20:07:10,964 - INFO - 
Configuration s6_n181 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00022520718065505214",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n181",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n181/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:12
  Validation Loss: 10.895116
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.65e-07
2024-11-20 20:07:10,964 - INFO - 
Starting training for config s6_n114:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n114/checkpoint.bin
2024-11-20 20:07:10,964 - INFO - Running command: ./train_gpt2cu -l 0.00022347810711559555 -o hyperband_runs_20241120_172038/run_s6_n114 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n114/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:07:22,024 - INFO - Training completed for config s6_n114:
  Training time: 0:00:11
  Final validation loss: 10.895243
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.58e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n114/checkpoint.bin
2024-11-20 20:07:22,024 - INFO - 
Configuration s6_n114 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00022347810711559555",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n114",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n114/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.895243
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.58e-07
2024-11-20 20:07:22,024 - INFO - 
Starting training for config s6_n589:
  Iterations: 3
  Previous iterations: 1
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n589/checkpoint.bin
2024-11-20 20:07:22,024 - INFO - Running command: ./train_gpt2cu -l 0.00022371115865239027 -o hyperband_runs_20241120_172038/run_s6_n589 -x 3 -n 3 -y 1 -e hyperband_runs_20241120_172038/run_s6_n589/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:07:33,082 - INFO - Training completed for config s6_n589:
  Training time: 0:00:11
  Final validation loss: 10.895229
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.59e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n589/checkpoint.bin
2024-11-20 20:07:33,082 - INFO - 
Configuration s6_n589 (bracket_6_round_1):
  Hyperparameters: {
  "learning_rate": "0.00022371115865239027",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n589",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n589/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:11
  Validation Loss: 10.895229
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.59e-07
2024-11-20 20:07:33,100 - INFO - 
Eliminating 162 configurations:
  Surviving: 81
2024-11-20 20:07:41,298 - INFO - 
Bracket 6, Round 2:
  Active configs: 81
  Iterations: 9
2024-11-20 20:07:41,298 - INFO - 
Starting training for config s6_n0:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin
2024-11-20 20:07:41,298 - INFO - Running command: ./train_gpt2cu -l 0.0009977479607140977 -o hyperband_runs_20241120_172038/run_s6_n0 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:08:01,650 - INFO - Training completed for config s6_n0:
  Training time: 0:00:20
  Final validation loss: 10.522310
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.28e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin
2024-11-20 20:08:01,650 - INFO - 
Configuration s6_n0 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009977479607140977",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n0",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.522310
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.28e-05
2024-11-20 20:08:01,650 - INFO - 
New best configuration found!
  Config ID: s6_n0
  Validation Loss: 10.522310
  Hellaswag Accuracy: 0.00%
  Training Time: 0:00:20
2024-11-20 20:08:01,650 - INFO - 
Starting training for config s6_n452:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin
2024-11-20 20:08:01,651 - INFO - Running command: ./train_gpt2cu -l 0.0009894839327752709 -o hyperband_runs_20241120_172038/run_s6_n452 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:08:21,886 - INFO - Training completed for config s6_n452:
  Training time: 0:00:20
  Final validation loss: 10.524179
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.27e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin
2024-11-20 20:08:21,886 - INFO - 
Configuration s6_n452 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009894839327752709",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n452",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.524179
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.27e-05
2024-11-20 20:08:21,886 - INFO - 
Starting training for config s6_n610:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin
2024-11-20 20:08:21,886 - INFO - Running command: ./train_gpt2cu -l 0.0009840193661966614 -o hyperband_runs_20241120_172038/run_s6_n610 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:08:42,129 - INFO - Training completed for config s6_n610:
  Training time: 0:00:20
  Final validation loss: 10.525414
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.27e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin
2024-11-20 20:08:42,129 - INFO - 
Configuration s6_n610 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009840193661966614",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n610",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.525414
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.27e-05
2024-11-20 20:08:42,129 - INFO - 
Starting training for config s6_n334:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin
2024-11-20 20:08:42,129 - INFO - Running command: ./train_gpt2cu -l 0.00097968892904061 -o hyperband_runs_20241120_172038/run_s6_n334 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:09:02,362 - INFO - Training completed for config s6_n334:
  Training time: 0:00:20
  Final validation loss: 10.526405
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.26e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin
2024-11-20 20:09:02,362 - INFO - 
Configuration s6_n334 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.00097968892904061",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n334",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.526405
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.26e-05
2024-11-20 20:09:02,362 - INFO - 
Starting training for config s6_n553:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin
2024-11-20 20:09:02,362 - INFO - Running command: ./train_gpt2cu -l 0.0009757562917808082 -o hyperband_runs_20241120_172038/run_s6_n553 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:09:22,601 - INFO - Training completed for config s6_n553:
  Training time: 0:00:20
  Final validation loss: 10.527318
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.25e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin
2024-11-20 20:09:22,601 - INFO - 
Configuration s6_n553 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009757562917808082",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n553",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.527318
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.25e-05
2024-11-20 20:09:22,601 - INFO - 
Starting training for config s6_n37:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin
2024-11-20 20:09:22,602 - INFO - Running command: ./train_gpt2cu -l 0.0009748120712873382 -o hyperband_runs_20241120_172038/run_s6_n37 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:09:42,834 - INFO - Training completed for config s6_n37:
  Training time: 0:00:20
  Final validation loss: 10.527529
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.25e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin
2024-11-20 20:09:42,835 - INFO - 
Configuration s6_n37 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009748120712873382",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n37",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.527529
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.25e-05
2024-11-20 20:09:42,835 - INFO - 
Starting training for config s6_n496:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin
2024-11-20 20:09:42,835 - INFO - Running command: ./train_gpt2cu -l 0.0009743088881485038 -o hyperband_runs_20241120_172038/run_s6_n496 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:10:03,064 - INFO - Training completed for config s6_n496:
  Training time: 0:00:20
  Final validation loss: 10.527628
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.25e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin
2024-11-20 20:10:03,065 - INFO - 
Configuration s6_n496 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009743088881485038",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n496",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.527628
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.25e-05
2024-11-20 20:10:03,065 - INFO - 
Starting training for config s6_n3:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin
2024-11-20 20:10:03,065 - INFO - Running command: ./train_gpt2cu -l 0.0009583333644205056 -o hyperband_runs_20241120_172038/run_s6_n3 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:10:23,302 - INFO - Training completed for config s6_n3:
  Training time: 0:00:20
  Final validation loss: 10.531318
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.23e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin
2024-11-20 20:10:23,302 - INFO - 
Configuration s6_n3 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009583333644205056",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n3",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.531318
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.23e-05
2024-11-20 20:10:23,302 - INFO - 
Starting training for config s6_n561:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin
2024-11-20 20:10:23,303 - INFO - Running command: ./train_gpt2cu -l 0.0009466935556371588 -o hyperband_runs_20241120_172038/run_s6_n561 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:10:43,233 - INFO - Training completed for config s6_n561:
  Training time: 0:00:19
  Final validation loss: 10.534033
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.22e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin
2024-11-20 20:10:43,234 - INFO - 
Configuration s6_n561 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009466935556371588",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n561",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:19
  Validation Loss: 10.534033
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.22e-05
2024-11-20 20:10:43,234 - INFO - 
Starting training for config s6_n490:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n490/checkpoint.bin
2024-11-20 20:10:43,234 - INFO - Running command: ./train_gpt2cu -l 0.0009437860734729266 -o hyperband_runs_20241120_172038/run_s6_n490 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n490/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:11:01,807 - INFO - Training completed for config s6_n490:
  Training time: 0:00:18
  Final validation loss: 10.534728
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.21e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n490/checkpoint.bin
2024-11-20 20:11:01,807 - INFO - 
Configuration s6_n490 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009437860734729266",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n490",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n490/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:18
  Validation Loss: 10.534728
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.21e-05
2024-11-20 20:11:01,807 - INFO - 
Starting training for config s6_n122:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n122/checkpoint.bin
2024-11-20 20:11:01,807 - INFO - Running command: ./train_gpt2cu -l 0.0009278776931084436 -o hyperband_runs_20241120_172038/run_s6_n122 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n122/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:11:21,966 - INFO - Training completed for config s6_n122:
  Training time: 0:00:20
  Final validation loss: 10.538528
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.19e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n122/checkpoint.bin
2024-11-20 20:11:21,966 - INFO - 
Configuration s6_n122 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009278776931084436",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n122",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n122/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.538528
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.19e-05
2024-11-20 20:11:21,966 - INFO - 
Starting training for config s6_n147:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n147/checkpoint.bin
2024-11-20 20:11:21,966 - INFO - Running command: ./train_gpt2cu -l 0.0009244094155573718 -o hyperband_runs_20241120_172038/run_s6_n147 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n147/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:11:42,072 - INFO - Training completed for config s6_n147:
  Training time: 0:00:20
  Final validation loss: 10.539365
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.19e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n147/checkpoint.bin
2024-11-20 20:11:42,072 - INFO - 
Configuration s6_n147 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009244094155573718",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n147",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n147/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.539365
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.19e-05
2024-11-20 20:11:42,072 - INFO - 
Starting training for config s6_n333:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n333/checkpoint.bin
2024-11-20 20:11:42,072 - INFO - Running command: ./train_gpt2cu -l 0.00090492595944296 -o hyperband_runs_20241120_172038/run_s6_n333 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n333/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:12:02,303 - INFO - Training completed for config s6_n333:
  Training time: 0:00:20
  Final validation loss: 10.544146
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.16e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n333/checkpoint.bin
2024-11-20 20:12:02,303 - INFO - 
Configuration s6_n333 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.00090492595944296",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n333",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n333/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.544146
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.16e-05
2024-11-20 20:12:02,303 - INFO - 
Starting training for config s6_n146:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n146/checkpoint.bin
2024-11-20 20:12:02,304 - INFO - Running command: ./train_gpt2cu -l 0.0008942480821014569 -o hyperband_runs_20241120_172038/run_s6_n146 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n146/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:12:22,538 - INFO - Training completed for config s6_n146:
  Training time: 0:00:20
  Final validation loss: 10.546773
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.15e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n146/checkpoint.bin
2024-11-20 20:12:22,538 - INFO - 
Configuration s6_n146 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008942480821014569",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n146",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n146/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.546773
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.15e-05
2024-11-20 20:12:22,538 - INFO - 
Starting training for config s6_n339:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n339/checkpoint.bin
2024-11-20 20:12:22,538 - INFO - Running command: ./train_gpt2cu -l 0.0008881775390564398 -o hyperband_runs_20241120_172038/run_s6_n339 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n339/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:12:42,790 - INFO - Training completed for config s6_n339:
  Training time: 0:00:20
  Final validation loss: 10.548301
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.14e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n339/checkpoint.bin
2024-11-20 20:12:42,790 - INFO - 
Configuration s6_n339 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008881775390564398",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n339",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n339/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.548301
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.14e-05
2024-11-20 20:12:42,791 - INFO - 
Starting training for config s6_n85:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n85/checkpoint.bin
2024-11-20 20:12:42,791 - INFO - Running command: ./train_gpt2cu -l 0.0008833451139763101 -o hyperband_runs_20241120_172038/run_s6_n85 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n85/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:13:03,041 - INFO - Training completed for config s6_n85:
  Training time: 0:00:20
  Final validation loss: 10.549506
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.14e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n85/checkpoint.bin
2024-11-20 20:13:03,041 - INFO - 
Configuration s6_n85 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008833451139763101",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n85",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n85/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.549506
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.14e-05
2024-11-20 20:13:03,041 - INFO - 
Starting training for config s6_n617:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n617/checkpoint.bin
2024-11-20 20:13:03,042 - INFO - Running command: ./train_gpt2cu -l 0.0008822222688470273 -o hyperband_runs_20241120_172038/run_s6_n617 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n617/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:13:23,285 - INFO - Training completed for config s6_n617:
  Training time: 0:00:20
  Final validation loss: 10.549787
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.13e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n617/checkpoint.bin
2024-11-20 20:13:23,285 - INFO - 
Configuration s6_n617 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008822222688470273",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n617",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n617/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.549787
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.13e-05
2024-11-20 20:13:23,286 - INFO - 
Starting training for config s6_n460:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n460/checkpoint.bin
2024-11-20 20:13:23,286 - INFO - Running command: ./train_gpt2cu -l 0.0008650173683974301 -o hyperband_runs_20241120_172038/run_s6_n460 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n460/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:13:43,538 - INFO - Training completed for config s6_n460:
  Training time: 0:00:20
  Final validation loss: 10.554167
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.11e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n460/checkpoint.bin
2024-11-20 20:13:43,538 - INFO - 
Configuration s6_n460 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008650173683974301",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n460",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n460/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.554167
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.11e-05
2024-11-20 20:13:43,539 - INFO - 
Starting training for config s6_n22:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n22/checkpoint.bin
2024-11-20 20:13:43,539 - INFO - Running command: ./train_gpt2cu -l 0.000859266840585978 -o hyperband_runs_20241120_172038/run_s6_n22 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n22/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:14:03,778 - INFO - Training completed for config s6_n22:
  Training time: 0:00:20
  Final validation loss: 10.555647
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.10e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n22/checkpoint.bin
2024-11-20 20:14:03,778 - INFO - 
Configuration s6_n22 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.000859266840585978",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n22",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n22/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.555647
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-05
2024-11-20 20:14:03,778 - INFO - 
Starting training for config s6_n380:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n380/checkpoint.bin
2024-11-20 20:14:03,779 - INFO - Running command: ./train_gpt2cu -l 0.0008587527623389926 -o hyperband_runs_20241120_172038/run_s6_n380 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n380/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:14:24,036 - INFO - Training completed for config s6_n380:
  Training time: 0:00:20
  Final validation loss: 10.555777
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.10e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n380/checkpoint.bin
2024-11-20 20:14:24,036 - INFO - 
Configuration s6_n380 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008587527623389926",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n380",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n380/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.555777
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-05
2024-11-20 20:14:24,036 - INFO - 
Starting training for config s6_n154:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n154/checkpoint.bin
2024-11-20 20:14:24,036 - INFO - Running command: ./train_gpt2cu -l 0.0008562517308020131 -o hyperband_runs_20241120_172038/run_s6_n154 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n154/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:14:44,274 - INFO - Training completed for config s6_n154:
  Training time: 0:00:20
  Final validation loss: 10.556409
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.10e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n154/checkpoint.bin
2024-11-20 20:14:44,274 - INFO - 
Configuration s6_n154 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008562517308020131",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n154",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n154/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.556409
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-05
2024-11-20 20:14:44,274 - INFO - 
Starting training for config s6_n420:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n420/checkpoint.bin
2024-11-20 20:14:44,275 - INFO - Running command: ./train_gpt2cu -l 0.0008560188308167667 -o hyperband_runs_20241120_172038/run_s6_n420 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n420/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:15:04,515 - INFO - Training completed for config s6_n420:
  Training time: 0:00:20
  Final validation loss: 10.556469
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.10e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n420/checkpoint.bin
2024-11-20 20:15:04,515 - INFO - 
Configuration s6_n420 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008560188308167667",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n420",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n420/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.556469
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-05
2024-11-20 20:15:04,515 - INFO - 
Starting training for config s6_n540:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n540/checkpoint.bin
2024-11-20 20:15:04,515 - INFO - Running command: ./train_gpt2cu -l 0.0008554037131933193 -o hyperband_runs_20241120_172038/run_s6_n540 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n540/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:15:24,757 - INFO - Training completed for config s6_n540:
  Training time: 0:00:20
  Final validation loss: 10.556623
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.10e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n540/checkpoint.bin
2024-11-20 20:15:24,757 - INFO - 
Configuration s6_n540 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008554037131933193",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n540",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n540/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.556623
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-05
2024-11-20 20:15:24,757 - INFO - 
Starting training for config s6_n234:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n234/checkpoint.bin
2024-11-20 20:15:24,757 - INFO - Running command: ./train_gpt2cu -l 0.000853428541786053 -o hyperband_runs_20241120_172038/run_s6_n234 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n234/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:15:45,010 - INFO - Training completed for config s6_n234:
  Training time: 0:00:20
  Final validation loss: 10.557149
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.10e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n234/checkpoint.bin
2024-11-20 20:15:45,011 - INFO - 
Configuration s6_n234 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.000853428541786053",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n234",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n234/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.557149
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-05
2024-11-20 20:15:45,011 - INFO - 
Starting training for config s6_n167:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n167/checkpoint.bin
2024-11-20 20:15:45,011 - INFO - Running command: ./train_gpt2cu -l 0.0008525192676792822 -o hyperband_runs_20241120_172038/run_s6_n167 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n167/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:16:05,265 - INFO - Training completed for config s6_n167:
  Training time: 0:00:20
  Final validation loss: 10.557389
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.10e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n167/checkpoint.bin
2024-11-20 20:16:05,265 - INFO - 
Configuration s6_n167 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008525192676792822",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n167",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n167/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.557389
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-05
2024-11-20 20:16:05,265 - INFO - 
Starting training for config s6_n173:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n173/checkpoint.bin
2024-11-20 20:16:05,265 - INFO - Running command: ./train_gpt2cu -l 0.0008431900534300434 -o hyperband_runs_20241120_172038/run_s6_n173 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n173/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:16:25,517 - INFO - Training completed for config s6_n173:
  Training time: 0:00:20
  Final validation loss: 10.559810
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.08e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n173/checkpoint.bin
2024-11-20 20:16:25,518 - INFO - 
Configuration s6_n173 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008431900534300434",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n173",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n173/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.559810
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.08e-05
2024-11-20 20:16:25,518 - INFO - 
Starting training for config s6_n42:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n42/checkpoint.bin
2024-11-20 20:16:25,518 - INFO - Running command: ./train_gpt2cu -l 0.0008427581488465726 -o hyperband_runs_20241120_172038/run_s6_n42 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n42/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:16:45,772 - INFO - Training completed for config s6_n42:
  Training time: 0:00:20
  Final validation loss: 10.559926
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.08e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n42/checkpoint.bin
2024-11-20 20:16:45,772 - INFO - 
Configuration s6_n42 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008427581488465726",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n42",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n42/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.559926
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.08e-05
2024-11-20 20:16:45,772 - INFO - 
Starting training for config s6_n15:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n15/checkpoint.bin
2024-11-20 20:16:45,772 - INFO - Running command: ./train_gpt2cu -l 0.0008401301724146576 -o hyperband_runs_20241120_172038/run_s6_n15 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n15/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:17:06,011 - INFO - Training completed for config s6_n15:
  Training time: 0:00:20
  Final validation loss: 10.560611
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.08e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n15/checkpoint.bin
2024-11-20 20:17:06,012 - INFO - 
Configuration s6_n15 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008401301724146576",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n15",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n15/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.560611
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.08e-05
2024-11-20 20:17:06,012 - INFO - 
Starting training for config s6_n280:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n280/checkpoint.bin
2024-11-20 20:17:06,012 - INFO - Running command: ./train_gpt2cu -l 0.0008339139310003893 -o hyperband_runs_20241120_172038/run_s6_n280 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n280/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:17:26,269 - INFO - Training completed for config s6_n280:
  Training time: 0:00:20
  Final validation loss: 10.562234
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.07e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n280/checkpoint.bin
2024-11-20 20:17:26,270 - INFO - 
Configuration s6_n280 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008339139310003893",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n280",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n280/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.562234
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.07e-05
2024-11-20 20:17:26,270 - INFO - 
Starting training for config s6_n313:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n313/checkpoint.bin
2024-11-20 20:17:26,270 - INFO - Running command: ./train_gpt2cu -l 0.0008309356853545224 -o hyperband_runs_20241120_172038/run_s6_n313 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n313/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:17:46,505 - INFO - Training completed for config s6_n313:
  Training time: 0:00:20
  Final validation loss: 10.563013
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.07e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n313/checkpoint.bin
2024-11-20 20:17:46,506 - INFO - 
Configuration s6_n313 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008309356853545224",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n313",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n313/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.563013
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.07e-05
2024-11-20 20:17:46,506 - INFO - 
Starting training for config s6_n309:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n309/checkpoint.bin
2024-11-20 20:17:46,506 - INFO - Running command: ./train_gpt2cu -l 0.000830841442264205 -o hyperband_runs_20241120_172038/run_s6_n309 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n309/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:18:06,756 - INFO - Training completed for config s6_n309:
  Training time: 0:00:20
  Final validation loss: 10.563047
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.07e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n309/checkpoint.bin
2024-11-20 20:18:06,756 - INFO - 
Configuration s6_n309 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.000830841442264205",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n309",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n309/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.563047
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.07e-05
2024-11-20 20:18:06,756 - INFO - 
Starting training for config s6_n259:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n259/checkpoint.bin
2024-11-20 20:18:06,756 - INFO - Running command: ./train_gpt2cu -l 0.0008249355759153884 -o hyperband_runs_20241120_172038/run_s6_n259 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n259/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:18:26,993 - INFO - Training completed for config s6_n259:
  Training time: 0:00:20
  Final validation loss: 10.564627
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.06e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n259/checkpoint.bin
2024-11-20 20:18:26,994 - INFO - 
Configuration s6_n259 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008249355759153884",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n259",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n259/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.564627
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.06e-05
2024-11-20 20:18:26,994 - INFO - 
Starting training for config s6_n152:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n152/checkpoint.bin
2024-11-20 20:18:26,994 - INFO - Running command: ./train_gpt2cu -l 0.0008225875504756807 -o hyperband_runs_20241120_172038/run_s6_n152 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n152/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:18:47,235 - INFO - Training completed for config s6_n152:
  Training time: 0:00:20
  Final validation loss: 10.565251
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.06e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n152/checkpoint.bin
2024-11-20 20:18:47,235 - INFO - 
Configuration s6_n152 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008225875504756807",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n152",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n152/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.565251
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.06e-05
2024-11-20 20:18:47,235 - INFO - 
Starting training for config s6_n338:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n338/checkpoint.bin
2024-11-20 20:18:47,235 - INFO - Running command: ./train_gpt2cu -l 0.0008157981726792546 -o hyperband_runs_20241120_172038/run_s6_n338 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n338/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:19:07,480 - INFO - Training completed for config s6_n338:
  Training time: 0:00:20
  Final validation loss: 10.567059
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.05e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n338/checkpoint.bin
2024-11-20 20:19:07,481 - INFO - 
Configuration s6_n338 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008157981726792546",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n338",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n338/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.567059
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.05e-05
2024-11-20 20:19:07,481 - INFO - 
Starting training for config s6_n652:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n652/checkpoint.bin
2024-11-20 20:19:07,481 - INFO - Running command: ./train_gpt2cu -l 0.00081477193361014 -o hyperband_runs_20241120_172038/run_s6_n652 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n652/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:19:27,750 - INFO - Training completed for config s6_n652:
  Training time: 0:00:20
  Final validation loss: 10.567351
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.05e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n652/checkpoint.bin
2024-11-20 20:19:27,751 - INFO - 
Configuration s6_n652 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.00081477193361014",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n652",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n652/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.567351
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.05e-05
2024-11-20 20:19:27,751 - INFO - 
Starting training for config s6_n306:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n306/checkpoint.bin
2024-11-20 20:19:27,751 - INFO - Running command: ./train_gpt2cu -l 0.0008099582756449049 -o hyperband_runs_20241120_172038/run_s6_n306 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n306/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:19:48,021 - INFO - Training completed for config s6_n306:
  Training time: 0:00:20
  Final validation loss: 10.568659
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.04e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n306/checkpoint.bin
2024-11-20 20:19:48,022 - INFO - 
Configuration s6_n306 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008099582756449049",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n306",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n306/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.568659
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.04e-05
2024-11-20 20:19:48,022 - INFO - 
Starting training for config s6_n591:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n591/checkpoint.bin
2024-11-20 20:19:48,022 - INFO - Running command: ./train_gpt2cu -l 0.0008079629767133919 -o hyperband_runs_20241120_172038/run_s6_n591 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n591/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:20:08,281 - INFO - Training completed for config s6_n591:
  Training time: 0:00:20
  Final validation loss: 10.569201
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.04e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n591/checkpoint.bin
2024-11-20 20:20:08,281 - INFO - 
Configuration s6_n591 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008079629767133919",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n591",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n591/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.569201
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.04e-05
2024-11-20 20:20:08,281 - INFO - 
Starting training for config s6_n343:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n343/checkpoint.bin
2024-11-20 20:20:08,281 - INFO - Running command: ./train_gpt2cu -l 0.0008029478952801089 -o hyperband_runs_20241120_172038/run_s6_n343 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n343/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:20:28,520 - INFO - Training completed for config s6_n343:
  Training time: 0:00:20
  Final validation loss: 10.570589
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.03e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n343/checkpoint.bin
2024-11-20 20:20:28,520 - INFO - 
Configuration s6_n343 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008029478952801089",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n343",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n343/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.570589
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.03e-05
2024-11-20 20:20:28,520 - INFO - 
Starting training for config s6_n53:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n53/checkpoint.bin
2024-11-20 20:20:28,520 - INFO - Running command: ./train_gpt2cu -l 0.0007988992971993117 -o hyperband_runs_20241120_172038/run_s6_n53 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n53/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:20:48,764 - INFO - Training completed for config s6_n53:
  Training time: 0:00:20
  Final validation loss: 10.571703
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.03e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n53/checkpoint.bin
2024-11-20 20:20:48,764 - INFO - 
Configuration s6_n53 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007988992971993117",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n53",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n53/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.571703
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.03e-05
2024-11-20 20:20:48,764 - INFO - 
Starting training for config s6_n116:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n116/checkpoint.bin
2024-11-20 20:20:48,764 - INFO - Running command: ./train_gpt2cu -l 0.0007975447996901649 -o hyperband_runs_20241120_172038/run_s6_n116 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n116/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:21:09,001 - INFO - Training completed for config s6_n116:
  Training time: 0:00:20
  Final validation loss: 10.572072
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.03e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n116/checkpoint.bin
2024-11-20 20:21:09,001 - INFO - 
Configuration s6_n116 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007975447996901649",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n116",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n116/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.572072
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.03e-05
2024-11-20 20:21:09,001 - INFO - 
Starting training for config s6_n210:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n210/checkpoint.bin
2024-11-20 20:21:09,001 - INFO - Running command: ./train_gpt2cu -l 0.000796614898741513 -o hyperband_runs_20241120_172038/run_s6_n210 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n210/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:21:29,232 - INFO - Training completed for config s6_n210:
  Training time: 0:00:20
  Final validation loss: 10.572329
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.02e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n210/checkpoint.bin
2024-11-20 20:21:29,232 - INFO - 
Configuration s6_n210 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.000796614898741513",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n210",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n210/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.572329
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-05
2024-11-20 20:21:29,232 - INFO - 
Starting training for config s6_n364:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n364/checkpoint.bin
2024-11-20 20:21:29,232 - INFO - Running command: ./train_gpt2cu -l 0.0007960447614808076 -o hyperband_runs_20241120_172038/run_s6_n364 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n364/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:21:49,471 - INFO - Training completed for config s6_n364:
  Training time: 0:00:20
  Final validation loss: 10.572474
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.02e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n364/checkpoint.bin
2024-11-20 20:21:49,471 - INFO - 
Configuration s6_n364 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007960447614808076",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n364",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n364/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.572474
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-05
2024-11-20 20:21:49,471 - INFO - 
Starting training for config s6_n229:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n229/checkpoint.bin
2024-11-20 20:21:49,471 - INFO - Running command: ./train_gpt2cu -l 0.00079540403785159 -o hyperband_runs_20241120_172038/run_s6_n229 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n229/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:22:09,704 - INFO - Training completed for config s6_n229:
  Training time: 0:00:20
  Final validation loss: 10.572649
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.02e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n229/checkpoint.bin
2024-11-20 20:22:09,704 - INFO - 
Configuration s6_n229 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.00079540403785159",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n229",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n229/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.572649
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-05
2024-11-20 20:22:09,704 - INFO - 
Starting training for config s6_n28:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n28/checkpoint.bin
2024-11-20 20:22:09,704 - INFO - Running command: ./train_gpt2cu -l 0.0007944460308724998 -o hyperband_runs_20241120_172038/run_s6_n28 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n28/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:22:29,954 - INFO - Training completed for config s6_n28:
  Training time: 0:00:20
  Final validation loss: 10.572908
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.02e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n28/checkpoint.bin
2024-11-20 20:22:29,954 - INFO - 
Configuration s6_n28 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007944460308724998",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n28",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n28/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.572908
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-05
2024-11-20 20:22:29,954 - INFO - 
Starting training for config s6_n638:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n638/checkpoint.bin
2024-11-20 20:22:29,954 - INFO - Running command: ./train_gpt2cu -l 0.0007915379022221989 -o hyperband_runs_20241120_172038/run_s6_n638 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n638/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:22:50,203 - INFO - Training completed for config s6_n638:
  Training time: 0:00:20
  Final validation loss: 10.573713
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.02e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n638/checkpoint.bin
2024-11-20 20:22:50,203 - INFO - 
Configuration s6_n638 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007915379022221989",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n638",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n638/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.573713
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-05
2024-11-20 20:22:50,203 - INFO - 
Starting training for config s6_n551:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n551/checkpoint.bin
2024-11-20 20:22:50,203 - INFO - Running command: ./train_gpt2cu -l 0.0007833672223959862 -o hyperband_runs_20241120_172038/run_s6_n551 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n551/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:23:10,478 - INFO - Training completed for config s6_n551:
  Training time: 0:00:20
  Final validation loss: 10.575996
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.01e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n551/checkpoint.bin
2024-11-20 20:23:10,479 - INFO - 
Configuration s6_n551 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007833672223959862",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n551",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n551/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.575996
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.01e-05
2024-11-20 20:23:10,479 - INFO - 
Starting training for config s6_n100:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n100/checkpoint.bin
2024-11-20 20:23:10,479 - INFO - Running command: ./train_gpt2cu -l 0.0007748331409407934 -o hyperband_runs_20241120_172038/run_s6_n100 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n100/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:23:30,729 - INFO - Training completed for config s6_n100:
  Training time: 0:00:20
  Final validation loss: 10.578402
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.96e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n100/checkpoint.bin
2024-11-20 20:23:30,729 - INFO - 
Configuration s6_n100 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007748331409407934",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n100",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n100/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.578402
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.96e-06
2024-11-20 20:23:30,729 - INFO - 
Starting training for config s6_n677:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n677/checkpoint.bin
2024-11-20 20:23:30,729 - INFO - Running command: ./train_gpt2cu -l 0.0007683502023562 -o hyperband_runs_20241120_172038/run_s6_n677 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n677/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:23:50,984 - INFO - Training completed for config s6_n677:
  Training time: 0:00:20
  Final validation loss: 10.580202
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.88e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n677/checkpoint.bin
2024-11-20 20:23:50,984 - INFO - 
Configuration s6_n677 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007683502023562",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n677",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n677/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.580202
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.88e-06
2024-11-20 20:23:50,984 - INFO - 
Starting training for config s6_n607:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n607/checkpoint.bin
2024-11-20 20:23:50,985 - INFO - Running command: ./train_gpt2cu -l 0.000765146304141897 -o hyperband_runs_20241120_172038/run_s6_n607 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n607/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:24:11,216 - INFO - Training completed for config s6_n607:
  Training time: 0:00:20
  Final validation loss: 10.581114
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.84e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n607/checkpoint.bin
2024-11-20 20:24:11,216 - INFO - 
Configuration s6_n607 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.000765146304141897",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n607",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n607/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.581114
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.84e-06
2024-11-20 20:24:11,216 - INFO - 
Starting training for config s6_n632:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n632/checkpoint.bin
2024-11-20 20:24:11,216 - INFO - Running command: ./train_gpt2cu -l 0.0007609596504620381 -o hyperband_runs_20241120_172038/run_s6_n632 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n632/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:24:31,464 - INFO - Training completed for config s6_n632:
  Training time: 0:00:20
  Final validation loss: 10.582295
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.78e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n632/checkpoint.bin
2024-11-20 20:24:31,465 - INFO - 
Configuration s6_n632 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007609596504620381",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n632",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n632/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.582295
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.78e-06
2024-11-20 20:24:31,465 - INFO - 
Starting training for config s6_n467:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n467/checkpoint.bin
2024-11-20 20:24:31,465 - INFO - Running command: ./train_gpt2cu -l 0.0007548680660404933 -o hyperband_runs_20241120_172038/run_s6_n467 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n467/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:24:51,715 - INFO - Training completed for config s6_n467:
  Training time: 0:00:20
  Final validation loss: 10.584054
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.71e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n467/checkpoint.bin
2024-11-20 20:24:51,715 - INFO - 
Configuration s6_n467 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007548680660404933",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n467",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n467/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.584054
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.71e-06
2024-11-20 20:24:51,715 - INFO - 
Starting training for config s6_n322:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n322/checkpoint.bin
2024-11-20 20:24:51,715 - INFO - Running command: ./train_gpt2cu -l 0.0007535574287081613 -o hyperband_runs_20241120_172038/run_s6_n322 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n322/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:25:11,965 - INFO - Training completed for config s6_n322:
  Training time: 0:00:20
  Final validation loss: 10.584434
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.69e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n322/checkpoint.bin
2024-11-20 20:25:11,965 - INFO - 
Configuration s6_n322 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007535574287081613",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n322",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n322/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.584434
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.69e-06
2024-11-20 20:25:11,965 - INFO - 
Starting training for config s6_n615:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n615/checkpoint.bin
2024-11-20 20:25:11,966 - INFO - Running command: ./train_gpt2cu -l 0.0007505781567021048 -o hyperband_runs_20241120_172038/run_s6_n615 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n615/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:25:32,227 - INFO - Training completed for config s6_n615:
  Training time: 0:00:20
  Final validation loss: 10.585294
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.65e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n615/checkpoint.bin
2024-11-20 20:25:32,228 - INFO - 
Configuration s6_n615 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007505781567021048",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n615",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n615/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.585294
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.65e-06
2024-11-20 20:25:32,228 - INFO - 
Starting training for config s6_n588:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n588/checkpoint.bin
2024-11-20 20:25:32,228 - INFO - Running command: ./train_gpt2cu -l 0.0007278567127169047 -o hyperband_runs_20241120_172038/run_s6_n588 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n588/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:25:52,471 - INFO - Training completed for config s6_n588:
  Training time: 0:00:20
  Final validation loss: 10.591933
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.36e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n588/checkpoint.bin
2024-11-20 20:25:52,471 - INFO - 
Configuration s6_n588 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007278567127169047",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n588",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n588/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.591933
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.36e-06
2024-11-20 20:25:52,471 - INFO - 
Starting training for config s6_n601:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n601/checkpoint.bin
2024-11-20 20:25:52,471 - INFO - Running command: ./train_gpt2cu -l 0.0007221173134528555 -o hyperband_runs_20241120_172038/run_s6_n601 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n601/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:26:12,719 - INFO - Training completed for config s6_n601:
  Training time: 0:00:20
  Final validation loss: 10.593626
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.28e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n601/checkpoint.bin
2024-11-20 20:26:12,719 - INFO - 
Configuration s6_n601 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007221173134528555",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n601",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n601/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.593626
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.28e-06
2024-11-20 20:26:12,719 - INFO - 
Starting training for config s6_n236:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n236/checkpoint.bin
2024-11-20 20:26:12,719 - INFO - Running command: ./train_gpt2cu -l 0.0007215956007704206 -o hyperband_runs_20241120_172038/run_s6_n236 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n236/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:26:32,975 - INFO - Training completed for config s6_n236:
  Training time: 0:00:20
  Final validation loss: 10.593801
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.28e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n236/checkpoint.bin
2024-11-20 20:26:32,975 - INFO - 
Configuration s6_n236 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007215956007704206",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n236",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n236/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.593801
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.28e-06
2024-11-20 20:26:32,975 - INFO - 
Starting training for config s6_n325:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n325/checkpoint.bin
2024-11-20 20:26:32,975 - INFO - Running command: ./train_gpt2cu -l 0.0007107889545943217 -o hyperband_runs_20241120_172038/run_s6_n325 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n325/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:26:53,240 - INFO - Training completed for config s6_n325:
  Training time: 0:00:20
  Final validation loss: 10.597058
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.14e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n325/checkpoint.bin
2024-11-20 20:26:53,240 - INFO - 
Configuration s6_n325 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007107889545943217",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n325",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n325/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.597058
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.14e-06
2024-11-20 20:26:53,241 - INFO - 
Starting training for config s6_n667:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n667/checkpoint.bin
2024-11-20 20:26:53,241 - INFO - Running command: ./train_gpt2cu -l 0.0007052164516636011 -o hyperband_runs_20241120_172038/run_s6_n667 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n667/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:27:13,494 - INFO - Training completed for config s6_n667:
  Training time: 0:00:20
  Final validation loss: 10.598745
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.07e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n667/checkpoint.bin
2024-11-20 20:27:13,494 - INFO - 
Configuration s6_n667 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007052164516636011",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n667",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n667/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.598745
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.07e-06
2024-11-20 20:27:13,494 - INFO - 
Starting training for config s6_n705:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n705/checkpoint.bin
2024-11-20 20:27:13,494 - INFO - Running command: ./train_gpt2cu -l 0.0007045014359961428 -o hyperband_runs_20241120_172038/run_s6_n705 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n705/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:27:33,757 - INFO - Training completed for config s6_n705:
  Training time: 0:00:20
  Final validation loss: 10.598957
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.06e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n705/checkpoint.bin
2024-11-20 20:27:33,757 - INFO - 
Configuration s6_n705 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007045014359961428",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n705",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n705/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.598957
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.06e-06
2024-11-20 20:27:33,757 - INFO - 
Starting training for config s6_n520:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n520/checkpoint.bin
2024-11-20 20:27:33,758 - INFO - Running command: ./train_gpt2cu -l 0.0007030878468635916 -o hyperband_runs_20241120_172038/run_s6_n520 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n520/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:27:54,011 - INFO - Training completed for config s6_n520:
  Training time: 0:00:20
  Final validation loss: 10.599375
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.04e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n520/checkpoint.bin
2024-11-20 20:27:54,012 - INFO - 
Configuration s6_n520 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007030878468635916",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n520",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n520/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.599375
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.04e-06
2024-11-20 20:27:54,012 - INFO - 
Starting training for config s6_n700:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n700/checkpoint.bin
2024-11-20 20:27:54,012 - INFO - Running command: ./train_gpt2cu -l 0.0006951122926882169 -o hyperband_runs_20241120_172038/run_s6_n700 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n700/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:28:14,254 - INFO - Training completed for config s6_n700:
  Training time: 0:00:20
  Final validation loss: 10.601848
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.94e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n700/checkpoint.bin
2024-11-20 20:28:14,255 - INFO - 
Configuration s6_n700 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006951122926882169",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n700",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n700/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.601848
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.94e-06
2024-11-20 20:28:14,255 - INFO - 
Starting training for config s6_n235:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n235/checkpoint.bin
2024-11-20 20:28:14,255 - INFO - Running command: ./train_gpt2cu -l 0.0006851603833257309 -o hyperband_runs_20241120_172038/run_s6_n235 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n235/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:28:34,513 - INFO - Training completed for config s6_n235:
  Training time: 0:00:20
  Final validation loss: 10.604906
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.81e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n235/checkpoint.bin
2024-11-20 20:28:34,513 - INFO - 
Configuration s6_n235 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006851603833257309",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n235",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n235/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.604906
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.81e-06
2024-11-20 20:28:34,513 - INFO - 
Starting training for config s6_n264:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n264/checkpoint.bin
2024-11-20 20:28:34,513 - INFO - Running command: ./train_gpt2cu -l 0.0006773380521221634 -o hyperband_runs_20241120_172038/run_s6_n264 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n264/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:28:54,764 - INFO - Training completed for config s6_n264:
  Training time: 0:00:20
  Final validation loss: 10.607332
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.71e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n264/checkpoint.bin
2024-11-20 20:28:54,764 - INFO - 
Configuration s6_n264 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006773380521221634",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n264",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n264/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.607332
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.71e-06
2024-11-20 20:28:54,764 - INFO - 
Starting training for config s6_n523:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n523/checkpoint.bin
2024-11-20 20:28:54,764 - INFO - Running command: ./train_gpt2cu -l 0.0006721463416277697 -o hyperband_runs_20241120_172038/run_s6_n523 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n523/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:29:15,014 - INFO - Training completed for config s6_n523:
  Training time: 0:00:20
  Final validation loss: 10.608964
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.64e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n523/checkpoint.bin
2024-11-20 20:29:15,015 - INFO - 
Configuration s6_n523 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006721463416277697",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n523",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n523/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.608964
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.64e-06
2024-11-20 20:29:15,015 - INFO - 
Starting training for config s6_n522:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n522/checkpoint.bin
2024-11-20 20:29:15,015 - INFO - Running command: ./train_gpt2cu -l 0.000671880458880737 -o hyperband_runs_20241120_172038/run_s6_n522 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n522/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:29:35,262 - INFO - Training completed for config s6_n522:
  Training time: 0:00:20
  Final validation loss: 10.609037
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.64e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n522/checkpoint.bin
2024-11-20 20:29:35,263 - INFO - 
Configuration s6_n522 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.000671880458880737",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n522",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n522/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.609037
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.64e-06
2024-11-20 20:29:35,263 - INFO - 
Starting training for config s6_n572:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n572/checkpoint.bin
2024-11-20 20:29:35,263 - INFO - Running command: ./train_gpt2cu -l 0.0006692136504312971 -o hyperband_runs_20241120_172038/run_s6_n572 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n572/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:29:55,506 - INFO - Training completed for config s6_n572:
  Training time: 0:00:20
  Final validation loss: 10.609873
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.60e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n572/checkpoint.bin
2024-11-20 20:29:55,506 - INFO - 
Configuration s6_n572 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006692136504312971",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n572",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n572/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.609873
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.60e-06
2024-11-20 20:29:55,506 - INFO - 
Starting training for config s6_n282:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n282/checkpoint.bin
2024-11-20 20:29:55,507 - INFO - Running command: ./train_gpt2cu -l 0.0006673066269854008 -o hyperband_runs_20241120_172038/run_s6_n282 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n282/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:30:15,749 - INFO - Training completed for config s6_n282:
  Training time: 0:00:20
  Final validation loss: 10.610486
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.58e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n282/checkpoint.bin
2024-11-20 20:30:15,750 - INFO - 
Configuration s6_n282 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006673066269854008",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n282",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n282/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.610486
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.58e-06
2024-11-20 20:30:15,750 - INFO - 
Starting training for config s6_n191:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n191/checkpoint.bin
2024-11-20 20:30:15,750 - INFO - Running command: ./train_gpt2cu -l 0.0006673650168736646 -o hyperband_runs_20241120_172038/run_s6_n191 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n191/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:30:36,007 - INFO - Training completed for config s6_n191:
  Training time: 0:00:20
  Final validation loss: 10.610462
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.58e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n191/checkpoint.bin
2024-11-20 20:30:36,008 - INFO - 
Configuration s6_n191 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006673650168736646",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n191",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n191/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.610462
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.58e-06
2024-11-20 20:30:36,008 - INFO - 
Starting training for config s6_n34:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n34/checkpoint.bin
2024-11-20 20:30:36,008 - INFO - Running command: ./train_gpt2cu -l 0.000655179765012117 -o hyperband_runs_20241120_172038/run_s6_n34 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n34/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:30:56,263 - INFO - Training completed for config s6_n34:
  Training time: 0:00:20
  Final validation loss: 10.614361
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.42e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n34/checkpoint.bin
2024-11-20 20:30:56,264 - INFO - 
Configuration s6_n34 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.000655179765012117",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n34",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n34/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.614361
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.42e-06
2024-11-20 20:30:56,264 - INFO - 
Starting training for config s6_n217:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n217/checkpoint.bin
2024-11-20 20:30:56,264 - INFO - Running command: ./train_gpt2cu -l 0.0006502089255387881 -o hyperband_runs_20241120_172038/run_s6_n217 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n217/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:31:16,518 - INFO - Training completed for config s6_n217:
  Training time: 0:00:20
  Final validation loss: 10.615949
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.36e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n217/checkpoint.bin
2024-11-20 20:31:16,518 - INFO - 
Configuration s6_n217 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006502089255387881",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n217",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n217/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.615949
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.36e-06
2024-11-20 20:31:16,518 - INFO - 
Starting training for config s6_n516:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n516/checkpoint.bin
2024-11-20 20:31:16,518 - INFO - Running command: ./train_gpt2cu -l 0.0006409848656735655 -o hyperband_runs_20241120_172038/run_s6_n516 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n516/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:31:36,759 - INFO - Training completed for config s6_n516:
  Training time: 0:00:20
  Final validation loss: 10.618937
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.24e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n516/checkpoint.bin
2024-11-20 20:31:36,760 - INFO - 
Configuration s6_n516 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006409848656735655",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n516",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n516/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.618937
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.24e-06
2024-11-20 20:31:36,760 - INFO - 
Starting training for config s6_n185:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n185/checkpoint.bin
2024-11-20 20:31:36,760 - INFO - Running command: ./train_gpt2cu -l 0.0006393198282527764 -o hyperband_runs_20241120_172038/run_s6_n185 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n185/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:31:57,001 - INFO - Training completed for config s6_n185:
  Training time: 0:00:20
  Final validation loss: 10.619486
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.22e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n185/checkpoint.bin
2024-11-20 20:31:57,001 - INFO - 
Configuration s6_n185 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006393198282527764",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n185",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n185/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.619486
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.22e-06
2024-11-20 20:31:57,002 - INFO - 
Starting training for config s6_n14:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n14/checkpoint.bin
2024-11-20 20:31:57,002 - INFO - Running command: ./train_gpt2cu -l 0.0006305830318046952 -o hyperband_runs_20241120_172038/run_s6_n14 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n14/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:32:17,260 - INFO - Training completed for config s6_n14:
  Training time: 0:00:20
  Final validation loss: 10.622351
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.11e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n14/checkpoint.bin
2024-11-20 20:32:17,261 - INFO - 
Configuration s6_n14 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006305830318046952",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n14",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n14/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.622351
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.11e-06
2024-11-20 20:32:17,261 - INFO - 
Starting training for config s6_n472:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n472/checkpoint.bin
2024-11-20 20:32:17,261 - INFO - Running command: ./train_gpt2cu -l 0.0006271523394724145 -o hyperband_runs_20241120_172038/run_s6_n472 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n472/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:32:37,521 - INFO - Training completed for config s6_n472:
  Training time: 0:00:20
  Final validation loss: 10.623499
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.06e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n472/checkpoint.bin
2024-11-20 20:32:37,522 - INFO - 
Configuration s6_n472 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006271523394724145",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n472",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n472/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.623499
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.06e-06
2024-11-20 20:32:37,522 - INFO - 
Starting training for config s6_n291:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n291/checkpoint.bin
2024-11-20 20:32:37,522 - INFO - Running command: ./train_gpt2cu -l 0.0006021443487263004 -o hyperband_runs_20241120_172038/run_s6_n291 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n291/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:32:57,782 - INFO - Training completed for config s6_n291:
  Training time: 0:00:20
  Final validation loss: 10.631921
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.74e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n291/checkpoint.bin
2024-11-20 20:32:57,782 - INFO - 
Configuration s6_n291 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006021443487263004",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n291",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n291/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.631921
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.74e-06
2024-11-20 20:32:57,782 - INFO - 
Starting training for config s6_n1:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n1/checkpoint.bin
2024-11-20 20:32:57,782 - INFO - Running command: ./train_gpt2cu -l 0.0006009494647743333 -o hyperband_runs_20241120_172038/run_s6_n1 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n1/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:33:18,039 - INFO - Training completed for config s6_n1:
  Training time: 0:00:20
  Final validation loss: 10.632320
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.73e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n1/checkpoint.bin
2024-11-20 20:33:18,039 - INFO - 
Configuration s6_n1 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006009494647743333",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n1",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n1/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.632320
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.73e-06
2024-11-20 20:33:18,039 - INFO - 
Starting training for config s6_n533:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n533/checkpoint.bin
2024-11-20 20:33:18,039 - INFO - Running command: ./train_gpt2cu -l 0.0005995598841000959 -o hyperband_runs_20241120_172038/run_s6_n533 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n533/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:33:38,305 - INFO - Training completed for config s6_n533:
  Training time: 0:00:20
  Final validation loss: 10.632787
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.71e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n533/checkpoint.bin
2024-11-20 20:33:38,305 - INFO - 
Configuration s6_n533 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0005995598841000959",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n533",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n533/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.632787
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.71e-06
2024-11-20 20:33:38,306 - INFO - 
Starting training for config s6_n206:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n206/checkpoint.bin
2024-11-20 20:33:38,306 - INFO - Running command: ./train_gpt2cu -l 0.0005960641560476585 -o hyperband_runs_20241120_172038/run_s6_n206 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n206/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:33:58,550 - INFO - Training completed for config s6_n206:
  Training time: 0:00:20
  Final validation loss: 10.633985
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.66e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n206/checkpoint.bin
2024-11-20 20:33:58,550 - INFO - 
Configuration s6_n206 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0005960641560476585",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n206",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n206/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.633985
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.66e-06
2024-11-20 20:33:58,550 - INFO - 
Starting training for config s6_n558:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n558/checkpoint.bin
2024-11-20 20:33:58,550 - INFO - Running command: ./train_gpt2cu -l 0.00058046999043979 -o hyperband_runs_20241120_172038/run_s6_n558 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n558/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:34:18,816 - INFO - Training completed for config s6_n558:
  Training time: 0:00:20
  Final validation loss: 10.639395
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.46e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n558/checkpoint.bin
2024-11-20 20:34:18,816 - INFO - 
Configuration s6_n558 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.00058046999043979",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n558",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n558/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.639395
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.46e-06
2024-11-20 20:34:18,816 - INFO - 
Starting training for config s6_n694:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n694/checkpoint.bin
2024-11-20 20:34:18,816 - INFO - Running command: ./train_gpt2cu -l 0.0005785577817493396 -o hyperband_runs_20241120_172038/run_s6_n694 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n694/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:34:39,077 - INFO - Training completed for config s6_n694:
  Training time: 0:00:20
  Final validation loss: 10.640055
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.44e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n694/checkpoint.bin
2024-11-20 20:34:39,077 - INFO - 
Configuration s6_n694 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0005785577817493396",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n694",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n694/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.640055
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.44e-06
2024-11-20 20:34:39,077 - INFO - 
Starting training for config s6_n88:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n88/checkpoint.bin
2024-11-20 20:34:39,077 - INFO - Running command: ./train_gpt2cu -l 0.0005770588695397528 -o hyperband_runs_20241120_172038/run_s6_n88 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s6_n88/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:34:59,447 - INFO - Training completed for config s6_n88:
  Training time: 0:00:20
  Final validation loss: 10.640593
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.42e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n88/checkpoint.bin
2024-11-20 20:34:59,447 - INFO - 
Configuration s6_n88 (bracket_6_round_2):
  Hyperparameters: {
  "learning_rate": "0.0005770588695397528",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n88",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n88/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.640593
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.42e-06
2024-11-20 20:34:59,448 - INFO - 
Eliminating 54 configurations:
  Surviving: 27
2024-11-20 20:35:03,068 - INFO - 
Bracket 6, Round 3:
  Active configs: 27
  Iterations: 27
2024-11-20 20:35:03,068 - INFO - 
Starting training for config s6_n0:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin
2024-11-20 20:35:03,068 - INFO - Running command: ./train_gpt2cu -l 0.0009977479607140977 -o hyperband_runs_20241120_172038/run_s6_n0 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:35:50,934 - INFO - Training completed for config s6_n0:
  Training time: 0:00:47
  Final validation loss: 10.037452
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.85e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin
2024-11-20 20:35:50,935 - INFO - 
Configuration s6_n0 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009977479607140977",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n0",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.037452
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.85e-05
2024-11-20 20:35:50,935 - INFO - 
New best configuration found!
  Config ID: s6_n0
  Validation Loss: 10.037452
  Hellaswag Accuracy: 0.00%
  Training Time: 0:00:47
2024-11-20 20:35:50,935 - INFO - 
Starting training for config s6_n452:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin
2024-11-20 20:35:50,935 - INFO - Running command: ./train_gpt2cu -l 0.0009894839327752709 -o hyperband_runs_20241120_172038/run_s6_n452 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:36:38,748 - INFO - Training completed for config s6_n452:
  Training time: 0:00:47
  Final validation loss: 10.039923
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.82e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin
2024-11-20 20:36:38,748 - INFO - 
Configuration s6_n452 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009894839327752709",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n452",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.039923
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.82e-05
2024-11-20 20:36:38,748 - INFO - 
Starting training for config s6_n610:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin
2024-11-20 20:36:38,748 - INFO - Running command: ./train_gpt2cu -l 0.0009840193661966614 -o hyperband_runs_20241120_172038/run_s6_n610 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:37:26,571 - INFO - Training completed for config s6_n610:
  Training time: 0:00:47
  Final validation loss: 10.041190
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.80e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin
2024-11-20 20:37:26,571 - INFO - 
Configuration s6_n610 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009840193661966614",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n610",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.041190
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.80e-05
2024-11-20 20:37:26,571 - INFO - 
Starting training for config s6_n334:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin
2024-11-20 20:37:26,571 - INFO - Running command: ./train_gpt2cu -l 0.00097968892904061 -o hyperband_runs_20241120_172038/run_s6_n334 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:38:14,391 - INFO - Training completed for config s6_n334:
  Training time: 0:00:47
  Final validation loss: 10.042152
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.78e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin
2024-11-20 20:38:14,391 - INFO - 
Configuration s6_n334 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.00097968892904061",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n334",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.042152
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.78e-05
2024-11-20 20:38:14,391 - INFO - 
Starting training for config s6_n553:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin
2024-11-20 20:38:14,391 - INFO - Running command: ./train_gpt2cu -l 0.0009757562917808082 -o hyperband_runs_20241120_172038/run_s6_n553 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:39:02,212 - INFO - Training completed for config s6_n553:
  Training time: 0:00:47
  Final validation loss: 10.043056
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.76e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin
2024-11-20 20:39:02,213 - INFO - 
Configuration s6_n553 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009757562917808082",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n553",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.043056
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.76e-05
2024-11-20 20:39:02,213 - INFO - 
Starting training for config s6_n37:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin
2024-11-20 20:39:02,213 - INFO - Running command: ./train_gpt2cu -l 0.0009748120712873382 -o hyperband_runs_20241120_172038/run_s6_n37 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:39:50,005 - INFO - Training completed for config s6_n37:
  Training time: 0:00:47
  Final validation loss: 10.043292
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.76e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin
2024-11-20 20:39:50,006 - INFO - 
Configuration s6_n37 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009748120712873382",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n37",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.043292
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.76e-05
2024-11-20 20:39:50,006 - INFO - 
Starting training for config s6_n496:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin
2024-11-20 20:39:50,006 - INFO - Running command: ./train_gpt2cu -l 0.0009743088881485038 -o hyperband_runs_20241120_172038/run_s6_n496 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:40:37,794 - INFO - Training completed for config s6_n496:
  Training time: 0:00:47
  Final validation loss: 10.043408
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.76e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin
2024-11-20 20:40:37,794 - INFO - 
Configuration s6_n496 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009743088881485038",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n496",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.043408
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.76e-05
2024-11-20 20:40:37,794 - INFO - 
Starting training for config s6_n3:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin
2024-11-20 20:40:37,794 - INFO - Running command: ./train_gpt2cu -l 0.0009583333644205056 -o hyperband_runs_20241120_172038/run_s6_n3 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:41:25,593 - INFO - Training completed for config s6_n3:
  Training time: 0:00:47
  Final validation loss: 10.047445
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.70e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin
2024-11-20 20:41:25,593 - INFO - 
Configuration s6_n3 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009583333644205056",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n3",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.047445
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.70e-05
2024-11-20 20:41:25,593 - INFO - 
Starting training for config s6_n561:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin
2024-11-20 20:41:25,593 - INFO - Running command: ./train_gpt2cu -l 0.0009466935556371588 -o hyperband_runs_20241120_172038/run_s6_n561 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:42:13,381 - INFO - Training completed for config s6_n561:
  Training time: 0:00:47
  Final validation loss: 10.050128
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.65e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin
2024-11-20 20:42:13,381 - INFO - 
Configuration s6_n561 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009466935556371588",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n561",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.050128
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.65e-05
2024-11-20 20:42:13,381 - INFO - 
Starting training for config s6_n490:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n490/checkpoint.bin
2024-11-20 20:42:13,381 - INFO - Running command: ./train_gpt2cu -l 0.0009437860734729266 -o hyperband_runs_20241120_172038/run_s6_n490 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n490/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:43:01,164 - INFO - Training completed for config s6_n490:
  Training time: 0:00:47
  Final validation loss: 10.050796
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.64e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n490/checkpoint.bin
2024-11-20 20:43:01,165 - INFO - 
Configuration s6_n490 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009437860734729266",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n490",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n490/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.050796
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.64e-05
2024-11-20 20:43:01,165 - INFO - 
Starting training for config s6_n122:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n122/checkpoint.bin
2024-11-20 20:43:01,165 - INFO - Running command: ./train_gpt2cu -l 0.0009278776931084436 -o hyperband_runs_20241120_172038/run_s6_n122 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n122/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:43:48,957 - INFO - Training completed for config s6_n122:
  Training time: 0:00:47
  Final validation loss: 10.055421
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.58e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n122/checkpoint.bin
2024-11-20 20:43:48,957 - INFO - 
Configuration s6_n122 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009278776931084436",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n122",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n122/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.055421
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.58e-05
2024-11-20 20:43:48,957 - INFO - 
Starting training for config s6_n147:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n147/checkpoint.bin
2024-11-20 20:43:48,957 - INFO - Running command: ./train_gpt2cu -l 0.0009244094155573718 -o hyperband_runs_20241120_172038/run_s6_n147 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n147/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:44:35,424 - INFO - Training completed for config s6_n147:
  Training time: 0:00:46
  Final validation loss: 10.056337
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.57e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n147/checkpoint.bin
2024-11-20 20:44:35,424 - INFO - 
Configuration s6_n147 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009244094155573718",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n147",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n147/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:46
  Validation Loss: 10.056337
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.57e-05
2024-11-20 20:44:35,424 - INFO - 
Starting training for config s6_n333:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n333/checkpoint.bin
2024-11-20 20:44:35,424 - INFO - Running command: ./train_gpt2cu -l 0.00090492595944296 -o hyperband_runs_20241120_172038/run_s6_n333 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n333/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:45:23,266 - INFO - Training completed for config s6_n333:
  Training time: 0:00:47
  Final validation loss: 10.060866
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.49e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n333/checkpoint.bin
2024-11-20 20:45:23,266 - INFO - 
Configuration s6_n333 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.00090492595944296",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n333",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n333/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.060866
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.49e-05
2024-11-20 20:45:23,267 - INFO - 
Starting training for config s6_n146:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n146/checkpoint.bin
2024-11-20 20:45:23,267 - INFO - Running command: ./train_gpt2cu -l 0.0008942480821014569 -o hyperband_runs_20241120_172038/run_s6_n146 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n146/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:46:11,080 - INFO - Training completed for config s6_n146:
  Training time: 0:00:47
  Final validation loss: 10.063644
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.45e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n146/checkpoint.bin
2024-11-20 20:46:11,081 - INFO - 
Configuration s6_n146 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008942480821014569",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n146",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n146/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.063644
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.45e-05
2024-11-20 20:46:11,081 - INFO - 
Starting training for config s6_n339:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n339/checkpoint.bin
2024-11-20 20:46:11,081 - INFO - Running command: ./train_gpt2cu -l 0.0008881775390564398 -o hyperband_runs_20241120_172038/run_s6_n339 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n339/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:46:58,886 - INFO - Training completed for config s6_n339:
  Training time: 0:00:47
  Final validation loss: 10.065087
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.43e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n339/checkpoint.bin
2024-11-20 20:46:58,886 - INFO - 
Configuration s6_n339 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008881775390564398",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n339",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n339/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.065087
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.43e-05
2024-11-20 20:46:58,887 - INFO - 
Starting training for config s6_n85:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n85/checkpoint.bin
2024-11-20 20:46:58,887 - INFO - Running command: ./train_gpt2cu -l 0.0008833451139763101 -o hyperband_runs_20241120_172038/run_s6_n85 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n85/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:47:46,680 - INFO - Training completed for config s6_n85:
  Training time: 0:00:47
  Final validation loss: 10.066148
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.41e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n85/checkpoint.bin
2024-11-20 20:47:46,681 - INFO - 
Configuration s6_n85 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008833451139763101",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n85",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n85/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.066148
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.41e-05
2024-11-20 20:47:46,681 - INFO - 
Starting training for config s6_n617:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n617/checkpoint.bin
2024-11-20 20:47:46,681 - INFO - Running command: ./train_gpt2cu -l 0.0008822222688470273 -o hyperband_runs_20241120_172038/run_s6_n617 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n617/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:48:34,463 - INFO - Training completed for config s6_n617:
  Training time: 0:00:47
  Final validation loss: 10.066419
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.40e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n617/checkpoint.bin
2024-11-20 20:48:34,463 - INFO - 
Configuration s6_n617 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008822222688470273",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n617",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n617/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.066419
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.40e-05
2024-11-20 20:48:34,464 - INFO - 
Starting training for config s6_n460:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n460/checkpoint.bin
2024-11-20 20:48:34,464 - INFO - Running command: ./train_gpt2cu -l 0.0008650173683974301 -o hyperband_runs_20241120_172038/run_s6_n460 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n460/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:49:22,278 - INFO - Training completed for config s6_n460:
  Training time: 0:00:47
  Final validation loss: 10.071711
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.34e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n460/checkpoint.bin
2024-11-20 20:49:22,279 - INFO - 
Configuration s6_n460 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008650173683974301",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n460",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n460/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.071711
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.34e-05
2024-11-20 20:49:22,279 - INFO - 
Starting training for config s6_n22:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n22/checkpoint.bin
2024-11-20 20:49:22,279 - INFO - Running command: ./train_gpt2cu -l 0.000859266840585978 -o hyperband_runs_20241120_172038/run_s6_n22 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n22/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:50:10,084 - INFO - Training completed for config s6_n22:
  Training time: 0:00:47
  Final validation loss: 10.073608
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.31e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n22/checkpoint.bin
2024-11-20 20:50:10,084 - INFO - 
Configuration s6_n22 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.000859266840585978",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n22",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n22/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.073608
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.31e-05
2024-11-20 20:50:10,085 - INFO - 
Starting training for config s6_n380:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n380/checkpoint.bin
2024-11-20 20:50:10,085 - INFO - Running command: ./train_gpt2cu -l 0.0008587527623389926 -o hyperband_runs_20241120_172038/run_s6_n380 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n380/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:50:57,869 - INFO - Training completed for config s6_n380:
  Training time: 0:00:47
  Final validation loss: 10.073763
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.31e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n380/checkpoint.bin
2024-11-20 20:50:57,869 - INFO - 
Configuration s6_n380 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008587527623389926",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n380",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n380/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.073763
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.31e-05
2024-11-20 20:50:57,869 - INFO - 
Starting training for config s6_n154:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n154/checkpoint.bin
2024-11-20 20:50:57,869 - INFO - Running command: ./train_gpt2cu -l 0.0008562517308020131 -o hyperband_runs_20241120_172038/run_s6_n154 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n154/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:51:45,663 - INFO - Training completed for config s6_n154:
  Training time: 0:00:47
  Final validation loss: 10.074454
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.30e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n154/checkpoint.bin
2024-11-20 20:51:45,663 - INFO - 
Configuration s6_n154 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008562517308020131",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n154",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n154/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.074454
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.30e-05
2024-11-20 20:51:45,663 - INFO - 
Starting training for config s6_n420:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n420/checkpoint.bin
2024-11-20 20:51:45,663 - INFO - Running command: ./train_gpt2cu -l 0.0008560188308167667 -o hyperband_runs_20241120_172038/run_s6_n420 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n420/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:52:33,464 - INFO - Training completed for config s6_n420:
  Training time: 0:00:47
  Final validation loss: 10.074511
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.30e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n420/checkpoint.bin
2024-11-20 20:52:33,464 - INFO - 
Configuration s6_n420 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008560188308167667",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n420",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n420/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.074511
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.30e-05
2024-11-20 20:52:33,464 - INFO - 
Starting training for config s6_n540:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n540/checkpoint.bin
2024-11-20 20:52:33,464 - INFO - Running command: ./train_gpt2cu -l 0.0008554037131933193 -o hyperband_runs_20241120_172038/run_s6_n540 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n540/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:53:21,265 - INFO - Training completed for config s6_n540:
  Training time: 0:00:47
  Final validation loss: 10.074651
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.30e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n540/checkpoint.bin
2024-11-20 20:53:21,265 - INFO - 
Configuration s6_n540 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008554037131933193",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n540",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n540/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.074651
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.30e-05
2024-11-20 20:53:21,265 - INFO - 
Starting training for config s6_n234:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n234/checkpoint.bin
2024-11-20 20:53:21,265 - INFO - Running command: ./train_gpt2cu -l 0.000853428541786053 -o hyperband_runs_20241120_172038/run_s6_n234 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n234/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:54:09,068 - INFO - Training completed for config s6_n234:
  Training time: 0:00:47
  Final validation loss: 10.075165
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.29e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n234/checkpoint.bin
2024-11-20 20:54:09,069 - INFO - 
Configuration s6_n234 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.000853428541786053",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n234",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n234/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.075165
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.29e-05
2024-11-20 20:54:09,069 - INFO - 
Starting training for config s6_n167:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n167/checkpoint.bin
2024-11-20 20:54:09,069 - INFO - Running command: ./train_gpt2cu -l 0.0008525192676792822 -o hyperband_runs_20241120_172038/run_s6_n167 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n167/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:54:56,864 - INFO - Training completed for config s6_n167:
  Training time: 0:00:47
  Final validation loss: 10.075368
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.29e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n167/checkpoint.bin
2024-11-20 20:54:56,864 - INFO - 
Configuration s6_n167 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008525192676792822",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n167",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n167/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.075368
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.29e-05
2024-11-20 20:54:56,865 - INFO - 
Starting training for config s6_n173:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n173/checkpoint.bin
2024-11-20 20:54:56,865 - INFO - Running command: ./train_gpt2cu -l 0.0008431900534300434 -o hyperband_runs_20241120_172038/run_s6_n173 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n173/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:55:44,679 - INFO - Training completed for config s6_n173:
  Training time: 0:00:47
  Final validation loss: 10.077513
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.25e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n173/checkpoint.bin
2024-11-20 20:55:44,679 - INFO - 
Configuration s6_n173 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008431900534300434",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n173",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n173/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.077513
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.25e-05
2024-11-20 20:55:44,679 - INFO - 
Starting training for config s6_n42:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n42/checkpoint.bin
2024-11-20 20:55:44,679 - INFO - Running command: ./train_gpt2cu -l 0.0008427581488465726 -o hyperband_runs_20241120_172038/run_s6_n42 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s6_n42/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:56:32,485 - INFO - Training completed for config s6_n42:
  Training time: 0:00:47
  Final validation loss: 10.077614
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.25e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n42/checkpoint.bin
2024-11-20 20:56:32,485 - INFO - 
Configuration s6_n42 (bracket_6_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008427581488465726",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n42",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n42/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.077614
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.25e-05
2024-11-20 20:56:32,486 - INFO - 
Eliminating 18 configurations:
  Surviving: 9
2024-11-20 20:56:35,114 - INFO - 
Bracket 6, Round 4:
  Active configs: 9
  Iterations: 81
2024-11-20 20:56:35,114 - INFO - 
Starting training for config s6_n0:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin
2024-11-20 20:56:35,114 - INFO - Running command: ./train_gpt2cu -l 0.0009977479607140977 -o hyperband_runs_20241120_172038/run_s6_n0 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 20:58:45,669 - INFO - Training completed for config s6_n0:
  Training time: 0:02:10
  Final validation loss: 8.288469
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.15e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin
2024-11-20 20:58:45,670 - INFO - 
Configuration s6_n0 (bracket_6_round_4):
  Hyperparameters: {
  "learning_rate": "0.0009977479607140977",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n0",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.288469
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.15e-04
2024-11-20 20:58:45,670 - INFO - 
New best configuration found!
  Config ID: s6_n0
  Validation Loss: 8.288469
  Hellaswag Accuracy: 0.00%
  Training Time: 0:02:10
2024-11-20 20:58:45,670 - INFO - 
Starting training for config s6_n452:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin
2024-11-20 20:58:45,670 - INFO - Running command: ./train_gpt2cu -l 0.0009894839327752709 -o hyperband_runs_20241120_172038/run_s6_n452 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 21:00:56,473 - INFO - Training completed for config s6_n452:
  Training time: 0:02:10
  Final validation loss: 8.299397
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.14e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin
2024-11-20 21:00:56,473 - INFO - 
Configuration s6_n452 (bracket_6_round_4):
  Hyperparameters: {
  "learning_rate": "0.0009894839327752709",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n452",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.299397
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.14e-04
2024-11-20 21:00:56,473 - INFO - 
Starting training for config s6_n610:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin
2024-11-20 21:00:56,474 - INFO - Running command: ./train_gpt2cu -l 0.0009840193661966614 -o hyperband_runs_20241120_172038/run_s6_n610 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 21:03:07,029 - INFO - Training completed for config s6_n610:
  Training time: 0:02:10
  Final validation loss: 8.306808
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.14e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin
2024-11-20 21:03:07,030 - INFO - 
Configuration s6_n610 (bracket_6_round_4):
  Hyperparameters: {
  "learning_rate": "0.0009840193661966614",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n610",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.306808
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.14e-04
2024-11-20 21:03:07,030 - INFO - 
Starting training for config s6_n334:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin
2024-11-20 21:03:07,030 - INFO - Running command: ./train_gpt2cu -l 0.00097968892904061 -o hyperband_runs_20241120_172038/run_s6_n334 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 21:05:17,829 - INFO - Training completed for config s6_n334:
  Training time: 0:02:10
  Final validation loss: 8.312685
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.13e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin
2024-11-20 21:05:17,830 - INFO - 
Configuration s6_n334 (bracket_6_round_4):
  Hyperparameters: {
  "learning_rate": "0.00097968892904061",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n334",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n334/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.312685
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.13e-04
2024-11-20 21:05:17,830 - INFO - 
Starting training for config s6_n553:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin
2024-11-20 21:05:17,830 - INFO - Running command: ./train_gpt2cu -l 0.0009757562917808082 -o hyperband_runs_20241120_172038/run_s6_n553 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 21:07:28,424 - INFO - Training completed for config s6_n553:
  Training time: 0:02:10
  Final validation loss: 8.318051
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.13e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin
2024-11-20 21:07:28,425 - INFO - 
Configuration s6_n553 (bracket_6_round_4):
  Hyperparameters: {
  "learning_rate": "0.0009757562917808082",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n553",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n553/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.318051
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.13e-04
2024-11-20 21:07:28,425 - INFO - 
Starting training for config s6_n37:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin
2024-11-20 21:07:28,425 - INFO - Running command: ./train_gpt2cu -l 0.0009748120712873382 -o hyperband_runs_20241120_172038/run_s6_n37 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 21:09:39,013 - INFO - Training completed for config s6_n37:
  Training time: 0:02:10
  Final validation loss: 8.319360
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.13e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin
2024-11-20 21:09:39,013 - INFO - 
Configuration s6_n37 (bracket_6_round_4):
  Hyperparameters: {
  "learning_rate": "0.0009748120712873382",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n37",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n37/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.319360
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.13e-04
2024-11-20 21:09:39,013 - INFO - 
Starting training for config s6_n496:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin
2024-11-20 21:09:39,013 - INFO - Running command: ./train_gpt2cu -l 0.0009743088881485038 -o hyperband_runs_20241120_172038/run_s6_n496 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 21:11:49,578 - INFO - Training completed for config s6_n496:
  Training time: 0:02:10
  Final validation loss: 8.320097
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.13e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin
2024-11-20 21:11:49,578 - INFO - 
Configuration s6_n496 (bracket_6_round_4):
  Hyperparameters: {
  "learning_rate": "0.0009743088881485038",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n496",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n496/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.320097
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.13e-04
2024-11-20 21:11:49,578 - INFO - 
Starting training for config s6_n3:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin
2024-11-20 21:11:49,578 - INFO - Running command: ./train_gpt2cu -l 0.0009583333644205056 -o hyperband_runs_20241120_172038/run_s6_n3 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 21:14:00,167 - INFO - Training completed for config s6_n3:
  Training time: 0:02:10
  Final validation loss: 8.341743
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.11e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin
2024-11-20 21:14:00,167 - INFO - 
Configuration s6_n3 (bracket_6_round_4):
  Hyperparameters: {
  "learning_rate": "0.0009583333644205056",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n3",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n3/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.341743
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.11e-04
2024-11-20 21:14:00,167 - INFO - 
Starting training for config s6_n561:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin
2024-11-20 21:14:00,167 - INFO - Running command: ./train_gpt2cu -l 0.0009466935556371588 -o hyperband_runs_20241120_172038/run_s6_n561 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 21:16:10,744 - INFO - Training completed for config s6_n561:
  Training time: 0:02:10
  Final validation loss: 8.357539
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.10e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin
2024-11-20 21:16:10,744 - INFO - 
Configuration s6_n561 (bracket_6_round_4):
  Hyperparameters: {
  "learning_rate": "0.0009466935556371588",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n561",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n561/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.357539
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-04
2024-11-20 21:16:10,744 - INFO - 
Eliminating 6 configurations:
  Surviving: 3
2024-11-20 21:16:11,980 - INFO - 
Bracket 6, Round 5:
  Active configs: 3
  Iterations: 243
2024-11-20 21:16:11,981 - INFO - 
Starting training for config s6_n0:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin
2024-11-20 21:16:11,981 - INFO - Running command: ./train_gpt2cu -l 0.0009977479607140977 -o hyperband_runs_20241120_172038/run_s6_n0 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 21:22:29,167 - INFO - Training completed for config s6_n0:
  Training time: 0:06:17
  Final validation loss: 6.348488
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 3.46e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin
2024-11-20 21:22:29,168 - INFO - 
Configuration s6_n0 (bracket_6_round_5):
  Hyperparameters: {
  "learning_rate": "0.0009977479607140977",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n0",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n0/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.348488
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.46e-04
2024-11-20 21:22:29,168 - INFO - 
New best configuration found!
  Config ID: s6_n0
  Validation Loss: 6.348488
  Hellaswag Accuracy: 0.00%
  Training Time: 0:06:17
2024-11-20 21:22:29,168 - INFO - 
Starting training for config s6_n452:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin
2024-11-20 21:22:29,168 - INFO - Running command: ./train_gpt2cu -l 0.0009894839327752709 -o hyperband_runs_20241120_172038/run_s6_n452 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 21:28:46,385 - INFO - Training completed for config s6_n452:
  Training time: 0:06:17
  Final validation loss: 6.346338
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 3.43e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin
2024-11-20 21:28:46,385 - INFO - 
Configuration s6_n452 (bracket_6_round_5):
  Hyperparameters: {
  "learning_rate": "0.0009894839327752709",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n452",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n452/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.346338
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.43e-04
2024-11-20 21:28:46,386 - INFO - 
New best configuration found!
  Config ID: s6_n452
  Validation Loss: 6.346338
  Hellaswag Accuracy: 0.00%
  Training Time: 0:06:17
2024-11-20 21:28:46,386 - INFO - 
Starting training for config s6_n610:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin
2024-11-20 21:28:46,386 - INFO - Running command: ./train_gpt2cu -l 0.0009840193661966614 -o hyperband_runs_20241120_172038/run_s6_n610 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 21:35:03,625 - INFO - Training completed for config s6_n610:
  Training time: 0:06:17
  Final validation loss: 6.337605
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 3.42e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin
2024-11-20 21:35:03,625 - INFO - 
Configuration s6_n610 (bracket_6_round_5):
  Hyperparameters: {
  "learning_rate": "0.0009840193661966614",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n610",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.337605
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.42e-04
2024-11-20 21:35:03,625 - INFO - 
New best configuration found!
  Config ID: s6_n610
  Validation Loss: 6.337605
  Hellaswag Accuracy: 0.00%
  Training Time: 0:06:17
2024-11-20 21:35:03,625 - INFO - 
Eliminating 2 configurations:
  Surviving: 1
2024-11-20 21:35:04,306 - INFO - 
Bracket 6, Round 6:
  Active configs: 1
  Iterations: 729
2024-11-20 21:35:04,306 - INFO - 
Starting training for config s6_n610:
  Iterations: 729
  Previous iterations: 243
  Previous checkpoint: hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin
2024-11-20 21:35:04,306 - INFO - Running command: ./train_gpt2cu -l 0.0009840193661966614 -o hyperband_runs_20241120_172038/run_s6_n610 -x 729 -n 729 -y 1 -e hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 21:35:05,153 - ERROR - Error training config s6_n610:
  stdout: Multi-GPU support is disabled. Using a single GPU.
+-----------------------+----------------------------------------------------+
| Parameter             | Value                                              |
+-----------------------+----------------------------------------------------+
| train data pattern    | data/fineweb_train_*.bin                           |
| val data pattern      | data/fineweb_val_*.bin                             |
| output log dir        | hyperband_runs_20241120_172038/run_s6_n610         |
| checkpoint_every      | 729                                                |
| resume                | 1                                                  |
| micro batch size B    | 64                                                 |
| sequence length T     | 1024                                               |
| total batch size      | 524288                                             |
| LR scheduler          | cosine                                             |
| learning rate (LR)    | 9.840194e-04                                       |
| warmup iterations     | 700                                                |
| final LR fraction     | 0.000000e+00                                       |
| weight decay          | 1.000000e-01                                       |
| skip update lossz     | 0.000000                                           |
| skip update gradz     | 0.000000                                           |
| max_steps             | 729                                                |
| val_loss_every        | 250                                                |
| val_max_steps         | 20                                                 |
| sample_every          | 20000                                              |
| genT                  | 64                                                 |
| overfit_single_batch  | 0                                                  |
| use_master_weights    | enabled                                            |
| gelu_fusion           | 0                                                  |
| recompute             | 1                                                  |
+-----------------------+----------------------------------------------------+
| device                | NVIDIA A10G                                        |
| peak TFlops           | -1.0                                               |
| precision             | BF16                                               |
+-----------------------+----------------------------------------------------+
| weight init method    | intermediate checkpoint                            |
| max_sequence_length T | 1024                                               |
| vocab_size V          | 50257                                              |
| padded_vocab_size Vp  | 50304                                              |
| num_layers L          | 6                                                  |
| num_heads NH          | 6                                                  |
| channels C            | 384                                                |
| num_parameters        | 30357504                                           |
+-----------------------+----------------------------------------------------+
| train_num_batches     | 729                                                |
| val_num_batches       | 20                                                 |
+-----------------------+----------------------------------------------------+
| run hellaswag         | no                                                 |
+-----------------------+----------------------------------------------------+
| num_processes         | 1                                                  |
| zero_stage            | 1                                                  |
+-----------------------+----------------------------------------------------+
num_parameters: 30357504 => bytes: 60715008
allocated 57 MiB for model parameters
batch_size B=64 * seq_len T=1024 * num_processes=1 and total_batch_size=524288
=> setting gr
  stderr: train_gpt2cu: train_gpt2.cu:1246: void load_state(int*, GPT2*, DataLoader*, const char*): Assertion `shard_num_samples == loader->shard_num_samples' failed.

2024-11-20 21:35:05,153 - INFO - 
Configuration s6_n610 (bracket_6_round_6):
  Hyperparameters: {
  "learning_rate": "0.0009840193661966614",
  "output_dir": "hyperband_runs_20241120_172038/run_s6_n610",
  "max_steps": "729",
  "checkpoint_every": "729",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s6_n610/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 729
  Total iterations: 243
  Training time: 0:00:00
  Validation Loss: inf
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 0.00e+00
2024-11-20 21:35:05,153 - INFO - 
Bracket 5:
  Initial configurations: 284
  Initial iterations: 3
2024-11-20 21:35:05,155 - INFO - 
Bracket 5, Round 0:
  Active configs: 284
  Iterations: 3
2024-11-20 21:35:05,155 - INFO - 
Starting training for config s5_n0:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:35:05,156 - INFO - Running command: ./train_gpt2cu -l 0.0003738016455208007 -o hyperband_runs_20241120_172038/run_s5_n0 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:35:19,912 - INFO - Training completed for config s5_n0:
  Training time: 0:00:14
  Final validation loss: 10.884232
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.60e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n0/checkpoint.bin
2024-11-20 21:35:19,912 - INFO - 
Configuration s5_n0 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003738016455208007",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n0",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.884232
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.60e-06
2024-11-20 21:35:19,912 - INFO - 
Starting training for config s5_n1:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:35:19,912 - INFO - Running command: ./train_gpt2cu -l 0.0003259694209443947 -o hyperband_runs_20241120_172038/run_s5_n1 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:35:34,453 - INFO - Training completed for config s5_n1:
  Training time: 0:00:14
  Final validation loss: 10.887744
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.40e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n1/checkpoint.bin
2024-11-20 21:35:34,453 - INFO - 
Configuration s5_n1 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003259694209443947",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n1",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.887744
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.40e-06
2024-11-20 21:35:34,454 - INFO - 
Starting training for config s5_n2:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:35:34,454 - INFO - Running command: ./train_gpt2cu -l 2.9813064542641045e-05 -o hyperband_runs_20241120_172038/run_s5_n2 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:35:48,967 - INFO - Training completed for config s5_n2:
  Training time: 0:00:14
  Final validation loss: 10.909426
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.28e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n2/checkpoint.bin
2024-11-20 21:35:48,967 - INFO - 
Configuration s5_n2 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.9813064542641045e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n2",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909426
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.28e-07
2024-11-20 21:35:48,967 - INFO - 
Starting training for config s5_n3:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:35:48,967 - INFO - Running command: ./train_gpt2cu -l 8.438017382736337e-05 -o hyperband_runs_20241120_172038/run_s5_n3 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:36:03,469 - INFO - Training completed for config s5_n3:
  Training time: 0:00:14
  Final validation loss: 10.905420
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.62e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n3/checkpoint.bin
2024-11-20 21:36:03,469 - INFO - 
Configuration s5_n3 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "8.438017382736337e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n3",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.905420
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.62e-07
2024-11-20 21:36:03,469 - INFO - 
Starting training for config s5_n4:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:36:03,469 - INFO - Running command: ./train_gpt2cu -l 5.387504084060661e-05 -o hyperband_runs_20241120_172038/run_s5_n4 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:36:17,962 - INFO - Training completed for config s5_n4:
  Training time: 0:00:14
  Final validation loss: 10.907651
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.31e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n4/checkpoint.bin
2024-11-20 21:36:17,962 - INFO - 
Configuration s5_n4 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "5.387504084060661e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n4",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.907651
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.31e-07
2024-11-20 21:36:17,962 - INFO - 
Starting training for config s5_n5:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:36:17,962 - INFO - Running command: ./train_gpt2cu -l 7.375443820370712e-05 -o hyperband_runs_20241120_172038/run_s5_n5 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:36:32,456 - INFO - Training completed for config s5_n5:
  Training time: 0:00:14
  Final validation loss: 10.906191
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.16e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n5/checkpoint.bin
2024-11-20 21:36:32,456 - INFO - 
Configuration s5_n5 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "7.375443820370712e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n5",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.906191
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.16e-07
2024-11-20 21:36:32,456 - INFO - 
Starting training for config s5_n6:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:36:32,456 - INFO - Running command: ./train_gpt2cu -l 4.2969517278906945e-05 -o hyperband_runs_20241120_172038/run_s5_n6 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:36:46,964 - INFO - Training completed for config s5_n6:
  Training time: 0:00:14
  Final validation loss: 10.908445
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.84e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n6/checkpoint.bin
2024-11-20 21:36:46,964 - INFO - 
Configuration s5_n6 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "4.2969517278906945e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n6",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.908445
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.84e-07
2024-11-20 21:36:46,964 - INFO - 
Starting training for config s5_n7:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:36:46,964 - INFO - Running command: ./train_gpt2cu -l 0.0006236868598086687 -o hyperband_runs_20241120_172038/run_s5_n7 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:37:01,466 - INFO - Training completed for config s5_n7:
  Training time: 0:00:14
  Final validation loss: 10.866081
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.67e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n7/checkpoint.bin
2024-11-20 21:37:01,466 - INFO - 
Configuration s5_n7 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006236868598086687",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n7",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.866081
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.67e-06
2024-11-20 21:37:01,466 - INFO - 
Starting training for config s5_n8:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:37:01,466 - INFO - Running command: ./train_gpt2cu -l 6.567051823399147e-05 -o hyperband_runs_20241120_172038/run_s5_n8 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:37:15,995 - INFO - Training completed for config s5_n8:
  Training time: 0:00:14
  Final validation loss: 10.906799
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.81e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n8/checkpoint.bin
2024-11-20 21:37:15,996 - INFO - 
Configuration s5_n8 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "6.567051823399147e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n8",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.906799
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.81e-07
2024-11-20 21:37:15,996 - INFO - 
Starting training for config s5_n9:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:37:15,996 - INFO - Running command: ./train_gpt2cu -l 0.0008687906691256375 -o hyperband_runs_20241120_172038/run_s5_n9 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:37:30,494 - INFO - Training completed for config s5_n9:
  Training time: 0:00:14
  Final validation loss: 10.848440
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.72e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n9/checkpoint.bin
2024-11-20 21:37:30,495 - INFO - 
Configuration s5_n9 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008687906691256375",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n9",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.848440
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.72e-06
2024-11-20 21:37:30,495 - INFO - 
Starting training for config s5_n10:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:37:30,495 - INFO - Running command: ./train_gpt2cu -l 2.8419297061170544e-05 -o hyperband_runs_20241120_172038/run_s5_n10 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:37:44,987 - INFO - Training completed for config s5_n10:
  Training time: 0:00:14
  Final validation loss: 10.909529
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.22e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n10/checkpoint.bin
2024-11-20 21:37:44,987 - INFO - 
Configuration s5_n10 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.8419297061170544e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n10",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909529
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.22e-07
2024-11-20 21:37:44,987 - INFO - 
Starting training for config s5_n11:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:37:44,987 - INFO - Running command: ./train_gpt2cu -l 0.000303173109497266 -o hyperband_runs_20241120_172038/run_s5_n11 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:37:59,488 - INFO - Training completed for config s5_n11:
  Training time: 0:00:14
  Final validation loss: 10.889413
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.30e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n11/checkpoint.bin
2024-11-20 21:37:59,488 - INFO - 
Configuration s5_n11 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.000303173109497266",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n11",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.889413
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.30e-06
2024-11-20 21:37:59,488 - INFO - 
Starting training for config s5_n12:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:37:59,488 - INFO - Running command: ./train_gpt2cu -l 0.00012192068903068377 -o hyperband_runs_20241120_172038/run_s5_n12 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:38:13,951 - INFO - Training completed for config s5_n12:
  Training time: 0:00:14
  Final validation loss: 10.902670
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.23e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n12/checkpoint.bin
2024-11-20 21:38:13,952 - INFO - 
Configuration s5_n12 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012192068903068377",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n12",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.902670
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.23e-07
2024-11-20 21:38:13,952 - INFO - 
Starting training for config s5_n13:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:38:13,952 - INFO - Running command: ./train_gpt2cu -l 0.000522387932881555 -o hyperband_runs_20241120_172038/run_s5_n13 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:38:28,455 - INFO - Training completed for config s5_n13:
  Training time: 0:00:14
  Final validation loss: 10.873414
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.24e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n13/checkpoint.bin
2024-11-20 21:38:28,455 - INFO - 
Configuration s5_n13 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.000522387932881555",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n13",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.873414
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.24e-06
2024-11-20 21:38:28,455 - INFO - 
Starting training for config s5_n14:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:38:28,455 - INFO - Running command: ./train_gpt2cu -l 0.0005562905470579442 -o hyperband_runs_20241120_172038/run_s5_n14 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:38:42,924 - INFO - Training completed for config s5_n14:
  Training time: 0:00:14
  Final validation loss: 10.870966
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.38e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n14/checkpoint.bin
2024-11-20 21:38:42,924 - INFO - 
Configuration s5_n14 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005562905470579442",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n14",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.870966
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.38e-06
2024-11-20 21:38:42,924 - INFO - 
Starting training for config s5_n15:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:38:42,924 - INFO - Running command: ./train_gpt2cu -l 0.000381333528879859 -o hyperband_runs_20241120_172038/run_s5_n15 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:38:57,414 - INFO - Training completed for config s5_n15:
  Training time: 0:00:14
  Final validation loss: 10.883683
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.63e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n15/checkpoint.bin
2024-11-20 21:38:57,415 - INFO - 
Configuration s5_n15 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.000381333528879859",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n15",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.883683
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.63e-06
2024-11-20 21:38:57,415 - INFO - 
Starting training for config s5_n16:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:38:57,415 - INFO - Running command: ./train_gpt2cu -l 0.0002722711815511042 -o hyperband_runs_20241120_172038/run_s5_n16 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:39:11,918 - INFO - Training completed for config s5_n16:
  Training time: 0:00:14
  Final validation loss: 10.891664
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.17e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n16/checkpoint.bin
2024-11-20 21:39:11,918 - INFO - 
Configuration s5_n16 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002722711815511042",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n16",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.891664
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.17e-06
2024-11-20 21:39:11,918 - INFO - 
Starting training for config s5_n17:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:39:11,919 - INFO - Running command: ./train_gpt2cu -l 2.3619257445243182e-05 -o hyperband_runs_20241120_172038/run_s5_n17 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:39:26,424 - INFO - Training completed for config s5_n17:
  Training time: 0:00:14
  Final validation loss: 10.909876
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.01e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n17/checkpoint.bin
2024-11-20 21:39:26,424 - INFO - 
Configuration s5_n17 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.3619257445243182e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n17",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909876
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.01e-07
2024-11-20 21:39:26,424 - INFO - 
Starting training for config s5_n18:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:39:26,424 - INFO - Running command: ./train_gpt2cu -l 0.00022246964268314364 -o hyperband_runs_20241120_172038/run_s5_n18 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:39:40,912 - INFO - Training completed for config s5_n18:
  Training time: 0:00:14
  Final validation loss: 10.895312
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.53e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n18/checkpoint.bin
2024-11-20 21:39:40,912 - INFO - 
Configuration s5_n18 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00022246964268314364",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n18",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.895312
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.53e-07
2024-11-20 21:39:40,912 - INFO - 
Starting training for config s5_n19:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:39:40,912 - INFO - Running command: ./train_gpt2cu -l 1.7511736335545104e-05 -o hyperband_runs_20241120_172038/run_s5_n19 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:39:55,433 - INFO - Training completed for config s5_n19:
  Training time: 0:00:14
  Final validation loss: 10.910314
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.51e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n19/checkpoint.bin
2024-11-20 21:39:55,433 - INFO - 
Configuration s5_n19 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.7511736335545104e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n19",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910314
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.51e-08
2024-11-20 21:39:55,433 - INFO - 
Starting training for config s5_n20:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:39:55,433 - INFO - Running command: ./train_gpt2cu -l 0.00014269484494382263 -o hyperband_runs_20241120_172038/run_s5_n20 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:40:09,955 - INFO - Training completed for config s5_n20:
  Training time: 0:00:14
  Final validation loss: 10.901137
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.12e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n20/checkpoint.bin
2024-11-20 21:40:09,955 - INFO - 
Configuration s5_n20 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014269484494382263",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n20",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.901137
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.12e-07
2024-11-20 21:40:09,955 - INFO - 
Starting training for config s5_n21:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:40:09,955 - INFO - Running command: ./train_gpt2cu -l 1.7326221547250407e-05 -o hyperband_runs_20241120_172038/run_s5_n21 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:40:24,437 - INFO - Training completed for config s5_n21:
  Training time: 0:00:14
  Final validation loss: 10.910336
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.43e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n21/checkpoint.bin
2024-11-20 21:40:24,438 - INFO - 
Configuration s5_n21 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.7326221547250407e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n21",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910336
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.43e-08
2024-11-20 21:40:24,438 - INFO - 
Starting training for config s5_n22:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:40:24,438 - INFO - Running command: ./train_gpt2cu -l 3.8197252415812014e-05 -o hyperband_runs_20241120_172038/run_s5_n22 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:40:38,949 - INFO - Training completed for config s5_n22:
  Training time: 0:00:14
  Final validation loss: 10.908814
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.64e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n22/checkpoint.bin
2024-11-20 21:40:38,949 - INFO - 
Configuration s5_n22 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.8197252415812014e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n22",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.908814
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.64e-07
2024-11-20 21:40:38,949 - INFO - 
Starting training for config s5_n23:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:40:38,949 - INFO - Running command: ./train_gpt2cu -l 9.172937956194915e-05 -o hyperband_runs_20241120_172038/run_s5_n23 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:40:53,462 - INFO - Training completed for config s5_n23:
  Training time: 0:00:14
  Final validation loss: 10.904882
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.93e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n23/checkpoint.bin
2024-11-20 21:40:53,463 - INFO - 
Configuration s5_n23 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "9.172937956194915e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n23",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.904882
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.93e-07
2024-11-20 21:40:53,463 - INFO - 
Starting training for config s5_n24:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:40:53,463 - INFO - Running command: ./train_gpt2cu -l 0.0007944281434975066 -o hyperband_runs_20241120_172038/run_s5_n24 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:41:07,957 - INFO - Training completed for config s5_n24:
  Training time: 0:00:14
  Final validation loss: 10.853742
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.40e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n24/checkpoint.bin
2024-11-20 21:41:07,957 - INFO - 
Configuration s5_n24 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007944281434975066",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n24",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.853742
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.40e-06
2024-11-20 21:41:07,957 - INFO - 
Starting training for config s5_n25:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:41:07,957 - INFO - Running command: ./train_gpt2cu -l 0.0001923404660084201 -o hyperband_runs_20241120_172038/run_s5_n25 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:41:22,440 - INFO - Training completed for config s5_n25:
  Training time: 0:00:14
  Final validation loss: 10.897518
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 8.24e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n25/checkpoint.bin
2024-11-20 21:41:22,440 - INFO - 
Configuration s5_n25 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001923404660084201",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n25",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.897518
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.24e-07
2024-11-20 21:41:22,440 - INFO - 
Starting training for config s5_n26:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:41:22,440 - INFO - Running command: ./train_gpt2cu -l 9.489666544097682e-05 -o hyperband_runs_20241120_172038/run_s5_n26 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:41:36,938 - INFO - Training completed for config s5_n26:
  Training time: 0:00:14
  Final validation loss: 10.904657
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.07e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n26/checkpoint.bin
2024-11-20 21:41:36,938 - INFO - 
Configuration s5_n26 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "9.489666544097682e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n26",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.904657
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.07e-07
2024-11-20 21:41:36,938 - INFO - 
Starting training for config s5_n27:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:41:36,938 - INFO - Running command: ./train_gpt2cu -l 2.7162253438318094e-05 -o hyperband_runs_20241120_172038/run_s5_n27 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:41:51,431 - INFO - Training completed for config s5_n27:
  Training time: 0:00:14
  Final validation loss: 10.909601
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.16e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n27/checkpoint.bin
2024-11-20 21:41:51,431 - INFO - 
Configuration s5_n27 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.7162253438318094e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n27",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909601
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.16e-07
2024-11-20 21:41:51,431 - INFO - 
Starting training for config s5_n28:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:41:51,432 - INFO - Running command: ./train_gpt2cu -l 1.379175628326211e-05 -o hyperband_runs_20241120_172038/run_s5_n28 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:42:05,944 - INFO - Training completed for config s5_n28:
  Training time: 0:00:14
  Final validation loss: 10.910588
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.91e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n28/checkpoint.bin
2024-11-20 21:42:05,944 - INFO - 
Configuration s5_n28 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.379175628326211e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n28",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910588
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.91e-08
2024-11-20 21:42:05,945 - INFO - 
Starting training for config s5_n29:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:42:05,945 - INFO - Running command: ./train_gpt2cu -l 0.0007043818706256417 -o hyperband_runs_20241120_172038/run_s5_n29 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:42:20,600 - INFO - Training completed for config s5_n29:
  Training time: 0:00:14
  Final validation loss: 10.860234
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.02e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n29/checkpoint.bin
2024-11-20 21:42:20,601 - INFO - 
Configuration s5_n29 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007043818706256417",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n29",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.860234
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.02e-06
2024-11-20 21:42:20,601 - INFO - 
Starting training for config s5_n30:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:42:20,601 - INFO - Running command: ./train_gpt2cu -l 0.0006397357687444202 -o hyperband_runs_20241120_172038/run_s5_n30 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:42:35,114 - INFO - Training completed for config s5_n30:
  Training time: 0:00:14
  Final validation loss: 10.864903
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.74e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n30/checkpoint.bin
2024-11-20 21:42:35,114 - INFO - 
Configuration s5_n30 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006397357687444202",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n30",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.864903
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.74e-06
2024-11-20 21:42:35,114 - INFO - 
Starting training for config s5_n31:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:42:35,114 - INFO - Running command: ./train_gpt2cu -l 0.00011334119778624724 -o hyperband_runs_20241120_172038/run_s5_n31 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:42:49,687 - INFO - Training completed for config s5_n31:
  Training time: 0:00:14
  Final validation loss: 10.903295
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.86e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n31/checkpoint.bin
2024-11-20 21:42:49,687 - INFO - 
Configuration s5_n31 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00011334119778624724",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n31",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.903295
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.86e-07
2024-11-20 21:42:49,687 - INFO - 
Starting training for config s5_n32:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:42:49,687 - INFO - Running command: ./train_gpt2cu -l 0.000995514234701091 -o hyperband_runs_20241120_172038/run_s5_n32 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:43:04,318 - INFO - Training completed for config s5_n32:
  Training time: 0:00:14
  Final validation loss: 10.839397
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.27e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin
2024-11-20 21:43:04,319 - INFO - 
Configuration s5_n32 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.000995514234701091",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n32",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.839397
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.27e-06
2024-11-20 21:43:04,319 - INFO - 
Starting training for config s5_n33:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:43:04,319 - INFO - Running command: ./train_gpt2cu -l 0.00011426790242114513 -o hyperband_runs_20241120_172038/run_s5_n33 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:43:18,806 - INFO - Training completed for config s5_n33:
  Training time: 0:00:14
  Final validation loss: 10.903242
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.90e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n33/checkpoint.bin
2024-11-20 21:43:18,806 - INFO - 
Configuration s5_n33 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00011426790242114513",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n33",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.903242
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.90e-07
2024-11-20 21:43:18,806 - INFO - 
Starting training for config s5_n34:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:43:18,806 - INFO - Running command: ./train_gpt2cu -l 5.989778702783013e-05 -o hyperband_runs_20241120_172038/run_s5_n34 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:43:33,415 - INFO - Training completed for config s5_n34:
  Training time: 0:00:14
  Final validation loss: 10.907209
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.57e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n34/checkpoint.bin
2024-11-20 21:43:33,415 - INFO - 
Configuration s5_n34 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "5.989778702783013e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n34",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.907209
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.57e-07
2024-11-20 21:43:33,416 - INFO - 
Starting training for config s5_n35:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:43:33,416 - INFO - Running command: ./train_gpt2cu -l 3.4410235270081206e-05 -o hyperband_runs_20241120_172038/run_s5_n35 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:43:47,861 - INFO - Training completed for config s5_n35:
  Training time: 0:00:14
  Final validation loss: 10.909086
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.47e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n35/checkpoint.bin
2024-11-20 21:43:47,861 - INFO - 
Configuration s5_n35 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.4410235270081206e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n35",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909086
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.47e-07
2024-11-20 21:43:47,861 - INFO - 
Starting training for config s5_n36:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:43:47,861 - INFO - Running command: ./train_gpt2cu -l 1.6649569965032164e-05 -o hyperband_runs_20241120_172038/run_s5_n36 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:44:02,259 - INFO - Training completed for config s5_n36:
  Training time: 0:00:14
  Final validation loss: 10.910379
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.14e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n36/checkpoint.bin
2024-11-20 21:44:02,260 - INFO - 
Configuration s5_n36 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.6649569965032164e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n36",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910379
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.14e-08
2024-11-20 21:44:02,260 - INFO - 
Starting training for config s5_n37:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:44:02,260 - INFO - Running command: ./train_gpt2cu -l 6.954671100611996e-05 -o hyperband_runs_20241120_172038/run_s5_n37 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:44:16,661 - INFO - Training completed for config s5_n37:
  Training time: 0:00:14
  Final validation loss: 10.906505
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.98e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n37/checkpoint.bin
2024-11-20 21:44:16,662 - INFO - 
Configuration s5_n37 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "6.954671100611996e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n37",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.906505
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.98e-07
2024-11-20 21:44:16,662 - INFO - 
Starting training for config s5_n38:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:44:16,662 - INFO - Running command: ./train_gpt2cu -l 0.0002803865627598923 -o hyperband_runs_20241120_172038/run_s5_n38 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:44:31,066 - INFO - Training completed for config s5_n38:
  Training time: 0:00:14
  Final validation loss: 10.891087
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.20e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n38/checkpoint.bin
2024-11-20 21:44:31,066 - INFO - 
Configuration s5_n38 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002803865627598923",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n38",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.891087
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.20e-06
2024-11-20 21:44:31,066 - INFO - 
Starting training for config s5_n39:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:44:31,066 - INFO - Running command: ./train_gpt2cu -l 4.3748190298345646e-05 -o hyperband_runs_20241120_172038/run_s5_n39 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:44:45,479 - INFO - Training completed for config s5_n39:
  Training time: 0:00:14
  Final validation loss: 10.908383
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.87e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n39/checkpoint.bin
2024-11-20 21:44:45,480 - INFO - 
Configuration s5_n39 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "4.3748190298345646e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n39",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.908383
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.87e-07
2024-11-20 21:44:45,480 - INFO - 
Starting training for config s5_n40:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:44:45,480 - INFO - Running command: ./train_gpt2cu -l 1.9921088588347952e-05 -o hyperband_runs_20241120_172038/run_s5_n40 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:44:59,884 - INFO - Training completed for config s5_n40:
  Training time: 0:00:14
  Final validation loss: 10.910155
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 8.54e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n40/checkpoint.bin
2024-11-20 21:44:59,885 - INFO - 
Configuration s5_n40 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.9921088588347952e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n40",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910155
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.54e-08
2024-11-20 21:44:59,885 - INFO - 
Starting training for config s5_n41:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:44:59,885 - INFO - Running command: ./train_gpt2cu -l 1.8635490275323046e-05 -o hyperband_runs_20241120_172038/run_s5_n41 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:45:14,292 - INFO - Training completed for config s5_n41:
  Training time: 0:00:14
  Final validation loss: 10.910235
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.99e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n41/checkpoint.bin
2024-11-20 21:45:14,292 - INFO - 
Configuration s5_n41 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.8635490275323046e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n41",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910235
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.99e-08
2024-11-20 21:45:14,292 - INFO - 
Starting training for config s5_n42:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:45:14,292 - INFO - Running command: ./train_gpt2cu -l 3.195417349864532e-05 -o hyperband_runs_20241120_172038/run_s5_n42 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:45:28,682 - INFO - Training completed for config s5_n42:
  Training time: 0:00:14
  Final validation loss: 10.909263
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.37e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n42/checkpoint.bin
2024-11-20 21:45:28,683 - INFO - 
Configuration s5_n42 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.195417349864532e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n42",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909263
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.37e-07
2024-11-20 21:45:28,683 - INFO - 
Starting training for config s5_n43:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:45:28,683 - INFO - Running command: ./train_gpt2cu -l 0.0002944430343264675 -o hyperband_runs_20241120_172038/run_s5_n43 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:45:43,087 - INFO - Training completed for config s5_n43:
  Training time: 0:00:14
  Final validation loss: 10.890039
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.26e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n43/checkpoint.bin
2024-11-20 21:45:43,087 - INFO - 
Configuration s5_n43 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002944430343264675",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n43",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.890039
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.26e-06
2024-11-20 21:45:43,088 - INFO - 
Starting training for config s5_n44:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:45:43,088 - INFO - Running command: ./train_gpt2cu -l 9.268273943221615e-05 -o hyperband_runs_20241120_172038/run_s5_n44 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:45:57,488 - INFO - Training completed for config s5_n44:
  Training time: 0:00:14
  Final validation loss: 10.904818
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.97e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n44/checkpoint.bin
2024-11-20 21:45:57,488 - INFO - 
Configuration s5_n44 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "9.268273943221615e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n44",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.904818
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.97e-07
2024-11-20 21:45:57,489 - INFO - 
Starting training for config s5_n45:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:45:57,489 - INFO - Running command: ./train_gpt2cu -l 1.064430917361535e-05 -o hyperband_runs_20241120_172038/run_s5_n45 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:46:11,887 - INFO - Training completed for config s5_n45:
  Training time: 0:00:14
  Final validation loss: 10.910830
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.56e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n45/checkpoint.bin
2024-11-20 21:46:11,887 - INFO - 
Configuration s5_n45 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.064430917361535e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n45",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910830
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.56e-08
2024-11-20 21:46:11,887 - INFO - 
Starting training for config s5_n46:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:46:11,888 - INFO - Running command: ./train_gpt2cu -l 0.00016740411158063922 -o hyperband_runs_20241120_172038/run_s5_n46 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:46:26,303 - INFO - Training completed for config s5_n46:
  Training time: 0:00:14
  Final validation loss: 10.899329
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.17e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n46/checkpoint.bin
2024-11-20 21:46:26,303 - INFO - 
Configuration s5_n46 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00016740411158063922",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n46",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.899329
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.17e-07
2024-11-20 21:46:26,303 - INFO - 
Starting training for config s5_n47:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:46:26,303 - INFO - Running command: ./train_gpt2cu -l 9.46304610610392e-05 -o hyperband_runs_20241120_172038/run_s5_n47 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:46:40,733 - INFO - Training completed for config s5_n47:
  Training time: 0:00:14
  Final validation loss: 10.904676
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.06e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n47/checkpoint.bin
2024-11-20 21:46:40,733 - INFO - 
Configuration s5_n47 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "9.46304610610392e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n47",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.904676
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.06e-07
2024-11-20 21:46:40,733 - INFO - 
Starting training for config s5_n48:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:46:40,733 - INFO - Running command: ./train_gpt2cu -l 0.0007550602914635752 -o hyperband_runs_20241120_172038/run_s5_n48 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:46:55,134 - INFO - Training completed for config s5_n48:
  Training time: 0:00:14
  Final validation loss: 10.856569
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.24e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n48/checkpoint.bin
2024-11-20 21:46:55,135 - INFO - 
Configuration s5_n48 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007550602914635752",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n48",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.856569
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.24e-06
2024-11-20 21:46:55,135 - INFO - 
Starting training for config s5_n49:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:46:55,135 - INFO - Running command: ./train_gpt2cu -l 0.0001537995725181695 -o hyperband_runs_20241120_172038/run_s5_n49 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:47:09,541 - INFO - Training completed for config s5_n49:
  Training time: 0:00:14
  Final validation loss: 10.900328
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.59e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n49/checkpoint.bin
2024-11-20 21:47:09,542 - INFO - 
Configuration s5_n49 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001537995725181695",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n49",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.900328
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.59e-07
2024-11-20 21:47:09,542 - INFO - 
Starting training for config s5_n50:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:47:09,542 - INFO - Running command: ./train_gpt2cu -l 0.00013471376730695716 -o hyperband_runs_20241120_172038/run_s5_n50 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:47:23,967 - INFO - Training completed for config s5_n50:
  Training time: 0:00:14
  Final validation loss: 10.901712
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.77e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n50/checkpoint.bin
2024-11-20 21:47:23,967 - INFO - 
Configuration s5_n50 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013471376730695716",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n50",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.901712
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.77e-07
2024-11-20 21:47:23,967 - INFO - 
Starting training for config s5_n51:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:47:23,967 - INFO - Running command: ./train_gpt2cu -l 0.0009968572861830537 -o hyperband_runs_20241120_172038/run_s5_n51 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:47:38,382 - INFO - Training completed for config s5_n51:
  Training time: 0:00:14
  Final validation loss: 10.839301
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.27e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin
2024-11-20 21:47:38,382 - INFO - 
Configuration s5_n51 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009968572861830537",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n51",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.839301
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.27e-06
2024-11-20 21:47:38,382 - INFO - 
Starting training for config s5_n52:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:47:38,382 - INFO - Running command: ./train_gpt2cu -l 0.0006679558460799921 -o hyperband_runs_20241120_172038/run_s5_n52 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:47:52,787 - INFO - Training completed for config s5_n52:
  Training time: 0:00:14
  Final validation loss: 10.862875
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.86e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n52/checkpoint.bin
2024-11-20 21:47:52,788 - INFO - 
Configuration s5_n52 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006679558460799921",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n52",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.862875
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.86e-06
2024-11-20 21:47:52,788 - INFO - 
Starting training for config s5_n53:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:47:52,788 - INFO - Running command: ./train_gpt2cu -l 0.00021262534966431636 -o hyperband_runs_20241120_172038/run_s5_n53 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:48:07,196 - INFO - Training completed for config s5_n53:
  Training time: 0:00:14
  Final validation loss: 10.896018
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.11e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n53/checkpoint.bin
2024-11-20 21:48:07,196 - INFO - 
Configuration s5_n53 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00021262534966431636",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n53",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.896018
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.11e-07
2024-11-20 21:48:07,197 - INFO - 
Starting training for config s5_n54:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:48:07,197 - INFO - Running command: ./train_gpt2cu -l 2.8070970079514815e-05 -o hyperband_runs_20241120_172038/run_s5_n54 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:48:21,607 - INFO - Training completed for config s5_n54:
  Training time: 0:00:14
  Final validation loss: 10.909556
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.20e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n54/checkpoint.bin
2024-11-20 21:48:21,607 - INFO - 
Configuration s5_n54 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.8070970079514815e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n54",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909556
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.20e-07
2024-11-20 21:48:21,607 - INFO - 
Starting training for config s5_n55:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:48:21,607 - INFO - Running command: ./train_gpt2cu -l 2.080744642740197e-05 -o hyperband_runs_20241120_172038/run_s5_n55 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:48:36,007 - INFO - Training completed for config s5_n55:
  Training time: 0:00:14
  Final validation loss: 10.910078
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 8.92e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n55/checkpoint.bin
2024-11-20 21:48:36,007 - INFO - 
Configuration s5_n55 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.080744642740197e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n55",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910078
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.92e-08
2024-11-20 21:48:36,007 - INFO - 
Starting training for config s5_n56:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:48:36,008 - INFO - Running command: ./train_gpt2cu -l 0.0008898164593245048 -o hyperband_runs_20241120_172038/run_s5_n56 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:48:50,415 - INFO - Training completed for config s5_n56:
  Training time: 0:00:14
  Final validation loss: 10.846952
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.81e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n56/checkpoint.bin
2024-11-20 21:48:50,415 - INFO - 
Configuration s5_n56 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008898164593245048",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n56",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.846952
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.81e-06
2024-11-20 21:48:50,415 - INFO - 
Starting training for config s5_n57:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:48:50,416 - INFO - Running command: ./train_gpt2cu -l 0.00014063521603028528 -o hyperband_runs_20241120_172038/run_s5_n57 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:49:04,808 - INFO - Training completed for config s5_n57:
  Training time: 0:00:14
  Final validation loss: 10.901289
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.03e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n57/checkpoint.bin
2024-11-20 21:49:04,808 - INFO - 
Configuration s5_n57 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014063521603028528",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n57",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.901289
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.03e-07
2024-11-20 21:49:04,809 - INFO - 
Starting training for config s5_n58:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:49:04,809 - INFO - Running command: ./train_gpt2cu -l 1.359618368136476e-05 -o hyperband_runs_20241120_172038/run_s5_n58 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:49:19,203 - INFO - Training completed for config s5_n58:
  Training time: 0:00:14
  Final validation loss: 10.910608
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.83e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n58/checkpoint.bin
2024-11-20 21:49:19,204 - INFO - 
Configuration s5_n58 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.359618368136476e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n58",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910608
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.83e-08
2024-11-20 21:49:19,204 - INFO - 
Starting training for config s5_n59:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:49:19,204 - INFO - Running command: ./train_gpt2cu -l 0.0007314827961887715 -o hyperband_runs_20241120_172038/run_s5_n59 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:49:33,616 - INFO - Training completed for config s5_n59:
  Training time: 0:00:14
  Final validation loss: 10.858244
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.13e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n59/checkpoint.bin
2024-11-20 21:49:33,617 - INFO - 
Configuration s5_n59 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007314827961887715",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n59",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.858244
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.13e-06
2024-11-20 21:49:33,617 - INFO - 
Starting training for config s5_n60:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:49:33,617 - INFO - Running command: ./train_gpt2cu -l 8.852931368492281e-05 -o hyperband_runs_20241120_172038/run_s5_n60 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:49:48,019 - INFO - Training completed for config s5_n60:
  Training time: 0:00:14
  Final validation loss: 10.905118
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.79e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n60/checkpoint.bin
2024-11-20 21:49:48,020 - INFO - 
Configuration s5_n60 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "8.852931368492281e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n60",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.905118
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.79e-07
2024-11-20 21:49:48,020 - INFO - 
Starting training for config s5_n61:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:49:48,020 - INFO - Running command: ./train_gpt2cu -l 3.2412096619329366e-05 -o hyperband_runs_20241120_172038/run_s5_n61 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:50:02,427 - INFO - Training completed for config s5_n61:
  Training time: 0:00:14
  Final validation loss: 10.909235
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.39e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n61/checkpoint.bin
2024-11-20 21:50:02,428 - INFO - 
Configuration s5_n61 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.2412096619329366e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n61",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909235
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.39e-07
2024-11-20 21:50:02,428 - INFO - 
Starting training for config s5_n62:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:50:02,428 - INFO - Running command: ./train_gpt2cu -l 2.026235590692628e-05 -o hyperband_runs_20241120_172038/run_s5_n62 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:50:16,829 - INFO - Training completed for config s5_n62:
  Training time: 0:00:14
  Final validation loss: 10.910116
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 8.68e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n62/checkpoint.bin
2024-11-20 21:50:16,829 - INFO - 
Configuration s5_n62 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.026235590692628e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n62",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910116
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.68e-08
2024-11-20 21:50:16,829 - INFO - 
Starting training for config s5_n63:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:50:16,830 - INFO - Running command: ./train_gpt2cu -l 4.7077526659034183e-05 -o hyperband_runs_20241120_172038/run_s5_n63 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:50:31,221 - INFO - Training completed for config s5_n63:
  Training time: 0:00:14
  Final validation loss: 10.908152
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.02e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n63/checkpoint.bin
2024-11-20 21:50:31,221 - INFO - 
Configuration s5_n63 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "4.7077526659034183e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n63",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.908152
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.02e-07
2024-11-20 21:50:31,222 - INFO - 
Starting training for config s5_n64:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:50:31,222 - INFO - Running command: ./train_gpt2cu -l 0.0002612423267904805 -o hyperband_runs_20241120_172038/run_s5_n64 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:50:45,637 - INFO - Training completed for config s5_n64:
  Training time: 0:00:14
  Final validation loss: 10.892466
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.12e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n64/checkpoint.bin
2024-11-20 21:50:45,637 - INFO - 
Configuration s5_n64 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002612423267904805",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n64",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.892466
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.12e-06
2024-11-20 21:50:45,637 - INFO - 
Starting training for config s5_n65:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:50:45,637 - INFO - Running command: ./train_gpt2cu -l 2.2608191070588365e-05 -o hyperband_runs_20241120_172038/run_s5_n65 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:51:00,049 - INFO - Training completed for config s5_n65:
  Training time: 0:00:14
  Final validation loss: 10.909967
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.69e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n65/checkpoint.bin
2024-11-20 21:51:00,049 - INFO - 
Configuration s5_n65 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.2608191070588365e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n65",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909967
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.69e-08
2024-11-20 21:51:00,049 - INFO - 
Starting training for config s5_n66:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:51:00,050 - INFO - Running command: ./train_gpt2cu -l 2.4318046411377474e-05 -o hyperband_runs_20241120_172038/run_s5_n66 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:51:14,450 - INFO - Training completed for config s5_n66:
  Training time: 0:00:14
  Final validation loss: 10.909832
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.04e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n66/checkpoint.bin
2024-11-20 21:51:14,451 - INFO - 
Configuration s5_n66 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.4318046411377474e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n66",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909832
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.04e-07
2024-11-20 21:51:14,451 - INFO - 
Starting training for config s5_n67:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:51:14,451 - INFO - Running command: ./train_gpt2cu -l 0.0004592736376297031 -o hyperband_runs_20241120_172038/run_s5_n67 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:51:28,867 - INFO - Training completed for config s5_n67:
  Training time: 0:00:14
  Final validation loss: 10.877982
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.97e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n67/checkpoint.bin
2024-11-20 21:51:28,867 - INFO - 
Configuration s5_n67 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004592736376297031",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n67",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.877982
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.97e-06
2024-11-20 21:51:28,868 - INFO - 
Starting training for config s5_n68:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:51:28,868 - INFO - Running command: ./train_gpt2cu -l 3.438302079775906e-05 -o hyperband_runs_20241120_172038/run_s5_n68 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:51:43,293 - INFO - Training completed for config s5_n68:
  Training time: 0:00:14
  Final validation loss: 10.909090
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.47e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n68/checkpoint.bin
2024-11-20 21:51:43,294 - INFO - 
Configuration s5_n68 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.438302079775906e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n68",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909090
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.47e-07
2024-11-20 21:51:43,294 - INFO - 
Starting training for config s5_n69:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:51:43,294 - INFO - Running command: ./train_gpt2cu -l 1.7777063938522994e-05 -o hyperband_runs_20241120_172038/run_s5_n69 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:51:57,730 - INFO - Training completed for config s5_n69:
  Training time: 0:00:14
  Final validation loss: 10.910298
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.62e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n69/checkpoint.bin
2024-11-20 21:51:57,730 - INFO - 
Configuration s5_n69 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.7777063938522994e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n69",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910298
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.62e-08
2024-11-20 21:51:57,730 - INFO - 
Starting training for config s5_n70:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:51:57,730 - INFO - Running command: ./train_gpt2cu -l 0.00038286924805000635 -o hyperband_runs_20241120_172038/run_s5_n70 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:52:12,157 - INFO - Training completed for config s5_n70:
  Training time: 0:00:14
  Final validation loss: 10.883573
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.64e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n70/checkpoint.bin
2024-11-20 21:52:12,157 - INFO - 
Configuration s5_n70 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00038286924805000635",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n70",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.883573
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.64e-06
2024-11-20 21:52:12,157 - INFO - 
Starting training for config s5_n71:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:52:12,157 - INFO - Running command: ./train_gpt2cu -l 0.0003192586067652104 -o hyperband_runs_20241120_172038/run_s5_n71 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:52:26,574 - INFO - Training completed for config s5_n71:
  Training time: 0:00:14
  Final validation loss: 10.888228
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.37e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n71/checkpoint.bin
2024-11-20 21:52:26,574 - INFO - 
Configuration s5_n71 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003192586067652104",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n71",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.888228
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.37e-06
2024-11-20 21:52:26,574 - INFO - 
Starting training for config s5_n72:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:52:26,574 - INFO - Running command: ./train_gpt2cu -l 0.0002910395102516586 -o hyperband_runs_20241120_172038/run_s5_n72 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:52:40,970 - INFO - Training completed for config s5_n72:
  Training time: 0:00:14
  Final validation loss: 10.890297
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.25e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n72/checkpoint.bin
2024-11-20 21:52:40,970 - INFO - 
Configuration s5_n72 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002910395102516586",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n72",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.890297
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.25e-06
2024-11-20 21:52:40,970 - INFO - 
Starting training for config s5_n73:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:52:40,971 - INFO - Running command: ./train_gpt2cu -l 0.00019926251199622633 -o hyperband_runs_20241120_172038/run_s5_n73 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:52:55,381 - INFO - Training completed for config s5_n73:
  Training time: 0:00:14
  Final validation loss: 10.896994
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 8.54e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n73/checkpoint.bin
2024-11-20 21:52:55,382 - INFO - 
Configuration s5_n73 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00019926251199622633",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n73",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.896994
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.54e-07
2024-11-20 21:52:55,382 - INFO - 
Starting training for config s5_n74:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:52:55,382 - INFO - Running command: ./train_gpt2cu -l 6.907334289337235e-05 -o hyperband_runs_20241120_172038/run_s5_n74 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:53:09,780 - INFO - Training completed for config s5_n74:
  Training time: 0:00:14
  Final validation loss: 10.906538
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.96e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n74/checkpoint.bin
2024-11-20 21:53:09,781 - INFO - 
Configuration s5_n74 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "6.907334289337235e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n74",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.906538
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.96e-07
2024-11-20 21:53:09,781 - INFO - 
Starting training for config s5_n75:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:53:09,781 - INFO - Running command: ./train_gpt2cu -l 0.00013007736552407393 -o hyperband_runs_20241120_172038/run_s5_n75 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:53:24,187 - INFO - Training completed for config s5_n75:
  Training time: 0:00:14
  Final validation loss: 10.902069
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.57e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n75/checkpoint.bin
2024-11-20 21:53:24,187 - INFO - 
Configuration s5_n75 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013007736552407393",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n75",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.902069
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.57e-07
2024-11-20 21:53:24,187 - INFO - 
Starting training for config s5_n76:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:53:24,187 - INFO - Running command: ./train_gpt2cu -l 1.052225037264735e-05 -o hyperband_runs_20241120_172038/run_s5_n76 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:53:38,603 - INFO - Training completed for config s5_n76:
  Training time: 0:00:14
  Final validation loss: 10.910831
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.51e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n76/checkpoint.bin
2024-11-20 21:53:38,603 - INFO - 
Configuration s5_n76 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.052225037264735e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n76",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910831
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.51e-08
2024-11-20 21:53:38,603 - INFO - 
Starting training for config s5_n77:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:53:38,603 - INFO - Running command: ./train_gpt2cu -l 0.0005737331307205387 -o hyperband_runs_20241120_172038/run_s5_n77 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:53:53,000 - INFO - Training completed for config s5_n77:
  Training time: 0:00:14
  Final validation loss: 10.869681
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.46e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n77/checkpoint.bin
2024-11-20 21:53:53,000 - INFO - 
Configuration s5_n77 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005737331307205387",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n77",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.869681
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.46e-06
2024-11-20 21:53:53,001 - INFO - 
Starting training for config s5_n78:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:53:53,001 - INFO - Running command: ./train_gpt2cu -l 1.1256941770078447e-05 -o hyperband_runs_20241120_172038/run_s5_n78 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:54:07,438 - INFO - Training completed for config s5_n78:
  Training time: 0:00:14
  Final validation loss: 10.910777
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.82e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n78/checkpoint.bin
2024-11-20 21:54:07,439 - INFO - 
Configuration s5_n78 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.1256941770078447e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n78",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910777
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.82e-08
2024-11-20 21:54:07,439 - INFO - 
Starting training for config s5_n79:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:54:07,439 - INFO - Running command: ./train_gpt2cu -l 0.0001360004626611196 -o hyperband_runs_20241120_172038/run_s5_n79 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:54:21,842 - INFO - Training completed for config s5_n79:
  Training time: 0:00:14
  Final validation loss: 10.901629
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.83e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n79/checkpoint.bin
2024-11-20 21:54:21,842 - INFO - 
Configuration s5_n79 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001360004626611196",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n79",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.901629
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.83e-07
2024-11-20 21:54:21,842 - INFO - 
Starting training for config s5_n80:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:54:21,842 - INFO - Running command: ./train_gpt2cu -l 5.4972031403429575e-05 -o hyperband_runs_20241120_172038/run_s5_n80 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:54:36,238 - INFO - Training completed for config s5_n80:
  Training time: 0:00:14
  Final validation loss: 10.907569
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.36e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n80/checkpoint.bin
2024-11-20 21:54:36,238 - INFO - 
Configuration s5_n80 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "5.4972031403429575e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n80",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.907569
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.36e-07
2024-11-20 21:54:36,238 - INFO - 
Starting training for config s5_n81:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:54:36,239 - INFO - Running command: ./train_gpt2cu -l 0.00031465210588944186 -o hyperband_runs_20241120_172038/run_s5_n81 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:54:50,652 - INFO - Training completed for config s5_n81:
  Training time: 0:00:14
  Final validation loss: 10.888582
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.35e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n81/checkpoint.bin
2024-11-20 21:54:50,652 - INFO - 
Configuration s5_n81 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00031465210588944186",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n81",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.888582
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.35e-06
2024-11-20 21:54:50,652 - INFO - 
Starting training for config s5_n82:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:54:50,652 - INFO - Running command: ./train_gpt2cu -l 0.00014218457139838364 -o hyperband_runs_20241120_172038/run_s5_n82 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:55:05,039 - INFO - Training completed for config s5_n82:
  Training time: 0:00:14
  Final validation loss: 10.901182
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.09e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n82/checkpoint.bin
2024-11-20 21:55:05,039 - INFO - 
Configuration s5_n82 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014218457139838364",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n82",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.901182
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.09e-07
2024-11-20 21:55:05,039 - INFO - 
Starting training for config s5_n83:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:55:05,039 - INFO - Running command: ./train_gpt2cu -l 0.0005546446554246793 -o hyperband_runs_20241120_172038/run_s5_n83 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:55:19,468 - INFO - Training completed for config s5_n83:
  Training time: 0:00:14
  Final validation loss: 10.871096
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.38e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n83/checkpoint.bin
2024-11-20 21:55:19,469 - INFO - 
Configuration s5_n83 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005546446554246793",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n83",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.871096
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.38e-06
2024-11-20 21:55:19,469 - INFO - 
Starting training for config s5_n84:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:55:19,469 - INFO - Running command: ./train_gpt2cu -l 0.0002563835894495119 -o hyperband_runs_20241120_172038/run_s5_n84 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:55:33,888 - INFO - Training completed for config s5_n84:
  Training time: 0:00:14
  Final validation loss: 10.892825
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.10e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n84/checkpoint.bin
2024-11-20 21:55:33,888 - INFO - 
Configuration s5_n84 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002563835894495119",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n84",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.892825
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-06
2024-11-20 21:55:33,888 - INFO - 
Starting training for config s5_n85:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:55:33,888 - INFO - Running command: ./train_gpt2cu -l 1.3420066192951047e-05 -o hyperband_runs_20241120_172038/run_s5_n85 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:55:48,293 - INFO - Training completed for config s5_n85:
  Training time: 0:00:14
  Final validation loss: 10.910620
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.75e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n85/checkpoint.bin
2024-11-20 21:55:48,294 - INFO - 
Configuration s5_n85 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.3420066192951047e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n85",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910620
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.75e-08
2024-11-20 21:55:48,294 - INFO - 
Starting training for config s5_n86:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:55:48,294 - INFO - Running command: ./train_gpt2cu -l 0.0006402538968106657 -o hyperband_runs_20241120_172038/run_s5_n86 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:56:02,728 - INFO - Training completed for config s5_n86:
  Training time: 0:00:14
  Final validation loss: 10.864874
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.74e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n86/checkpoint.bin
2024-11-20 21:56:02,728 - INFO - 
Configuration s5_n86 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006402538968106657",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n86",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.864874
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.74e-06
2024-11-20 21:56:02,729 - INFO - 
Starting training for config s5_n87:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:56:02,729 - INFO - Running command: ./train_gpt2cu -l 0.00030349709381722543 -o hyperband_runs_20241120_172038/run_s5_n87 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:56:17,134 - INFO - Training completed for config s5_n87:
  Training time: 0:00:14
  Final validation loss: 10.889388
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.30e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n87/checkpoint.bin
2024-11-20 21:56:17,134 - INFO - 
Configuration s5_n87 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00030349709381722543",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n87",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.889388
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.30e-06
2024-11-20 21:56:17,134 - INFO - 
Starting training for config s5_n88:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:56:17,134 - INFO - Running command: ./train_gpt2cu -l 1.8452889200479814e-05 -o hyperband_runs_20241120_172038/run_s5_n88 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:56:31,546 - INFO - Training completed for config s5_n88:
  Training time: 0:00:14
  Final validation loss: 10.910254
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.91e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n88/checkpoint.bin
2024-11-20 21:56:31,546 - INFO - 
Configuration s5_n88 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.8452889200479814e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n88",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910254
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.91e-08
2024-11-20 21:56:31,546 - INFO - 
Starting training for config s5_n89:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:56:31,546 - INFO - Running command: ./train_gpt2cu -l 1.9542863201936352e-05 -o hyperband_runs_20241120_172038/run_s5_n89 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:56:45,979 - INFO - Training completed for config s5_n89:
  Training time: 0:00:14
  Final validation loss: 10.910170
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 8.38e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n89/checkpoint.bin
2024-11-20 21:56:45,979 - INFO - 
Configuration s5_n89 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.9542863201936352e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n89",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910170
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.38e-08
2024-11-20 21:56:45,979 - INFO - 
Starting training for config s5_n90:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:56:45,979 - INFO - Running command: ./train_gpt2cu -l 0.00016041300662891208 -o hyperband_runs_20241120_172038/run_s5_n90 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:57:00,393 - INFO - Training completed for config s5_n90:
  Training time: 0:00:14
  Final validation loss: 10.899843
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.87e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n90/checkpoint.bin
2024-11-20 21:57:00,393 - INFO - 
Configuration s5_n90 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00016041300662891208",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n90",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.899843
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.87e-07
2024-11-20 21:57:00,393 - INFO - 
Starting training for config s5_n91:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:57:00,393 - INFO - Running command: ./train_gpt2cu -l 0.0001646800517116266 -o hyperband_runs_20241120_172038/run_s5_n91 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:57:14,809 - INFO - Training completed for config s5_n91:
  Training time: 0:00:14
  Final validation loss: 10.899521
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.06e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n91/checkpoint.bin
2024-11-20 21:57:14,809 - INFO - 
Configuration s5_n91 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001646800517116266",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n91",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.899521
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.06e-07
2024-11-20 21:57:14,809 - INFO - 
Starting training for config s5_n92:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:57:14,809 - INFO - Running command: ./train_gpt2cu -l 0.0001555490473603658 -o hyperband_runs_20241120_172038/run_s5_n92 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:57:29,230 - INFO - Training completed for config s5_n92:
  Training time: 0:00:14
  Final validation loss: 10.900205
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.67e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n92/checkpoint.bin
2024-11-20 21:57:29,230 - INFO - 
Configuration s5_n92 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001555490473603658",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n92",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.900205
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.67e-07
2024-11-20 21:57:29,230 - INFO - 
Starting training for config s5_n93:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:57:29,230 - INFO - Running command: ./train_gpt2cu -l 0.0008001779748372474 -o hyperband_runs_20241120_172038/run_s5_n93 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:57:43,632 - INFO - Training completed for config s5_n93:
  Training time: 0:00:14
  Final validation loss: 10.853336
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.43e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n93/checkpoint.bin
2024-11-20 21:57:43,632 - INFO - 
Configuration s5_n93 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008001779748372474",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n93",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.853336
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.43e-06
2024-11-20 21:57:43,632 - INFO - 
Starting training for config s5_n94:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:57:43,632 - INFO - Running command: ./train_gpt2cu -l 9.547307202236088e-05 -o hyperband_runs_20241120_172038/run_s5_n94 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:57:58,040 - INFO - Training completed for config s5_n94:
  Training time: 0:00:14
  Final validation loss: 10.904622
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.09e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n94/checkpoint.bin
2024-11-20 21:57:58,040 - INFO - 
Configuration s5_n94 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "9.547307202236088e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n94",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.904622
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.09e-07
2024-11-20 21:57:58,040 - INFO - 
Starting training for config s5_n95:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:57:58,040 - INFO - Running command: ./train_gpt2cu -l 0.0003257966907619246 -o hyperband_runs_20241120_172038/run_s5_n95 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:58:12,449 - INFO - Training completed for config s5_n95:
  Training time: 0:00:14
  Final validation loss: 10.887757
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.40e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n95/checkpoint.bin
2024-11-20 21:58:12,449 - INFO - 
Configuration s5_n95 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003257966907619246",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n95",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.887757
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.40e-06
2024-11-20 21:58:12,449 - INFO - 
Starting training for config s5_n96:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:58:12,449 - INFO - Running command: ./train_gpt2cu -l 0.00025795437022796565 -o hyperband_runs_20241120_172038/run_s5_n96 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:58:26,854 - INFO - Training completed for config s5_n96:
  Training time: 0:00:14
  Final validation loss: 10.892703
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.11e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n96/checkpoint.bin
2024-11-20 21:58:26,854 - INFO - 
Configuration s5_n96 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00025795437022796565",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n96",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.892703
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.11e-06
2024-11-20 21:58:26,854 - INFO - 
Starting training for config s5_n97:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:58:26,854 - INFO - Running command: ./train_gpt2cu -l 6.355545733119997e-05 -o hyperband_runs_20241120_172038/run_s5_n97 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:58:41,261 - INFO - Training completed for config s5_n97:
  Training time: 0:00:14
  Final validation loss: 10.906953
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.72e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n97/checkpoint.bin
2024-11-20 21:58:41,262 - INFO - 
Configuration s5_n97 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "6.355545733119997e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n97",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.906953
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.72e-07
2024-11-20 21:58:41,262 - INFO - 
Starting training for config s5_n98:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:58:41,262 - INFO - Running command: ./train_gpt2cu -l 2.8126886740893744e-05 -o hyperband_runs_20241120_172038/run_s5_n98 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:58:55,674 - INFO - Training completed for config s5_n98:
  Training time: 0:00:14
  Final validation loss: 10.909550
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.21e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n98/checkpoint.bin
2024-11-20 21:58:55,675 - INFO - 
Configuration s5_n98 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.8126886740893744e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n98",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909550
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.21e-07
2024-11-20 21:58:55,675 - INFO - 
Starting training for config s5_n99:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:58:55,676 - INFO - Running command: ./train_gpt2cu -l 0.00010247950266440242 -o hyperband_runs_20241120_172038/run_s5_n99 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:59:10,091 - INFO - Training completed for config s5_n99:
  Training time: 0:00:14
  Final validation loss: 10.904100
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.39e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n99/checkpoint.bin
2024-11-20 21:59:10,091 - INFO - 
Configuration s5_n99 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010247950266440242",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n99",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.904100
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.39e-07
2024-11-20 21:59:10,091 - INFO - 
Starting training for config s5_n100:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:59:10,092 - INFO - Running command: ./train_gpt2cu -l 3.0775963310125274e-05 -o hyperband_runs_20241120_172038/run_s5_n100 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:59:24,516 - INFO - Training completed for config s5_n100:
  Training time: 0:00:14
  Final validation loss: 10.909342
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.32e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n100/checkpoint.bin
2024-11-20 21:59:24,516 - INFO - 
Configuration s5_n100 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.0775963310125274e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n100",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909342
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.32e-07
2024-11-20 21:59:24,516 - INFO - 
Starting training for config s5_n101:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:59:24,516 - INFO - Running command: ./train_gpt2cu -l 0.00016466394675088137 -o hyperband_runs_20241120_172038/run_s5_n101 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:59:38,916 - INFO - Training completed for config s5_n101:
  Training time: 0:00:14
  Final validation loss: 10.899535
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.06e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n101/checkpoint.bin
2024-11-20 21:59:38,916 - INFO - 
Configuration s5_n101 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00016466394675088137",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n101",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.899535
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.06e-07
2024-11-20 21:59:38,916 - INFO - 
Starting training for config s5_n102:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:59:38,916 - INFO - Running command: ./train_gpt2cu -l 5.265088398444967e-05 -o hyperband_runs_20241120_172038/run_s5_n102 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 21:59:53,313 - INFO - Training completed for config s5_n102:
  Training time: 0:00:14
  Final validation loss: 10.907726
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.26e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n102/checkpoint.bin
2024-11-20 21:59:53,313 - INFO - 
Configuration s5_n102 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "5.265088398444967e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n102",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.907726
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.26e-07
2024-11-20 21:59:53,313 - INFO - 
Starting training for config s5_n103:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 21:59:53,313 - INFO - Running command: ./train_gpt2cu -l 0.0002835450696406215 -o hyperband_runs_20241120_172038/run_s5_n103 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:00:07,729 - INFO - Training completed for config s5_n103:
  Training time: 0:00:14
  Final validation loss: 10.890844
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.22e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n103/checkpoint.bin
2024-11-20 22:00:07,729 - INFO - 
Configuration s5_n103 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002835450696406215",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n103",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.890844
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.22e-06
2024-11-20 22:00:07,729 - INFO - 
Starting training for config s5_n104:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:00:07,730 - INFO - Running command: ./train_gpt2cu -l 0.0005153006805113633 -o hyperband_runs_20241120_172038/run_s5_n104 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:00:22,155 - INFO - Training completed for config s5_n104:
  Training time: 0:00:14
  Final validation loss: 10.873941
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.21e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n104/checkpoint.bin
2024-11-20 22:00:22,155 - INFO - 
Configuration s5_n104 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005153006805113633",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n104",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.873941
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.21e-06
2024-11-20 22:00:22,155 - INFO - 
Starting training for config s5_n105:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:00:22,155 - INFO - Running command: ./train_gpt2cu -l 0.00023864716872958307 -o hyperband_runs_20241120_172038/run_s5_n105 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:00:36,563 - INFO - Training completed for config s5_n105:
  Training time: 0:00:14
  Final validation loss: 10.894132
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.02e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n105/checkpoint.bin
2024-11-20 22:00:36,563 - INFO - 
Configuration s5_n105 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00023864716872958307",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n105",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.894132
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-06
2024-11-20 22:00:36,563 - INFO - 
Starting training for config s5_n106:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:00:36,563 - INFO - Running command: ./train_gpt2cu -l 0.00021540333236000735 -o hyperband_runs_20241120_172038/run_s5_n106 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:00:50,965 - INFO - Training completed for config s5_n106:
  Training time: 0:00:14
  Final validation loss: 10.895827
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.23e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n106/checkpoint.bin
2024-11-20 22:00:50,965 - INFO - 
Configuration s5_n106 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00021540333236000735",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n106",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.895827
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.23e-07
2024-11-20 22:00:50,965 - INFO - 
Starting training for config s5_n107:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:00:50,965 - INFO - Running command: ./train_gpt2cu -l 1.3987966473623842e-05 -o hyperband_runs_20241120_172038/run_s5_n107 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:01:05,391 - INFO - Training completed for config s5_n107:
  Training time: 0:00:14
  Final validation loss: 10.910574
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.99e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n107/checkpoint.bin
2024-11-20 22:01:05,391 - INFO - 
Configuration s5_n107 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.3987966473623842e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n107",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910574
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.99e-08
2024-11-20 22:01:05,391 - INFO - 
Starting training for config s5_n108:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:01:05,391 - INFO - Running command: ./train_gpt2cu -l 9.726378066392643e-05 -o hyperband_runs_20241120_172038/run_s5_n108 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:01:19,812 - INFO - Training completed for config s5_n108:
  Training time: 0:00:14
  Final validation loss: 10.904490
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.17e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n108/checkpoint.bin
2024-11-20 22:01:19,812 - INFO - 
Configuration s5_n108 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "9.726378066392643e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n108",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.904490
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.17e-07
2024-11-20 22:01:19,812 - INFO - 
Starting training for config s5_n109:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:01:19,812 - INFO - Running command: ./train_gpt2cu -l 5.451865352570808e-05 -o hyperband_runs_20241120_172038/run_s5_n109 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:01:34,219 - INFO - Training completed for config s5_n109:
  Training time: 0:00:14
  Final validation loss: 10.907595
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.34e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n109/checkpoint.bin
2024-11-20 22:01:34,219 - INFO - 
Configuration s5_n109 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "5.451865352570808e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n109",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.907595
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.34e-07
2024-11-20 22:01:34,219 - INFO - 
Starting training for config s5_n110:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:01:34,219 - INFO - Running command: ./train_gpt2cu -l 0.00012547393279117253 -o hyperband_runs_20241120_172038/run_s5_n110 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:01:48,619 - INFO - Training completed for config s5_n110:
  Training time: 0:00:14
  Final validation loss: 10.902414
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.38e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n110/checkpoint.bin
2024-11-20 22:01:48,619 - INFO - 
Configuration s5_n110 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012547393279117253",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n110",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.902414
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.38e-07
2024-11-20 22:01:48,619 - INFO - 
Starting training for config s5_n111:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:01:48,619 - INFO - Running command: ./train_gpt2cu -l 0.0004537901260077919 -o hyperband_runs_20241120_172038/run_s5_n111 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:02:03,034 - INFO - Training completed for config s5_n111:
  Training time: 0:00:14
  Final validation loss: 10.878371
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.94e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n111/checkpoint.bin
2024-11-20 22:02:03,034 - INFO - 
Configuration s5_n111 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004537901260077919",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n111",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.878371
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.94e-06
2024-11-20 22:02:03,034 - INFO - 
Starting training for config s5_n112:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:02:03,034 - INFO - Running command: ./train_gpt2cu -l 3.462405621334375e-05 -o hyperband_runs_20241120_172038/run_s5_n112 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:02:17,461 - INFO - Training completed for config s5_n112:
  Training time: 0:00:14
  Final validation loss: 10.909081
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.48e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n112/checkpoint.bin
2024-11-20 22:02:17,462 - INFO - 
Configuration s5_n112 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.462405621334375e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n112",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909081
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.48e-07
2024-11-20 22:02:17,462 - INFO - 
Starting training for config s5_n113:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:02:17,462 - INFO - Running command: ./train_gpt2cu -l 0.00012629085934006358 -o hyperband_runs_20241120_172038/run_s5_n113 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:02:31,874 - INFO - Training completed for config s5_n113:
  Training time: 0:00:14
  Final validation loss: 10.902351
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.41e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n113/checkpoint.bin
2024-11-20 22:02:31,875 - INFO - 
Configuration s5_n113 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012629085934006358",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n113",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.902351
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.41e-07
2024-11-20 22:02:31,875 - INFO - 
Starting training for config s5_n114:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:02:31,875 - INFO - Running command: ./train_gpt2cu -l 0.00011690999711515019 -o hyperband_runs_20241120_172038/run_s5_n114 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:02:46,304 - INFO - Training completed for config s5_n114:
  Training time: 0:00:14
  Final validation loss: 10.903039
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.01e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n114/checkpoint.bin
2024-11-20 22:02:46,304 - INFO - 
Configuration s5_n114 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00011690999711515019",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n114",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.903039
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.01e-07
2024-11-20 22:02:46,304 - INFO - 
Starting training for config s5_n115:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:02:46,304 - INFO - Running command: ./train_gpt2cu -l 1.5703082281679556e-05 -o hyperband_runs_20241120_172038/run_s5_n115 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:03:00,748 - INFO - Training completed for config s5_n115:
  Training time: 0:00:14
  Final validation loss: 10.910445
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.73e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n115/checkpoint.bin
2024-11-20 22:03:00,749 - INFO - 
Configuration s5_n115 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.5703082281679556e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n115",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910445
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.73e-08
2024-11-20 22:03:00,749 - INFO - 
Starting training for config s5_n116:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:03:00,749 - INFO - Running command: ./train_gpt2cu -l 1.4156822277366903e-05 -o hyperband_runs_20241120_172038/run_s5_n116 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:03:15,159 - INFO - Training completed for config s5_n116:
  Training time: 0:00:14
  Final validation loss: 10.910562
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.07e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n116/checkpoint.bin
2024-11-20 22:03:15,159 - INFO - 
Configuration s5_n116 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.4156822277366903e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n116",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910562
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.07e-08
2024-11-20 22:03:15,159 - INFO - 
Starting training for config s5_n117:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:03:15,159 - INFO - Running command: ./train_gpt2cu -l 0.00015826577178767873 -o hyperband_runs_20241120_172038/run_s5_n117 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:03:29,571 - INFO - Training completed for config s5_n117:
  Training time: 0:00:14
  Final validation loss: 10.900009
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.78e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n117/checkpoint.bin
2024-11-20 22:03:29,571 - INFO - 
Configuration s5_n117 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00015826577178767873",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n117",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.900009
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.78e-07
2024-11-20 22:03:29,571 - INFO - 
Starting training for config s5_n118:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:03:29,571 - INFO - Running command: ./train_gpt2cu -l 2.8372745802496815e-05 -o hyperband_runs_20241120_172038/run_s5_n118 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:03:43,981 - INFO - Training completed for config s5_n118:
  Training time: 0:00:14
  Final validation loss: 10.909529
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.22e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n118/checkpoint.bin
2024-11-20 22:03:43,982 - INFO - 
Configuration s5_n118 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.8372745802496815e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n118",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909529
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.22e-07
2024-11-20 22:03:43,982 - INFO - 
Starting training for config s5_n119:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:03:43,982 - INFO - Running command: ./train_gpt2cu -l 1.4721065655906791e-05 -o hyperband_runs_20241120_172038/run_s5_n119 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:03:58,403 - INFO - Training completed for config s5_n119:
  Training time: 0:00:14
  Final validation loss: 10.910524
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.31e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n119/checkpoint.bin
2024-11-20 22:03:58,403 - INFO - 
Configuration s5_n119 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.4721065655906791e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n119",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910524
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.31e-08
2024-11-20 22:03:58,403 - INFO - 
Starting training for config s5_n120:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:03:58,403 - INFO - Running command: ./train_gpt2cu -l 3.188244133733278e-05 -o hyperband_runs_20241120_172038/run_s5_n120 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:04:12,821 - INFO - Training completed for config s5_n120:
  Training time: 0:00:14
  Final validation loss: 10.909269
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.37e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n120/checkpoint.bin
2024-11-20 22:04:12,822 - INFO - 
Configuration s5_n120 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.188244133733278e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n120",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909269
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.37e-07
2024-11-20 22:04:12,822 - INFO - 
Starting training for config s5_n121:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:04:12,822 - INFO - Running command: ./train_gpt2cu -l 0.00026063420623900156 -o hyperband_runs_20241120_172038/run_s5_n121 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:04:27,244 - INFO - Training completed for config s5_n121:
  Training time: 0:00:14
  Final validation loss: 10.892508
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.12e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n121/checkpoint.bin
2024-11-20 22:04:27,244 - INFO - 
Configuration s5_n121 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00026063420623900156",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n121",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.892508
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.12e-06
2024-11-20 22:04:27,244 - INFO - 
Starting training for config s5_n122:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:04:27,244 - INFO - Running command: ./train_gpt2cu -l 2.5618799720630532e-05 -o hyperband_runs_20241120_172038/run_s5_n122 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:04:41,692 - INFO - Training completed for config s5_n122:
  Training time: 0:00:14
  Final validation loss: 10.909734
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.10e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n122/checkpoint.bin
2024-11-20 22:04:41,692 - INFO - 
Configuration s5_n122 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.5618799720630532e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n122",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909734
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-07
2024-11-20 22:04:41,692 - INFO - 
Starting training for config s5_n123:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:04:41,692 - INFO - Running command: ./train_gpt2cu -l 1.125125780961317e-05 -o hyperband_runs_20241120_172038/run_s5_n123 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:04:56,100 - INFO - Training completed for config s5_n123:
  Training time: 0:00:14
  Final validation loss: 10.910776
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.82e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n123/checkpoint.bin
2024-11-20 22:04:56,101 - INFO - 
Configuration s5_n123 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.125125780961317e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n123",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910776
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.82e-08
2024-11-20 22:04:56,101 - INFO - 
Starting training for config s5_n124:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:04:56,101 - INFO - Running command: ./train_gpt2cu -l 0.00011808999863282604 -o hyperband_runs_20241120_172038/run_s5_n124 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:05:10,512 - INFO - Training completed for config s5_n124:
  Training time: 0:00:14
  Final validation loss: 10.902953
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.06e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n124/checkpoint.bin
2024-11-20 22:05:10,512 - INFO - 
Configuration s5_n124 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00011808999863282604",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n124",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.902953
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.06e-07
2024-11-20 22:05:10,512 - INFO - 
Starting training for config s5_n125:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:05:10,512 - INFO - Running command: ./train_gpt2cu -l 1.199440770924073e-05 -o hyperband_runs_20241120_172038/run_s5_n125 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:05:24,927 - INFO - Training completed for config s5_n125:
  Training time: 0:00:14
  Final validation loss: 10.910735
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.14e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n125/checkpoint.bin
2024-11-20 22:05:24,928 - INFO - 
Configuration s5_n125 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.199440770924073e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n125",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910735
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.14e-08
2024-11-20 22:05:24,928 - INFO - 
Starting training for config s5_n126:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:05:24,928 - INFO - Running command: ./train_gpt2cu -l 3.263802748867193e-05 -o hyperband_runs_20241120_172038/run_s5_n126 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:05:39,338 - INFO - Training completed for config s5_n126:
  Training time: 0:00:14
  Final validation loss: 10.909209
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.40e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n126/checkpoint.bin
2024-11-20 22:05:39,338 - INFO - 
Configuration s5_n126 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.263802748867193e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n126",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909209
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.40e-07
2024-11-20 22:05:39,338 - INFO - 
Starting training for config s5_n127:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:05:39,338 - INFO - Running command: ./train_gpt2cu -l 1.8276018965120218e-05 -o hyperband_runs_20241120_172038/run_s5_n127 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:05:53,751 - INFO - Training completed for config s5_n127:
  Training time: 0:00:14
  Final validation loss: 10.910260
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.83e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n127/checkpoint.bin
2024-11-20 22:05:53,752 - INFO - 
Configuration s5_n127 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.8276018965120218e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n127",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910260
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.83e-08
2024-11-20 22:05:53,752 - INFO - 
Starting training for config s5_n128:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:05:53,752 - INFO - Running command: ./train_gpt2cu -l 0.00020781191343618587 -o hyperband_runs_20241120_172038/run_s5_n128 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:06:08,163 - INFO - Training completed for config s5_n128:
  Training time: 0:00:14
  Final validation loss: 10.896383
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 8.91e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n128/checkpoint.bin
2024-11-20 22:06:08,163 - INFO - 
Configuration s5_n128 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00020781191343618587",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n128",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.896383
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.91e-07
2024-11-20 22:06:08,163 - INFO - 
Starting training for config s5_n129:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:06:08,163 - INFO - Running command: ./train_gpt2cu -l 0.00038390080874090856 -o hyperband_runs_20241120_172038/run_s5_n129 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:06:22,567 - INFO - Training completed for config s5_n129:
  Training time: 0:00:14
  Final validation loss: 10.883497
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.65e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n129/checkpoint.bin
2024-11-20 22:06:22,567 - INFO - 
Configuration s5_n129 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00038390080874090856",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n129",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.883497
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.65e-06
2024-11-20 22:06:22,567 - INFO - 
Starting training for config s5_n130:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:06:22,567 - INFO - Running command: ./train_gpt2cu -l 0.00011227005096936456 -o hyperband_runs_20241120_172038/run_s5_n130 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:06:36,963 - INFO - Training completed for config s5_n130:
  Training time: 0:00:14
  Final validation loss: 10.903383
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.81e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n130/checkpoint.bin
2024-11-20 22:06:36,963 - INFO - 
Configuration s5_n130 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00011227005096936456",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n130",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.903383
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.81e-07
2024-11-20 22:06:36,963 - INFO - 
Starting training for config s5_n131:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:06:36,964 - INFO - Running command: ./train_gpt2cu -l 0.0008602543209504669 -o hyperband_runs_20241120_172038/run_s5_n131 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:06:51,373 - INFO - Training completed for config s5_n131:
  Training time: 0:00:14
  Final validation loss: 10.849046
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.69e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n131/checkpoint.bin
2024-11-20 22:06:51,373 - INFO - 
Configuration s5_n131 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008602543209504669",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n131",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.849046
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.69e-06
2024-11-20 22:06:51,373 - INFO - 
Starting training for config s5_n132:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:06:51,374 - INFO - Running command: ./train_gpt2cu -l 0.00019959970376562264 -o hyperband_runs_20241120_172038/run_s5_n132 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:07:05,792 - INFO - Training completed for config s5_n132:
  Training time: 0:00:14
  Final validation loss: 10.896977
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 8.55e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n132/checkpoint.bin
2024-11-20 22:07:05,792 - INFO - 
Configuration s5_n132 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00019959970376562264",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n132",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.896977
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.55e-07
2024-11-20 22:07:05,793 - INFO - 
Starting training for config s5_n133:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:07:05,793 - INFO - Running command: ./train_gpt2cu -l 0.0005115511140942006 -o hyperband_runs_20241120_172038/run_s5_n133 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:07:20,205 - INFO - Training completed for config s5_n133:
  Training time: 0:00:14
  Final validation loss: 10.874214
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.19e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n133/checkpoint.bin
2024-11-20 22:07:20,205 - INFO - 
Configuration s5_n133 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005115511140942006",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n133",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.874214
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.19e-06
2024-11-20 22:07:20,205 - INFO - 
Starting training for config s5_n134:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:07:20,205 - INFO - Running command: ./train_gpt2cu -l 0.0009660126338049484 -o hyperband_runs_20241120_172038/run_s5_n134 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:07:34,632 - INFO - Training completed for config s5_n134:
  Training time: 0:00:14
  Final validation loss: 10.841481
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.14e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n134/checkpoint.bin
2024-11-20 22:07:34,632 - INFO - 
Configuration s5_n134 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009660126338049484",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n134",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.841481
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.14e-06
2024-11-20 22:07:34,633 - INFO - 
Starting training for config s5_n135:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:07:34,633 - INFO - Running command: ./train_gpt2cu -l 1.2116934900331066e-05 -o hyperband_runs_20241120_172038/run_s5_n135 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:07:49,050 - INFO - Training completed for config s5_n135:
  Training time: 0:00:14
  Final validation loss: 10.910707
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.19e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n135/checkpoint.bin
2024-11-20 22:07:49,050 - INFO - 
Configuration s5_n135 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.2116934900331066e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n135",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910707
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.19e-08
2024-11-20 22:07:49,051 - INFO - 
Starting training for config s5_n136:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:07:49,051 - INFO - Running command: ./train_gpt2cu -l 2.8181480654400047e-05 -o hyperband_runs_20241120_172038/run_s5_n136 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:08:03,460 - INFO - Training completed for config s5_n136:
  Training time: 0:00:14
  Final validation loss: 10.909549
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.21e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n136/checkpoint.bin
2024-11-20 22:08:03,461 - INFO - 
Configuration s5_n136 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.8181480654400047e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n136",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909549
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.21e-07
2024-11-20 22:08:03,461 - INFO - 
Starting training for config s5_n137:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:08:03,461 - INFO - Running command: ./train_gpt2cu -l 0.00010755742685582655 -o hyperband_runs_20241120_172038/run_s5_n137 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:08:17,889 - INFO - Training completed for config s5_n137:
  Training time: 0:00:14
  Final validation loss: 10.903732
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.61e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n137/checkpoint.bin
2024-11-20 22:08:17,889 - INFO - 
Configuration s5_n137 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010755742685582655",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n137",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.903732
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.61e-07
2024-11-20 22:08:17,889 - INFO - 
Starting training for config s5_n138:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:08:17,889 - INFO - Running command: ./train_gpt2cu -l 1.6635946992197136e-05 -o hyperband_runs_20241120_172038/run_s5_n138 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:08:32,299 - INFO - Training completed for config s5_n138:
  Training time: 0:00:14
  Final validation loss: 10.910371
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.13e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n138/checkpoint.bin
2024-11-20 22:08:32,300 - INFO - 
Configuration s5_n138 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.6635946992197136e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n138",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910371
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.13e-08
2024-11-20 22:08:32,300 - INFO - 
Starting training for config s5_n139:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:08:32,300 - INFO - Running command: ./train_gpt2cu -l 0.0008272293688785697 -o hyperband_runs_20241120_172038/run_s5_n139 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:08:46,697 - INFO - Training completed for config s5_n139:
  Training time: 0:00:14
  Final validation loss: 10.851416
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.55e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n139/checkpoint.bin
2024-11-20 22:08:46,698 - INFO - 
Configuration s5_n139 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008272293688785697",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n139",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.851416
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.55e-06
2024-11-20 22:08:46,698 - INFO - 
Starting training for config s5_n140:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:08:46,698 - INFO - Running command: ./train_gpt2cu -l 0.00024967442199541964 -o hyperband_runs_20241120_172038/run_s5_n140 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:09:01,107 - INFO - Training completed for config s5_n140:
  Training time: 0:00:14
  Final validation loss: 10.893334
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.07e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n140/checkpoint.bin
2024-11-20 22:09:01,107 - INFO - 
Configuration s5_n140 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00024967442199541964",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n140",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.893334
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.07e-06
2024-11-20 22:09:01,107 - INFO - 
Starting training for config s5_n141:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:09:01,107 - INFO - Running command: ./train_gpt2cu -l 0.0004327990049038078 -o hyperband_runs_20241120_172038/run_s5_n141 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:09:15,516 - INFO - Training completed for config s5_n141:
  Training time: 0:00:14
  Final validation loss: 10.879909
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.85e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n141/checkpoint.bin
2024-11-20 22:09:15,516 - INFO - 
Configuration s5_n141 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004327990049038078",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n141",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.879909
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.85e-06
2024-11-20 22:09:15,516 - INFO - 
Starting training for config s5_n142:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:09:15,516 - INFO - Running command: ./train_gpt2cu -l 0.00037537975536683246 -o hyperband_runs_20241120_172038/run_s5_n142 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:09:29,915 - INFO - Training completed for config s5_n142:
  Training time: 0:00:14
  Final validation loss: 10.884102
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.61e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n142/checkpoint.bin
2024-11-20 22:09:29,915 - INFO - 
Configuration s5_n142 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00037537975536683246",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n142",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.884102
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.61e-06
2024-11-20 22:09:29,915 - INFO - 
Starting training for config s5_n143:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:09:29,915 - INFO - Running command: ./train_gpt2cu -l 5.954911619306399e-05 -o hyperband_runs_20241120_172038/run_s5_n143 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:09:44,350 - INFO - Training completed for config s5_n143:
  Training time: 0:00:14
  Final validation loss: 10.907235
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.55e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n143/checkpoint.bin
2024-11-20 22:09:44,350 - INFO - 
Configuration s5_n143 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "5.954911619306399e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n143",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.907235
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.55e-07
2024-11-20 22:09:44,350 - INFO - 
Starting training for config s5_n144:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:09:44,351 - INFO - Running command: ./train_gpt2cu -l 0.0005113530148493589 -o hyperband_runs_20241120_172038/run_s5_n144 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:09:58,755 - INFO - Training completed for config s5_n144:
  Training time: 0:00:14
  Final validation loss: 10.874222
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.19e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n144/checkpoint.bin
2024-11-20 22:09:58,755 - INFO - 
Configuration s5_n144 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005113530148493589",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n144",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.874222
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.19e-06
2024-11-20 22:09:58,755 - INFO - 
Starting training for config s5_n145:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:09:58,755 - INFO - Running command: ./train_gpt2cu -l 1.30702141985552e-05 -o hyperband_runs_20241120_172038/run_s5_n145 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:10:13,164 - INFO - Training completed for config s5_n145:
  Training time: 0:00:14
  Final validation loss: 10.910654
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.60e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n145/checkpoint.bin
2024-11-20 22:10:13,164 - INFO - 
Configuration s5_n145 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.30702141985552e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n145",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910654
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.60e-08
2024-11-20 22:10:13,164 - INFO - 
Starting training for config s5_n146:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:10:13,164 - INFO - Running command: ./train_gpt2cu -l 0.0008813068343693393 -o hyperband_runs_20241120_172038/run_s5_n146 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:10:27,574 - INFO - Training completed for config s5_n146:
  Training time: 0:00:14
  Final validation loss: 10.847554
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.78e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n146/checkpoint.bin
2024-11-20 22:10:27,574 - INFO - 
Configuration s5_n146 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008813068343693393",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n146",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.847554
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.78e-06
2024-11-20 22:10:27,574 - INFO - 
Starting training for config s5_n147:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:10:27,574 - INFO - Running command: ./train_gpt2cu -l 0.00014979390841124128 -o hyperband_runs_20241120_172038/run_s5_n147 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:10:41,969 - INFO - Training completed for config s5_n147:
  Training time: 0:00:14
  Final validation loss: 10.900629
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.42e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n147/checkpoint.bin
2024-11-20 22:10:41,969 - INFO - 
Configuration s5_n147 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014979390841124128",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n147",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.900629
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.42e-07
2024-11-20 22:10:41,969 - INFO - 
Starting training for config s5_n148:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:10:41,970 - INFO - Running command: ./train_gpt2cu -l 2.8426119968784288e-05 -o hyperband_runs_20241120_172038/run_s5_n148 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:10:56,374 - INFO - Training completed for config s5_n148:
  Training time: 0:00:14
  Final validation loss: 10.909541
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.22e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n148/checkpoint.bin
2024-11-20 22:10:56,374 - INFO - 
Configuration s5_n148 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.8426119968784288e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n148",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909541
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.22e-07
2024-11-20 22:10:56,374 - INFO - 
Starting training for config s5_n149:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:10:56,374 - INFO - Running command: ./train_gpt2cu -l 2.396671461233906e-05 -o hyperband_runs_20241120_172038/run_s5_n149 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:11:10,781 - INFO - Training completed for config s5_n149:
  Training time: 0:00:14
  Final validation loss: 10.909853
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.03e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n149/checkpoint.bin
2024-11-20 22:11:10,782 - INFO - 
Configuration s5_n149 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.396671461233906e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n149",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909853
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.03e-07
2024-11-20 22:11:10,782 - INFO - 
Starting training for config s5_n150:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:11:10,782 - INFO - Running command: ./train_gpt2cu -l 0.00047891054478801877 -o hyperband_runs_20241120_172038/run_s5_n150 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:11:25,189 - INFO - Training completed for config s5_n150:
  Training time: 0:00:14
  Final validation loss: 10.876562
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.05e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n150/checkpoint.bin
2024-11-20 22:11:25,189 - INFO - 
Configuration s5_n150 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00047891054478801877",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n150",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.876562
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.05e-06
2024-11-20 22:11:25,189 - INFO - 
Starting training for config s5_n151:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:11:25,189 - INFO - Running command: ./train_gpt2cu -l 0.0006133593856173028 -o hyperband_runs_20241120_172038/run_s5_n151 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:11:39,594 - INFO - Training completed for config s5_n151:
  Training time: 0:00:14
  Final validation loss: 10.866836
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.63e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n151/checkpoint.bin
2024-11-20 22:11:39,594 - INFO - 
Configuration s5_n151 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006133593856173028",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n151",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.866836
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.63e-06
2024-11-20 22:11:39,594 - INFO - 
Starting training for config s5_n152:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:11:39,594 - INFO - Running command: ./train_gpt2cu -l 0.0004227493452401578 -o hyperband_runs_20241120_172038/run_s5_n152 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:11:54,011 - INFO - Training completed for config s5_n152:
  Training time: 0:00:14
  Final validation loss: 10.880655
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.81e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n152/checkpoint.bin
2024-11-20 22:11:54,012 - INFO - 
Configuration s5_n152 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004227493452401578",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n152",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.880655
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.81e-06
2024-11-20 22:11:54,012 - INFO - 
Starting training for config s5_n153:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:11:54,012 - INFO - Running command: ./train_gpt2cu -l 0.00029206344126709867 -o hyperband_runs_20241120_172038/run_s5_n153 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:12:08,422 - INFO - Training completed for config s5_n153:
  Training time: 0:00:14
  Final validation loss: 10.890219
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.25e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n153/checkpoint.bin
2024-11-20 22:12:08,422 - INFO - 
Configuration s5_n153 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00029206344126709867",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n153",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.890219
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.25e-06
2024-11-20 22:12:08,422 - INFO - 
Starting training for config s5_n154:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:12:08,422 - INFO - Running command: ./train_gpt2cu -l 3.6330199620860965e-05 -o hyperband_runs_20241120_172038/run_s5_n154 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:12:22,854 - INFO - Training completed for config s5_n154:
  Training time: 0:00:14
  Final validation loss: 10.908953
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.56e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n154/checkpoint.bin
2024-11-20 22:12:22,854 - INFO - 
Configuration s5_n154 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.6330199620860965e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n154",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.908953
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.56e-07
2024-11-20 22:12:22,854 - INFO - 
Starting training for config s5_n155:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:12:22,855 - INFO - Running command: ./train_gpt2cu -l 0.00039233776926718314 -o hyperband_runs_20241120_172038/run_s5_n155 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:12:37,271 - INFO - Training completed for config s5_n155:
  Training time: 0:00:14
  Final validation loss: 10.882877
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.68e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n155/checkpoint.bin
2024-11-20 22:12:37,271 - INFO - 
Configuration s5_n155 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00039233776926718314",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n155",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.882877
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.68e-06
2024-11-20 22:12:37,271 - INFO - 
Starting training for config s5_n156:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:12:37,272 - INFO - Running command: ./train_gpt2cu -l 1.8294422495183636e-05 -o hyperband_runs_20241120_172038/run_s5_n156 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:12:51,702 - INFO - Training completed for config s5_n156:
  Training time: 0:00:14
  Final validation loss: 10.910261
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.84e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n156/checkpoint.bin
2024-11-20 22:12:51,703 - INFO - 
Configuration s5_n156 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.8294422495183636e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n156",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910261
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.84e-08
2024-11-20 22:12:51,703 - INFO - 
Starting training for config s5_n157:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:12:51,703 - INFO - Running command: ./train_gpt2cu -l 0.0006705481284587626 -o hyperband_runs_20241120_172038/run_s5_n157 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:13:06,106 - INFO - Training completed for config s5_n157:
  Training time: 0:00:14
  Final validation loss: 10.862679
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.87e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n157/checkpoint.bin
2024-11-20 22:13:06,106 - INFO - 
Configuration s5_n157 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006705481284587626",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n157",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.862679
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.87e-06
2024-11-20 22:13:06,107 - INFO - 
Starting training for config s5_n158:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:13:06,107 - INFO - Running command: ./train_gpt2cu -l 2.4535620539647463e-05 -o hyperband_runs_20241120_172038/run_s5_n158 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:13:20,524 - INFO - Training completed for config s5_n158:
  Training time: 0:00:14
  Final validation loss: 10.909804
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.05e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n158/checkpoint.bin
2024-11-20 22:13:20,524 - INFO - 
Configuration s5_n158 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.4535620539647463e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n158",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909804
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.05e-07
2024-11-20 22:13:20,524 - INFO - 
Starting training for config s5_n159:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:13:20,524 - INFO - Running command: ./train_gpt2cu -l 1.788598906571309e-05 -o hyperband_runs_20241120_172038/run_s5_n159 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:13:34,938 - INFO - Training completed for config s5_n159:
  Training time: 0:00:14
  Final validation loss: 10.910285
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.67e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n159/checkpoint.bin
2024-11-20 22:13:34,938 - INFO - 
Configuration s5_n159 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.788598906571309e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n159",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910285
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.67e-08
2024-11-20 22:13:34,938 - INFO - 
Starting training for config s5_n160:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:13:34,938 - INFO - Running command: ./train_gpt2cu -l 0.0009822324088212349 -o hyperband_runs_20241120_172038/run_s5_n160 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:13:49,347 - INFO - Training completed for config s5_n160:
  Training time: 0:00:14
  Final validation loss: 10.840334
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.21e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin
2024-11-20 22:13:49,347 - INFO - 
Configuration s5_n160 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009822324088212349",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n160",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.840334
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.21e-06
2024-11-20 22:13:49,347 - INFO - 
Starting training for config s5_n161:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:13:49,348 - INFO - Running command: ./train_gpt2cu -l 1.6174864650040912e-05 -o hyperband_runs_20241120_172038/run_s5_n161 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:14:03,769 - INFO - Training completed for config s5_n161:
  Training time: 0:00:14
  Final validation loss: 10.910416
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.93e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n161/checkpoint.bin
2024-11-20 22:14:03,769 - INFO - 
Configuration s5_n161 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.6174864650040912e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n161",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910416
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.93e-08
2024-11-20 22:14:03,770 - INFO - 
Starting training for config s5_n162:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:14:03,770 - INFO - Running command: ./train_gpt2cu -l 0.00016760270119083712 -o hyperband_runs_20241120_172038/run_s5_n162 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:14:18,183 - INFO - Training completed for config s5_n162:
  Training time: 0:00:14
  Final validation loss: 10.899314
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.18e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n162/checkpoint.bin
2024-11-20 22:14:18,183 - INFO - 
Configuration s5_n162 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00016760270119083712",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n162",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.899314
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.18e-07
2024-11-20 22:14:18,183 - INFO - 
Starting training for config s5_n163:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:14:18,184 - INFO - Running command: ./train_gpt2cu -l 2.400899158034307e-05 -o hyperband_runs_20241120_172038/run_s5_n163 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:14:32,603 - INFO - Training completed for config s5_n163:
  Training time: 0:00:14
  Final validation loss: 10.909856
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.03e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n163/checkpoint.bin
2024-11-20 22:14:32,603 - INFO - 
Configuration s5_n163 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.400899158034307e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n163",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909856
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.03e-07
2024-11-20 22:14:32,603 - INFO - 
Starting training for config s5_n164:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:14:32,604 - INFO - Running command: ./train_gpt2cu -l 0.0003862436206482557 -o hyperband_runs_20241120_172038/run_s5_n164 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:14:47,012 - INFO - Training completed for config s5_n164:
  Training time: 0:00:14
  Final validation loss: 10.883318
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.66e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n164/checkpoint.bin
2024-11-20 22:14:47,012 - INFO - 
Configuration s5_n164 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003862436206482557",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n164",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.883318
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.66e-06
2024-11-20 22:14:47,012 - INFO - 
Starting training for config s5_n165:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:14:47,013 - INFO - Running command: ./train_gpt2cu -l 3.4915633103839184e-05 -o hyperband_runs_20241120_172038/run_s5_n165 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:15:01,424 - INFO - Training completed for config s5_n165:
  Training time: 0:00:14
  Final validation loss: 10.909046
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.50e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n165/checkpoint.bin
2024-11-20 22:15:01,424 - INFO - 
Configuration s5_n165 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.4915633103839184e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n165",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909046
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.50e-07
2024-11-20 22:15:01,424 - INFO - 
Starting training for config s5_n166:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:15:01,424 - INFO - Running command: ./train_gpt2cu -l 5.302392906939359e-05 -o hyperband_runs_20241120_172038/run_s5_n166 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:15:15,845 - INFO - Training completed for config s5_n166:
  Training time: 0:00:14
  Final validation loss: 10.907705
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.27e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n166/checkpoint.bin
2024-11-20 22:15:15,845 - INFO - 
Configuration s5_n166 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "5.302392906939359e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n166",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.907705
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.27e-07
2024-11-20 22:15:15,846 - INFO - 
Starting training for config s5_n167:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:15:15,846 - INFO - Running command: ./train_gpt2cu -l 0.0006705540199959338 -o hyperband_runs_20241120_172038/run_s5_n167 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:15:30,253 - INFO - Training completed for config s5_n167:
  Training time: 0:00:14
  Final validation loss: 10.862692
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.87e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n167/checkpoint.bin
2024-11-20 22:15:30,253 - INFO - 
Configuration s5_n167 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006705540199959338",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n167",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.862692
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.87e-06
2024-11-20 22:15:30,254 - INFO - 
Starting training for config s5_n168:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:15:30,254 - INFO - Running command: ./train_gpt2cu -l 2.9255918417157e-05 -o hyperband_runs_20241120_172038/run_s5_n168 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:15:44,669 - INFO - Training completed for config s5_n168:
  Training time: 0:00:14
  Final validation loss: 10.909460
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.25e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n168/checkpoint.bin
2024-11-20 22:15:44,670 - INFO - 
Configuration s5_n168 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.9255918417157e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n168",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909460
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.25e-07
2024-11-20 22:15:44,670 - INFO - 
Starting training for config s5_n169:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:15:44,670 - INFO - Running command: ./train_gpt2cu -l 0.0004396348926023942 -o hyperband_runs_20241120_172038/run_s5_n169 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:15:59,065 - INFO - Training completed for config s5_n169:
  Training time: 0:00:14
  Final validation loss: 10.879416
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.88e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n169/checkpoint.bin
2024-11-20 22:15:59,065 - INFO - 
Configuration s5_n169 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004396348926023942",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n169",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.879416
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.88e-06
2024-11-20 22:15:59,066 - INFO - 
Starting training for config s5_n170:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:15:59,066 - INFO - Running command: ./train_gpt2cu -l 0.0006832720543350221 -o hyperband_runs_20241120_172038/run_s5_n170 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:16:13,458 - INFO - Training completed for config s5_n170:
  Training time: 0:00:14
  Final validation loss: 10.861774
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.93e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n170/checkpoint.bin
2024-11-20 22:16:13,459 - INFO - 
Configuration s5_n170 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006832720543350221",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n170",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.861774
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.93e-06
2024-11-20 22:16:13,459 - INFO - 
Starting training for config s5_n171:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:16:13,459 - INFO - Running command: ./train_gpt2cu -l 3.0424933294492693e-05 -o hyperband_runs_20241120_172038/run_s5_n171 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:16:27,849 - INFO - Training completed for config s5_n171:
  Training time: 0:00:14
  Final validation loss: 10.909391
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.30e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n171/checkpoint.bin
2024-11-20 22:16:27,849 - INFO - 
Configuration s5_n171 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.0424933294492693e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n171",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909391
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.30e-07
2024-11-20 22:16:27,849 - INFO - 
Starting training for config s5_n172:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:16:27,849 - INFO - Running command: ./train_gpt2cu -l 0.00033982779562731827 -o hyperband_runs_20241120_172038/run_s5_n172 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:16:42,235 - INFO - Training completed for config s5_n172:
  Training time: 0:00:14
  Final validation loss: 10.886714
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.46e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n172/checkpoint.bin
2024-11-20 22:16:42,235 - INFO - 
Configuration s5_n172 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00033982779562731827",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n172",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.886714
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.46e-06
2024-11-20 22:16:42,235 - INFO - 
Starting training for config s5_n173:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:16:42,235 - INFO - Running command: ./train_gpt2cu -l 0.0004956644074228404 -o hyperband_runs_20241120_172038/run_s5_n173 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:16:56,630 - INFO - Training completed for config s5_n173:
  Training time: 0:00:14
  Final validation loss: 10.875353
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.12e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n173/checkpoint.bin
2024-11-20 22:16:56,630 - INFO - 
Configuration s5_n173 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004956644074228404",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n173",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.875353
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.12e-06
2024-11-20 22:16:56,631 - INFO - 
Starting training for config s5_n174:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:16:56,631 - INFO - Running command: ./train_gpt2cu -l 0.0003201668875819047 -o hyperband_runs_20241120_172038/run_s5_n174 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:17:11,031 - INFO - Training completed for config s5_n174:
  Training time: 0:00:14
  Final validation loss: 10.888168
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.37e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n174/checkpoint.bin
2024-11-20 22:17:11,031 - INFO - 
Configuration s5_n174 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003201668875819047",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n174",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.888168
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.37e-06
2024-11-20 22:17:11,031 - INFO - 
Starting training for config s5_n175:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:17:11,031 - INFO - Running command: ./train_gpt2cu -l 3.0353556711834146e-05 -o hyperband_runs_20241120_172038/run_s5_n175 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:17:25,438 - INFO - Training completed for config s5_n175:
  Training time: 0:00:14
  Final validation loss: 10.909383
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.30e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n175/checkpoint.bin
2024-11-20 22:17:25,438 - INFO - 
Configuration s5_n175 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.0353556711834146e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n175",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909383
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.30e-07
2024-11-20 22:17:25,439 - INFO - 
Starting training for config s5_n176:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:17:25,439 - INFO - Running command: ./train_gpt2cu -l 1.4667520680977203e-05 -o hyperband_runs_20241120_172038/run_s5_n176 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:17:39,846 - INFO - Training completed for config s5_n176:
  Training time: 0:00:14
  Final validation loss: 10.910521
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.29e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n176/checkpoint.bin
2024-11-20 22:17:39,847 - INFO - 
Configuration s5_n176 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.4667520680977203e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n176",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910521
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.29e-08
2024-11-20 22:17:39,847 - INFO - 
Starting training for config s5_n177:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:17:39,847 - INFO - Running command: ./train_gpt2cu -l 4.446228001019753e-05 -o hyperband_runs_20241120_172038/run_s5_n177 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:17:54,246 - INFO - Training completed for config s5_n177:
  Training time: 0:00:14
  Final validation loss: 10.908353
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.91e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n177/checkpoint.bin
2024-11-20 22:17:54,246 - INFO - 
Configuration s5_n177 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "4.446228001019753e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n177",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.908353
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.91e-07
2024-11-20 22:17:54,246 - INFO - 
Starting training for config s5_n178:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:17:54,246 - INFO - Running command: ./train_gpt2cu -l 0.00029093265701808955 -o hyperband_runs_20241120_172038/run_s5_n178 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:18:08,662 - INFO - Training completed for config s5_n178:
  Training time: 0:00:14
  Final validation loss: 10.890306
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.25e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n178/checkpoint.bin
2024-11-20 22:18:08,662 - INFO - 
Configuration s5_n178 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00029093265701808955",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n178",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.890306
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.25e-06
2024-11-20 22:18:08,662 - INFO - 
Starting training for config s5_n179:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:18:08,662 - INFO - Running command: ./train_gpt2cu -l 0.00024174509235077194 -o hyperband_runs_20241120_172038/run_s5_n179 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:18:23,063 - INFO - Training completed for config s5_n179:
  Training time: 0:00:14
  Final validation loss: 10.893915
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.04e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n179/checkpoint.bin
2024-11-20 22:18:23,063 - INFO - 
Configuration s5_n179 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00024174509235077194",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n179",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.893915
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.04e-06
2024-11-20 22:18:23,063 - INFO - 
Starting training for config s5_n180:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:18:23,063 - INFO - Running command: ./train_gpt2cu -l 7.912158053489148e-05 -o hyperband_runs_20241120_172038/run_s5_n180 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:18:37,471 - INFO - Training completed for config s5_n180:
  Training time: 0:00:14
  Final validation loss: 10.905812
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.39e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n180/checkpoint.bin
2024-11-20 22:18:37,471 - INFO - 
Configuration s5_n180 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "7.912158053489148e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n180",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.905812
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.39e-07
2024-11-20 22:18:37,471 - INFO - 
Starting training for config s5_n181:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:18:37,472 - INFO - Running command: ./train_gpt2cu -l 3.071737772318664e-05 -o hyperband_runs_20241120_172038/run_s5_n181 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:18:51,921 - INFO - Training completed for config s5_n181:
  Training time: 0:00:14
  Final validation loss: 10.909362
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.32e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n181/checkpoint.bin
2024-11-20 22:18:51,921 - INFO - 
Configuration s5_n181 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.071737772318664e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n181",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909362
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.32e-07
2024-11-20 22:18:51,921 - INFO - 
Starting training for config s5_n182:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:18:51,921 - INFO - Running command: ./train_gpt2cu -l 1.7629868210458066e-05 -o hyperband_runs_20241120_172038/run_s5_n182 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:19:06,325 - INFO - Training completed for config s5_n182:
  Training time: 0:00:14
  Final validation loss: 10.910311
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.56e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n182/checkpoint.bin
2024-11-20 22:19:06,325 - INFO - 
Configuration s5_n182 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.7629868210458066e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n182",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910311
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.56e-08
2024-11-20 22:19:06,325 - INFO - 
Starting training for config s5_n183:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:19:06,325 - INFO - Running command: ./train_gpt2cu -l 1.3496433687727099e-05 -o hyperband_runs_20241120_172038/run_s5_n183 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:19:20,762 - INFO - Training completed for config s5_n183:
  Training time: 0:00:14
  Final validation loss: 10.910608
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.78e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n183/checkpoint.bin
2024-11-20 22:19:20,762 - INFO - 
Configuration s5_n183 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.3496433687727099e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n183",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910608
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.78e-08
2024-11-20 22:19:20,762 - INFO - 
Starting training for config s5_n184:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:19:20,762 - INFO - Running command: ./train_gpt2cu -l 6.341146995923818e-05 -o hyperband_runs_20241120_172038/run_s5_n184 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:19:35,166 - INFO - Training completed for config s5_n184:
  Training time: 0:00:14
  Final validation loss: 10.906958
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.72e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n184/checkpoint.bin
2024-11-20 22:19:35,166 - INFO - 
Configuration s5_n184 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "6.341146995923818e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n184",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.906958
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.72e-07
2024-11-20 22:19:35,166 - INFO - 
Starting training for config s5_n185:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:19:35,166 - INFO - Running command: ./train_gpt2cu -l 1.396550628481838e-05 -o hyperband_runs_20241120_172038/run_s5_n185 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:19:49,576 - INFO - Training completed for config s5_n185:
  Training time: 0:00:14
  Final validation loss: 10.910585
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.99e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n185/checkpoint.bin
2024-11-20 22:19:49,576 - INFO - 
Configuration s5_n185 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.396550628481838e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n185",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910585
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.99e-08
2024-11-20 22:19:49,576 - INFO - 
Starting training for config s5_n186:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:19:49,577 - INFO - Running command: ./train_gpt2cu -l 0.0005880547945739206 -o hyperband_runs_20241120_172038/run_s5_n186 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:20:03,976 - INFO - Training completed for config s5_n186:
  Training time: 0:00:14
  Final validation loss: 10.868646
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.52e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n186/checkpoint.bin
2024-11-20 22:20:03,976 - INFO - 
Configuration s5_n186 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005880547945739206",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n186",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.868646
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.52e-06
2024-11-20 22:20:03,976 - INFO - 
Starting training for config s5_n187:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:20:03,976 - INFO - Running command: ./train_gpt2cu -l 1.4453373093891094e-05 -o hyperband_runs_20241120_172038/run_s5_n187 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:20:18,389 - INFO - Training completed for config s5_n187:
  Training time: 0:00:14
  Final validation loss: 10.910540
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.19e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n187/checkpoint.bin
2024-11-20 22:20:18,390 - INFO - 
Configuration s5_n187 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.4453373093891094e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n187",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910540
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.19e-08
2024-11-20 22:20:18,390 - INFO - 
Starting training for config s5_n188:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:20:18,390 - INFO - Running command: ./train_gpt2cu -l 4.803229226893213e-05 -o hyperband_runs_20241120_172038/run_s5_n188 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:20:32,800 - INFO - Training completed for config s5_n188:
  Training time: 0:00:14
  Final validation loss: 10.908075
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.06e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n188/checkpoint.bin
2024-11-20 22:20:32,800 - INFO - 
Configuration s5_n188 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "4.803229226893213e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n188",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.908075
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.06e-07
2024-11-20 22:20:32,800 - INFO - 
Starting training for config s5_n189:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:20:32,800 - INFO - Running command: ./train_gpt2cu -l 0.00029278188084328177 -o hyperband_runs_20241120_172038/run_s5_n189 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:20:47,212 - INFO - Training completed for config s5_n189:
  Training time: 0:00:14
  Final validation loss: 10.890171
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.25e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n189/checkpoint.bin
2024-11-20 22:20:47,212 - INFO - 
Configuration s5_n189 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00029278188084328177",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n189",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.890171
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.25e-06
2024-11-20 22:20:47,212 - INFO - 
Starting training for config s5_n190:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:20:47,212 - INFO - Running command: ./train_gpt2cu -l 0.00048201894452236854 -o hyperband_runs_20241120_172038/run_s5_n190 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:21:01,633 - INFO - Training completed for config s5_n190:
  Training time: 0:00:14
  Final validation loss: 10.876342
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.07e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n190/checkpoint.bin
2024-11-20 22:21:01,633 - INFO - 
Configuration s5_n190 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00048201894452236854",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n190",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.876342
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.07e-06
2024-11-20 22:21:01,634 - INFO - 
Starting training for config s5_n191:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:21:01,634 - INFO - Running command: ./train_gpt2cu -l 1.0865641035974079e-05 -o hyperband_runs_20241120_172038/run_s5_n191 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:21:16,042 - INFO - Training completed for config s5_n191:
  Training time: 0:00:14
  Final validation loss: 10.910803
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.66e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n191/checkpoint.bin
2024-11-20 22:21:16,042 - INFO - 
Configuration s5_n191 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.0865641035974079e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n191",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910803
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.66e-08
2024-11-20 22:21:16,042 - INFO - 
Starting training for config s5_n192:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:21:16,042 - INFO - Running command: ./train_gpt2cu -l 1.7745145810461805e-05 -o hyperband_runs_20241120_172038/run_s5_n192 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:21:30,448 - INFO - Training completed for config s5_n192:
  Training time: 0:00:14
  Final validation loss: 10.910310
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.61e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n192/checkpoint.bin
2024-11-20 22:21:30,449 - INFO - 
Configuration s5_n192 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.7745145810461805e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n192",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910310
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.61e-08
2024-11-20 22:21:30,449 - INFO - 
Starting training for config s5_n193:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:21:30,449 - INFO - Running command: ./train_gpt2cu -l 0.0007853484168511458 -o hyperband_runs_20241120_172038/run_s5_n193 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:21:44,862 - INFO - Training completed for config s5_n193:
  Training time: 0:00:14
  Final validation loss: 10.854395
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.37e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n193/checkpoint.bin
2024-11-20 22:21:44,862 - INFO - 
Configuration s5_n193 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007853484168511458",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n193",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.854395
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.37e-06
2024-11-20 22:21:44,862 - INFO - 
Starting training for config s5_n194:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:21:44,862 - INFO - Running command: ./train_gpt2cu -l 5.716876074277193e-05 -o hyperband_runs_20241120_172038/run_s5_n194 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:21:59,263 - INFO - Training completed for config s5_n194:
  Training time: 0:00:14
  Final validation loss: 10.907397
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.45e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n194/checkpoint.bin
2024-11-20 22:21:59,263 - INFO - 
Configuration s5_n194 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "5.716876074277193e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n194",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.907397
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.45e-07
2024-11-20 22:21:59,263 - INFO - 
Starting training for config s5_n195:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:21:59,263 - INFO - Running command: ./train_gpt2cu -l 1.1505864988701645e-05 -o hyperband_runs_20241120_172038/run_s5_n195 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:22:13,685 - INFO - Training completed for config s5_n195:
  Training time: 0:00:14
  Final validation loss: 10.910757
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.93e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n195/checkpoint.bin
2024-11-20 22:22:13,685 - INFO - 
Configuration s5_n195 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.1505864988701645e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n195",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910757
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.93e-08
2024-11-20 22:22:13,685 - INFO - 
Starting training for config s5_n196:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:22:13,686 - INFO - Running command: ./train_gpt2cu -l 0.00026721099071312654 -o hyperband_runs_20241120_172038/run_s5_n196 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:22:28,084 - INFO - Training completed for config s5_n196:
  Training time: 0:00:14
  Final validation loss: 10.892031
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.15e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n196/checkpoint.bin
2024-11-20 22:22:28,085 - INFO - 
Configuration s5_n196 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00026721099071312654",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n196",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.892031
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.15e-06
2024-11-20 22:22:28,085 - INFO - 
Starting training for config s5_n197:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:22:28,085 - INFO - Running command: ./train_gpt2cu -l 2.6696103641199992e-05 -o hyperband_runs_20241120_172038/run_s5_n197 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:22:42,491 - INFO - Training completed for config s5_n197:
  Training time: 0:00:14
  Final validation loss: 10.909651
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.14e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n197/checkpoint.bin
2024-11-20 22:22:42,491 - INFO - 
Configuration s5_n197 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.6696103641199992e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n197",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909651
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.14e-07
2024-11-20 22:22:42,491 - INFO - 
Starting training for config s5_n198:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:22:42,491 - INFO - Running command: ./train_gpt2cu -l 1.06488658384139e-05 -o hyperband_runs_20241120_172038/run_s5_n198 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:22:56,912 - INFO - Training completed for config s5_n198:
  Training time: 0:00:14
  Final validation loss: 10.910826
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.56e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n198/checkpoint.bin
2024-11-20 22:22:56,912 - INFO - 
Configuration s5_n198 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.06488658384139e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n198",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910826
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.56e-08
2024-11-20 22:22:56,912 - INFO - 
Starting training for config s5_n199:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:22:56,913 - INFO - Running command: ./train_gpt2cu -l 0.00016013747726348912 -o hyperband_runs_20241120_172038/run_s5_n199 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:23:11,318 - INFO - Training completed for config s5_n199:
  Training time: 0:00:14
  Final validation loss: 10.899867
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.86e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n199/checkpoint.bin
2024-11-20 22:23:11,318 - INFO - 
Configuration s5_n199 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00016013747726348912",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n199",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.899867
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.86e-07
2024-11-20 22:23:11,318 - INFO - 
Starting training for config s5_n200:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:23:11,319 - INFO - Running command: ./train_gpt2cu -l 0.0003427184507712492 -o hyperband_runs_20241120_172038/run_s5_n200 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:23:25,735 - INFO - Training completed for config s5_n200:
  Training time: 0:00:14
  Final validation loss: 10.886510
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.47e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n200/checkpoint.bin
2024-11-20 22:23:25,735 - INFO - 
Configuration s5_n200 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003427184507712492",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n200",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.886510
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.47e-06
2024-11-20 22:23:25,735 - INFO - 
Starting training for config s5_n201:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:23:25,735 - INFO - Running command: ./train_gpt2cu -l 0.0008419142751758245 -o hyperband_runs_20241120_172038/run_s5_n201 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:23:40,147 - INFO - Training completed for config s5_n201:
  Training time: 0:00:14
  Final validation loss: 10.850363
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.61e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n201/checkpoint.bin
2024-11-20 22:23:40,147 - INFO - 
Configuration s5_n201 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008419142751758245",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n201",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.850363
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.61e-06
2024-11-20 22:23:40,147 - INFO - 
Starting training for config s5_n202:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:23:40,147 - INFO - Running command: ./train_gpt2cu -l 0.0001367130480618527 -o hyperband_runs_20241120_172038/run_s5_n202 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:23:54,547 - INFO - Training completed for config s5_n202:
  Training time: 0:00:14
  Final validation loss: 10.901577
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.86e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n202/checkpoint.bin
2024-11-20 22:23:54,548 - INFO - 
Configuration s5_n202 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001367130480618527",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n202",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.901577
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.86e-07
2024-11-20 22:23:54,548 - INFO - 
Starting training for config s5_n203:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:23:54,548 - INFO - Running command: ./train_gpt2cu -l 4.851378051383756e-05 -o hyperband_runs_20241120_172038/run_s5_n203 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:24:08,951 - INFO - Training completed for config s5_n203:
  Training time: 0:00:14
  Final validation loss: 10.908052
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.08e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n203/checkpoint.bin
2024-11-20 22:24:08,951 - INFO - 
Configuration s5_n203 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "4.851378051383756e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n203",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.908052
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.08e-07
2024-11-20 22:24:08,951 - INFO - 
Starting training for config s5_n204:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:24:08,952 - INFO - Running command: ./train_gpt2cu -l 9.789866391126416e-05 -o hyperband_runs_20241120_172038/run_s5_n204 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:24:23,342 - INFO - Training completed for config s5_n204:
  Training time: 0:00:14
  Final validation loss: 10.904449
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.20e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n204/checkpoint.bin
2024-11-20 22:24:23,342 - INFO - 
Configuration s5_n204 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "9.789866391126416e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n204",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.904449
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.20e-07
2024-11-20 22:24:23,342 - INFO - 
Starting training for config s5_n205:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:24:23,343 - INFO - Running command: ./train_gpt2cu -l 0.0002611687203778593 -o hyperband_runs_20241120_172038/run_s5_n205 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:24:37,753 - INFO - Training completed for config s5_n205:
  Training time: 0:00:14
  Final validation loss: 10.892473
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.12e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n205/checkpoint.bin
2024-11-20 22:24:37,754 - INFO - 
Configuration s5_n205 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002611687203778593",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n205",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.892473
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.12e-06
2024-11-20 22:24:37,754 - INFO - 
Starting training for config s5_n206:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:24:37,754 - INFO - Running command: ./train_gpt2cu -l 0.00019803431142593827 -o hyperband_runs_20241120_172038/run_s5_n206 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:24:52,153 - INFO - Training completed for config s5_n206:
  Training time: 0:00:14
  Final validation loss: 10.897089
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 8.49e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n206/checkpoint.bin
2024-11-20 22:24:52,154 - INFO - 
Configuration s5_n206 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00019803431142593827",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n206",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.897089
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.49e-07
2024-11-20 22:24:52,154 - INFO - 
Starting training for config s5_n207:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:24:52,154 - INFO - Running command: ./train_gpt2cu -l 0.0006507552592411038 -o hyperband_runs_20241120_172038/run_s5_n207 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:25:06,561 - INFO - Training completed for config s5_n207:
  Training time: 0:00:14
  Final validation loss: 10.864100
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.79e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n207/checkpoint.bin
2024-11-20 22:25:06,561 - INFO - 
Configuration s5_n207 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006507552592411038",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n207",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.864100
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.79e-06
2024-11-20 22:25:06,561 - INFO - 
Starting training for config s5_n208:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:25:06,561 - INFO - Running command: ./train_gpt2cu -l 0.0005829119447162065 -o hyperband_runs_20241120_172038/run_s5_n208 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:25:20,960 - INFO - Training completed for config s5_n208:
  Training time: 0:00:14
  Final validation loss: 10.869024
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.50e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n208/checkpoint.bin
2024-11-20 22:25:20,960 - INFO - 
Configuration s5_n208 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005829119447162065",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n208",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.869024
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.50e-06
2024-11-20 22:25:20,960 - INFO - 
Starting training for config s5_n209:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:25:20,960 - INFO - Running command: ./train_gpt2cu -l 1.0077613618043684e-05 -o hyperband_runs_20241120_172038/run_s5_n209 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:25:35,391 - INFO - Training completed for config s5_n209:
  Training time: 0:00:14
  Final validation loss: 10.910866
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.32e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n209/checkpoint.bin
2024-11-20 22:25:35,391 - INFO - 
Configuration s5_n209 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.0077613618043684e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n209",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910866
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.32e-08
2024-11-20 22:25:35,391 - INFO - 
Starting training for config s5_n210:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:25:35,391 - INFO - Running command: ./train_gpt2cu -l 0.0006410662231365501 -o hyperband_runs_20241120_172038/run_s5_n210 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:25:49,794 - INFO - Training completed for config s5_n210:
  Training time: 0:00:14
  Final validation loss: 10.864818
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.75e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n210/checkpoint.bin
2024-11-20 22:25:49,794 - INFO - 
Configuration s5_n210 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006410662231365501",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n210",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.864818
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.75e-06
2024-11-20 22:25:49,794 - INFO - 
Starting training for config s5_n211:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:25:49,794 - INFO - Running command: ./train_gpt2cu -l 1.0590155461548745e-05 -o hyperband_runs_20241120_172038/run_s5_n211 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:26:04,203 - INFO - Training completed for config s5_n211:
  Training time: 0:00:14
  Final validation loss: 10.910833
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.54e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n211/checkpoint.bin
2024-11-20 22:26:04,203 - INFO - 
Configuration s5_n211 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.0590155461548745e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n211",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910833
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.54e-08
2024-11-20 22:26:04,203 - INFO - 
Starting training for config s5_n212:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:26:04,203 - INFO - Running command: ./train_gpt2cu -l 8.308586852792218e-05 -o hyperband_runs_20241120_172038/run_s5_n212 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:26:18,607 - INFO - Training completed for config s5_n212:
  Training time: 0:00:14
  Final validation loss: 10.905515
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.56e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n212/checkpoint.bin
2024-11-20 22:26:18,607 - INFO - 
Configuration s5_n212 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "8.308586852792218e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n212",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.905515
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.56e-07
2024-11-20 22:26:18,607 - INFO - 
Starting training for config s5_n213:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:26:18,608 - INFO - Running command: ./train_gpt2cu -l 0.0003256394600316364 -o hyperband_runs_20241120_172038/run_s5_n213 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:26:33,024 - INFO - Training completed for config s5_n213:
  Training time: 0:00:14
  Final validation loss: 10.887763
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.40e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n213/checkpoint.bin
2024-11-20 22:26:33,024 - INFO - 
Configuration s5_n213 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003256394600316364",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n213",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.887763
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.40e-06
2024-11-20 22:26:33,024 - INFO - 
Starting training for config s5_n214:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:26:33,024 - INFO - Running command: ./train_gpt2cu -l 0.00024531369836096995 -o hyperband_runs_20241120_172038/run_s5_n214 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:26:47,435 - INFO - Training completed for config s5_n214:
  Training time: 0:00:14
  Final validation loss: 10.893653
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.05e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n214/checkpoint.bin
2024-11-20 22:26:47,435 - INFO - 
Configuration s5_n214 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00024531369836096995",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n214",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.893653
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.05e-06
2024-11-20 22:26:47,435 - INFO - 
Starting training for config s5_n215:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:26:47,435 - INFO - Running command: ./train_gpt2cu -l 2.44475756667793e-05 -o hyperband_runs_20241120_172038/run_s5_n215 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:27:01,847 - INFO - Training completed for config s5_n215:
  Training time: 0:00:14
  Final validation loss: 10.909825
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.05e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n215/checkpoint.bin
2024-11-20 22:27:01,848 - INFO - 
Configuration s5_n215 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.44475756667793e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n215",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909825
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.05e-07
2024-11-20 22:27:01,848 - INFO - 
Starting training for config s5_n216:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:27:01,848 - INFO - Running command: ./train_gpt2cu -l 8.972791138387132e-05 -o hyperband_runs_20241120_172038/run_s5_n216 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:27:16,289 - INFO - Training completed for config s5_n216:
  Training time: 0:00:14
  Final validation loss: 10.905028
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.85e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n216/checkpoint.bin
2024-11-20 22:27:16,289 - INFO - 
Configuration s5_n216 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "8.972791138387132e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n216",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.905028
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.85e-07
2024-11-20 22:27:16,289 - INFO - 
Starting training for config s5_n217:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:27:16,289 - INFO - Running command: ./train_gpt2cu -l 9.931549340933117e-05 -o hyperband_runs_20241120_172038/run_s5_n217 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:27:30,687 - INFO - Training completed for config s5_n217:
  Training time: 0:00:14
  Final validation loss: 10.904337
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.26e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n217/checkpoint.bin
2024-11-20 22:27:30,688 - INFO - 
Configuration s5_n217 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "9.931549340933117e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n217",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.904337
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.26e-07
2024-11-20 22:27:30,688 - INFO - 
Starting training for config s5_n218:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:27:30,688 - INFO - Running command: ./train_gpt2cu -l 0.0005460938244902235 -o hyperband_runs_20241120_172038/run_s5_n218 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:27:45,093 - INFO - Training completed for config s5_n218:
  Training time: 0:00:14
  Final validation loss: 10.871706
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.34e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n218/checkpoint.bin
2024-11-20 22:27:45,093 - INFO - 
Configuration s5_n218 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005460938244902235",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n218",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.871706
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.34e-06
2024-11-20 22:27:45,093 - INFO - 
Starting training for config s5_n219:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:27:45,094 - INFO - Running command: ./train_gpt2cu -l 0.00010139706695259967 -o hyperband_runs_20241120_172038/run_s5_n219 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:27:59,492 - INFO - Training completed for config s5_n219:
  Training time: 0:00:14
  Final validation loss: 10.904181
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.35e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n219/checkpoint.bin
2024-11-20 22:27:59,492 - INFO - 
Configuration s5_n219 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010139706695259967",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n219",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.904181
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.35e-07
2024-11-20 22:27:59,492 - INFO - 
Starting training for config s5_n220:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:27:59,492 - INFO - Running command: ./train_gpt2cu -l 2.3336066011875665e-05 -o hyperband_runs_20241120_172038/run_s5_n220 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:28:13,908 - INFO - Training completed for config s5_n220:
  Training time: 0:00:14
  Final validation loss: 10.909900
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.00e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n220/checkpoint.bin
2024-11-20 22:28:13,909 - INFO - 
Configuration s5_n220 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.3336066011875665e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n220",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909900
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.00e-07
2024-11-20 22:28:13,909 - INFO - 
Starting training for config s5_n221:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:28:13,909 - INFO - Running command: ./train_gpt2cu -l 0.00038452647855839804 -o hyperband_runs_20241120_172038/run_s5_n221 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:28:28,320 - INFO - Training completed for config s5_n221:
  Training time: 0:00:14
  Final validation loss: 10.883451
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.65e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n221/checkpoint.bin
2024-11-20 22:28:28,320 - INFO - 
Configuration s5_n221 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00038452647855839804",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n221",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.883451
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.65e-06
2024-11-20 22:28:28,320 - INFO - 
Starting training for config s5_n222:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:28:28,320 - INFO - Running command: ./train_gpt2cu -l 2.4309428226340053e-05 -o hyperband_runs_20241120_172038/run_s5_n222 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:28:42,741 - INFO - Training completed for config s5_n222:
  Training time: 0:00:14
  Final validation loss: 10.909831
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.04e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n222/checkpoint.bin
2024-11-20 22:28:42,741 - INFO - 
Configuration s5_n222 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.4309428226340053e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n222",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909831
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.04e-07
2024-11-20 22:28:42,742 - INFO - 
Starting training for config s5_n223:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:28:42,742 - INFO - Running command: ./train_gpt2cu -l 1.666310400317767e-05 -o hyperband_runs_20241120_172038/run_s5_n223 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:28:57,148 - INFO - Training completed for config s5_n223:
  Training time: 0:00:14
  Final validation loss: 10.910382
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.14e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n223/checkpoint.bin
2024-11-20 22:28:57,149 - INFO - 
Configuration s5_n223 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.666310400317767e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n223",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910382
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.14e-08
2024-11-20 22:28:57,149 - INFO - 
Starting training for config s5_n224:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:28:57,149 - INFO - Running command: ./train_gpt2cu -l 2.9593874054192796e-05 -o hyperband_runs_20241120_172038/run_s5_n224 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:29:11,555 - INFO - Training completed for config s5_n224:
  Training time: 0:00:14
  Final validation loss: 10.909437
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.27e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n224/checkpoint.bin
2024-11-20 22:29:11,555 - INFO - 
Configuration s5_n224 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.9593874054192796e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n224",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909437
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.27e-07
2024-11-20 22:29:11,555 - INFO - 
Starting training for config s5_n225:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:29:11,556 - INFO - Running command: ./train_gpt2cu -l 0.00016813169946991498 -o hyperband_runs_20241120_172038/run_s5_n225 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:29:25,961 - INFO - Training completed for config s5_n225:
  Training time: 0:00:14
  Final validation loss: 10.899271
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.21e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n225/checkpoint.bin
2024-11-20 22:29:25,961 - INFO - 
Configuration s5_n225 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00016813169946991498",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n225",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.899271
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.21e-07
2024-11-20 22:29:25,961 - INFO - 
Starting training for config s5_n226:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:29:25,962 - INFO - Running command: ./train_gpt2cu -l 0.0002808280625384985 -o hyperband_runs_20241120_172038/run_s5_n226 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:29:40,363 - INFO - Training completed for config s5_n226:
  Training time: 0:00:14
  Final validation loss: 10.891042
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.20e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n226/checkpoint.bin
2024-11-20 22:29:40,363 - INFO - 
Configuration s5_n226 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002808280625384985",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n226",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.891042
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.20e-06
2024-11-20 22:29:40,364 - INFO - 
Starting training for config s5_n227:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:29:40,364 - INFO - Running command: ./train_gpt2cu -l 0.00039323417404199117 -o hyperband_runs_20241120_172038/run_s5_n227 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:29:54,771 - INFO - Training completed for config s5_n227:
  Training time: 0:00:14
  Final validation loss: 10.882810
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.69e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n227/checkpoint.bin
2024-11-20 22:29:54,771 - INFO - 
Configuration s5_n227 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00039323417404199117",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n227",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.882810
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.69e-06
2024-11-20 22:29:54,771 - INFO - 
Starting training for config s5_n228:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:29:54,772 - INFO - Running command: ./train_gpt2cu -l 3.7013654449665006e-05 -o hyperband_runs_20241120_172038/run_s5_n228 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:30:09,184 - INFO - Training completed for config s5_n228:
  Training time: 0:00:14
  Final validation loss: 10.908890
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.59e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n228/checkpoint.bin
2024-11-20 22:30:09,184 - INFO - 
Configuration s5_n228 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.7013654449665006e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n228",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.908890
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.59e-07
2024-11-20 22:30:09,184 - INFO - 
Starting training for config s5_n229:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:30:09,184 - INFO - Running command: ./train_gpt2cu -l 0.0002740542958174265 -o hyperband_runs_20241120_172038/run_s5_n229 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:30:23,589 - INFO - Training completed for config s5_n229:
  Training time: 0:00:14
  Final validation loss: 10.891533
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.17e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n229/checkpoint.bin
2024-11-20 22:30:23,589 - INFO - 
Configuration s5_n229 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002740542958174265",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n229",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.891533
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.17e-06
2024-11-20 22:30:23,589 - INFO - 
Starting training for config s5_n230:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:30:23,589 - INFO - Running command: ./train_gpt2cu -l 2.2656554192372028e-05 -o hyperband_runs_20241120_172038/run_s5_n230 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:30:37,989 - INFO - Training completed for config s5_n230:
  Training time: 0:00:14
  Final validation loss: 10.909953
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.71e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n230/checkpoint.bin
2024-11-20 22:30:37,989 - INFO - 
Configuration s5_n230 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.2656554192372028e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n230",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909953
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.71e-08
2024-11-20 22:30:37,990 - INFO - 
Starting training for config s5_n231:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:30:37,990 - INFO - Running command: ./train_gpt2cu -l 1.3908021721819393e-05 -o hyperband_runs_20241120_172038/run_s5_n231 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:30:52,410 - INFO - Training completed for config s5_n231:
  Training time: 0:00:14
  Final validation loss: 10.910581
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.96e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n231/checkpoint.bin
2024-11-20 22:30:52,411 - INFO - 
Configuration s5_n231 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.3908021721819393e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n231",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910581
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.96e-08
2024-11-20 22:30:52,411 - INFO - 
Starting training for config s5_n232:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:30:52,411 - INFO - Running command: ./train_gpt2cu -l 5.004738900597307e-05 -o hyperband_runs_20241120_172038/run_s5_n232 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:31:06,826 - INFO - Training completed for config s5_n232:
  Training time: 0:00:14
  Final validation loss: 10.907931
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.14e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n232/checkpoint.bin
2024-11-20 22:31:06,826 - INFO - 
Configuration s5_n232 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "5.004738900597307e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n232",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.907931
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.14e-07
2024-11-20 22:31:06,826 - INFO - 
Starting training for config s5_n233:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:31:06,826 - INFO - Running command: ./train_gpt2cu -l 4.23314023175533e-05 -o hyperband_runs_20241120_172038/run_s5_n233 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:31:21,241 - INFO - Training completed for config s5_n233:
  Training time: 0:00:14
  Final validation loss: 10.908501
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.81e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n233/checkpoint.bin
2024-11-20 22:31:21,241 - INFO - 
Configuration s5_n233 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "4.23314023175533e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n233",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.908501
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.81e-07
2024-11-20 22:31:21,241 - INFO - 
Starting training for config s5_n234:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:31:21,242 - INFO - Running command: ./train_gpt2cu -l 0.00013496800279292828 -o hyperband_runs_20241120_172038/run_s5_n234 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:31:35,652 - INFO - Training completed for config s5_n234:
  Training time: 0:00:14
  Final validation loss: 10.901694
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.78e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n234/checkpoint.bin
2024-11-20 22:31:35,652 - INFO - 
Configuration s5_n234 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013496800279292828",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n234",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.901694
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.78e-07
2024-11-20 22:31:35,652 - INFO - 
Starting training for config s5_n235:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:31:35,653 - INFO - Running command: ./train_gpt2cu -l 9.593948116734458e-05 -o hyperband_runs_20241120_172038/run_s5_n235 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:31:50,075 - INFO - Training completed for config s5_n235:
  Training time: 0:00:14
  Final validation loss: 10.904584
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.11e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n235/checkpoint.bin
2024-11-20 22:31:50,075 - INFO - 
Configuration s5_n235 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "9.593948116734458e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n235",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.904584
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.11e-07
2024-11-20 22:31:50,075 - INFO - 
Starting training for config s5_n236:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:31:50,075 - INFO - Running command: ./train_gpt2cu -l 0.00030235143011081835 -o hyperband_runs_20241120_172038/run_s5_n236 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:32:04,502 - INFO - Training completed for config s5_n236:
  Training time: 0:00:14
  Final validation loss: 10.889471
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.30e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n236/checkpoint.bin
2024-11-20 22:32:04,502 - INFO - 
Configuration s5_n236 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00030235143011081835",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n236",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.889471
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.30e-06
2024-11-20 22:32:04,502 - INFO - 
Starting training for config s5_n237:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:32:04,503 - INFO - Running command: ./train_gpt2cu -l 1.716488073405111e-05 -o hyperband_runs_20241120_172038/run_s5_n237 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:32:18,906 - INFO - Training completed for config s5_n237:
  Training time: 0:00:14
  Final validation loss: 10.910345
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.36e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n237/checkpoint.bin
2024-11-20 22:32:18,906 - INFO - 
Configuration s5_n237 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.716488073405111e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n237",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910345
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.36e-08
2024-11-20 22:32:18,906 - INFO - 
Starting training for config s5_n238:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:32:18,907 - INFO - Running command: ./train_gpt2cu -l 4.870145430133077e-05 -o hyperband_runs_20241120_172038/run_s5_n238 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:32:33,339 - INFO - Training completed for config s5_n238:
  Training time: 0:00:14
  Final validation loss: 10.908043
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.09e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n238/checkpoint.bin
2024-11-20 22:32:33,339 - INFO - 
Configuration s5_n238 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "4.870145430133077e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n238",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.908043
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.09e-07
2024-11-20 22:32:33,339 - INFO - 
Starting training for config s5_n239:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:32:33,339 - INFO - Running command: ./train_gpt2cu -l 0.00014416807466773816 -o hyperband_runs_20241120_172038/run_s5_n239 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:32:47,738 - INFO - Training completed for config s5_n239:
  Training time: 0:00:14
  Final validation loss: 10.901035
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.18e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n239/checkpoint.bin
2024-11-20 22:32:47,739 - INFO - 
Configuration s5_n239 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014416807466773816",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n239",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.901035
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.18e-07
2024-11-20 22:32:47,739 - INFO - 
Starting training for config s5_n240:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:32:47,739 - INFO - Running command: ./train_gpt2cu -l 1.1293399575596926e-05 -o hyperband_runs_20241120_172038/run_s5_n240 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:33:02,146 - INFO - Training completed for config s5_n240:
  Training time: 0:00:14
  Final validation loss: 10.910772
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.84e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n240/checkpoint.bin
2024-11-20 22:33:02,146 - INFO - 
Configuration s5_n240 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.1293399575596926e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n240",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910772
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.84e-08
2024-11-20 22:33:02,146 - INFO - 
Starting training for config s5_n241:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:33:02,146 - INFO - Running command: ./train_gpt2cu -l 3.575746538095134e-05 -o hyperband_runs_20241120_172038/run_s5_n241 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:33:16,559 - INFO - Training completed for config s5_n241:
  Training time: 0:00:14
  Final validation loss: 10.908983
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.53e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n241/checkpoint.bin
2024-11-20 22:33:16,559 - INFO - 
Configuration s5_n241 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.575746538095134e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n241",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.908983
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.53e-07
2024-11-20 22:33:16,559 - INFO - 
Starting training for config s5_n242:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:33:16,559 - INFO - Running command: ./train_gpt2cu -l 4.358766417342612e-05 -o hyperband_runs_20241120_172038/run_s5_n242 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:33:30,989 - INFO - Training completed for config s5_n242:
  Training time: 0:00:14
  Final validation loss: 10.908401
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.87e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n242/checkpoint.bin
2024-11-20 22:33:30,989 - INFO - 
Configuration s5_n242 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "4.358766417342612e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n242",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.908401
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.87e-07
2024-11-20 22:33:30,989 - INFO - 
Starting training for config s5_n243:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:33:30,989 - INFO - Running command: ./train_gpt2cu -l 3.987539344219209e-05 -o hyperband_runs_20241120_172038/run_s5_n243 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:33:45,387 - INFO - Training completed for config s5_n243:
  Training time: 0:00:14
  Final validation loss: 10.908688
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.71e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n243/checkpoint.bin
2024-11-20 22:33:45,387 - INFO - 
Configuration s5_n243 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.987539344219209e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n243",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.908688
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.71e-07
2024-11-20 22:33:45,387 - INFO - 
Starting training for config s5_n244:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:33:45,387 - INFO - Running command: ./train_gpt2cu -l 2.069473881671367e-05 -o hyperband_runs_20241120_172038/run_s5_n244 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:33:59,805 - INFO - Training completed for config s5_n244:
  Training time: 0:00:14
  Final validation loss: 10.910088
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 8.87e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n244/checkpoint.bin
2024-11-20 22:33:59,806 - INFO - 
Configuration s5_n244 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.069473881671367e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n244",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910088
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.87e-08
2024-11-20 22:33:59,806 - INFO - 
Starting training for config s5_n245:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:33:59,806 - INFO - Running command: ./train_gpt2cu -l 0.00017346052186769032 -o hyperband_runs_20241120_172038/run_s5_n245 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:34:14,216 - INFO - Training completed for config s5_n245:
  Training time: 0:00:14
  Final validation loss: 10.898887
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.43e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n245/checkpoint.bin
2024-11-20 22:34:14,216 - INFO - 
Configuration s5_n245 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00017346052186769032",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n245",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.898887
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.43e-07
2024-11-20 22:34:14,216 - INFO - 
Starting training for config s5_n246:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:34:14,216 - INFO - Running command: ./train_gpt2cu -l 1.2403428565994907e-05 -o hyperband_runs_20241120_172038/run_s5_n246 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:34:28,602 - INFO - Training completed for config s5_n246:
  Training time: 0:00:14
  Final validation loss: 10.910691
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.32e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n246/checkpoint.bin
2024-11-20 22:34:28,603 - INFO - 
Configuration s5_n246 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.2403428565994907e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n246",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910691
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.32e-08
2024-11-20 22:34:28,603 - INFO - 
Starting training for config s5_n247:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:34:28,603 - INFO - Running command: ./train_gpt2cu -l 0.0002748310573411585 -o hyperband_runs_20241120_172038/run_s5_n247 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:34:43,018 - INFO - Training completed for config s5_n247:
  Training time: 0:00:14
  Final validation loss: 10.891485
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.18e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n247/checkpoint.bin
2024-11-20 22:34:43,018 - INFO - 
Configuration s5_n247 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002748310573411585",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n247",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.891485
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.18e-06
2024-11-20 22:34:43,018 - INFO - 
Starting training for config s5_n248:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:34:43,018 - INFO - Running command: ./train_gpt2cu -l 0.0001875219577602757 -o hyperband_runs_20241120_172038/run_s5_n248 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:34:57,434 - INFO - Training completed for config s5_n248:
  Training time: 0:00:14
  Final validation loss: 10.897857
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 8.04e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n248/checkpoint.bin
2024-11-20 22:34:57,434 - INFO - 
Configuration s5_n248 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001875219577602757",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n248",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.897857
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.04e-07
2024-11-20 22:34:57,434 - INFO - 
Starting training for config s5_n249:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:34:57,434 - INFO - Running command: ./train_gpt2cu -l 1.0422645085533725e-05 -o hyperband_runs_20241120_172038/run_s5_n249 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:35:11,840 - INFO - Training completed for config s5_n249:
  Training time: 0:00:14
  Final validation loss: 10.910846
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.47e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n249/checkpoint.bin
2024-11-20 22:35:11,840 - INFO - 
Configuration s5_n249 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.0422645085533725e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n249",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910846
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.47e-08
2024-11-20 22:35:11,840 - INFO - 
Starting training for config s5_n250:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:35:11,840 - INFO - Running command: ./train_gpt2cu -l 0.00023554136110169827 -o hyperband_runs_20241120_172038/run_s5_n250 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:35:26,250 - INFO - Training completed for config s5_n250:
  Training time: 0:00:14
  Final validation loss: 10.894348
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.01e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n250/checkpoint.bin
2024-11-20 22:35:26,251 - INFO - 
Configuration s5_n250 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00023554136110169827",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n250",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.894348
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.01e-06
2024-11-20 22:35:26,251 - INFO - 
Starting training for config s5_n251:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:35:26,251 - INFO - Running command: ./train_gpt2cu -l 1.2827236016279892e-05 -o hyperband_runs_20241120_172038/run_s5_n251 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:35:40,670 - INFO - Training completed for config s5_n251:
  Training time: 0:00:14
  Final validation loss: 10.910658
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.50e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n251/checkpoint.bin
2024-11-20 22:35:40,670 - INFO - 
Configuration s5_n251 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.2827236016279892e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n251",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910658
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.50e-08
2024-11-20 22:35:40,670 - INFO - 
Starting training for config s5_n252:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:35:40,670 - INFO - Running command: ./train_gpt2cu -l 0.0004305699664790186 -o hyperband_runs_20241120_172038/run_s5_n252 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:35:55,114 - INFO - Training completed for config s5_n252:
  Training time: 0:00:14
  Final validation loss: 10.880072
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.85e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n252/checkpoint.bin
2024-11-20 22:35:55,114 - INFO - 
Configuration s5_n252 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004305699664790186",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n252",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.880072
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.85e-06
2024-11-20 22:35:55,114 - INFO - 
Starting training for config s5_n253:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:35:55,114 - INFO - Running command: ./train_gpt2cu -l 1.8136572287751873e-05 -o hyperband_runs_20241120_172038/run_s5_n253 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:36:09,564 - INFO - Training completed for config s5_n253:
  Training time: 0:00:14
  Final validation loss: 10.910287
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.77e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n253/checkpoint.bin
2024-11-20 22:36:09,564 - INFO - 
Configuration s5_n253 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.8136572287751873e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n253",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910287
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.77e-08
2024-11-20 22:36:09,564 - INFO - 
Starting training for config s5_n254:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:36:09,564 - INFO - Running command: ./train_gpt2cu -l 1.0797331482912803e-05 -o hyperband_runs_20241120_172038/run_s5_n254 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:36:23,979 - INFO - Training completed for config s5_n254:
  Training time: 0:00:14
  Final validation loss: 10.910822
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.63e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n254/checkpoint.bin
2024-11-20 22:36:23,980 - INFO - 
Configuration s5_n254 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.0797331482912803e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n254",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910822
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.63e-08
2024-11-20 22:36:23,980 - INFO - 
Starting training for config s5_n255:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:36:23,980 - INFO - Running command: ./train_gpt2cu -l 0.00013965309049418983 -o hyperband_runs_20241120_172038/run_s5_n255 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:36:38,383 - INFO - Training completed for config s5_n255:
  Training time: 0:00:14
  Final validation loss: 10.901368
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.99e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n255/checkpoint.bin
2024-11-20 22:36:38,383 - INFO - 
Configuration s5_n255 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013965309049418983",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n255",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.901368
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.99e-07
2024-11-20 22:36:38,383 - INFO - 
Starting training for config s5_n256:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:36:38,384 - INFO - Running command: ./train_gpt2cu -l 0.00033626599179865805 -o hyperband_runs_20241120_172038/run_s5_n256 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:36:52,793 - INFO - Training completed for config s5_n256:
  Training time: 0:00:14
  Final validation loss: 10.886969
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.44e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n256/checkpoint.bin
2024-11-20 22:36:52,793 - INFO - 
Configuration s5_n256 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00033626599179865805",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n256",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.886969
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.44e-06
2024-11-20 22:36:52,793 - INFO - 
Starting training for config s5_n257:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:36:52,793 - INFO - Running command: ./train_gpt2cu -l 0.0001598746890383768 -o hyperband_runs_20241120_172038/run_s5_n257 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:37:07,224 - INFO - Training completed for config s5_n257:
  Training time: 0:00:14
  Final validation loss: 10.899889
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.85e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n257/checkpoint.bin
2024-11-20 22:37:07,224 - INFO - 
Configuration s5_n257 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001598746890383768",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n257",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.899889
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.85e-07
2024-11-20 22:37:07,224 - INFO - 
Starting training for config s5_n258:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:37:07,224 - INFO - Running command: ./train_gpt2cu -l 0.0001545794395795291 -o hyperband_runs_20241120_172038/run_s5_n258 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:37:21,646 - INFO - Training completed for config s5_n258:
  Training time: 0:00:14
  Final validation loss: 10.900286
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 6.62e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n258/checkpoint.bin
2024-11-20 22:37:21,646 - INFO - 
Configuration s5_n258 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001545794395795291",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n258",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.900286
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.62e-07
2024-11-20 22:37:21,646 - INFO - 
Starting training for config s5_n259:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:37:21,646 - INFO - Running command: ./train_gpt2cu -l 0.00013729841280239264 -o hyperband_runs_20241120_172038/run_s5_n259 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:37:36,049 - INFO - Training completed for config s5_n259:
  Training time: 0:00:14
  Final validation loss: 10.901527
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.88e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n259/checkpoint.bin
2024-11-20 22:37:36,050 - INFO - 
Configuration s5_n259 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013729841280239264",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n259",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.901527
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.88e-07
2024-11-20 22:37:36,050 - INFO - 
Starting training for config s5_n260:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:37:36,050 - INFO - Running command: ./train_gpt2cu -l 0.0009293981044299633 -o hyperband_runs_20241120_172038/run_s5_n260 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:37:50,461 - INFO - Training completed for config s5_n260:
  Training time: 0:00:14
  Final validation loss: 10.844090
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.98e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n260/checkpoint.bin
2024-11-20 22:37:50,461 - INFO - 
Configuration s5_n260 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009293981044299633",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n260",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.844090
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.98e-06
2024-11-20 22:37:50,461 - INFO - 
Starting training for config s5_n261:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:37:50,462 - INFO - Running command: ./train_gpt2cu -l 2.1319113467884716e-05 -o hyperband_runs_20241120_172038/run_s5_n261 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:38:04,862 - INFO - Training completed for config s5_n261:
  Training time: 0:00:14
  Final validation loss: 10.910048
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.14e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n261/checkpoint.bin
2024-11-20 22:38:04,863 - INFO - 
Configuration s5_n261 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.1319113467884716e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n261",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910048
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.14e-08
2024-11-20 22:38:04,863 - INFO - 
Starting training for config s5_n262:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:38:04,863 - INFO - Running command: ./train_gpt2cu -l 0.0001710164241637613 -o hyperband_runs_20241120_172038/run_s5_n262 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:38:19,271 - INFO - Training completed for config s5_n262:
  Training time: 0:00:14
  Final validation loss: 10.899064
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.33e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n262/checkpoint.bin
2024-11-20 22:38:19,271 - INFO - 
Configuration s5_n262 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001710164241637613",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n262",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.899064
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.33e-07
2024-11-20 22:38:19,271 - INFO - 
Starting training for config s5_n263:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:38:19,271 - INFO - Running command: ./train_gpt2cu -l 1.1162844598802742e-05 -o hyperband_runs_20241120_172038/run_s5_n263 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:38:33,663 - INFO - Training completed for config s5_n263:
  Training time: 0:00:14
  Final validation loss: 10.910789
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.78e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n263/checkpoint.bin
2024-11-20 22:38:33,664 - INFO - 
Configuration s5_n263 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.1162844598802742e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n263",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910789
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.78e-08
2024-11-20 22:38:33,664 - INFO - 
Starting training for config s5_n264:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:38:33,664 - INFO - Running command: ./train_gpt2cu -l 0.0008252545505248207 -o hyperband_runs_20241120_172038/run_s5_n264 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:38:48,068 - INFO - Training completed for config s5_n264:
  Training time: 0:00:14
  Final validation loss: 10.851546
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.54e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n264/checkpoint.bin
2024-11-20 22:38:48,069 - INFO - 
Configuration s5_n264 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008252545505248207",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n264",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.851546
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.54e-06
2024-11-20 22:38:48,069 - INFO - 
Starting training for config s5_n265:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:38:48,069 - INFO - Running command: ./train_gpt2cu -l 8.255231245645786e-05 -o hyperband_runs_20241120_172038/run_s5_n265 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:39:02,465 - INFO - Training completed for config s5_n265:
  Training time: 0:00:14
  Final validation loss: 10.905560
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.54e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n265/checkpoint.bin
2024-11-20 22:39:02,465 - INFO - 
Configuration s5_n265 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "8.255231245645786e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n265",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.905560
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.54e-07
2024-11-20 22:39:02,465 - INFO - 
Starting training for config s5_n266:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:39:02,465 - INFO - Running command: ./train_gpt2cu -l 0.00017769530165617973 -o hyperband_runs_20241120_172038/run_s5_n266 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:39:16,874 - INFO - Training completed for config s5_n266:
  Training time: 0:00:14
  Final validation loss: 10.898581
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.62e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n266/checkpoint.bin
2024-11-20 22:39:16,875 - INFO - 
Configuration s5_n266 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00017769530165617973",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n266",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.898581
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.62e-07
2024-11-20 22:39:16,875 - INFO - 
Starting training for config s5_n267:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:39:16,875 - INFO - Running command: ./train_gpt2cu -l 0.0006020631276527434 -o hyperband_runs_20241120_172038/run_s5_n267 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:39:31,274 - INFO - Training completed for config s5_n267:
  Training time: 0:00:14
  Final validation loss: 10.867652
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.58e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n267/checkpoint.bin
2024-11-20 22:39:31,275 - INFO - 
Configuration s5_n267 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006020631276527434",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n267",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.867652
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.58e-06
2024-11-20 22:39:31,275 - INFO - 
Starting training for config s5_n268:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:39:31,275 - INFO - Running command: ./train_gpt2cu -l 2.3914526772233643e-05 -o hyperband_runs_20241120_172038/run_s5_n268 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:39:45,681 - INFO - Training completed for config s5_n268:
  Training time: 0:00:14
  Final validation loss: 10.909868
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.02e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n268/checkpoint.bin
2024-11-20 22:39:45,681 - INFO - 
Configuration s5_n268 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.3914526772233643e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n268",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909868
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-07
2024-11-20 22:39:45,681 - INFO - 
Starting training for config s5_n269:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:39:45,681 - INFO - Running command: ./train_gpt2cu -l 0.00017253707165384307 -o hyperband_runs_20241120_172038/run_s5_n269 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:40:00,085 - INFO - Training completed for config s5_n269:
  Training time: 0:00:14
  Final validation loss: 10.898957
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.39e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n269/checkpoint.bin
2024-11-20 22:40:00,085 - INFO - 
Configuration s5_n269 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00017253707165384307",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n269",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.898957
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.39e-07
2024-11-20 22:40:00,085 - INFO - 
Starting training for config s5_n270:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:40:00,086 - INFO - Running command: ./train_gpt2cu -l 0.0009517015653755315 -o hyperband_runs_20241120_172038/run_s5_n270 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:40:14,499 - INFO - Training completed for config s5_n270:
  Training time: 0:00:14
  Final validation loss: 10.842493
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.08e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n270/checkpoint.bin
2024-11-20 22:40:14,499 - INFO - 
Configuration s5_n270 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009517015653755315",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n270",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.842493
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.08e-06
2024-11-20 22:40:14,499 - INFO - 
Starting training for config s5_n271:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:40:14,499 - INFO - Running command: ./train_gpt2cu -l 0.0004512388596351136 -o hyperband_runs_20241120_172038/run_s5_n271 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:40:28,922 - INFO - Training completed for config s5_n271:
  Training time: 0:00:14
  Final validation loss: 10.878565
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.93e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n271/checkpoint.bin
2024-11-20 22:40:28,922 - INFO - 
Configuration s5_n271 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004512388596351136",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n271",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.878565
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.93e-06
2024-11-20 22:40:28,922 - INFO - 
Starting training for config s5_n272:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:40:28,923 - INFO - Running command: ./train_gpt2cu -l 1.2570030111097526e-05 -o hyperband_runs_20241120_172038/run_s5_n272 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:40:43,353 - INFO - Training completed for config s5_n272:
  Training time: 0:00:14
  Final validation loss: 10.910669
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 5.39e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n272/checkpoint.bin
2024-11-20 22:40:43,353 - INFO - 
Configuration s5_n272 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.2570030111097526e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n272",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910669
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.39e-08
2024-11-20 22:40:43,354 - INFO - 
Starting training for config s5_n273:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:40:43,354 - INFO - Running command: ./train_gpt2cu -l 0.0002729979077477309 -o hyperband_runs_20241120_172038/run_s5_n273 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:40:57,762 - INFO - Training completed for config s5_n273:
  Training time: 0:00:14
  Final validation loss: 10.891611
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.17e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n273/checkpoint.bin
2024-11-20 22:40:57,763 - INFO - 
Configuration s5_n273 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002729979077477309",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n273",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.891611
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.17e-06
2024-11-20 22:40:57,763 - INFO - 
Starting training for config s5_n274:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:40:57,763 - INFO - Running command: ./train_gpt2cu -l 1.6499012478683152e-05 -o hyperband_runs_20241120_172038/run_s5_n274 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:41:12,173 - INFO - Training completed for config s5_n274:
  Training time: 0:00:14
  Final validation loss: 10.910395
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 7.07e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n274/checkpoint.bin
2024-11-20 22:41:12,174 - INFO - 
Configuration s5_n274 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "1.6499012478683152e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n274",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910395
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.07e-08
2024-11-20 22:41:12,174 - INFO - 
Starting training for config s5_n275:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:41:12,174 - INFO - Running command: ./train_gpt2cu -l 3.4362634592073254e-05 -o hyperband_runs_20241120_172038/run_s5_n275 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:41:26,576 - INFO - Training completed for config s5_n275:
  Training time: 0:00:14
  Final validation loss: 10.909094
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.47e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n275/checkpoint.bin
2024-11-20 22:41:26,576 - INFO - 
Configuration s5_n275 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "3.4362634592073254e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n275",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909094
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.47e-07
2024-11-20 22:41:26,576 - INFO - 
Starting training for config s5_n276:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:41:26,577 - INFO - Running command: ./train_gpt2cu -l 2.2258678769106954e-05 -o hyperband_runs_20241120_172038/run_s5_n276 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:41:40,986 - INFO - Training completed for config s5_n276:
  Training time: 0:00:14
  Final validation loss: 10.909984
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.54e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n276/checkpoint.bin
2024-11-20 22:41:40,986 - INFO - 
Configuration s5_n276 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.2258678769106954e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n276",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909984
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.54e-08
2024-11-20 22:41:40,986 - INFO - 
Starting training for config s5_n277:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:41:40,986 - INFO - Running command: ./train_gpt2cu -l 2.5234061759398986e-05 -o hyperband_runs_20241120_172038/run_s5_n277 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:41:55,393 - INFO - Training completed for config s5_n277:
  Training time: 0:00:14
  Final validation loss: 10.909760
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.08e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n277/checkpoint.bin
2024-11-20 22:41:55,394 - INFO - 
Configuration s5_n277 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.5234061759398986e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n277",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909760
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.08e-07
2024-11-20 22:41:55,394 - INFO - 
Starting training for config s5_n278:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:41:55,394 - INFO - Running command: ./train_gpt2cu -l 8.048169284494734e-05 -o hyperband_runs_20241120_172038/run_s5_n278 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:42:09,818 - INFO - Training completed for config s5_n278:
  Training time: 0:00:14
  Final validation loss: 10.905696
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 3.45e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n278/checkpoint.bin
2024-11-20 22:42:09,818 - INFO - 
Configuration s5_n278 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "8.048169284494734e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n278",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.905696
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.45e-07
2024-11-20 22:42:09,819 - INFO - 
Starting training for config s5_n279:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:42:09,819 - INFO - Running command: ./train_gpt2cu -l 0.00011163199822203364 -o hyperband_runs_20241120_172038/run_s5_n279 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:42:24,222 - INFO - Training completed for config s5_n279:
  Training time: 0:00:14
  Final validation loss: 10.903433
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.78e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n279/checkpoint.bin
2024-11-20 22:42:24,223 - INFO - 
Configuration s5_n279 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00011163199822203364",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n279",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.903433
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.78e-07
2024-11-20 22:42:24,223 - INFO - 
Starting training for config s5_n280:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:42:24,223 - INFO - Running command: ./train_gpt2cu -l 0.00046880524160877295 -o hyperband_runs_20241120_172038/run_s5_n280 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:42:38,628 - INFO - Training completed for config s5_n280:
  Training time: 0:00:14
  Final validation loss: 10.877275
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 2.01e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n280/checkpoint.bin
2024-11-20 22:42:38,629 - INFO - 
Configuration s5_n280 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00046880524160877295",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n280",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.877275
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.01e-06
2024-11-20 22:42:38,629 - INFO - 
Starting training for config s5_n281:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:42:38,629 - INFO - Running command: ./train_gpt2cu -l 2.168131589869226e-05 -o hyperband_runs_20241120_172038/run_s5_n281 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:42:53,046 - INFO - Training completed for config s5_n281:
  Training time: 0:00:14
  Final validation loss: 10.910031
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 9.29e-08
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n281/checkpoint.bin
2024-11-20 22:42:53,046 - INFO - 
Configuration s5_n281 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.168131589869226e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n281",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.910031
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.29e-08
2024-11-20 22:42:53,046 - INFO - 
Starting training for config s5_n282:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:42:53,046 - INFO - Running command: ./train_gpt2cu -l 2.571300660772923e-05 -o hyperband_runs_20241120_172038/run_s5_n282 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:43:07,454 - INFO - Training completed for config s5_n282:
  Training time: 0:00:14
  Final validation loss: 10.909724
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 1.10e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n282/checkpoint.bin
2024-11-20 22:43:07,454 - INFO - 
Configuration s5_n282 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "2.571300660772923e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n282",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.909724
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-07
2024-11-20 22:43:07,454 - INFO - 
Starting training for config s5_n283:
  Iterations: 3
  Previous iterations: 0
  Previous checkpoint: None
2024-11-20 22:43:07,454 - INFO - Running command: ./train_gpt2cu -l 0.00010854860083998596 -o hyperband_runs_20241120_172038/run_s5_n283 -x 3 -n 3 -y 0 -b 64 -d 524288 -h 0
2024-11-20 22:43:21,867 - INFO - Training completed for config s5_n283:
  Training time: 0:00:14
  Final validation loss: 10.903652
  Hellaswag accuracy: 0.00%
  Total iterations: 3
  Maximum learning rate: 4.65e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n283/checkpoint.bin
2024-11-20 22:43:21,867 - INFO - 
Configuration s5_n283 (bracket_5_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010854860083998596",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n283",
  "max_steps": "3",
  "checkpoint_every": "3",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 3
  Total iterations: 3
  Training time: 0:00:14
  Validation Loss: 10.903652
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.65e-07
2024-11-20 22:43:21,867 - INFO - 
Eliminating 190 configurations:
  Surviving: 94
2024-11-20 22:43:27,879 - INFO - 
Bracket 5, Round 1:
  Active configs: 94
  Iterations: 9
2024-11-20 22:43:27,880 - INFO - 
Starting training for config s5_n51:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin
2024-11-20 22:43:27,880 - INFO - Running command: ./train_gpt2cu -l 0.0009968572861830537 -o hyperband_runs_20241120_172038/run_s5_n51 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:43:48,169 - INFO - Training completed for config s5_n51:
  Training time: 0:00:20
  Final validation loss: 10.522503
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.28e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin
2024-11-20 22:43:48,169 - INFO - 
Configuration s5_n51 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009968572861830537",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n51",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.522503
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.28e-05
2024-11-20 22:43:48,169 - INFO - 
Starting training for config s5_n32:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin
2024-11-20 22:43:48,169 - INFO - Running command: ./train_gpt2cu -l 0.000995514234701091 -o hyperband_runs_20241120_172038/run_s5_n32 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:44:08,492 - INFO - Training completed for config s5_n32:
  Training time: 0:00:20
  Final validation loss: 10.522808
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.28e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin
2024-11-20 22:44:08,492 - INFO - 
Configuration s5_n32 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.000995514234701091",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n32",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.522808
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.28e-05
2024-11-20 22:44:08,492 - INFO - 
Starting training for config s5_n160:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin
2024-11-20 22:44:08,492 - INFO - Running command: ./train_gpt2cu -l 0.0009822324088212349 -o hyperband_runs_20241120_172038/run_s5_n160 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:44:28,787 - INFO - Training completed for config s5_n160:
  Training time: 0:00:20
  Final validation loss: 10.525825
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.26e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin
2024-11-20 22:44:28,788 - INFO - 
Configuration s5_n160 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009822324088212349",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n160",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.525825
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.26e-05
2024-11-20 22:44:28,788 - INFO - 
Starting training for config s5_n134:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n134/checkpoint.bin
2024-11-20 22:44:28,788 - INFO - Running command: ./train_gpt2cu -l 0.0009660126338049484 -o hyperband_runs_20241120_172038/run_s5_n134 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n134/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:44:49,025 - INFO - Training completed for config s5_n134:
  Training time: 0:00:20
  Final validation loss: 10.529532
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.24e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n134/checkpoint.bin
2024-11-20 22:44:49,025 - INFO - 
Configuration s5_n134 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009660126338049484",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n134",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n134/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.529532
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.24e-05
2024-11-20 22:44:49,025 - INFO - 
Starting training for config s5_n270:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n270/checkpoint.bin
2024-11-20 22:44:49,025 - INFO - Running command: ./train_gpt2cu -l 0.0009517015653755315 -o hyperband_runs_20241120_172038/run_s5_n270 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n270/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:45:07,626 - INFO - Training completed for config s5_n270:
  Training time: 0:00:18
  Final validation loss: 10.532863
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.22e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n270/checkpoint.bin
2024-11-20 22:45:07,626 - INFO - 
Configuration s5_n270 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009517015653755315",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n270",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n270/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:18
  Validation Loss: 10.532863
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.22e-05
2024-11-20 22:45:07,626 - INFO - 
Starting training for config s5_n260:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n260/checkpoint.bin
2024-11-20 22:45:07,626 - INFO - Running command: ./train_gpt2cu -l 0.0009293981044299633 -o hyperband_runs_20241120_172038/run_s5_n260 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n260/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:45:27,892 - INFO - Training completed for config s5_n260:
  Training time: 0:00:20
  Final validation loss: 10.538171
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.19e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n260/checkpoint.bin
2024-11-20 22:45:27,892 - INFO - 
Configuration s5_n260 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009293981044299633",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n260",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n260/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.538171
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.19e-05
2024-11-20 22:45:27,892 - INFO - 
Starting training for config s5_n56:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n56/checkpoint.bin
2024-11-20 22:45:27,892 - INFO - Running command: ./train_gpt2cu -l 0.0008898164593245048 -o hyperband_runs_20241120_172038/run_s5_n56 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n56/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:45:48,149 - INFO - Training completed for config s5_n56:
  Training time: 0:00:20
  Final validation loss: 10.547887
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.14e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n56/checkpoint.bin
2024-11-20 22:45:48,149 - INFO - 
Configuration s5_n56 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008898164593245048",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n56",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n56/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.547887
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.14e-05
2024-11-20 22:45:48,149 - INFO - 
Starting training for config s5_n146:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n146/checkpoint.bin
2024-11-20 22:45:48,149 - INFO - Running command: ./train_gpt2cu -l 0.0008813068343693393 -o hyperband_runs_20241120_172038/run_s5_n146 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n146/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:46:08,398 - INFO - Training completed for config s5_n146:
  Training time: 0:00:20
  Final validation loss: 10.550025
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.13e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n146/checkpoint.bin
2024-11-20 22:46:08,398 - INFO - 
Configuration s5_n146 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008813068343693393",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n146",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n146/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.550025
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.13e-05
2024-11-20 22:46:08,398 - INFO - 
Starting training for config s5_n9:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n9/checkpoint.bin
2024-11-20 22:46:08,398 - INFO - Running command: ./train_gpt2cu -l 0.0008687906691256375 -o hyperband_runs_20241120_172038/run_s5_n9 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n9/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:46:28,684 - INFO - Training completed for config s5_n9:
  Training time: 0:00:20
  Final validation loss: 10.553223
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.12e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n9/checkpoint.bin
2024-11-20 22:46:28,684 - INFO - 
Configuration s5_n9 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008687906691256375",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n9",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n9/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.553223
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.12e-05
2024-11-20 22:46:28,684 - INFO - 
Starting training for config s5_n131:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n131/checkpoint.bin
2024-11-20 22:46:28,685 - INFO - Running command: ./train_gpt2cu -l 0.0008602543209504669 -o hyperband_runs_20241120_172038/run_s5_n131 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n131/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:46:48,957 - INFO - Training completed for config s5_n131:
  Training time: 0:00:20
  Final validation loss: 10.555386
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.11e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n131/checkpoint.bin
2024-11-20 22:46:48,957 - INFO - 
Configuration s5_n131 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008602543209504669",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n131",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n131/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.555386
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.11e-05
2024-11-20 22:46:48,957 - INFO - 
Starting training for config s5_n201:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n201/checkpoint.bin
2024-11-20 22:46:48,957 - INFO - Running command: ./train_gpt2cu -l 0.0008419142751758245 -o hyperband_runs_20241120_172038/run_s5_n201 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n201/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:47:09,251 - INFO - Training completed for config s5_n201:
  Training time: 0:00:20
  Final validation loss: 10.560147
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.08e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n201/checkpoint.bin
2024-11-20 22:47:09,251 - INFO - 
Configuration s5_n201 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008419142751758245",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n201",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n201/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.560147
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.08e-05
2024-11-20 22:47:09,251 - INFO - 
Starting training for config s5_n139:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n139/checkpoint.bin
2024-11-20 22:47:09,251 - INFO - Running command: ./train_gpt2cu -l 0.0008272293688785697 -o hyperband_runs_20241120_172038/run_s5_n139 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n139/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:47:29,509 - INFO - Training completed for config s5_n139:
  Training time: 0:00:20
  Final validation loss: 10.563994
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.06e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n139/checkpoint.bin
2024-11-20 22:47:29,509 - INFO - 
Configuration s5_n139 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008272293688785697",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n139",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n139/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.563994
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.06e-05
2024-11-20 22:47:29,509 - INFO - 
Starting training for config s5_n264:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n264/checkpoint.bin
2024-11-20 22:47:29,509 - INFO - Running command: ./train_gpt2cu -l 0.0008252545505248207 -o hyperband_runs_20241120_172038/run_s5_n264 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n264/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:47:49,780 - INFO - Training completed for config s5_n264:
  Training time: 0:00:20
  Final validation loss: 10.564541
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.06e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n264/checkpoint.bin
2024-11-20 22:47:49,780 - INFO - 
Configuration s5_n264 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008252545505248207",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n264",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n264/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.564541
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.06e-05
2024-11-20 22:47:49,780 - INFO - 
Starting training for config s5_n93:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n93/checkpoint.bin
2024-11-20 22:47:49,780 - INFO - Running command: ./train_gpt2cu -l 0.0008001779748372474 -o hyperband_runs_20241120_172038/run_s5_n93 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n93/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:48:10,048 - INFO - Training completed for config s5_n93:
  Training time: 0:00:20
  Final validation loss: 10.571332
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.03e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n93/checkpoint.bin
2024-11-20 22:48:10,048 - INFO - 
Configuration s5_n93 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008001779748372474",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n93",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n93/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.571332
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.03e-05
2024-11-20 22:48:10,048 - INFO - 
Starting training for config s5_n24:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n24/checkpoint.bin
2024-11-20 22:48:10,048 - INFO - Running command: ./train_gpt2cu -l 0.0007944281434975066 -o hyperband_runs_20241120_172038/run_s5_n24 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n24/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:48:30,322 - INFO - Training completed for config s5_n24:
  Training time: 0:00:20
  Final validation loss: 10.572930
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.02e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n24/checkpoint.bin
2024-11-20 22:48:30,322 - INFO - 
Configuration s5_n24 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007944281434975066",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n24",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n24/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.572930
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-05
2024-11-20 22:48:30,322 - INFO - 
Starting training for config s5_n193:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n193/checkpoint.bin
2024-11-20 22:48:30,323 - INFO - Running command: ./train_gpt2cu -l 0.0007853484168511458 -o hyperband_runs_20241120_172038/run_s5_n193 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n193/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:48:50,575 - INFO - Training completed for config s5_n193:
  Training time: 0:00:20
  Final validation loss: 10.575434
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.01e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n193/checkpoint.bin
2024-11-20 22:48:50,576 - INFO - 
Configuration s5_n193 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007853484168511458",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n193",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n193/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.575434
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.01e-05
2024-11-20 22:48:50,576 - INFO - 
Starting training for config s5_n48:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n48/checkpoint.bin
2024-11-20 22:48:50,576 - INFO - Running command: ./train_gpt2cu -l 0.0007550602914635752 -o hyperband_runs_20241120_172038/run_s5_n48 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n48/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:49:10,829 - INFO - Training completed for config s5_n48:
  Training time: 0:00:20
  Final validation loss: 10.583996
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.71e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n48/checkpoint.bin
2024-11-20 22:49:10,830 - INFO - 
Configuration s5_n48 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007550602914635752",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n48",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n48/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.583996
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.71e-06
2024-11-20 22:49:10,830 - INFO - 
Starting training for config s5_n59:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n59/checkpoint.bin
2024-11-20 22:49:10,830 - INFO - Running command: ./train_gpt2cu -l 0.0007314827961887715 -o hyperband_runs_20241120_172038/run_s5_n59 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n59/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:49:31,095 - INFO - Training completed for config s5_n59:
  Training time: 0:00:20
  Final validation loss: 10.590868
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.40e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n59/checkpoint.bin
2024-11-20 22:49:31,095 - INFO - 
Configuration s5_n59 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007314827961887715",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n59",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n59/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.590868
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.40e-06
2024-11-20 22:49:31,096 - INFO - 
Starting training for config s5_n29:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n29/checkpoint.bin
2024-11-20 22:49:31,096 - INFO - Running command: ./train_gpt2cu -l 0.0007043818706256417 -o hyperband_runs_20241120_172038/run_s5_n29 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n29/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:49:51,342 - INFO - Training completed for config s5_n29:
  Training time: 0:00:20
  Final validation loss: 10.598975
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.06e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n29/checkpoint.bin
2024-11-20 22:49:51,343 - INFO - 
Configuration s5_n29 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007043818706256417",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n29",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n29/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.598975
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.06e-06
2024-11-20 22:49:51,344 - INFO - 
Starting training for config s5_n170:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n170/checkpoint.bin
2024-11-20 22:49:51,344 - INFO - Running command: ./train_gpt2cu -l 0.0006832720543350221 -o hyperband_runs_20241120_172038/run_s5_n170 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n170/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:50:11,632 - INFO - Training completed for config s5_n170:
  Training time: 0:00:20
  Final validation loss: 10.605486
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.78e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n170/checkpoint.bin
2024-11-20 22:50:11,633 - INFO - 
Configuration s5_n170 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006832720543350221",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n170",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n170/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.605486
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.78e-06
2024-11-20 22:50:11,633 - INFO - 
Starting training for config s5_n157:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n157/checkpoint.bin
2024-11-20 22:50:11,633 - INFO - Running command: ./train_gpt2cu -l 0.0006705481284587626 -o hyperband_runs_20241120_172038/run_s5_n157 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n157/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:50:31,882 - INFO - Training completed for config s5_n157:
  Training time: 0:00:20
  Final validation loss: 10.609471
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.62e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n157/checkpoint.bin
2024-11-20 22:50:31,882 - INFO - 
Configuration s5_n157 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006705481284587626",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n157",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n157/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.609471
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.62e-06
2024-11-20 22:50:31,882 - INFO - 
Starting training for config s5_n167:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n167/checkpoint.bin
2024-11-20 22:50:31,883 - INFO - Running command: ./train_gpt2cu -l 0.0006705540199959338 -o hyperband_runs_20241120_172038/run_s5_n167 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n167/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:50:52,139 - INFO - Training completed for config s5_n167:
  Training time: 0:00:20
  Final validation loss: 10.609461
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.62e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n167/checkpoint.bin
2024-11-20 22:50:52,140 - INFO - 
Configuration s5_n167 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006705540199959338",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n167",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n167/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.609461
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.62e-06
2024-11-20 22:50:52,140 - INFO - 
Starting training for config s5_n52:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n52/checkpoint.bin
2024-11-20 22:50:52,140 - INFO - Running command: ./train_gpt2cu -l 0.0006679558460799921 -o hyperband_runs_20241120_172038/run_s5_n52 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n52/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:51:12,395 - INFO - Training completed for config s5_n52:
  Training time: 0:00:20
  Final validation loss: 10.610274
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.59e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n52/checkpoint.bin
2024-11-20 22:51:12,396 - INFO - 
Configuration s5_n52 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006679558460799921",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n52",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n52/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.610274
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.59e-06
2024-11-20 22:51:12,396 - INFO - 
Starting training for config s5_n207:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n207/checkpoint.bin
2024-11-20 22:51:12,396 - INFO - Running command: ./train_gpt2cu -l 0.0006507552592411038 -o hyperband_runs_20241120_172038/run_s5_n207 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n207/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:51:32,653 - INFO - Training completed for config s5_n207:
  Training time: 0:00:20
  Final validation loss: 10.615780
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.37e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n207/checkpoint.bin
2024-11-20 22:51:32,654 - INFO - 
Configuration s5_n207 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006507552592411038",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n207",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n207/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.615780
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.37e-06
2024-11-20 22:51:32,654 - INFO - 
Starting training for config s5_n210:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n210/checkpoint.bin
2024-11-20 22:51:32,654 - INFO - Running command: ./train_gpt2cu -l 0.0006410662231365501 -o hyperband_runs_20241120_172038/run_s5_n210 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n210/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:51:52,906 - INFO - Training completed for config s5_n210:
  Training time: 0:00:20
  Final validation loss: 10.618910
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.24e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n210/checkpoint.bin
2024-11-20 22:51:52,906 - INFO - 
Configuration s5_n210 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006410662231365501",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n210",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n210/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.618910
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.24e-06
2024-11-20 22:51:52,906 - INFO - 
Starting training for config s5_n86:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n86/checkpoint.bin
2024-11-20 22:51:52,906 - INFO - Running command: ./train_gpt2cu -l 0.0006402538968106657 -o hyperband_runs_20241120_172038/run_s5_n86 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n86/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:52:13,163 - INFO - Training completed for config s5_n86:
  Training time: 0:00:20
  Final validation loss: 10.619182
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.23e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n86/checkpoint.bin
2024-11-20 22:52:13,164 - INFO - 
Configuration s5_n86 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006402538968106657",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n86",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n86/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.619182
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.23e-06
2024-11-20 22:52:13,164 - INFO - 
Starting training for config s5_n30:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n30/checkpoint.bin
2024-11-20 22:52:13,164 - INFO - Running command: ./train_gpt2cu -l 0.0006397357687444202 -o hyperband_runs_20241120_172038/run_s5_n30 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n30/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:52:33,420 - INFO - Training completed for config s5_n30:
  Training time: 0:00:20
  Final validation loss: 10.619343
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.23e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n30/checkpoint.bin
2024-11-20 22:52:33,421 - INFO - 
Configuration s5_n30 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006397357687444202",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n30",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n30/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.619343
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.23e-06
2024-11-20 22:52:33,421 - INFO - 
Starting training for config s5_n7:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n7/checkpoint.bin
2024-11-20 22:52:33,421 - INFO - Running command: ./train_gpt2cu -l 0.0006236868598086687 -o hyperband_runs_20241120_172038/run_s5_n7 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n7/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:52:53,699 - INFO - Training completed for config s5_n7:
  Training time: 0:00:20
  Final validation loss: 10.624667
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.02e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n7/checkpoint.bin
2024-11-20 22:52:53,700 - INFO - 
Configuration s5_n7 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006236868598086687",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n7",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n7/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.624667
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.02e-06
2024-11-20 22:52:53,700 - INFO - 
Starting training for config s5_n151:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n151/checkpoint.bin
2024-11-20 22:52:53,700 - INFO - Running command: ./train_gpt2cu -l 0.0006133593856173028 -o hyperband_runs_20241120_172038/run_s5_n151 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n151/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:53:13,963 - INFO - Training completed for config s5_n151:
  Training time: 0:00:20
  Final validation loss: 10.628098
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.89e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n151/checkpoint.bin
2024-11-20 22:53:13,963 - INFO - 
Configuration s5_n151 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006133593856173028",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n151",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n151/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.628098
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.89e-06
2024-11-20 22:53:13,963 - INFO - 
Starting training for config s5_n267:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n267/checkpoint.bin
2024-11-20 22:53:13,964 - INFO - Running command: ./train_gpt2cu -l 0.0006020631276527434 -o hyperband_runs_20241120_172038/run_s5_n267 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n267/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:53:34,207 - INFO - Training completed for config s5_n267:
  Training time: 0:00:20
  Final validation loss: 10.631939
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.74e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n267/checkpoint.bin
2024-11-20 22:53:34,208 - INFO - 
Configuration s5_n267 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006020631276527434",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n267",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n267/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.631939
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.74e-06
2024-11-20 22:53:34,208 - INFO - 
Starting training for config s5_n186:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n186/checkpoint.bin
2024-11-20 22:53:34,208 - INFO - Running command: ./train_gpt2cu -l 0.0005880547945739206 -o hyperband_runs_20241120_172038/run_s5_n186 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n186/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:53:54,469 - INFO - Training completed for config s5_n186:
  Training time: 0:00:20
  Final validation loss: 10.636769
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.56e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n186/checkpoint.bin
2024-11-20 22:53:54,469 - INFO - 
Configuration s5_n186 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005880547945739206",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n186",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n186/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.636769
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.56e-06
2024-11-20 22:53:54,469 - INFO - 
Starting training for config s5_n208:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n208/checkpoint.bin
2024-11-20 22:53:54,469 - INFO - Running command: ./train_gpt2cu -l 0.0005829119447162065 -o hyperband_runs_20241120_172038/run_s5_n208 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n208/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:54:14,727 - INFO - Training completed for config s5_n208:
  Training time: 0:00:20
  Final validation loss: 10.638567
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.49e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n208/checkpoint.bin
2024-11-20 22:54:14,728 - INFO - 
Configuration s5_n208 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005829119447162065",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n208",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n208/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.638567
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.49e-06
2024-11-20 22:54:14,728 - INFO - 
Starting training for config s5_n77:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n77/checkpoint.bin
2024-11-20 22:54:14,728 - INFO - Running command: ./train_gpt2cu -l 0.0005737331307205387 -o hyperband_runs_20241120_172038/run_s5_n77 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n77/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:54:34,970 - INFO - Training completed for config s5_n77:
  Training time: 0:00:20
  Final validation loss: 10.641756
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.38e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n77/checkpoint.bin
2024-11-20 22:54:34,970 - INFO - 
Configuration s5_n77 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005737331307205387",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n77",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n77/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.641756
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.38e-06
2024-11-20 22:54:34,970 - INFO - 
Starting training for config s5_n14:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n14/checkpoint.bin
2024-11-20 22:54:34,970 - INFO - Running command: ./train_gpt2cu -l 0.0005562905470579442 -o hyperband_runs_20241120_172038/run_s5_n14 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n14/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:54:55,217 - INFO - Training completed for config s5_n14:
  Training time: 0:00:20
  Final validation loss: 10.647982
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.15e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n14/checkpoint.bin
2024-11-20 22:54:55,217 - INFO - 
Configuration s5_n14 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005562905470579442",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n14",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n14/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.647982
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.15e-06
2024-11-20 22:54:55,217 - INFO - 
Starting training for config s5_n83:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n83/checkpoint.bin
2024-11-20 22:54:55,217 - INFO - Running command: ./train_gpt2cu -l 0.0005546446554246793 -o hyperband_runs_20241120_172038/run_s5_n83 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n83/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:55:15,466 - INFO - Training completed for config s5_n83:
  Training time: 0:00:20
  Final validation loss: 10.648578
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.13e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n83/checkpoint.bin
2024-11-20 22:55:15,467 - INFO - 
Configuration s5_n83 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005546446554246793",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n83",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n83/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.648578
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.13e-06
2024-11-20 22:55:15,467 - INFO - 
Starting training for config s5_n218:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n218/checkpoint.bin
2024-11-20 22:55:15,467 - INFO - Running command: ./train_gpt2cu -l 0.0005460938244902235 -o hyperband_runs_20241120_172038/run_s5_n218 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n218/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:55:35,734 - INFO - Training completed for config s5_n218:
  Training time: 0:00:20
  Final validation loss: 10.651681
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.02e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n218/checkpoint.bin
2024-11-20 22:55:35,734 - INFO - 
Configuration s5_n218 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005460938244902235",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n218",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n218/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.651681
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.02e-06
2024-11-20 22:55:35,734 - INFO - 
Starting training for config s5_n13:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n13/checkpoint.bin
2024-11-20 22:55:35,734 - INFO - Running command: ./train_gpt2cu -l 0.000522387932881555 -o hyperband_runs_20241120_172038/run_s5_n13 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n13/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:55:55,983 - INFO - Training completed for config s5_n13:
  Training time: 0:00:20
  Final validation loss: 10.660379
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 6.72e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n13/checkpoint.bin
2024-11-20 22:55:55,983 - INFO - 
Configuration s5_n13 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.000522387932881555",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n13",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n13/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.660379
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.72e-06
2024-11-20 22:55:55,983 - INFO - 
Starting training for config s5_n104:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n104/checkpoint.bin
2024-11-20 22:55:55,983 - INFO - Running command: ./train_gpt2cu -l 0.0005153006805113633 -o hyperband_runs_20241120_172038/run_s5_n104 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n104/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:56:16,246 - INFO - Training completed for config s5_n104:
  Training time: 0:00:20
  Final validation loss: 10.663051
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 6.63e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n104/checkpoint.bin
2024-11-20 22:56:16,246 - INFO - 
Configuration s5_n104 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005153006805113633",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n104",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n104/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.663051
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.63e-06
2024-11-20 22:56:16,246 - INFO - 
Starting training for config s5_n133:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n133/checkpoint.bin
2024-11-20 22:56:16,246 - INFO - Running command: ./train_gpt2cu -l 0.0005115511140942006 -o hyperband_runs_20241120_172038/run_s5_n133 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n133/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:56:36,516 - INFO - Training completed for config s5_n133:
  Training time: 0:00:20
  Final validation loss: 10.664468
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 6.58e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n133/checkpoint.bin
2024-11-20 22:56:36,517 - INFO - 
Configuration s5_n133 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005115511140942006",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n133",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n133/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.664468
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.58e-06
2024-11-20 22:56:36,517 - INFO - 
Starting training for config s5_n144:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n144/checkpoint.bin
2024-11-20 22:56:36,517 - INFO - Running command: ./train_gpt2cu -l 0.0005113530148493589 -o hyperband_runs_20241120_172038/run_s5_n144 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n144/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:56:56,769 - INFO - Training completed for config s5_n144:
  Training time: 0:00:20
  Final validation loss: 10.664537
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 6.57e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n144/checkpoint.bin
2024-11-20 22:56:56,769 - INFO - 
Configuration s5_n144 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005113530148493589",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n144",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n144/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.664537
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.57e-06
2024-11-20 22:56:56,769 - INFO - 
Starting training for config s5_n173:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n173/checkpoint.bin
2024-11-20 22:56:56,770 - INFO - Running command: ./train_gpt2cu -l 0.0004956644074228404 -o hyperband_runs_20241120_172038/run_s5_n173 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n173/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:57:17,027 - INFO - Training completed for config s5_n173:
  Training time: 0:00:20
  Final validation loss: 10.670532
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 6.37e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n173/checkpoint.bin
2024-11-20 22:57:17,027 - INFO - 
Configuration s5_n173 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004956644074228404",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n173",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n173/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.670532
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.37e-06
2024-11-20 22:57:17,027 - INFO - 
Starting training for config s5_n190:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n190/checkpoint.bin
2024-11-20 22:57:17,028 - INFO - Running command: ./train_gpt2cu -l 0.00048201894452236854 -o hyperband_runs_20241120_172038/run_s5_n190 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n190/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:57:37,278 - INFO - Training completed for config s5_n190:
  Training time: 0:00:20
  Final validation loss: 10.675828
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 6.20e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n190/checkpoint.bin
2024-11-20 22:57:37,279 - INFO - 
Configuration s5_n190 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00048201894452236854",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n190",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n190/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.675828
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.20e-06
2024-11-20 22:57:37,279 - INFO - 
Starting training for config s5_n150:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n150/checkpoint.bin
2024-11-20 22:57:37,279 - INFO - Running command: ./train_gpt2cu -l 0.00047891054478801877 -o hyperband_runs_20241120_172038/run_s5_n150 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n150/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:57:57,538 - INFO - Training completed for config s5_n150:
  Training time: 0:00:20
  Final validation loss: 10.677049
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 6.16e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n150/checkpoint.bin
2024-11-20 22:57:57,538 - INFO - 
Configuration s5_n150 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00047891054478801877",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n150",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n150/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.677049
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.16e-06
2024-11-20 22:57:57,538 - INFO - 
Starting training for config s5_n280:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n280/checkpoint.bin
2024-11-20 22:57:57,538 - INFO - Running command: ./train_gpt2cu -l 0.00046880524160877295 -o hyperband_runs_20241120_172038/run_s5_n280 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n280/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:58:17,777 - INFO - Training completed for config s5_n280:
  Training time: 0:00:20
  Final validation loss: 10.681060
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 6.03e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n280/checkpoint.bin
2024-11-20 22:58:17,777 - INFO - 
Configuration s5_n280 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00046880524160877295",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n280",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n280/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.681060
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.03e-06
2024-11-20 22:58:17,777 - INFO - 
Starting training for config s5_n67:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n67/checkpoint.bin
2024-11-20 22:58:17,778 - INFO - Running command: ./train_gpt2cu -l 0.0004592736376297031 -o hyperband_runs_20241120_172038/run_s5_n67 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n67/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:58:38,006 - INFO - Training completed for config s5_n67:
  Training time: 0:00:20
  Final validation loss: 10.684885
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.90e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n67/checkpoint.bin
2024-11-20 22:58:38,006 - INFO - 
Configuration s5_n67 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004592736376297031",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n67",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n67/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.684885
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.90e-06
2024-11-20 22:58:38,006 - INFO - 
Starting training for config s5_n111:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n111/checkpoint.bin
2024-11-20 22:58:38,006 - INFO - Running command: ./train_gpt2cu -l 0.0004537901260077919 -o hyperband_runs_20241120_172038/run_s5_n111 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n111/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:58:58,254 - INFO - Training completed for config s5_n111:
  Training time: 0:00:20
  Final validation loss: 10.687118
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.83e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n111/checkpoint.bin
2024-11-20 22:58:58,255 - INFO - 
Configuration s5_n111 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004537901260077919",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n111",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n111/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.687118
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.83e-06
2024-11-20 22:58:58,255 - INFO - 
Starting training for config s5_n271:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n271/checkpoint.bin
2024-11-20 22:58:58,255 - INFO - Running command: ./train_gpt2cu -l 0.0004512388596351136 -o hyperband_runs_20241120_172038/run_s5_n271 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n271/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:59:18,496 - INFO - Training completed for config s5_n271:
  Training time: 0:00:20
  Final validation loss: 10.688169
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.80e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n271/checkpoint.bin
2024-11-20 22:59:18,496 - INFO - 
Configuration s5_n271 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004512388596351136",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n271",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n271/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.688169
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.80e-06
2024-11-20 22:59:18,497 - INFO - 
Starting training for config s5_n169:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n169/checkpoint.bin
2024-11-20 22:59:18,497 - INFO - Running command: ./train_gpt2cu -l 0.0004396348926023942 -o hyperband_runs_20241120_172038/run_s5_n169 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n169/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:59:38,759 - INFO - Training completed for config s5_n169:
  Training time: 0:00:20
  Final validation loss: 10.692910
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.65e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n169/checkpoint.bin
2024-11-20 22:59:38,759 - INFO - 
Configuration s5_n169 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004396348926023942",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n169",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n169/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.692910
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.65e-06
2024-11-20 22:59:38,760 - INFO - 
Starting training for config s5_n141:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n141/checkpoint.bin
2024-11-20 22:59:38,760 - INFO - Running command: ./train_gpt2cu -l 0.0004327990049038078 -o hyperband_runs_20241120_172038/run_s5_n141 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n141/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 22:59:59,024 - INFO - Training completed for config s5_n141:
  Training time: 0:00:20
  Final validation loss: 10.695729
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.56e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n141/checkpoint.bin
2024-11-20 22:59:59,024 - INFO - 
Configuration s5_n141 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004327990049038078",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n141",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n141/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.695729
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.56e-06
2024-11-20 22:59:59,024 - INFO - 
Starting training for config s5_n252:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n252/checkpoint.bin
2024-11-20 22:59:59,024 - INFO - Running command: ./train_gpt2cu -l 0.0004305699664790186 -o hyperband_runs_20241120_172038/run_s5_n252 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n252/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:00:19,282 - INFO - Training completed for config s5_n252:
  Training time: 0:00:20
  Final validation loss: 10.696663
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.54e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n252/checkpoint.bin
2024-11-20 23:00:19,282 - INFO - 
Configuration s5_n252 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004305699664790186",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n252",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n252/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.696663
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.54e-06
2024-11-20 23:00:19,283 - INFO - 
Starting training for config s5_n152:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n152/checkpoint.bin
2024-11-20 23:00:19,283 - INFO - Running command: ./train_gpt2cu -l 0.0004227493452401578 -o hyperband_runs_20241120_172038/run_s5_n152 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n152/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:00:39,554 - INFO - Training completed for config s5_n152:
  Training time: 0:00:20
  Final validation loss: 10.699923
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.44e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n152/checkpoint.bin
2024-11-20 23:00:39,554 - INFO - 
Configuration s5_n152 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004227493452401578",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n152",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n152/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.699923
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.44e-06
2024-11-20 23:00:39,555 - INFO - 
Starting training for config s5_n227:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n227/checkpoint.bin
2024-11-20 23:00:39,555 - INFO - Running command: ./train_gpt2cu -l 0.00039323417404199117 -o hyperband_runs_20241120_172038/run_s5_n227 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n227/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:00:59,801 - INFO - Training completed for config s5_n227:
  Training time: 0:00:20
  Final validation loss: 10.712497
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.06e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n227/checkpoint.bin
2024-11-20 23:00:59,801 - INFO - 
Configuration s5_n227 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00039323417404199117",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n227",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n227/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.712497
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.06e-06
2024-11-20 23:00:59,802 - INFO - 
Starting training for config s5_n155:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n155/checkpoint.bin
2024-11-20 23:00:59,802 - INFO - Running command: ./train_gpt2cu -l 0.00039233776926718314 -o hyperband_runs_20241120_172038/run_s5_n155 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n155/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:01:20,066 - INFO - Training completed for config s5_n155:
  Training time: 0:00:20
  Final validation loss: 10.712891
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.04e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n155/checkpoint.bin
2024-11-20 23:01:20,066 - INFO - 
Configuration s5_n155 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00039233776926718314",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n155",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n155/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.712891
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.04e-06
2024-11-20 23:01:20,066 - INFO - 
Starting training for config s5_n164:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n164/checkpoint.bin
2024-11-20 23:01:20,066 - INFO - Running command: ./train_gpt2cu -l 0.0003862436206482557 -o hyperband_runs_20241120_172038/run_s5_n164 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n164/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:01:40,317 - INFO - Training completed for config s5_n164:
  Training time: 0:00:20
  Final validation loss: 10.715553
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.97e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n164/checkpoint.bin
2024-11-20 23:01:40,317 - INFO - 
Configuration s5_n164 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003862436206482557",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n164",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n164/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.715553
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.97e-06
2024-11-20 23:01:40,317 - INFO - 
Starting training for config s5_n221:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n221/checkpoint.bin
2024-11-20 23:01:40,317 - INFO - Running command: ./train_gpt2cu -l 0.00038452647855839804 -o hyperband_runs_20241120_172038/run_s5_n221 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n221/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:02:00,558 - INFO - Training completed for config s5_n221:
  Training time: 0:00:20
  Final validation loss: 10.716324
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.94e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n221/checkpoint.bin
2024-11-20 23:02:00,559 - INFO - 
Configuration s5_n221 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00038452647855839804",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n221",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n221/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.716324
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.94e-06
2024-11-20 23:02:00,559 - INFO - 
Starting training for config s5_n129:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n129/checkpoint.bin
2024-11-20 23:02:00,559 - INFO - Running command: ./train_gpt2cu -l 0.00038390080874090856 -o hyperband_runs_20241120_172038/run_s5_n129 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n129/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:02:20,810 - INFO - Training completed for config s5_n129:
  Training time: 0:00:20
  Final validation loss: 10.716595
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.94e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n129/checkpoint.bin
2024-11-20 23:02:20,810 - INFO - 
Configuration s5_n129 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00038390080874090856",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n129",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n129/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.716595
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.94e-06
2024-11-20 23:02:20,810 - INFO - 
Starting training for config s5_n70:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n70/checkpoint.bin
2024-11-20 23:02:20,810 - INFO - Running command: ./train_gpt2cu -l 0.00038286924805000635 -o hyperband_runs_20241120_172038/run_s5_n70 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n70/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:02:41,050 - INFO - Training completed for config s5_n70:
  Training time: 0:00:20
  Final validation loss: 10.717033
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.92e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n70/checkpoint.bin
2024-11-20 23:02:41,051 - INFO - 
Configuration s5_n70 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00038286924805000635",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n70",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n70/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.717033
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.92e-06
2024-11-20 23:02:41,051 - INFO - 
Starting training for config s5_n15:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n15/checkpoint.bin
2024-11-20 23:02:41,051 - INFO - Running command: ./train_gpt2cu -l 0.000381333528879859 -o hyperband_runs_20241120_172038/run_s5_n15 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n15/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:03:01,291 - INFO - Training completed for config s5_n15:
  Training time: 0:00:20
  Final validation loss: 10.717707
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.90e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n15/checkpoint.bin
2024-11-20 23:03:01,291 - INFO - 
Configuration s5_n15 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.000381333528879859",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n15",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n15/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.717707
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.90e-06
2024-11-20 23:03:01,291 - INFO - 
Starting training for config s5_n142:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n142/checkpoint.bin
2024-11-20 23:03:01,291 - INFO - Running command: ./train_gpt2cu -l 0.00037537975536683246 -o hyperband_runs_20241120_172038/run_s5_n142 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n142/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:03:21,559 - INFO - Training completed for config s5_n142:
  Training time: 0:00:20
  Final validation loss: 10.720304
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.83e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n142/checkpoint.bin
2024-11-20 23:03:21,560 - INFO - 
Configuration s5_n142 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00037537975536683246",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n142",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n142/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.720304
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.83e-06
2024-11-20 23:03:21,560 - INFO - 
Starting training for config s5_n0:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n0/checkpoint.bin
2024-11-20 23:03:21,560 - INFO - Running command: ./train_gpt2cu -l 0.0003738016455208007 -o hyperband_runs_20241120_172038/run_s5_n0 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n0/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:03:41,818 - INFO - Training completed for config s5_n0:
  Training time: 0:00:20
  Final validation loss: 10.721003
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.81e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n0/checkpoint.bin
2024-11-20 23:03:41,818 - INFO - 
Configuration s5_n0 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003738016455208007",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n0",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n0/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.721003
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.81e-06
2024-11-20 23:03:41,818 - INFO - 
Starting training for config s5_n200:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n200/checkpoint.bin
2024-11-20 23:03:41,819 - INFO - Running command: ./train_gpt2cu -l 0.0003427184507712492 -o hyperband_runs_20241120_172038/run_s5_n200 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n200/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:04:02,069 - INFO - Training completed for config s5_n200:
  Training time: 0:00:20
  Final validation loss: 10.734911
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.41e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n200/checkpoint.bin
2024-11-20 23:04:02,069 - INFO - 
Configuration s5_n200 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003427184507712492",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n200",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n200/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.734911
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.41e-06
2024-11-20 23:04:02,069 - INFO - 
Starting training for config s5_n172:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n172/checkpoint.bin
2024-11-20 23:04:02,069 - INFO - Running command: ./train_gpt2cu -l 0.00033982779562731827 -o hyperband_runs_20241120_172038/run_s5_n172 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n172/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:04:22,325 - INFO - Training completed for config s5_n172:
  Training time: 0:00:20
  Final validation loss: 10.736239
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.37e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n172/checkpoint.bin
2024-11-20 23:04:22,326 - INFO - 
Configuration s5_n172 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00033982779562731827",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n172",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n172/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.736239
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.37e-06
2024-11-20 23:04:22,326 - INFO - 
Starting training for config s5_n256:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n256/checkpoint.bin
2024-11-20 23:04:22,326 - INFO - Running command: ./train_gpt2cu -l 0.00033626599179865805 -o hyperband_runs_20241120_172038/run_s5_n256 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n256/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:04:42,578 - INFO - Training completed for config s5_n256:
  Training time: 0:00:20
  Final validation loss: 10.737875
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.32e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n256/checkpoint.bin
2024-11-20 23:04:42,578 - INFO - 
Configuration s5_n256 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00033626599179865805",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n256",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n256/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.737875
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.32e-06
2024-11-20 23:04:42,578 - INFO - 
Starting training for config s5_n1:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n1/checkpoint.bin
2024-11-20 23:04:42,578 - INFO - Running command: ./train_gpt2cu -l 0.0003259694209443947 -o hyperband_runs_20241120_172038/run_s5_n1 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n1/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:05:02,848 - INFO - Training completed for config s5_n1:
  Training time: 0:00:20
  Final validation loss: 10.742612
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.19e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n1/checkpoint.bin
2024-11-20 23:05:02,848 - INFO - 
Configuration s5_n1 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003259694209443947",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n1",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n1/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.742612
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.19e-06
2024-11-20 23:05:02,849 - INFO - 
Starting training for config s5_n95:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n95/checkpoint.bin
2024-11-20 23:05:02,849 - INFO - Running command: ./train_gpt2cu -l 0.0003257966907619246 -o hyperband_runs_20241120_172038/run_s5_n95 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n95/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:05:23,101 - INFO - Training completed for config s5_n95:
  Training time: 0:00:20
  Final validation loss: 10.742692
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.19e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n95/checkpoint.bin
2024-11-20 23:05:23,101 - INFO - 
Configuration s5_n95 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003257966907619246",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n95",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n95/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.742692
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.19e-06
2024-11-20 23:05:23,101 - INFO - 
Starting training for config s5_n213:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n213/checkpoint.bin
2024-11-20 23:05:23,102 - INFO - Running command: ./train_gpt2cu -l 0.0003256394600316364 -o hyperband_runs_20241120_172038/run_s5_n213 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n213/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:05:43,347 - INFO - Training completed for config s5_n213:
  Training time: 0:00:20
  Final validation loss: 10.742771
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.19e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n213/checkpoint.bin
2024-11-20 23:05:43,347 - INFO - 
Configuration s5_n213 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003256394600316364",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n213",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n213/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.742771
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.19e-06
2024-11-20 23:05:43,347 - INFO - 
Starting training for config s5_n174:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n174/checkpoint.bin
2024-11-20 23:05:43,348 - INFO - Running command: ./train_gpt2cu -l 0.0003201668875819047 -o hyperband_runs_20241120_172038/run_s5_n174 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n174/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:06:03,597 - INFO - Training completed for config s5_n174:
  Training time: 0:00:20
  Final validation loss: 10.745321
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.12e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n174/checkpoint.bin
2024-11-20 23:06:03,597 - INFO - 
Configuration s5_n174 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003201668875819047",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n174",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n174/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.745321
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.12e-06
2024-11-20 23:06:03,598 - INFO - 
Starting training for config s5_n71:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n71/checkpoint.bin
2024-11-20 23:06:03,598 - INFO - Running command: ./train_gpt2cu -l 0.0003192586067652104 -o hyperband_runs_20241120_172038/run_s5_n71 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n71/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:06:23,838 - INFO - Training completed for config s5_n71:
  Training time: 0:00:20
  Final validation loss: 10.745745
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.10e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n71/checkpoint.bin
2024-11-20 23:06:23,838 - INFO - 
Configuration s5_n71 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003192586067652104",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n71",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n71/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.745745
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.10e-06
2024-11-20 23:06:23,838 - INFO - 
Starting training for config s5_n81:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n81/checkpoint.bin
2024-11-20 23:06:23,838 - INFO - Running command: ./train_gpt2cu -l 0.00031465210588944186 -o hyperband_runs_20241120_172038/run_s5_n81 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n81/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:06:44,077 - INFO - Training completed for config s5_n81:
  Training time: 0:00:20
  Final validation loss: 10.747893
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.05e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n81/checkpoint.bin
2024-11-20 23:06:44,077 - INFO - 
Configuration s5_n81 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00031465210588944186",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n81",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n81/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.747893
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.05e-06
2024-11-20 23:06:44,077 - INFO - 
Starting training for config s5_n87:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n87/checkpoint.bin
2024-11-20 23:06:44,077 - INFO - Running command: ./train_gpt2cu -l 0.00030349709381722543 -o hyperband_runs_20241120_172038/run_s5_n87 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n87/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:07:04,327 - INFO - Training completed for config s5_n87:
  Training time: 0:00:20
  Final validation loss: 10.753119
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.90e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n87/checkpoint.bin
2024-11-20 23:07:04,327 - INFO - 
Configuration s5_n87 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00030349709381722543",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n87",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n87/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.753119
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.90e-06
2024-11-20 23:07:04,327 - INFO - 
Starting training for config s5_n11:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n11/checkpoint.bin
2024-11-20 23:07:04,327 - INFO - Running command: ./train_gpt2cu -l 0.000303173109497266 -o hyperband_runs_20241120_172038/run_s5_n11 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n11/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:07:24,578 - INFO - Training completed for config s5_n11:
  Training time: 0:00:20
  Final validation loss: 10.753274
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.90e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n11/checkpoint.bin
2024-11-20 23:07:24,578 - INFO - 
Configuration s5_n11 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.000303173109497266",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n11",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n11/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.753274
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.90e-06
2024-11-20 23:07:24,578 - INFO - 
Starting training for config s5_n236:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n236/checkpoint.bin
2024-11-20 23:07:24,578 - INFO - Running command: ./train_gpt2cu -l 0.00030235143011081835 -o hyperband_runs_20241120_172038/run_s5_n236 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n236/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:07:44,842 - INFO - Training completed for config s5_n236:
  Training time: 0:00:20
  Final validation loss: 10.753672
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.89e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n236/checkpoint.bin
2024-11-20 23:07:44,842 - INFO - 
Configuration s5_n236 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00030235143011081835",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n236",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n236/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.753672
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.89e-06
2024-11-20 23:07:44,843 - INFO - 
Starting training for config s5_n43:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n43/checkpoint.bin
2024-11-20 23:07:44,843 - INFO - Running command: ./train_gpt2cu -l 0.0002944430343264675 -o hyperband_runs_20241120_172038/run_s5_n43 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n43/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:08:05,119 - INFO - Training completed for config s5_n43:
  Training time: 0:00:20
  Final validation loss: 10.757412
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.79e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n43/checkpoint.bin
2024-11-20 23:08:05,120 - INFO - 
Configuration s5_n43 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002944430343264675",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n43",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n43/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.757412
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.79e-06
2024-11-20 23:08:05,120 - INFO - 
Starting training for config s5_n189:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n189/checkpoint.bin
2024-11-20 23:08:05,120 - INFO - Running command: ./train_gpt2cu -l 0.00029278188084328177 -o hyperband_runs_20241120_172038/run_s5_n189 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n189/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:08:25,374 - INFO - Training completed for config s5_n189:
  Training time: 0:00:20
  Final validation loss: 10.758169
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.76e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n189/checkpoint.bin
2024-11-20 23:08:25,374 - INFO - 
Configuration s5_n189 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00029278188084328177",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n189",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n189/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.758169
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.76e-06
2024-11-20 23:08:25,374 - INFO - 
Starting training for config s5_n153:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n153/checkpoint.bin
2024-11-20 23:08:25,374 - INFO - Running command: ./train_gpt2cu -l 0.00029206344126709867 -o hyperband_runs_20241120_172038/run_s5_n153 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n153/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:08:45,626 - INFO - Training completed for config s5_n153:
  Training time: 0:00:20
  Final validation loss: 10.758520
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.76e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n153/checkpoint.bin
2024-11-20 23:08:45,626 - INFO - 
Configuration s5_n153 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00029206344126709867",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n153",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n153/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.758520
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.76e-06
2024-11-20 23:08:45,626 - INFO - 
Starting training for config s5_n72:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n72/checkpoint.bin
2024-11-20 23:08:45,626 - INFO - Running command: ./train_gpt2cu -l 0.0002910395102516586 -o hyperband_runs_20241120_172038/run_s5_n72 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n72/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:09:05,858 - INFO - Training completed for config s5_n72:
  Training time: 0:00:20
  Final validation loss: 10.759019
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.74e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n72/checkpoint.bin
2024-11-20 23:09:05,858 - INFO - 
Configuration s5_n72 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002910395102516586",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n72",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n72/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.759019
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.74e-06
2024-11-20 23:09:05,858 - INFO - 
Starting training for config s5_n178:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n178/checkpoint.bin
2024-11-20 23:09:05,858 - INFO - Running command: ./train_gpt2cu -l 0.00029093265701808955 -o hyperband_runs_20241120_172038/run_s5_n178 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n178/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:09:26,106 - INFO - Training completed for config s5_n178:
  Training time: 0:00:20
  Final validation loss: 10.759072
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.74e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n178/checkpoint.bin
2024-11-20 23:09:26,106 - INFO - 
Configuration s5_n178 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00029093265701808955",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n178",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n178/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.759072
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.74e-06
2024-11-20 23:09:26,106 - INFO - 
Starting training for config s5_n103:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n103/checkpoint.bin
2024-11-20 23:09:26,106 - INFO - Running command: ./train_gpt2cu -l 0.0002835450696406215 -o hyperband_runs_20241120_172038/run_s5_n103 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n103/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:09:46,355 - INFO - Training completed for config s5_n103:
  Training time: 0:00:20
  Final validation loss: 10.762617
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.65e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n103/checkpoint.bin
2024-11-20 23:09:46,355 - INFO - 
Configuration s5_n103 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002835450696406215",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n103",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n103/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.762617
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.65e-06
2024-11-20 23:09:46,355 - INFO - 
Starting training for config s5_n226:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n226/checkpoint.bin
2024-11-20 23:09:46,355 - INFO - Running command: ./train_gpt2cu -l 0.0002808280625384985 -o hyperband_runs_20241120_172038/run_s5_n226 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n226/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:10:06,608 - INFO - Training completed for config s5_n226:
  Training time: 0:00:20
  Final validation loss: 10.763915
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.61e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n226/checkpoint.bin
2024-11-20 23:10:06,608 - INFO - 
Configuration s5_n226 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002808280625384985",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n226",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n226/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.763915
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.61e-06
2024-11-20 23:10:06,608 - INFO - 
Starting training for config s5_n38:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n38/checkpoint.bin
2024-11-20 23:10:06,608 - INFO - Running command: ./train_gpt2cu -l 0.0002803865627598923 -o hyperband_runs_20241120_172038/run_s5_n38 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n38/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:10:26,860 - INFO - Training completed for config s5_n38:
  Training time: 0:00:20
  Final validation loss: 10.764135
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.60e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n38/checkpoint.bin
2024-11-20 23:10:26,861 - INFO - 
Configuration s5_n38 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002803865627598923",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n38",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n38/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.764135
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.60e-06
2024-11-20 23:10:26,861 - INFO - 
Starting training for config s5_n247:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n247/checkpoint.bin
2024-11-20 23:10:26,861 - INFO - Running command: ./train_gpt2cu -l 0.0002748310573411585 -o hyperband_runs_20241120_172038/run_s5_n247 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n247/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:10:47,128 - INFO - Training completed for config s5_n247:
  Training time: 0:00:20
  Final validation loss: 10.766821
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.53e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n247/checkpoint.bin
2024-11-20 23:10:47,128 - INFO - 
Configuration s5_n247 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002748310573411585",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n247",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n247/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.766821
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.53e-06
2024-11-20 23:10:47,128 - INFO - 
Starting training for config s5_n229:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n229/checkpoint.bin
2024-11-20 23:10:47,129 - INFO - Running command: ./train_gpt2cu -l 0.0002740542958174265 -o hyperband_runs_20241120_172038/run_s5_n229 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n229/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:11:07,386 - INFO - Training completed for config s5_n229:
  Training time: 0:00:20
  Final validation loss: 10.767192
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.52e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n229/checkpoint.bin
2024-11-20 23:11:07,386 - INFO - 
Configuration s5_n229 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002740542958174265",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n229",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n229/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.767192
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.52e-06
2024-11-20 23:11:07,386 - INFO - 
Starting training for config s5_n273:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n273/checkpoint.bin
2024-11-20 23:11:07,386 - INFO - Running command: ./train_gpt2cu -l 0.0002729979077477309 -o hyperband_runs_20241120_172038/run_s5_n273 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n273/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:11:27,640 - INFO - Training completed for config s5_n273:
  Training time: 0:00:20
  Final validation loss: 10.767717
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.51e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n273/checkpoint.bin
2024-11-20 23:11:27,640 - INFO - 
Configuration s5_n273 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002729979077477309",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n273",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n273/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.767717
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.51e-06
2024-11-20 23:11:27,640 - INFO - 
Starting training for config s5_n16:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n16/checkpoint.bin
2024-11-20 23:11:27,640 - INFO - Running command: ./train_gpt2cu -l 0.0002722711815511042 -o hyperband_runs_20241120_172038/run_s5_n16 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n16/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:11:47,890 - INFO - Training completed for config s5_n16:
  Training time: 0:00:20
  Final validation loss: 10.768080
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.50e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n16/checkpoint.bin
2024-11-20 23:11:47,890 - INFO - 
Configuration s5_n16 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002722711815511042",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n16",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n16/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.768080
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.50e-06
2024-11-20 23:11:47,890 - INFO - 
Starting training for config s5_n196:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n196/checkpoint.bin
2024-11-20 23:11:47,890 - INFO - Running command: ./train_gpt2cu -l 0.00026721099071312654 -o hyperband_runs_20241120_172038/run_s5_n196 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n196/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:12:08,150 - INFO - Training completed for config s5_n196:
  Training time: 0:00:20
  Final validation loss: 10.770535
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.44e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n196/checkpoint.bin
2024-11-20 23:12:08,151 - INFO - 
Configuration s5_n196 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00026721099071312654",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n196",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n196/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.770535
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.44e-06
2024-11-20 23:12:08,151 - INFO - 
Starting training for config s5_n64:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n64/checkpoint.bin
2024-11-20 23:12:08,151 - INFO - Running command: ./train_gpt2cu -l 0.0002612423267904805 -o hyperband_runs_20241120_172038/run_s5_n64 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n64/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:12:28,398 - INFO - Training completed for config s5_n64:
  Training time: 0:00:20
  Final validation loss: 10.773454
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.36e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n64/checkpoint.bin
2024-11-20 23:12:28,398 - INFO - 
Configuration s5_n64 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002612423267904805",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n64",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n64/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.773454
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.36e-06
2024-11-20 23:12:28,399 - INFO - 
Starting training for config s5_n205:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n205/checkpoint.bin
2024-11-20 23:12:28,399 - INFO - Running command: ./train_gpt2cu -l 0.0002611687203778593 -o hyperband_runs_20241120_172038/run_s5_n205 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n205/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:12:48,649 - INFO - Training completed for config s5_n205:
  Training time: 0:00:20
  Final validation loss: 10.773504
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.36e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n205/checkpoint.bin
2024-11-20 23:12:48,649 - INFO - 
Configuration s5_n205 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002611687203778593",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n205",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n205/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.773504
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.36e-06
2024-11-20 23:12:48,649 - INFO - 
Starting training for config s5_n121:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n121/checkpoint.bin
2024-11-20 23:12:48,649 - INFO - Running command: ./train_gpt2cu -l 0.00026063420623900156 -o hyperband_runs_20241120_172038/run_s5_n121 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n121/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:13:08,894 - INFO - Training completed for config s5_n121:
  Training time: 0:00:20
  Final validation loss: 10.773767
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.35e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n121/checkpoint.bin
2024-11-20 23:13:08,895 - INFO - 
Configuration s5_n121 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00026063420623900156",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n121",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n121/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.773767
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.35e-06
2024-11-20 23:13:08,895 - INFO - 
Starting training for config s5_n96:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n96/checkpoint.bin
2024-11-20 23:13:08,895 - INFO - Running command: ./train_gpt2cu -l 0.00025795437022796565 -o hyperband_runs_20241120_172038/run_s5_n96 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n96/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:13:29,120 - INFO - Training completed for config s5_n96:
  Training time: 0:00:20
  Final validation loss: 10.775075
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.32e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n96/checkpoint.bin
2024-11-20 23:13:29,120 - INFO - 
Configuration s5_n96 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00025795437022796565",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n96",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n96/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.775075
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.32e-06
2024-11-20 23:13:29,120 - INFO - 
Starting training for config s5_n84:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n84/checkpoint.bin
2024-11-20 23:13:29,120 - INFO - Running command: ./train_gpt2cu -l 0.0002563835894495119 -o hyperband_runs_20241120_172038/run_s5_n84 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n84/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:13:49,381 - INFO - Training completed for config s5_n84:
  Training time: 0:00:20
  Final validation loss: 10.775825
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.30e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n84/checkpoint.bin
2024-11-20 23:13:49,381 - INFO - 
Configuration s5_n84 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002563835894495119",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n84",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n84/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.775825
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.30e-06
2024-11-20 23:13:49,381 - INFO - 
Starting training for config s5_n140:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n140/checkpoint.bin
2024-11-20 23:13:49,381 - INFO - Running command: ./train_gpt2cu -l 0.00024967442199541964 -o hyperband_runs_20241120_172038/run_s5_n140 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n140/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:14:09,627 - INFO - Training completed for config s5_n140:
  Training time: 0:00:20
  Final validation loss: 10.779115
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.21e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n140/checkpoint.bin
2024-11-20 23:14:09,627 - INFO - 
Configuration s5_n140 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00024967442199541964",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n140",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n140/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.779115
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.21e-06
2024-11-20 23:14:09,627 - INFO - 
Starting training for config s5_n214:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n214/checkpoint.bin
2024-11-20 23:14:09,627 - INFO - Running command: ./train_gpt2cu -l 0.00024531369836096995 -o hyperband_runs_20241120_172038/run_s5_n214 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n214/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:14:29,891 - INFO - Training completed for config s5_n214:
  Training time: 0:00:20
  Final validation loss: 10.781286
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.15e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n214/checkpoint.bin
2024-11-20 23:14:29,892 - INFO - 
Configuration s5_n214 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00024531369836096995",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n214",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n214/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.781286
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.15e-06
2024-11-20 23:14:29,892 - INFO - 
Starting training for config s5_n179:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n179/checkpoint.bin
2024-11-20 23:14:29,892 - INFO - Running command: ./train_gpt2cu -l 0.00024174509235077194 -o hyperband_runs_20241120_172038/run_s5_n179 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n179/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:14:50,139 - INFO - Training completed for config s5_n179:
  Training time: 0:00:20
  Final validation loss: 10.783053
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.11e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n179/checkpoint.bin
2024-11-20 23:14:50,140 - INFO - 
Configuration s5_n179 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00024174509235077194",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n179",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n179/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.783053
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.11e-06
2024-11-20 23:14:50,140 - INFO - 
Starting training for config s5_n105:
  Iterations: 9
  Previous iterations: 3
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n105/checkpoint.bin
2024-11-20 23:14:50,140 - INFO - Running command: ./train_gpt2cu -l 0.00023864716872958307 -o hyperband_runs_20241120_172038/run_s5_n105 -x 9 -n 9 -y 1 -e hyperband_runs_20241120_172038/run_s5_n105/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:15:10,393 - INFO - Training completed for config s5_n105:
  Training time: 0:00:20
  Final validation loss: 10.784592
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.07e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n105/checkpoint.bin
2024-11-20 23:15:10,394 - INFO - 
Configuration s5_n105 (bracket_5_round_1):
  Hyperparameters: {
  "learning_rate": "0.00023864716872958307",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n105",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n105/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:20
  Validation Loss: 10.784592
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.07e-06
2024-11-20 23:15:10,394 - INFO - 
Eliminating 63 configurations:
  Surviving: 31
2024-11-20 23:15:14,596 - INFO - 
Bracket 5, Round 2:
  Active configs: 31
  Iterations: 27
2024-11-20 23:15:14,596 - INFO - 
Starting training for config s5_n51:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin
2024-11-20 23:15:14,597 - INFO - Running command: ./train_gpt2cu -l 0.0009968572861830537 -o hyperband_runs_20241120_172038/run_s5_n51 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:16:02,454 - INFO - Training completed for config s5_n51:
  Training time: 0:00:47
  Final validation loss: 10.037762
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.85e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin
2024-11-20 23:16:02,454 - INFO - 
Configuration s5_n51 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009968572861830537",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n51",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.037762
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.85e-05
2024-11-20 23:16:02,455 - INFO - 
Starting training for config s5_n32:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin
2024-11-20 23:16:02,455 - INFO - Running command: ./train_gpt2cu -l 0.000995514234701091 -o hyperband_runs_20241120_172038/run_s5_n32 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:16:50,280 - INFO - Training completed for config s5_n32:
  Training time: 0:00:47
  Final validation loss: 10.038216
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.84e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin
2024-11-20 23:16:50,280 - INFO - 
Configuration s5_n32 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.000995514234701091",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n32",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.038216
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.84e-05
2024-11-20 23:16:50,280 - INFO - 
Starting training for config s5_n160:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin
2024-11-20 23:16:50,281 - INFO - Running command: ./train_gpt2cu -l 0.0009822324088212349 -o hyperband_runs_20241120_172038/run_s5_n160 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:17:38,096 - INFO - Training completed for config s5_n160:
  Training time: 0:00:47
  Final validation loss: 10.041580
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.79e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin
2024-11-20 23:17:38,097 - INFO - 
Configuration s5_n160 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009822324088212349",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n160",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.041580
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.79e-05
2024-11-20 23:17:38,097 - INFO - 
Starting training for config s5_n134:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n134/checkpoint.bin
2024-11-20 23:17:38,097 - INFO - Running command: ./train_gpt2cu -l 0.0009660126338049484 -o hyperband_runs_20241120_172038/run_s5_n134 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n134/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:18:25,922 - INFO - Training completed for config s5_n134:
  Training time: 0:00:47
  Final validation loss: 10.045534
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.73e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n134/checkpoint.bin
2024-11-20 23:18:25,922 - INFO - 
Configuration s5_n134 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009660126338049484",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n134",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n134/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.045534
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.73e-05
2024-11-20 23:18:25,922 - INFO - 
Starting training for config s5_n270:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n270/checkpoint.bin
2024-11-20 23:18:25,922 - INFO - Running command: ./train_gpt2cu -l 0.0009517015653755315 -o hyperband_runs_20241120_172038/run_s5_n270 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n270/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:19:13,740 - INFO - Training completed for config s5_n270:
  Training time: 0:00:47
  Final validation loss: 10.048947
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.67e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n270/checkpoint.bin
2024-11-20 23:19:13,740 - INFO - 
Configuration s5_n270 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009517015653755315",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n270",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n270/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.048947
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.67e-05
2024-11-20 23:19:13,741 - INFO - 
Starting training for config s5_n260:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n260/checkpoint.bin
2024-11-20 23:19:13,741 - INFO - Running command: ./train_gpt2cu -l 0.0009293981044299633 -o hyperband_runs_20241120_172038/run_s5_n260 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n260/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:20:01,555 - INFO - Training completed for config s5_n260:
  Training time: 0:00:47
  Final validation loss: 10.055006
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.58e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n260/checkpoint.bin
2024-11-20 23:20:01,555 - INFO - 
Configuration s5_n260 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009293981044299633",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n260",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n260/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.055006
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.58e-05
2024-11-20 23:20:01,555 - INFO - 
Starting training for config s5_n56:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n56/checkpoint.bin
2024-11-20 23:20:01,555 - INFO - Running command: ./train_gpt2cu -l 0.0008898164593245048 -o hyperband_runs_20241120_172038/run_s5_n56 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n56/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:20:49,367 - INFO - Training completed for config s5_n56:
  Training time: 0:00:47
  Final validation loss: 10.064696
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.43e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n56/checkpoint.bin
2024-11-20 23:20:49,368 - INFO - 
Configuration s5_n56 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008898164593245048",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n56",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n56/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.064696
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.43e-05
2024-11-20 23:20:49,368 - INFO - 
Starting training for config s5_n146:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n146/checkpoint.bin
2024-11-20 23:20:49,368 - INFO - Running command: ./train_gpt2cu -l 0.0008813068343693393 -o hyperband_runs_20241120_172038/run_s5_n146 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n146/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:21:37,006 - INFO - Training completed for config s5_n146:
  Training time: 0:00:47
  Final validation loss: 10.066639
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.40e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n146/checkpoint.bin
2024-11-20 23:21:37,006 - INFO - 
Configuration s5_n146 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008813068343693393",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n146",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n146/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.066639
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.40e-05
2024-11-20 23:21:37,006 - INFO - 
Starting training for config s5_n9:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n9/checkpoint.bin
2024-11-20 23:21:37,007 - INFO - Running command: ./train_gpt2cu -l 0.0008687906691256375 -o hyperband_runs_20241120_172038/run_s5_n9 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n9/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:22:23,219 - INFO - Training completed for config s5_n9:
  Training time: 0:00:46
  Final validation loss: 10.070347
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.35e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n9/checkpoint.bin
2024-11-20 23:22:23,220 - INFO - 
Configuration s5_n9 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008687906691256375",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n9",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n9/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:46
  Validation Loss: 10.070347
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.35e-05
2024-11-20 23:22:23,220 - INFO - 
Starting training for config s5_n131:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n131/checkpoint.bin
2024-11-20 23:22:23,220 - INFO - Running command: ./train_gpt2cu -l 0.0008602543209504669 -o hyperband_runs_20241120_172038/run_s5_n131 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n131/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:23:09,384 - INFO - Training completed for config s5_n131:
  Training time: 0:00:46
  Final validation loss: 10.073299
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.32e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n131/checkpoint.bin
2024-11-20 23:23:09,384 - INFO - 
Configuration s5_n131 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008602543209504669",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n131",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n131/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:46
  Validation Loss: 10.073299
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.32e-05
2024-11-20 23:23:09,384 - INFO - 
Starting training for config s5_n201:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n201/checkpoint.bin
2024-11-20 23:23:09,385 - INFO - Running command: ./train_gpt2cu -l 0.0008419142751758245 -o hyperband_runs_20241120_172038/run_s5_n201 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n201/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:23:55,620 - INFO - Training completed for config s5_n201:
  Training time: 0:00:46
  Final validation loss: 10.077797
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.25e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n201/checkpoint.bin
2024-11-20 23:23:55,620 - INFO - 
Configuration s5_n201 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008419142751758245",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n201",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n201/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:46
  Validation Loss: 10.077797
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.25e-05
2024-11-20 23:23:55,620 - INFO - 
Starting training for config s5_n139:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n139/checkpoint.bin
2024-11-20 23:23:55,621 - INFO - Running command: ./train_gpt2cu -l 0.0008272293688785697 -o hyperband_runs_20241120_172038/run_s5_n139 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n139/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:24:43,391 - INFO - Training completed for config s5_n139:
  Training time: 0:00:47
  Final validation loss: 10.081517
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.19e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n139/checkpoint.bin
2024-11-20 23:24:43,391 - INFO - 
Configuration s5_n139 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008272293688785697",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n139",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n139/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.081517
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.19e-05
2024-11-20 23:24:43,391 - INFO - 
Starting training for config s5_n264:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n264/checkpoint.bin
2024-11-20 23:24:43,391 - INFO - Running command: ./train_gpt2cu -l 0.0008252545505248207 -o hyperband_runs_20241120_172038/run_s5_n264 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n264/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:25:31,215 - INFO - Training completed for config s5_n264:
  Training time: 0:00:47
  Final validation loss: 10.082003
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.18e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n264/checkpoint.bin
2024-11-20 23:25:31,215 - INFO - 
Configuration s5_n264 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008252545505248207",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n264",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n264/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.082003
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.18e-05
2024-11-20 23:25:31,216 - INFO - 
Starting training for config s5_n93:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n93/checkpoint.bin
2024-11-20 23:25:31,216 - INFO - Running command: ./train_gpt2cu -l 0.0008001779748372474 -o hyperband_runs_20241120_172038/run_s5_n93 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n93/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:26:19,044 - INFO - Training completed for config s5_n93:
  Training time: 0:00:47
  Final validation loss: 10.088091
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.09e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n93/checkpoint.bin
2024-11-20 23:26:19,044 - INFO - 
Configuration s5_n93 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008001779748372474",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n93",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n93/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.088091
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.09e-05
2024-11-20 23:26:19,044 - INFO - 
Starting training for config s5_n24:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n24/checkpoint.bin
2024-11-20 23:26:19,044 - INFO - Running command: ./train_gpt2cu -l 0.0007944281434975066 -o hyperband_runs_20241120_172038/run_s5_n24 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n24/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:27:06,869 - INFO - Training completed for config s5_n24:
  Training time: 0:00:47
  Final validation loss: 10.089836
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.06e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n24/checkpoint.bin
2024-11-20 23:27:06,869 - INFO - 
Configuration s5_n24 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007944281434975066",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n24",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n24/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.089836
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.06e-05
2024-11-20 23:27:06,869 - INFO - 
Starting training for config s5_n193:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n193/checkpoint.bin
2024-11-20 23:27:06,869 - INFO - Running command: ./train_gpt2cu -l 0.0007853484168511458 -o hyperband_runs_20241120_172038/run_s5_n193 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n193/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:27:54,714 - INFO - Training completed for config s5_n193:
  Training time: 0:00:47
  Final validation loss: 10.092272
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.03e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n193/checkpoint.bin
2024-11-20 23:27:54,715 - INFO - 
Configuration s5_n193 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007853484168511458",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n193",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n193/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.092272
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.03e-05
2024-11-20 23:27:54,716 - INFO - 
Starting training for config s5_n48:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n48/checkpoint.bin
2024-11-20 23:27:54,716 - INFO - Running command: ./train_gpt2cu -l 0.0007550602914635752 -o hyperband_runs_20241120_172038/run_s5_n48 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n48/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:28:42,543 - INFO - Training completed for config s5_n48:
  Training time: 0:00:47
  Final validation loss: 10.099806
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.91e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n48/checkpoint.bin
2024-11-20 23:28:42,543 - INFO - 
Configuration s5_n48 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007550602914635752",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n48",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n48/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.099806
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.91e-05
2024-11-20 23:28:42,543 - INFO - 
Starting training for config s5_n59:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n59/checkpoint.bin
2024-11-20 23:28:42,543 - INFO - Running command: ./train_gpt2cu -l 0.0007314827961887715 -o hyperband_runs_20241120_172038/run_s5_n59 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n59/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:29:30,364 - INFO - Training completed for config s5_n59:
  Training time: 0:00:47
  Final validation loss: 10.105725
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.82e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n59/checkpoint.bin
2024-11-20 23:29:30,365 - INFO - 
Configuration s5_n59 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007314827961887715",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n59",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n59/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.105725
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.82e-05
2024-11-20 23:29:30,365 - INFO - 
Starting training for config s5_n29:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n29/checkpoint.bin
2024-11-20 23:29:30,365 - INFO - Running command: ./train_gpt2cu -l 0.0007043818706256417 -o hyperband_runs_20241120_172038/run_s5_n29 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n29/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:30:18,192 - INFO - Training completed for config s5_n29:
  Training time: 0:00:47
  Final validation loss: 10.113723
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.72e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n29/checkpoint.bin
2024-11-20 23:30:18,192 - INFO - 
Configuration s5_n29 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007043818706256417",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n29",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n29/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.113723
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.72e-05
2024-11-20 23:30:18,192 - INFO - 
Starting training for config s5_n170:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n170/checkpoint.bin
2024-11-20 23:30:18,193 - INFO - Running command: ./train_gpt2cu -l 0.0006832720543350221 -o hyperband_runs_20241120_172038/run_s5_n170 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n170/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:31:05,987 - INFO - Training completed for config s5_n170:
  Training time: 0:00:47
  Final validation loss: 10.119066
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.64e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n170/checkpoint.bin
2024-11-20 23:31:05,987 - INFO - 
Configuration s5_n170 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006832720543350221",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n170",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n170/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.119066
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.64e-05
2024-11-20 23:31:05,987 - INFO - 
Starting training for config s5_n167:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n167/checkpoint.bin
2024-11-20 23:31:05,987 - INFO - Running command: ./train_gpt2cu -l 0.0006705540199959338 -o hyperband_runs_20241120_172038/run_s5_n167 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n167/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:31:53,796 - INFO - Training completed for config s5_n167:
  Training time: 0:00:47
  Final validation loss: 10.122293
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.59e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n167/checkpoint.bin
2024-11-20 23:31:53,796 - INFO - 
Configuration s5_n167 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006705540199959338",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n167",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n167/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.122293
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.59e-05
2024-11-20 23:31:53,796 - INFO - 
Starting training for config s5_n157:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n157/checkpoint.bin
2024-11-20 23:31:53,796 - INFO - Running command: ./train_gpt2cu -l 0.0006705481284587626 -o hyperband_runs_20241120_172038/run_s5_n157 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n157/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:32:41,627 - INFO - Training completed for config s5_n157:
  Training time: 0:00:47
  Final validation loss: 10.122295
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.59e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n157/checkpoint.bin
2024-11-20 23:32:41,627 - INFO - 
Configuration s5_n157 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006705481284587626",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n157",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n157/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.122295
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.59e-05
2024-11-20 23:32:41,627 - INFO - 
Starting training for config s5_n52:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n52/checkpoint.bin
2024-11-20 23:32:41,627 - INFO - Running command: ./train_gpt2cu -l 0.0006679558460799921 -o hyperband_runs_20241120_172038/run_s5_n52 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n52/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:33:29,448 - INFO - Training completed for config s5_n52:
  Training time: 0:00:47
  Final validation loss: 10.122945
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.58e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n52/checkpoint.bin
2024-11-20 23:33:29,449 - INFO - 
Configuration s5_n52 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006679558460799921",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n52",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n52/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.122945
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.58e-05
2024-11-20 23:33:29,449 - INFO - 
Starting training for config s5_n207:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n207/checkpoint.bin
2024-11-20 23:33:29,449 - INFO - Running command: ./train_gpt2cu -l 0.0006507552592411038 -o hyperband_runs_20241120_172038/run_s5_n207 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n207/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:34:17,281 - INFO - Training completed for config s5_n207:
  Training time: 0:00:47
  Final validation loss: 10.127688
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.51e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n207/checkpoint.bin
2024-11-20 23:34:17,282 - INFO - 
Configuration s5_n207 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006507552592411038",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n207",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n207/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.127688
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.51e-05
2024-11-20 23:34:17,282 - INFO - 
Starting training for config s5_n210:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n210/checkpoint.bin
2024-11-20 23:34:17,282 - INFO - Running command: ./train_gpt2cu -l 0.0006410662231365501 -o hyperband_runs_20241120_172038/run_s5_n210 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n210/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:35:05,147 - INFO - Training completed for config s5_n210:
  Training time: 0:00:47
  Final validation loss: 10.130690
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.47e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n210/checkpoint.bin
2024-11-20 23:35:05,148 - INFO - 
Configuration s5_n210 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006410662231365501",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n210",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n210/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.130690
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.47e-05
2024-11-20 23:35:05,148 - INFO - 
Starting training for config s5_n86:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n86/checkpoint.bin
2024-11-20 23:35:05,148 - INFO - Running command: ./train_gpt2cu -l 0.0006402538968106657 -o hyperband_runs_20241120_172038/run_s5_n86 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n86/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:35:52,999 - INFO - Training completed for config s5_n86:
  Training time: 0:00:47
  Final validation loss: 10.130938
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.47e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n86/checkpoint.bin
2024-11-20 23:35:52,999 - INFO - 
Configuration s5_n86 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006402538968106657",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n86",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n86/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.130938
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.47e-05
2024-11-20 23:35:52,999 - INFO - 
Starting training for config s5_n30:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n30/checkpoint.bin
2024-11-20 23:35:52,999 - INFO - Running command: ./train_gpt2cu -l 0.0006397357687444202 -o hyperband_runs_20241120_172038/run_s5_n30 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n30/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:36:40,849 - INFO - Training completed for config s5_n30:
  Training time: 0:00:47
  Final validation loss: 10.131117
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.47e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n30/checkpoint.bin
2024-11-20 23:36:40,849 - INFO - 
Configuration s5_n30 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006397357687444202",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n30",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n30/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.131117
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.47e-05
2024-11-20 23:36:40,849 - INFO - 
Starting training for config s5_n7:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n7/checkpoint.bin
2024-11-20 23:36:40,849 - INFO - Running command: ./train_gpt2cu -l 0.0006236868598086687 -o hyperband_runs_20241120_172038/run_s5_n7 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n7/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:37:28,683 - INFO - Training completed for config s5_n7:
  Training time: 0:00:47
  Final validation loss: 10.135340
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.41e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n7/checkpoint.bin
2024-11-20 23:37:28,684 - INFO - 
Configuration s5_n7 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006236868598086687",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n7",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n7/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.135340
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.41e-05
2024-11-20 23:37:28,684 - INFO - 
Starting training for config s5_n151:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n151/checkpoint.bin
2024-11-20 23:37:28,684 - INFO - Running command: ./train_gpt2cu -l 0.0006133593856173028 -o hyperband_runs_20241120_172038/run_s5_n151 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n151/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:38:16,511 - INFO - Training completed for config s5_n151:
  Training time: 0:00:47
  Final validation loss: 10.138098
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.37e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n151/checkpoint.bin
2024-11-20 23:38:16,511 - INFO - 
Configuration s5_n151 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006133593856173028",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n151",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n151/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.138098
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.37e-05
2024-11-20 23:38:16,511 - INFO - 
Starting training for config s5_n267:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n267/checkpoint.bin
2024-11-20 23:38:16,511 - INFO - Running command: ./train_gpt2cu -l 0.0006020631276527434 -o hyperband_runs_20241120_172038/run_s5_n267 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n267/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:39:04,340 - INFO - Training completed for config s5_n267:
  Training time: 0:00:47
  Final validation loss: 10.141373
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.32e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n267/checkpoint.bin
2024-11-20 23:39:04,340 - INFO - 
Configuration s5_n267 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006020631276527434",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n267",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n267/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.141373
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.32e-05
2024-11-20 23:39:04,341 - INFO - 
Starting training for config s5_n186:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n186/checkpoint.bin
2024-11-20 23:39:04,341 - INFO - Running command: ./train_gpt2cu -l 0.0005880547945739206 -o hyperband_runs_20241120_172038/run_s5_n186 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s5_n186/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:39:52,165 - INFO - Training completed for config s5_n186:
  Training time: 0:00:47
  Final validation loss: 10.145227
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.27e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n186/checkpoint.bin
2024-11-20 23:39:52,166 - INFO - 
Configuration s5_n186 (bracket_5_round_2):
  Hyperparameters: {
  "learning_rate": "0.0005880547945739206",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n186",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n186/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.145227
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.27e-05
2024-11-20 23:39:52,166 - INFO - 
Eliminating 21 configurations:
  Surviving: 10
2024-11-20 23:39:54,934 - INFO - 
Bracket 5, Round 3:
  Active configs: 10
  Iterations: 81
2024-11-20 23:39:54,934 - INFO - 
Starting training for config s5_n51:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin
2024-11-20 23:39:54,934 - INFO - Running command: ./train_gpt2cu -l 0.0009968572861830537 -o hyperband_runs_20241120_172038/run_s5_n51 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:42:05,533 - INFO - Training completed for config s5_n51:
  Training time: 0:02:10
  Final validation loss: 8.289655
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.15e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin
2024-11-20 23:42:05,533 - INFO - 
Configuration s5_n51 (bracket_5_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009968572861830537",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n51",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.289655
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.15e-04
2024-11-20 23:42:05,533 - INFO - 
Starting training for config s5_n32:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin
2024-11-20 23:42:05,533 - INFO - Running command: ./train_gpt2cu -l 0.000995514234701091 -o hyperband_runs_20241120_172038/run_s5_n32 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:44:16,162 - INFO - Training completed for config s5_n32:
  Training time: 0:02:10
  Final validation loss: 8.291447
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.15e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin
2024-11-20 23:44:16,162 - INFO - 
Configuration s5_n32 (bracket_5_round_3):
  Hyperparameters: {
  "learning_rate": "0.000995514234701091",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n32",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.291447
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.15e-04
2024-11-20 23:44:16,163 - INFO - 
Starting training for config s5_n160:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin
2024-11-20 23:44:16,163 - INFO - Running command: ./train_gpt2cu -l 0.0009822324088212349 -o hyperband_runs_20241120_172038/run_s5_n160 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:46:26,751 - INFO - Training completed for config s5_n160:
  Training time: 0:02:10
  Final validation loss: 8.309191
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.14e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin
2024-11-20 23:46:26,751 - INFO - 
Configuration s5_n160 (bracket_5_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009822324088212349",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n160",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.309191
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.14e-04
2024-11-20 23:46:26,751 - INFO - 
Starting training for config s5_n134:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n134/checkpoint.bin
2024-11-20 23:46:26,751 - INFO - Running command: ./train_gpt2cu -l 0.0009660126338049484 -o hyperband_runs_20241120_172038/run_s5_n134 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s5_n134/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:48:37,342 - INFO - Training completed for config s5_n134:
  Training time: 0:02:10
  Final validation loss: 8.331333
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.12e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n134/checkpoint.bin
2024-11-20 23:48:37,343 - INFO - 
Configuration s5_n134 (bracket_5_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009660126338049484",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n134",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n134/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.331333
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.12e-04
2024-11-20 23:48:37,343 - INFO - 
Starting training for config s5_n270:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n270/checkpoint.bin
2024-11-20 23:48:37,343 - INFO - Running command: ./train_gpt2cu -l 0.0009517015653755315 -o hyperband_runs_20241120_172038/run_s5_n270 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s5_n270/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:50:47,935 - INFO - Training completed for config s5_n270:
  Training time: 0:02:10
  Final validation loss: 8.350757
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.10e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n270/checkpoint.bin
2024-11-20 23:50:47,936 - INFO - 
Configuration s5_n270 (bracket_5_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009517015653755315",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n270",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n270/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.350757
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-04
2024-11-20 23:50:47,936 - INFO - 
Starting training for config s5_n260:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n260/checkpoint.bin
2024-11-20 23:50:47,936 - INFO - Running command: ./train_gpt2cu -l 0.0009293981044299633 -o hyperband_runs_20241120_172038/run_s5_n260 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s5_n260/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:52:58,513 - INFO - Training completed for config s5_n260:
  Training time: 0:02:10
  Final validation loss: 8.381461
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.08e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n260/checkpoint.bin
2024-11-20 23:52:58,513 - INFO - 
Configuration s5_n260 (bracket_5_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009293981044299633",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n260",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n260/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.381461
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.08e-04
2024-11-20 23:52:58,513 - INFO - 
Starting training for config s5_n56:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n56/checkpoint.bin
2024-11-20 23:52:58,513 - INFO - Running command: ./train_gpt2cu -l 0.0008898164593245048 -o hyperband_runs_20241120_172038/run_s5_n56 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s5_n56/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:55:09,089 - INFO - Training completed for config s5_n56:
  Training time: 0:02:10
  Final validation loss: 8.437460
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.03e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n56/checkpoint.bin
2024-11-20 23:55:09,089 - INFO - 
Configuration s5_n56 (bracket_5_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008898164593245048",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n56",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n56/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.437460
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.03e-04
2024-11-20 23:55:09,089 - INFO - 
Starting training for config s5_n146:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n146/checkpoint.bin
2024-11-20 23:55:09,090 - INFO - Running command: ./train_gpt2cu -l 0.0008813068343693393 -o hyperband_runs_20241120_172038/run_s5_n146 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s5_n146/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:57:19,672 - INFO - Training completed for config s5_n146:
  Training time: 0:02:10
  Final validation loss: 8.449739
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.02e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n146/checkpoint.bin
2024-11-20 23:57:19,672 - INFO - 
Configuration s5_n146 (bracket_5_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008813068343693393",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n146",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n146/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.449739
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-04
2024-11-20 23:57:19,672 - INFO - 
Starting training for config s5_n9:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n9/checkpoint.bin
2024-11-20 23:57:19,672 - INFO - Running command: ./train_gpt2cu -l 0.0008687906691256375 -o hyperband_runs_20241120_172038/run_s5_n9 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s5_n9/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-20 23:59:30,238 - INFO - Training completed for config s5_n9:
  Training time: 0:02:10
  Final validation loss: 8.468138
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.01e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n9/checkpoint.bin
2024-11-20 23:59:30,238 - INFO - 
Configuration s5_n9 (bracket_5_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008687906691256375",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n9",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n9/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.468138
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.01e-04
2024-11-20 23:59:30,238 - INFO - 
Starting training for config s5_n131:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n131/checkpoint.bin
2024-11-20 23:59:30,238 - INFO - Running command: ./train_gpt2cu -l 0.0008602543209504669 -o hyperband_runs_20241120_172038/run_s5_n131 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s5_n131/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 00:01:40,806 - INFO - Training completed for config s5_n131:
  Training time: 0:02:10
  Final validation loss: 8.480378
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 9.95e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n131/checkpoint.bin
2024-11-21 00:01:40,807 - INFO - 
Configuration s5_n131 (bracket_5_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008602543209504669",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n131",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n131/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.480378
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.95e-05
2024-11-21 00:01:40,807 - INFO - 
Eliminating 7 configurations:
  Surviving: 3
2024-11-21 00:01:42,330 - INFO - 
Bracket 5, Round 4:
  Active configs: 3
  Iterations: 243
2024-11-21 00:01:42,331 - INFO - 
Starting training for config s5_n51:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin
2024-11-21 00:01:42,331 - INFO - Running command: ./train_gpt2cu -l 0.0009968572861830537 -o hyperband_runs_20241120_172038/run_s5_n51 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 00:07:59,497 - INFO - Training completed for config s5_n51:
  Training time: 0:06:17
  Final validation loss: 6.331724
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 3.46e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin
2024-11-21 00:07:59,497 - INFO - 
Configuration s5_n51 (bracket_5_round_4):
  Hyperparameters: {
  "learning_rate": "0.0009968572861830537",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n51",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.331724
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.46e-04
2024-11-21 00:07:59,497 - INFO - 
New best configuration found!
  Config ID: s5_n51
  Validation Loss: 6.331724
  Hellaswag Accuracy: 0.00%
  Training Time: 0:06:17
2024-11-21 00:07:59,497 - INFO - 
Starting training for config s5_n32:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin
2024-11-21 00:07:59,497 - INFO - Running command: ./train_gpt2cu -l 0.000995514234701091 -o hyperband_runs_20241120_172038/run_s5_n32 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 00:14:16,688 - INFO - Training completed for config s5_n32:
  Training time: 0:06:17
  Final validation loss: 6.333501
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 3.46e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin
2024-11-21 00:14:16,688 - INFO - 
Configuration s5_n32 (bracket_5_round_4):
  Hyperparameters: {
  "learning_rate": "0.000995514234701091",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n32",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n32/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.333501
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.46e-04
2024-11-21 00:14:16,688 - INFO - 
Starting training for config s5_n160:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin
2024-11-21 00:14:16,689 - INFO - Running command: ./train_gpt2cu -l 0.0009822324088212349 -o hyperband_runs_20241120_172038/run_s5_n160 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 00:20:33,884 - INFO - Training completed for config s5_n160:
  Training time: 0:06:17
  Final validation loss: 6.344004
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 3.41e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin
2024-11-21 00:20:33,885 - INFO - 
Configuration s5_n160 (bracket_5_round_4):
  Hyperparameters: {
  "learning_rate": "0.0009822324088212349",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n160",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n160/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.344004
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.41e-04
2024-11-21 00:20:33,885 - INFO - 


Eliminating 2 configurations:
  Surviving: 1
2024-11-21 00:20:34,484 - INFO - 
Bracket 5, Round 5:
  Active configs: 1
  Iterations: 729
2024-11-21 00:20:34,484 - INFO - 
Starting training for config s5_n51:
  Iterations: 729
  Previous iterations: 243
  Previous checkpoint: hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin
2024-11-21 00:20:34,484 - INFO - Running command: ./train_gpt2cu -l 0.0009968572861830537 -o hyperband_runs_20241120_172038/run_s5_n51 -x 729 -n 729 -y 1 -e hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 00:20:35,289 - ERROR - Error training config s5_n51:
  stdout: Multi-GPU support is disabled. Using a single GPU.
+-----------------------+----------------------------------------------------+
| Parameter             | Value                                              |
+-----------------------+----------------------------------------------------+
| train data pattern    | data/fineweb_train_*.bin                           |
| val data pattern      | data/fineweb_val_*.bin                             |
| output log dir        | hyperband_runs_20241120_172038/run_s5_n51          |
| checkpoint_every      | 729                                                |
| resume                | 1                                                  |
| micro batch size B    | 64                                                 |
| sequence length T     | 1024                                               |
| total batch size      | 524288                                             |
| LR scheduler          | cosine                                             |
| learning rate (LR)    | 9.968573e-04                                       |
| warmup iterations     | 700                                                |
| final LR fraction     | 0.000000e+00                                       |
| weight decay          | 1.000000e-01                                       |
| skip update lossz     | 0.000000                                           |
| skip update gradz     | 0.000000                                           |
| max_steps             | 729                                                |
| val_loss_every        | 250                                                |
| val_max_steps         | 20                                                 |
| sample_every          | 20000                                              |
| genT                  | 64                                                 |
| overfit_single_batch  | 0                                                  |
| use_master_weights    | enabled                                            |
| gelu_fusion           | 0                                                  |
| recompute             | 1                                                  |
+-----------------------+----------------------------------------------------+
| device                | NVIDIA A10G                                        |
| peak TFlops           | -1.0                                               |
| precision             | BF16                                               |
+-----------------------+----------------------------------------------------+
| weight init method    | intermediate checkpoint                            |
| max_sequence_length T | 1024                                               |
| vocab_size V          | 50257                                              |
| padded_vocab_size Vp  | 50304                                              |
| num_layers L          | 6                                                  |
| num_heads NH          | 6                                                  |
| channels C            | 384                                                |
| num_parameters        | 30357504                                           |
+-----------------------+----------------------------------------------------+
| train_num_batches     | 729                                                |
| val_num_batches       | 20                                                 |
+-----------------------+----------------------------------------------------+
| run hellaswag         | no                                                 |
+-----------------------+----------------------------------------------------+
| num_processes         | 1                                                  |
| zero_stage            | 1                                                  |
+-----------------------+----------------------------------------------------+
num_parameters: 30357504 => bytes: 60715008
allocated 57 MiB for model parameters
batch_size B=64 * seq_len T=1024 * num_processes=1 and total_batch_size=524288
=> setting gr
  stderr: train_gpt2cu: train_gpt2.cu:1246: void load_state(int*, GPT2*, DataLoader*, const char*): Assertion `shard_num_samples == loader->shard_num_samples' failed.

2024-11-21 00:20:35,289 - INFO - 
Configuration s5_n51 (bracket_5_round_5):
  Hyperparameters: {
  "learning_rate": "0.0009968572861830537",
  "output_dir": "hyperband_runs_20241120_172038/run_s5_n51",
  "max_steps": "729",
  "checkpoint_every": "729",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s5_n51/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 729
  Total iterations: 243
  Training time: 0:00:00
  Validation Loss: inf
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 0.00e+00
2024-11-21 00:20:35,290 - INFO - 
Bracket 4:
  Initial configurations: 114
  Initial iterations: 9
2024-11-21 00:20:35,290 - INFO - 
Bracket 4, Round 0:
  Active configs: 114
  Iterations: 9
2024-11-21 00:20:35,290 - INFO - 
Starting training for config s4_n0:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:20:35,291 - INFO - Running command: ./train_gpt2cu -l 0.00035331710641866486 -o hyperband_runs_20241120_172038/run_s4_n0 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:21:03,505 - INFO - Training completed for config s4_n0:
  Training time: 0:00:28
  Final validation loss: 10.730116
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.54e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n0/checkpoint.bin
2024-11-21 00:21:03,505 - INFO - 
Configuration s4_n0 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00035331710641866486",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n0",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.730116
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.54e-06
2024-11-21 00:21:03,505 - INFO - 
Starting training for config s4_n1:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:21:03,505 - INFO - Running command: ./train_gpt2cu -l 1.031000967498225e-05 -o hyperband_runs_20241120_172038/run_s4_n1 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:21:31,730 - INFO - Training completed for config s4_n1:
  Training time: 0:00:28
  Final validation loss: 10.905918
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.33e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n1/checkpoint.bin
2024-11-21 00:21:31,730 - INFO - 
Configuration s4_n1 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.031000967498225e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n1",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.905918
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.33e-07
2024-11-21 00:21:31,730 - INFO - 
Starting training for config s4_n2:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:21:31,730 - INFO - Running command: ./train_gpt2cu -l 0.0007307575392695935 -o hyperband_runs_20241120_172038/run_s4_n2 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:21:59,923 - INFO - Training completed for config s4_n2:
  Training time: 0:00:28
  Final validation loss: 10.591075
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.40e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n2/checkpoint.bin
2024-11-21 00:21:59,923 - INFO - 
Configuration s4_n2 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007307575392695935",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n2",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.591075
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.40e-06
2024-11-21 00:21:59,923 - INFO - 
Starting training for config s4_n3:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:21:59,923 - INFO - Running command: ./train_gpt2cu -l 0.00020806874585260768 -o hyperband_runs_20241120_172038/run_s4_n3 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:22:28,125 - INFO - Training completed for config s4_n3:
  Training time: 0:00:28
  Final validation loss: 10.800053
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.68e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n3/checkpoint.bin
2024-11-21 00:22:28,125 - INFO - 
Configuration s4_n3 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00020806874585260768",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n3",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.800053
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.68e-06
2024-11-21 00:22:28,125 - INFO - 
Starting training for config s4_n4:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:22:28,125 - INFO - Running command: ./train_gpt2cu -l 1.8770606783933485e-05 -o hyperband_runs_20241120_172038/run_s4_n4 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:22:56,316 - INFO - Training completed for config s4_n4:
  Training time: 0:00:28
  Final validation loss: 10.901291
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.41e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n4/checkpoint.bin
2024-11-21 00:22:56,316 - INFO - 
Configuration s4_n4 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.8770606783933485e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n4",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.901291
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.41e-07
2024-11-21 00:22:56,316 - INFO - 
Starting training for config s4_n5:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:22:56,316 - INFO - Running command: ./train_gpt2cu -l 2.943727804832503e-05 -o hyperband_runs_20241120_172038/run_s4_n5 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:23:24,514 - INFO - Training completed for config s4_n5:
  Training time: 0:00:28
  Final validation loss: 10.895472
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.78e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n5/checkpoint.bin
2024-11-21 00:23:24,514 - INFO - 
Configuration s4_n5 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "2.943727804832503e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n5",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.895472
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.78e-07
2024-11-21 00:23:24,514 - INFO - 
Starting training for config s4_n6:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:23:24,514 - INFO - Running command: ./train_gpt2cu -l 2.8905898181349817e-05 -o hyperband_runs_20241120_172038/run_s4_n6 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:23:52,713 - INFO - Training completed for config s4_n6:
  Training time: 0:00:28
  Final validation loss: 10.895760
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.72e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n6/checkpoint.bin
2024-11-21 00:23:52,714 - INFO - 
Configuration s4_n6 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "2.8905898181349817e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n6",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.895760
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.72e-07
2024-11-21 00:23:52,714 - INFO - 
Starting training for config s4_n7:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:23:52,714 - INFO - Running command: ./train_gpt2cu -l 1.3861947769370355e-05 -o hyperband_runs_20241120_172038/run_s4_n7 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:24:20,907 - INFO - Training completed for config s4_n7:
  Training time: 0:00:28
  Final validation loss: 10.903994
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.78e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n7/checkpoint.bin
2024-11-21 00:24:20,907 - INFO - 
Configuration s4_n7 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.3861947769370355e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n7",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.903994
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.78e-07
2024-11-21 00:24:20,907 - INFO - 
Starting training for config s4_n8:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:24:20,908 - INFO - Running command: ./train_gpt2cu -l 0.0005827342819023812 -o hyperband_runs_20241120_172038/run_s4_n8 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:24:49,094 - INFO - Training completed for config s4_n8:
  Training time: 0:00:28
  Final validation loss: 10.638623
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.49e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n8/checkpoint.bin
2024-11-21 00:24:49,094 - INFO - 
Configuration s4_n8 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005827342819023812",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n8",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.638623
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.49e-06
2024-11-21 00:24:49,094 - INFO - 
Starting training for config s4_n9:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:24:49,094 - INFO - Running command: ./train_gpt2cu -l 7.95021045067349e-05 -o hyperband_runs_20241120_172038/run_s4_n9 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:25:17,282 - INFO - Training completed for config s4_n9:
  Training time: 0:00:28
  Final validation loss: 10.868185
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.02e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n9/checkpoint.bin
2024-11-21 00:25:17,282 - INFO - 
Configuration s4_n9 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "7.95021045067349e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n9",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.868185
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-06
2024-11-21 00:25:17,282 - INFO - 
Starting training for config s4_n10:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:25:17,283 - INFO - Running command: ./train_gpt2cu -l 0.00035214374366128665 -o hyperband_runs_20241120_172038/run_s4_n10 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:25:45,458 - INFO - Training completed for config s4_n10:
  Training time: 0:00:28
  Final validation loss: 10.730659
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.53e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n10/checkpoint.bin
2024-11-21 00:25:45,458 - INFO - 
Configuration s4_n10 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00035214374366128665",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n10",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.730659
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.53e-06
2024-11-21 00:25:45,459 - INFO - 
Starting training for config s4_n11:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:25:45,459 - INFO - Running command: ./train_gpt2cu -l 0.00016392780619355827 -o hyperband_runs_20241120_172038/run_s4_n11 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:26:13,653 - INFO - Training completed for config s4_n11:
  Training time: 0:00:28
  Final validation loss: 10.822977
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.11e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n11/checkpoint.bin
2024-11-21 00:26:13,653 - INFO - 
Configuration s4_n11 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00016392780619355827",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n11",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.822977
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.11e-06
2024-11-21 00:26:13,653 - INFO - 
Starting training for config s4_n12:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:26:13,653 - INFO - Running command: ./train_gpt2cu -l 0.0008160374256239891 -o hyperband_runs_20241120_172038/run_s4_n12 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:26:41,839 - INFO - Training completed for config s4_n12:
  Training time: 0:00:28
  Final validation loss: 10.566999
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.05e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n12/checkpoint.bin
2024-11-21 00:26:41,839 - INFO - 
Configuration s4_n12 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008160374256239891",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n12",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.566999
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.05e-05
2024-11-21 00:26:41,839 - INFO - 
Starting training for config s4_n13:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:26:41,839 - INFO - Running command: ./train_gpt2cu -l 0.00021721593445545514 -o hyperband_runs_20241120_172038/run_s4_n13 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:27:10,022 - INFO - Training completed for config s4_n13:
  Training time: 0:00:28
  Final validation loss: 10.795396
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.79e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n13/checkpoint.bin
2024-11-21 00:27:10,022 - INFO - 
Configuration s4_n13 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00021721593445545514",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n13",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.795396
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.79e-06
2024-11-21 00:27:10,022 - INFO - 
Starting training for config s4_n14:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:27:10,022 - INFO - Running command: ./train_gpt2cu -l 0.0009599436171833041 -o hyperband_runs_20241120_172038/run_s4_n14 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:27:38,195 - INFO - Training completed for config s4_n14:
  Training time: 0:00:28
  Final validation loss: 10.530935
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.23e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin
2024-11-21 00:27:38,195 - INFO - 
Configuration s4_n14 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009599436171833041",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n14",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.530935
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.23e-05
2024-11-21 00:27:38,195 - INFO - 
Starting training for config s4_n15:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:27:38,195 - INFO - Running command: ./train_gpt2cu -l 1.3067505868284614e-05 -o hyperband_runs_20241120_172038/run_s4_n15 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:28:06,377 - INFO - Training completed for config s4_n15:
  Training time: 0:00:28
  Final validation loss: 10.904425
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.68e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n15/checkpoint.bin
2024-11-21 00:28:06,377 - INFO - 
Configuration s4_n15 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.3067505868284614e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n15",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.904425
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.68e-07
2024-11-21 00:28:06,377 - INFO - 
Starting training for config s4_n16:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:28:06,377 - INFO - Running command: ./train_gpt2cu -l 0.0007221224018725761 -o hyperband_runs_20241120_172038/run_s4_n16 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:28:34,555 - INFO - Training completed for config s4_n16:
  Training time: 0:00:28
  Final validation loss: 10.593634
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.28e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n16/checkpoint.bin
2024-11-21 00:28:34,555 - INFO - 
Configuration s4_n16 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007221224018725761",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n16",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.593634
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.28e-06
2024-11-21 00:28:34,555 - INFO - 
Starting training for config s4_n17:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:28:34,555 - INFO - Running command: ./train_gpt2cu -l 0.0003694681993618972 -o hyperband_runs_20241120_172038/run_s4_n17 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:29:02,738 - INFO - Training completed for config s4_n17:
  Training time: 0:00:28
  Final validation loss: 10.722926
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.75e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n17/checkpoint.bin
2024-11-21 00:29:02,739 - INFO - 
Configuration s4_n17 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003694681993618972",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n17",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.722926
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.75e-06
2024-11-21 00:29:02,739 - INFO - 
Starting training for config s4_n18:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:29:02,739 - INFO - Running command: ./train_gpt2cu -l 0.00013314168599416268 -o hyperband_runs_20241120_172038/run_s4_n18 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:29:30,932 - INFO - Training completed for config s4_n18:
  Training time: 0:00:28
  Final validation loss: 10.839345
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.71e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n18/checkpoint.bin
2024-11-21 00:29:30,932 - INFO - 
Configuration s4_n18 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013314168599416268",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n18",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.839345
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.71e-06
2024-11-21 00:29:30,932 - INFO - 
Starting training for config s4_n19:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:29:30,932 - INFO - Running command: ./train_gpt2cu -l 4.2590672876720255e-05 -o hyperband_runs_20241120_172038/run_s4_n19 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:29:59,113 - INFO - Training completed for config s4_n19:
  Training time: 0:00:28
  Final validation loss: 10.888291
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.48e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n19/checkpoint.bin
2024-11-21 00:29:59,113 - INFO - 
Configuration s4_n19 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "4.2590672876720255e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n19",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.888291
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.48e-07
2024-11-21 00:29:59,113 - INFO - 
Starting training for config s4_n20:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:29:59,114 - INFO - Running command: ./train_gpt2cu -l 0.0001965817385122481 -o hyperband_runs_20241120_172038/run_s4_n20 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:30:27,292 - INFO - Training completed for config s4_n20:
  Training time: 0:00:28
  Final validation loss: 10.805946
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.53e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n20/checkpoint.bin
2024-11-21 00:30:27,292 - INFO - 
Configuration s4_n20 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001965817385122481",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n20",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.805946
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.53e-06
2024-11-21 00:30:27,292 - INFO - 
Starting training for config s4_n21:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:30:27,292 - INFO - Running command: ./train_gpt2cu -l 7.755910738466332e-05 -o hyperband_runs_20241120_172038/run_s4_n21 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:30:55,482 - INFO - Training completed for config s4_n21:
  Training time: 0:00:28
  Final validation loss: 10.869238
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.97e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n21/checkpoint.bin
2024-11-21 00:30:55,482 - INFO - 
Configuration s4_n21 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "7.755910738466332e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n21",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.869238
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.97e-07
2024-11-21 00:30:55,482 - INFO - 
Starting training for config s4_n22:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:30:55,482 - INFO - Running command: ./train_gpt2cu -l 0.0003556119024864199 -o hyperband_runs_20241120_172038/run_s4_n22 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:31:23,673 - INFO - Training completed for config s4_n22:
  Training time: 0:00:28
  Final validation loss: 10.729090
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.57e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n22/checkpoint.bin
2024-11-21 00:31:23,673 - INFO - 
Configuration s4_n22 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003556119024864199",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n22",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.729090
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.57e-06
2024-11-21 00:31:23,673 - INFO - 
Starting training for config s4_n23:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:31:23,673 - INFO - Running command: ./train_gpt2cu -l 3.0816088235671825e-05 -o hyperband_runs_20241120_172038/run_s4_n23 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:31:51,886 - INFO - Training completed for config s4_n23:
  Training time: 0:00:28
  Final validation loss: 10.894716
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.96e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n23/checkpoint.bin
2024-11-21 00:31:51,886 - INFO - 
Configuration s4_n23 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "3.0816088235671825e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n23",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.894716
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.96e-07
2024-11-21 00:31:51,886 - INFO - 
Starting training for config s4_n24:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:31:51,886 - INFO - Running command: ./train_gpt2cu -l 8.61364574987166e-05 -o hyperband_runs_20241120_172038/run_s4_n24 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:32:20,087 - INFO - Training completed for config s4_n24:
  Training time: 0:00:28
  Final validation loss: 10.864594
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.11e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n24/checkpoint.bin
2024-11-21 00:32:20,087 - INFO - 
Configuration s4_n24 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "8.61364574987166e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n24",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.864594
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.11e-06
2024-11-21 00:32:20,087 - INFO - 
Starting training for config s4_n25:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:32:20,087 - INFO - Running command: ./train_gpt2cu -l 4.736579586714042e-05 -o hyperband_runs_20241120_172038/run_s4_n25 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:32:48,297 - INFO - Training completed for config s4_n25:
  Training time: 0:00:28
  Final validation loss: 10.885720
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 6.09e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n25/checkpoint.bin
2024-11-21 00:32:48,297 - INFO - 
Configuration s4_n25 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "4.736579586714042e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n25",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.885720
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.09e-07
2024-11-21 00:32:48,297 - INFO - 
Starting training for config s4_n26:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:32:48,297 - INFO - Running command: ./train_gpt2cu -l 6.311286556516687e-05 -o hyperband_runs_20241120_172038/run_s4_n26 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:33:16,493 - INFO - Training completed for config s4_n26:
  Training time: 0:00:28
  Final validation loss: 10.877117
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.11e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n26/checkpoint.bin
2024-11-21 00:33:16,493 - INFO - 
Configuration s4_n26 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "6.311286556516687e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n26",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.877117
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.11e-07
2024-11-21 00:33:16,493 - INFO - 
Starting training for config s4_n27:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:33:16,493 - INFO - Running command: ./train_gpt2cu -l 9.866167166686259e-05 -o hyperband_runs_20241120_172038/run_s4_n27 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:33:44,681 - INFO - Training completed for config s4_n27:
  Training time: 0:00:28
  Final validation loss: 10.857782
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.27e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n27/checkpoint.bin
2024-11-21 00:33:44,681 - INFO - 
Configuration s4_n27 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "9.866167166686259e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n27",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.857782
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.27e-06
2024-11-21 00:33:44,681 - INFO - 
Starting training for config s4_n28:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:33:44,681 - INFO - Running command: ./train_gpt2cu -l 1.1680158933770736e-05 -o hyperband_runs_20241120_172038/run_s4_n28 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:34:12,892 - INFO - Training completed for config s4_n28:
  Training time: 0:00:28
  Final validation loss: 10.905178
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.50e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n28/checkpoint.bin
2024-11-21 00:34:12,892 - INFO - 
Configuration s4_n28 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.1680158933770736e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n28",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.905178
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.50e-07
2024-11-21 00:34:12,892 - INFO - 
Starting training for config s4_n29:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:34:12,892 - INFO - Running command: ./train_gpt2cu -l 0.0002755830782103017 -o hyperband_runs_20241120_172038/run_s4_n29 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:34:41,096 - INFO - Training completed for config s4_n29:
  Training time: 0:00:28
  Final validation loss: 10.766453
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.54e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n29/checkpoint.bin
2024-11-21 00:34:41,097 - INFO - 
Configuration s4_n29 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002755830782103017",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n29",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.766453
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.54e-06
2024-11-21 00:34:41,097 - INFO - 
Starting training for config s4_n30:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:34:41,097 - INFO - Running command: ./train_gpt2cu -l 4.0441187043874666e-05 -o hyperband_runs_20241120_172038/run_s4_n30 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:35:09,294 - INFO - Training completed for config s4_n30:
  Training time: 0:00:28
  Final validation loss: 10.889465
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.20e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n30/checkpoint.bin
2024-11-21 00:35:09,294 - INFO - 
Configuration s4_n30 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "4.0441187043874666e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n30",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.889465
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.20e-07
2024-11-21 00:35:09,295 - INFO - 
Starting training for config s4_n31:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:35:09,295 - INFO - Running command: ./train_gpt2cu -l 4.332692826728789e-05 -o hyperband_runs_20241120_172038/run_s4_n31 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:35:37,498 - INFO - Training completed for config s4_n31:
  Training time: 0:00:28
  Final validation loss: 10.887892
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.57e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n31/checkpoint.bin
2024-11-21 00:35:37,499 - INFO - 
Configuration s4_n31 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "4.332692826728789e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n31",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.887892
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.57e-07
2024-11-21 00:35:37,499 - INFO - 
Starting training for config s4_n32:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:35:37,499 - INFO - Running command: ./train_gpt2cu -l 2.9734591666552544e-05 -o hyperband_runs_20241120_172038/run_s4_n32 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:36:05,711 - INFO - Training completed for config s4_n32:
  Training time: 0:00:28
  Final validation loss: 10.895311
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.82e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n32/checkpoint.bin
2024-11-21 00:36:05,711 - INFO - 
Configuration s4_n32 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "2.9734591666552544e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n32",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.895311
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.82e-07
2024-11-21 00:36:05,711 - INFO - 
Starting training for config s4_n33:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:36:05,711 - INFO - Running command: ./train_gpt2cu -l 1.1357247722581436e-05 -o hyperband_runs_20241120_172038/run_s4_n33 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:36:33,921 - INFO - Training completed for config s4_n33:
  Training time: 0:00:28
  Final validation loss: 10.905363
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.46e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n33/checkpoint.bin
2024-11-21 00:36:33,922 - INFO - 
Configuration s4_n33 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.1357247722581436e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n33",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.905363
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.46e-07
2024-11-21 00:36:33,922 - INFO - 
Starting training for config s4_n34:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:36:33,922 - INFO - Running command: ./train_gpt2cu -l 0.0005986281949357964 -o hyperband_runs_20241120_172038/run_s4_n34 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:37:02,114 - INFO - Training completed for config s4_n34:
  Training time: 0:00:28
  Final validation loss: 10.633099
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.70e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n34/checkpoint.bin
2024-11-21 00:37:02,115 - INFO - 
Configuration s4_n34 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005986281949357964",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n34",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.633099
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.70e-06
2024-11-21 00:37:02,115 - INFO - 
Starting training for config s4_n35:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:37:02,115 - INFO - Running command: ./train_gpt2cu -l 2.452019200309217e-05 -o hyperband_runs_20241120_172038/run_s4_n35 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:37:30,307 - INFO - Training completed for config s4_n35:
  Training time: 0:00:28
  Final validation loss: 10.898141
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.15e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n35/checkpoint.bin
2024-11-21 00:37:30,307 - INFO - 
Configuration s4_n35 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "2.452019200309217e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n35",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.898141
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.15e-07
2024-11-21 00:37:30,307 - INFO - 
Starting training for config s4_n36:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:37:30,307 - INFO - Running command: ./train_gpt2cu -l 5.635883426455137e-05 -o hyperband_runs_20241120_172038/run_s4_n36 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:37:58,502 - INFO - Training completed for config s4_n36:
  Training time: 0:00:28
  Final validation loss: 10.880812
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.25e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n36/checkpoint.bin
2024-11-21 00:37:58,503 - INFO - 
Configuration s4_n36 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "5.635883426455137e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n36",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.880812
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.25e-07
2024-11-21 00:37:58,503 - INFO - 
Starting training for config s4_n37:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:37:58,503 - INFO - Running command: ./train_gpt2cu -l 1.3515349125871335e-05 -o hyperband_runs_20241120_172038/run_s4_n37 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:38:26,680 - INFO - Training completed for config s4_n37:
  Training time: 0:00:28
  Final validation loss: 10.904191
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.74e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n37/checkpoint.bin
2024-11-21 00:38:26,681 - INFO - 
Configuration s4_n37 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.3515349125871335e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n37",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.904191
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.74e-07
2024-11-21 00:38:26,681 - INFO - 
Starting training for config s4_n38:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:38:26,681 - INFO - Running command: ./train_gpt2cu -l 8.786882558383645e-05 -o hyperband_runs_20241120_172038/run_s4_n38 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:38:54,863 - INFO - Training completed for config s4_n38:
  Training time: 0:00:28
  Final validation loss: 10.863658
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.13e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n38/checkpoint.bin
2024-11-21 00:38:54,863 - INFO - 
Configuration s4_n38 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "8.786882558383645e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n38",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.863658
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.13e-06
2024-11-21 00:38:54,863 - INFO - 
Starting training for config s4_n39:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:38:54,864 - INFO - Running command: ./train_gpt2cu -l 0.0008099707125751382 -o hyperband_runs_20241120_172038/run_s4_n39 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:39:23,048 - INFO - Training completed for config s4_n39:
  Training time: 0:00:28
  Final validation loss: 10.568651
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.04e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n39/checkpoint.bin
2024-11-21 00:39:23,048 - INFO - 
Configuration s4_n39 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008099707125751382",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n39",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.568651
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.04e-05
2024-11-21 00:39:23,048 - INFO - 
Starting training for config s4_n40:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:39:23,048 - INFO - Running command: ./train_gpt2cu -l 2.140289907890666e-05 -o hyperband_runs_20241120_172038/run_s4_n40 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:39:51,242 - INFO - Training completed for config s4_n40:
  Training time: 0:00:28
  Final validation loss: 10.899845
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.75e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n40/checkpoint.bin
2024-11-21 00:39:51,243 - INFO - 
Configuration s4_n40 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "2.140289907890666e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n40",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.899845
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.75e-07
2024-11-21 00:39:51,243 - INFO - 
Starting training for config s4_n41:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:39:51,243 - INFO - Running command: ./train_gpt2cu -l 1.0711267819212877e-05 -o hyperband_runs_20241120_172038/run_s4_n41 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:40:19,431 - INFO - Training completed for config s4_n41:
  Training time: 0:00:28
  Final validation loss: 10.905698
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.38e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n41/checkpoint.bin
2024-11-21 00:40:19,431 - INFO - 
Configuration s4_n41 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.0711267819212877e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n41",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.905698
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.38e-07
2024-11-21 00:40:19,431 - INFO - 
Starting training for config s4_n42:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:40:19,432 - INFO - Running command: ./train_gpt2cu -l 0.00021224069955023812 -o hyperband_runs_20241120_172038/run_s4_n42 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:40:47,626 - INFO - Training completed for config s4_n42:
  Training time: 0:00:28
  Final validation loss: 10.797922
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.73e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n42/checkpoint.bin
2024-11-21 00:40:47,626 - INFO - 
Configuration s4_n42 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00021224069955023812",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n42",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.797922
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.73e-06
2024-11-21 00:40:47,626 - INFO - 
Starting training for config s4_n43:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:40:47,627 - INFO - Running command: ./train_gpt2cu -l 7.428365469749075e-05 -o hyperband_runs_20241120_172038/run_s4_n43 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:41:15,809 - INFO - Training completed for config s4_n43:
  Training time: 0:00:28
  Final validation loss: 10.871013
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.55e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n43/checkpoint.bin
2024-11-21 00:41:15,810 - INFO - 
Configuration s4_n43 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "7.428365469749075e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n43",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.871013
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.55e-07
2024-11-21 00:41:15,810 - INFO - 
Starting training for config s4_n44:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:41:15,810 - INFO - Running command: ./train_gpt2cu -l 0.00019311486144132716 -o hyperband_runs_20241120_172038/run_s4_n44 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:41:44,024 - INFO - Training completed for config s4_n44:
  Training time: 0:00:28
  Final validation loss: 10.807743
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.48e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n44/checkpoint.bin
2024-11-21 00:41:44,024 - INFO - 
Configuration s4_n44 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00019311486144132716",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n44",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.807743
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.48e-06
2024-11-21 00:41:44,024 - INFO - 
Starting training for config s4_n45:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:41:44,024 - INFO - Running command: ./train_gpt2cu -l 0.00024190067140793267 -o hyperband_runs_20241120_172038/run_s4_n45 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:42:12,226 - INFO - Training completed for config s4_n45:
  Training time: 0:00:28
  Final validation loss: 10.782980
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.11e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n45/checkpoint.bin
2024-11-21 00:42:12,226 - INFO - 
Configuration s4_n45 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00024190067140793267",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n45",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.782980
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.11e-06
2024-11-21 00:42:12,227 - INFO - 
Starting training for config s4_n46:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:42:12,227 - INFO - Running command: ./train_gpt2cu -l 1.5410424441099302e-05 -o hyperband_runs_20241120_172038/run_s4_n46 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:42:40,417 - INFO - Training completed for config s4_n46:
  Training time: 0:00:28
  Final validation loss: 10.903142
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.98e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n46/checkpoint.bin
2024-11-21 00:42:40,417 - INFO - 
Configuration s4_n46 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.5410424441099302e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n46",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.903142
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.98e-07
2024-11-21 00:42:40,417 - INFO - 
Starting training for config s4_n47:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:42:40,417 - INFO - Running command: ./train_gpt2cu -l 0.00047913609504335596 -o hyperband_runs_20241120_172038/run_s4_n47 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:43:08,619 - INFO - Training completed for config s4_n47:
  Training time: 0:00:28
  Final validation loss: 10.676967
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 6.16e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n47/checkpoint.bin
2024-11-21 00:43:08,619 - INFO - 
Configuration s4_n47 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00047913609504335596",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n47",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.676967
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.16e-06
2024-11-21 00:43:08,619 - INFO - 
Starting training for config s4_n48:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:43:08,620 - INFO - Running command: ./train_gpt2cu -l 2.7910045779624783e-05 -o hyperband_runs_20241120_172038/run_s4_n48 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:43:36,814 - INFO - Training completed for config s4_n48:
  Training time: 0:00:28
  Final validation loss: 10.896307
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.59e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n48/checkpoint.bin
2024-11-21 00:43:36,814 - INFO - 
Configuration s4_n48 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "2.7910045779624783e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n48",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.896307
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.59e-07
2024-11-21 00:43:36,814 - INFO - 
Starting training for config s4_n49:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:43:36,815 - INFO - Running command: ./train_gpt2cu -l 0.00017430889178604646 -o hyperband_runs_20241120_172038/run_s4_n49 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:44:05,003 - INFO - Training completed for config s4_n49:
  Training time: 0:00:28
  Final validation loss: 10.817464
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.24e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n49/checkpoint.bin
2024-11-21 00:44:05,003 - INFO - 
Configuration s4_n49 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00017430889178604646",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n49",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.817464
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.24e-06
2024-11-21 00:44:05,003 - INFO - 
Starting training for config s4_n50:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:44:05,003 - INFO - Running command: ./train_gpt2cu -l 0.00019427488338987257 -o hyperband_runs_20241120_172038/run_s4_n50 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:44:33,187 - INFO - Training completed for config s4_n50:
  Training time: 0:00:28
  Final validation loss: 10.807131
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.50e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n50/checkpoint.bin
2024-11-21 00:44:33,188 - INFO - 
Configuration s4_n50 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00019427488338987257",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n50",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.807131
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.50e-06
2024-11-21 00:44:33,188 - INFO - 
Starting training for config s4_n51:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:44:33,188 - INFO - Running command: ./train_gpt2cu -l 4.100739271778529e-05 -o hyperband_runs_20241120_172038/run_s4_n51 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:45:01,382 - INFO - Training completed for config s4_n51:
  Training time: 0:00:28
  Final validation loss: 10.889146
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.27e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n51/checkpoint.bin
2024-11-21 00:45:01,382 - INFO - 
Configuration s4_n51 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "4.100739271778529e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n51",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.889146
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.27e-07
2024-11-21 00:45:01,382 - INFO - 
Starting training for config s4_n52:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:45:01,382 - INFO - Running command: ./train_gpt2cu -l 0.00021151461013036834 -o hyperband_runs_20241120_172038/run_s4_n52 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:45:29,570 - INFO - Training completed for config s4_n52:
  Training time: 0:00:28
  Final validation loss: 10.798296
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.72e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n52/checkpoint.bin
2024-11-21 00:45:29,570 - INFO - 
Configuration s4_n52 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00021151461013036834",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n52",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.798296
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.72e-06
2024-11-21 00:45:29,570 - INFO - 
Starting training for config s4_n53:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:45:29,570 - INFO - Running command: ./train_gpt2cu -l 0.0007170288176891574 -o hyperband_runs_20241120_172038/run_s4_n53 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:45:57,758 - INFO - Training completed for config s4_n53:
  Training time: 0:00:28
  Final validation loss: 10.595152
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.22e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n53/checkpoint.bin
2024-11-21 00:45:57,758 - INFO - 
Configuration s4_n53 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007170288176891574",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n53",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.595152
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.22e-06
2024-11-21 00:45:57,759 - INFO - 
Starting training for config s4_n54:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:45:57,759 - INFO - Running command: ./train_gpt2cu -l 0.000160885489349386 -o hyperband_runs_20241120_172038/run_s4_n54 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:46:25,946 - INFO - Training completed for config s4_n54:
  Training time: 0:00:28
  Final validation loss: 10.824616
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.07e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n54/checkpoint.bin
2024-11-21 00:46:25,946 - INFO - 
Configuration s4_n54 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.000160885489349386",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n54",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.824616
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.07e-06
2024-11-21 00:46:25,946 - INFO - 
Starting training for config s4_n55:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:46:25,947 - INFO - Running command: ./train_gpt2cu -l 2.800939622375687e-05 -o hyperband_runs_20241120_172038/run_s4_n55 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:46:54,132 - INFO - Training completed for config s4_n55:
  Training time: 0:00:28
  Final validation loss: 10.896240
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.60e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n55/checkpoint.bin
2024-11-21 00:46:54,133 - INFO - 
Configuration s4_n55 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "2.800939622375687e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n55",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.896240
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.60e-07
2024-11-21 00:46:54,133 - INFO - 
Starting training for config s4_n56:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:46:54,133 - INFO - Running command: ./train_gpt2cu -l 0.0008679772739034899 -o hyperband_runs_20241120_172038/run_s4_n56 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:47:22,315 - INFO - Training completed for config s4_n56:
  Training time: 0:00:28
  Final validation loss: 10.553442
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.12e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n56/checkpoint.bin
2024-11-21 00:47:22,316 - INFO - 
Configuration s4_n56 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008679772739034899",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n56",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.553442
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.12e-05
2024-11-21 00:47:22,316 - INFO - 
Starting training for config s4_n57:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:47:22,316 - INFO - Running command: ./train_gpt2cu -l 1.3067016167541204e-05 -o hyperband_runs_20241120_172038/run_s4_n57 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:47:50,520 - INFO - Training completed for config s4_n57:
  Training time: 0:00:28
  Final validation loss: 10.904430
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.68e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n57/checkpoint.bin
2024-11-21 00:47:50,520 - INFO - 
Configuration s4_n57 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.3067016167541204e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n57",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.904430
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.68e-07
2024-11-21 00:47:50,520 - INFO - 
Starting training for config s4_n58:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:47:50,521 - INFO - Running command: ./train_gpt2cu -l 5.035530755169482e-05 -o hyperband_runs_20241120_172038/run_s4_n58 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:48:18,714 - INFO - Training completed for config s4_n58:
  Training time: 0:00:28
  Final validation loss: 10.884073
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 6.47e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n58/checkpoint.bin
2024-11-21 00:48:18,714 - INFO - 
Configuration s4_n58 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "5.035530755169482e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n58",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.884073
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.47e-07
2024-11-21 00:48:18,714 - INFO - 
Starting training for config s4_n59:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:48:18,714 - INFO - Running command: ./train_gpt2cu -l 0.00023567113330513875 -o hyperband_runs_20241120_172038/run_s4_n59 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:48:46,896 - INFO - Training completed for config s4_n59:
  Training time: 0:00:28
  Final validation loss: 10.786089
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.03e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n59/checkpoint.bin
2024-11-21 00:48:46,896 - INFO - 
Configuration s4_n59 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00023567113330513875",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n59",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.786089
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.03e-06
2024-11-21 00:48:46,896 - INFO - 
Starting training for config s4_n60:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:48:46,896 - INFO - Running command: ./train_gpt2cu -l 1.1376452729205147e-05 -o hyperband_runs_20241120_172038/run_s4_n60 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:49:15,096 - INFO - Training completed for config s4_n60:
  Training time: 0:00:28
  Final validation loss: 10.905336
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.46e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n60/checkpoint.bin
2024-11-21 00:49:15,096 - INFO - 
Configuration s4_n60 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.1376452729205147e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n60",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.905336
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.46e-07
2024-11-21 00:49:15,097 - INFO - 
Starting training for config s4_n61:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:49:15,097 - INFO - Running command: ./train_gpt2cu -l 4.6219319834028774e-05 -o hyperband_runs_20241120_172038/run_s4_n61 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:49:43,322 - INFO - Training completed for config s4_n61:
  Training time: 0:00:28
  Final validation loss: 10.886338
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.94e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n61/checkpoint.bin
2024-11-21 00:49:43,322 - INFO - 
Configuration s4_n61 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "4.6219319834028774e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n61",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.886338
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.94e-07
2024-11-21 00:49:43,322 - INFO - 
Starting training for config s4_n62:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:49:43,322 - INFO - Running command: ./train_gpt2cu -l 0.00021274458241307516 -o hyperband_runs_20241120_172038/run_s4_n62 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:50:11,501 - INFO - Training completed for config s4_n62:
  Training time: 0:00:28
  Final validation loss: 10.797668
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.74e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n62/checkpoint.bin
2024-11-21 00:50:11,502 - INFO - 
Configuration s4_n62 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00021274458241307516",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n62",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.797668
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.74e-06
2024-11-21 00:50:11,502 - INFO - 
Starting training for config s4_n63:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:50:11,502 - INFO - Running command: ./train_gpt2cu -l 0.00010882991905459946 -o hyperband_runs_20241120_172038/run_s4_n63 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:50:39,710 - INFO - Training completed for config s4_n63:
  Training time: 0:00:28
  Final validation loss: 10.852324
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.40e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n63/checkpoint.bin
2024-11-21 00:50:39,710 - INFO - 
Configuration s4_n63 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010882991905459946",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n63",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.852324
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.40e-06
2024-11-21 00:50:39,710 - INFO - 
Starting training for config s4_n64:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:50:39,710 - INFO - Running command: ./train_gpt2cu -l 6.344998815248107e-05 -o hyperband_runs_20241120_172038/run_s4_n64 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:51:07,901 - INFO - Training completed for config s4_n64:
  Training time: 0:00:28
  Final validation loss: 10.876936
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.16e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n64/checkpoint.bin
2024-11-21 00:51:07,901 - INFO - 
Configuration s4_n64 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "6.344998815248107e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n64",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.876936
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.16e-07
2024-11-21 00:51:07,901 - INFO - 
Starting training for config s4_n65:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:51:07,902 - INFO - Running command: ./train_gpt2cu -l 0.0005082707112054526 -o hyperband_runs_20241120_172038/run_s4_n65 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:51:36,116 - INFO - Training completed for config s4_n65:
  Training time: 0:00:28
  Final validation loss: 10.665708
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 6.53e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n65/checkpoint.bin
2024-11-21 00:51:36,116 - INFO - 
Configuration s4_n65 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005082707112054526",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n65",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.665708
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.53e-06
2024-11-21 00:51:36,116 - INFO - 
Starting training for config s4_n66:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:51:36,116 - INFO - Running command: ./train_gpt2cu -l 0.0008647672609053191 -o hyperband_runs_20241120_172038/run_s4_n66 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:52:04,312 - INFO - Training completed for config s4_n66:
  Training time: 0:00:28
  Final validation loss: 10.554233
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.11e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n66/checkpoint.bin
2024-11-21 00:52:04,312 - INFO - 
Configuration s4_n66 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008647672609053191",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n66",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.554233
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.11e-05
2024-11-21 00:52:04,312 - INFO - 
Starting training for config s4_n67:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:52:04,312 - INFO - Running command: ./train_gpt2cu -l 1.5723778152262073e-05 -o hyperband_runs_20241120_172038/run_s4_n67 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:52:32,521 - INFO - Training completed for config s4_n67:
  Training time: 0:00:28
  Final validation loss: 10.902966
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.02e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n67/checkpoint.bin
2024-11-21 00:52:32,522 - INFO - 
Configuration s4_n67 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.5723778152262073e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n67",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.902966
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.02e-07
2024-11-21 00:52:32,522 - INFO - 
Starting training for config s4_n68:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:52:32,522 - INFO - Running command: ./train_gpt2cu -l 0.0003446425808455775 -o hyperband_runs_20241120_172038/run_s4_n68 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:53:00,739 - INFO - Training completed for config s4_n68:
  Training time: 0:00:28
  Final validation loss: 10.734041
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.43e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n68/checkpoint.bin
2024-11-21 00:53:00,739 - INFO - 
Configuration s4_n68 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003446425808455775",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n68",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.734041
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.43e-06
2024-11-21 00:53:00,739 - INFO - 
Starting training for config s4_n69:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:53:00,740 - INFO - Running command: ./train_gpt2cu -l 0.0005453192687893656 -o hyperband_runs_20241120_172038/run_s4_n69 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:53:28,934 - INFO - Training completed for config s4_n69:
  Training time: 0:00:28
  Final validation loss: 10.651960
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.01e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n69/checkpoint.bin
2024-11-21 00:53:28,935 - INFO - 
Configuration s4_n69 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005453192687893656",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n69",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.651960
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.01e-06
2024-11-21 00:53:28,935 - INFO - 
Starting training for config s4_n70:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:53:28,935 - INFO - Running command: ./train_gpt2cu -l 0.00010665538012376569 -o hyperband_runs_20241120_172038/run_s4_n70 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:53:57,126 - INFO - Training completed for config s4_n70:
  Training time: 0:00:28
  Final validation loss: 10.853487
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.37e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n70/checkpoint.bin
2024-11-21 00:53:57,127 - INFO - 
Configuration s4_n70 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010665538012376569",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n70",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.853487
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.37e-06
2024-11-21 00:53:57,127 - INFO - 
Starting training for config s4_n71:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:53:57,127 - INFO - Running command: ./train_gpt2cu -l 1.0479906068351677e-05 -o hyperband_runs_20241120_172038/run_s4_n71 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:54:25,348 - INFO - Training completed for config s4_n71:
  Training time: 0:00:28
  Final validation loss: 10.905833
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.35e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n71/checkpoint.bin
2024-11-21 00:54:25,349 - INFO - 
Configuration s4_n71 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.0479906068351677e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n71",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.905833
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.35e-07
2024-11-21 00:54:25,349 - INFO - 
Starting training for config s4_n72:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:54:25,349 - INFO - Running command: ./train_gpt2cu -l 0.00014103817291016865 -o hyperband_runs_20241120_172038/run_s4_n72 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:54:53,566 - INFO - Training completed for config s4_n72:
  Training time: 0:00:28
  Final validation loss: 10.835141
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.81e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n72/checkpoint.bin
2024-11-21 00:54:53,566 - INFO - 
Configuration s4_n72 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014103817291016865",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n72",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.835141
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.81e-06
2024-11-21 00:54:53,566 - INFO - 
Starting training for config s4_n73:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:54:53,566 - INFO - Running command: ./train_gpt2cu -l 0.0006262451478113708 -o hyperband_runs_20241120_172038/run_s4_n73 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:55:21,782 - INFO - Training completed for config s4_n73:
  Training time: 0:00:28
  Final validation loss: 10.623805
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.05e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n73/checkpoint.bin
2024-11-21 00:55:21,782 - INFO - 
Configuration s4_n73 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006262451478113708",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n73",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.623805
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.05e-06
2024-11-21 00:55:21,782 - INFO - 
Starting training for config s4_n74:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:55:21,783 - INFO - Running command: ./train_gpt2cu -l 1.3019015661905446e-05 -o hyperband_runs_20241120_172038/run_s4_n74 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:55:49,988 - INFO - Training completed for config s4_n74:
  Training time: 0:00:28
  Final validation loss: 10.904451
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.67e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n74/checkpoint.bin
2024-11-21 00:55:49,988 - INFO - 
Configuration s4_n74 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.3019015661905446e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n74",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.904451
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.67e-07
2024-11-21 00:55:49,989 - INFO - 
Starting training for config s4_n75:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:55:49,989 - INFO - Running command: ./train_gpt2cu -l 5.375056668780572e-05 -o hyperband_runs_20241120_172038/run_s4_n75 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:56:18,194 - INFO - Training completed for config s4_n75:
  Training time: 0:00:28
  Final validation loss: 10.882234
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 6.91e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n75/checkpoint.bin
2024-11-21 00:56:18,195 - INFO - 
Configuration s4_n75 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "5.375056668780572e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n75",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.882234
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.91e-07
2024-11-21 00:56:18,195 - INFO - 
Starting training for config s4_n76:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:56:18,195 - INFO - Running command: ./train_gpt2cu -l 3.413783580655611e-05 -o hyperband_runs_20241120_172038/run_s4_n76 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:56:46,384 - INFO - Training completed for config s4_n76:
  Training time: 0:00:28
  Final validation loss: 10.892906
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.39e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n76/checkpoint.bin
2024-11-21 00:56:46,384 - INFO - 
Configuration s4_n76 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "3.413783580655611e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n76",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.892906
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.39e-07
2024-11-21 00:56:46,384 - INFO - 
Starting training for config s4_n77:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:56:46,384 - INFO - Running command: ./train_gpt2cu -l 7.820546658883568e-05 -o hyperband_runs_20241120_172038/run_s4_n77 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:57:14,572 - INFO - Training completed for config s4_n77:
  Training time: 0:00:28
  Final validation loss: 10.868891
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.01e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n77/checkpoint.bin
2024-11-21 00:57:14,572 - INFO - 
Configuration s4_n77 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "7.820546658883568e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n77",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.868891
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.01e-06
2024-11-21 00:57:14,572 - INFO - 
Starting training for config s4_n78:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:57:14,572 - INFO - Running command: ./train_gpt2cu -l 0.00014170505923032748 -o hyperband_runs_20241120_172038/run_s4_n78 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:57:42,805 - INFO - Training completed for config s4_n78:
  Training time: 0:00:28
  Final validation loss: 10.834788
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.82e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n78/checkpoint.bin
2024-11-21 00:57:42,805 - INFO - 
Configuration s4_n78 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014170505923032748",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n78",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.834788
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.82e-06
2024-11-21 00:57:42,805 - INFO - 
Starting training for config s4_n79:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:57:42,805 - INFO - Running command: ./train_gpt2cu -l 0.0006403459176372873 -o hyperband_runs_20241120_172038/run_s4_n79 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:58:11,013 - INFO - Training completed for config s4_n79:
  Training time: 0:00:28
  Final validation loss: 10.619154
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.23e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n79/checkpoint.bin
2024-11-21 00:58:11,013 - INFO - 
Configuration s4_n79 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006403459176372873",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n79",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.619154
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.23e-06
2024-11-21 00:58:11,014 - INFO - 
Starting training for config s4_n80:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:58:11,014 - INFO - Running command: ./train_gpt2cu -l 0.00019134422338662753 -o hyperband_runs_20241120_172038/run_s4_n80 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:58:39,204 - INFO - Training completed for config s4_n80:
  Training time: 0:00:28
  Final validation loss: 10.808633
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.46e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n80/checkpoint.bin
2024-11-21 00:58:39,204 - INFO - 
Configuration s4_n80 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00019134422338662753",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n80",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.808633
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.46e-06
2024-11-21 00:58:39,204 - INFO - 
Starting training for config s4_n81:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:58:39,204 - INFO - Running command: ./train_gpt2cu -l 9.279974818771123e-05 -o hyperband_runs_20241120_172038/run_s4_n81 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:59:07,392 - INFO - Training completed for config s4_n81:
  Training time: 0:00:28
  Final validation loss: 10.860961
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.19e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n81/checkpoint.bin
2024-11-21 00:59:07,392 - INFO - 
Configuration s4_n81 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "9.279974818771123e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n81",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.860961
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.19e-06
2024-11-21 00:59:07,393 - INFO - 
Starting training for config s4_n82:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:59:07,393 - INFO - Running command: ./train_gpt2cu -l 0.00013299285310778146 -o hyperband_runs_20241120_172038/run_s4_n82 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 00:59:35,596 - INFO - Training completed for config s4_n82:
  Training time: 0:00:28
  Final validation loss: 10.839432
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.71e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n82/checkpoint.bin
2024-11-21 00:59:35,596 - INFO - 
Configuration s4_n82 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013299285310778146",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n82",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.839432
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.71e-06
2024-11-21 00:59:35,596 - INFO - 
Starting training for config s4_n83:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 00:59:35,596 - INFO - Running command: ./train_gpt2cu -l 0.0008162827430508194 -o hyperband_runs_20241120_172038/run_s4_n83 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:00:03,772 - INFO - Training completed for config s4_n83:
  Training time: 0:00:28
  Final validation loss: 10.566932
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.05e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n83/checkpoint.bin
2024-11-21 01:00:03,772 - INFO - 
Configuration s4_n83 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0008162827430508194",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n83",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.566932
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.05e-05
2024-11-21 01:00:03,773 - INFO - 
Starting training for config s4_n84:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:00:03,773 - INFO - Running command: ./train_gpt2cu -l 4.211333665086997e-05 -o hyperband_runs_20241120_172038/run_s4_n84 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:00:31,970 - INFO - Training completed for config s4_n84:
  Training time: 0:00:28
  Final validation loss: 10.888547
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.41e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n84/checkpoint.bin
2024-11-21 01:00:31,970 - INFO - 
Configuration s4_n84 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "4.211333665086997e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n84",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.888547
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.41e-07
2024-11-21 01:00:31,970 - INFO - 
Starting training for config s4_n85:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:00:31,970 - INFO - Running command: ./train_gpt2cu -l 0.00023017336454977575 -o hyperband_runs_20241120_172038/run_s4_n85 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:01:00,165 - INFO - Training completed for config s4_n85:
  Training time: 0:00:28
  Final validation loss: 10.788824
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.96e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n85/checkpoint.bin
2024-11-21 01:01:00,165 - INFO - 
Configuration s4_n85 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00023017336454977575",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n85",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.788824
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.96e-06
2024-11-21 01:01:00,165 - INFO - 
Starting training for config s4_n86:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:01:00,166 - INFO - Running command: ./train_gpt2cu -l 1.3881239751945435e-05 -o hyperband_runs_20241120_172038/run_s4_n86 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:01:28,371 - INFO - Training completed for config s4_n86:
  Training time: 0:00:28
  Final validation loss: 10.903982
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.78e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n86/checkpoint.bin
2024-11-21 01:01:28,371 - INFO - 
Configuration s4_n86 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.3881239751945435e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n86",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.903982
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.78e-07
2024-11-21 01:01:28,371 - INFO - 
Starting training for config s4_n87:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:01:28,371 - INFO - Running command: ./train_gpt2cu -l 1.32167566000617e-05 -o hyperband_runs_20241120_172038/run_s4_n87 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:01:56,567 - INFO - Training completed for config s4_n87:
  Training time: 0:00:28
  Final validation loss: 10.904356
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.70e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n87/checkpoint.bin
2024-11-21 01:01:56,568 - INFO - 
Configuration s4_n87 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.32167566000617e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n87",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.904356
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.70e-07
2024-11-21 01:01:56,568 - INFO - 
Starting training for config s4_n88:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:01:56,568 - INFO - Running command: ./train_gpt2cu -l 3.310126957278331e-05 -o hyperband_runs_20241120_172038/run_s4_n88 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:02:24,758 - INFO - Training completed for config s4_n88:
  Training time: 0:00:28
  Final validation loss: 10.893472
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.26e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n88/checkpoint.bin
2024-11-21 01:02:24,758 - INFO - 
Configuration s4_n88 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "3.310126957278331e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n88",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.893472
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.26e-07
2024-11-21 01:02:24,758 - INFO - 
Starting training for config s4_n89:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:02:24,759 - INFO - Running command: ./train_gpt2cu -l 0.00013543211402345133 -o hyperband_runs_20241120_172038/run_s4_n89 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:02:52,940 - INFO - Training completed for config s4_n89:
  Training time: 0:00:28
  Final validation loss: 10.838129
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.74e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n89/checkpoint.bin
2024-11-21 01:02:52,940 - INFO - 
Configuration s4_n89 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013543211402345133",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n89",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.838129
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.74e-06
2024-11-21 01:02:52,940 - INFO - 
Starting training for config s4_n90:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:02:52,940 - INFO - Running command: ./train_gpt2cu -l 1.82444064586937e-05 -o hyperband_runs_20241120_172038/run_s4_n90 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:03:21,138 - INFO - Training completed for config s4_n90:
  Training time: 0:00:28
  Final validation loss: 10.901579
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.35e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n90/checkpoint.bin
2024-11-21 01:03:21,138 - INFO - 
Configuration s4_n90 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.82444064586937e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n90",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.901579
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.35e-07
2024-11-21 01:03:21,138 - INFO - 
Starting training for config s4_n91:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:03:21,138 - INFO - Running command: ./train_gpt2cu -l 0.00019162876256103095 -o hyperband_runs_20241120_172038/run_s4_n91 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:03:49,326 - INFO - Training completed for config s4_n91:
  Training time: 0:00:28
  Final validation loss: 10.808502
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.46e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n91/checkpoint.bin
2024-11-21 01:03:49,326 - INFO - 
Configuration s4_n91 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00019162876256103095",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n91",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.808502
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.46e-06
2024-11-21 01:03:49,326 - INFO - 
Starting training for config s4_n92:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:03:49,327 - INFO - Running command: ./train_gpt2cu -l 0.00030916268094108144 -o hyperband_runs_20241120_172038/run_s4_n92 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:04:17,503 - INFO - Training completed for config s4_n92:
  Training time: 0:00:28
  Final validation loss: 10.750443
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.97e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n92/checkpoint.bin
2024-11-21 01:04:17,504 - INFO - 
Configuration s4_n92 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00030916268094108144",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n92",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.750443
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.97e-06
2024-11-21 01:04:17,504 - INFO - 
Starting training for config s4_n93:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:04:17,504 - INFO - Running command: ./train_gpt2cu -l 0.00037468857511800414 -o hyperband_runs_20241120_172038/run_s4_n93 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:04:45,694 - INFO - Training completed for config s4_n93:
  Training time: 0:00:28
  Final validation loss: 10.720611
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.82e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n93/checkpoint.bin
2024-11-21 01:04:45,694 - INFO - 
Configuration s4_n93 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00037468857511800414",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n93",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.720611
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.82e-06
2024-11-21 01:04:45,694 - INFO - 
Starting training for config s4_n94:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:04:45,694 - INFO - Running command: ./train_gpt2cu -l 0.00019763596054150648 -o hyperband_runs_20241120_172038/run_s4_n94 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:05:13,902 - INFO - Training completed for config s4_n94:
  Training time: 0:00:28
  Final validation loss: 10.805392
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.54e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n94/checkpoint.bin
2024-11-21 01:05:13,902 - INFO - 
Configuration s4_n94 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00019763596054150648",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n94",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.805392
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.54e-06
2024-11-21 01:05:13,902 - INFO - 
Starting training for config s4_n95:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:05:13,902 - INFO - Running command: ./train_gpt2cu -l 1.99634516815087e-05 -o hyperband_runs_20241120_172038/run_s4_n95 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:05:42,134 - INFO - Training completed for config s4_n95:
  Training time: 0:00:28
  Final validation loss: 10.900642
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.57e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n95/checkpoint.bin
2024-11-21 01:05:42,134 - INFO - 
Configuration s4_n95 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.99634516815087e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n95",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.900642
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.57e-07
2024-11-21 01:05:42,134 - INFO - 
Starting training for config s4_n96:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:05:42,135 - INFO - Running command: ./train_gpt2cu -l 0.0006308238102118147 -o hyperband_runs_20241120_172038/run_s4_n96 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:06:10,299 - INFO - Training completed for config s4_n96:
  Training time: 0:00:28
  Final validation loss: 10.622260
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 8.11e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n96/checkpoint.bin
2024-11-21 01:06:10,299 - INFO - 
Configuration s4_n96 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006308238102118147",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n96",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.622260
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.11e-06
2024-11-21 01:06:10,299 - INFO - 
Starting training for config s4_n97:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:06:10,299 - INFO - Running command: ./train_gpt2cu -l 0.000716234585655273 -o hyperband_runs_20241120_172038/run_s4_n97 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:06:38,499 - INFO - Training completed for config s4_n97:
  Training time: 0:00:28
  Final validation loss: 10.595403
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.21e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n97/checkpoint.bin
2024-11-21 01:06:38,499 - INFO - 
Configuration s4_n97 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.000716234585655273",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n97",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.595403
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.21e-06
2024-11-21 01:06:38,499 - INFO - 
Starting training for config s4_n98:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:06:38,499 - INFO - Running command: ./train_gpt2cu -l 1.6463071913133514e-05 -o hyperband_runs_20241120_172038/run_s4_n98 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:07:06,701 - INFO - Training completed for config s4_n98:
  Training time: 0:00:28
  Final validation loss: 10.902563
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 2.12e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n98/checkpoint.bin
2024-11-21 01:07:06,701 - INFO - 
Configuration s4_n98 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "1.6463071913133514e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n98",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.902563
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.12e-07
2024-11-21 01:07:06,701 - INFO - 
Starting training for config s4_n99:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:07:06,702 - INFO - Running command: ./train_gpt2cu -l 0.0002644411243575372 -o hyperband_runs_20241120_172038/run_s4_n99 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:07:34,887 - INFO - Training completed for config s4_n99:
  Training time: 0:00:28
  Final validation loss: 10.771902
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.40e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n99/checkpoint.bin
2024-11-21 01:07:34,887 - INFO - 
Configuration s4_n99 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002644411243575372",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n99",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.771902
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.40e-06
2024-11-21 01:07:34,887 - INFO - 
Starting training for config s4_n100:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:07:34,888 - INFO - Running command: ./train_gpt2cu -l 4.604350784943692e-05 -o hyperband_runs_20241120_172038/run_s4_n100 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:08:03,082 - INFO - Training completed for config s4_n100:
  Training time: 0:00:28
  Final validation loss: 10.886430
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 5.92e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n100/checkpoint.bin
2024-11-21 01:08:03,082 - INFO - 
Configuration s4_n100 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "4.604350784943692e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n100",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.886430
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.92e-07
2024-11-21 01:08:03,082 - INFO - 
Starting training for config s4_n101:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:08:03,082 - INFO - Running command: ./train_gpt2cu -l 0.00026913125362437496 -o hyperband_runs_20241120_172038/run_s4_n101 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:08:31,256 - INFO - Training completed for config s4_n101:
  Training time: 0:00:28
  Final validation loss: 10.769617
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.46e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n101/checkpoint.bin
2024-11-21 01:08:31,256 - INFO - 
Configuration s4_n101 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00026913125362437496",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n101",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.769617
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.46e-06
2024-11-21 01:08:31,256 - INFO - 
Starting training for config s4_n102:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:08:31,256 - INFO - Running command: ./train_gpt2cu -l 0.0009463534291604628 -o hyperband_runs_20241120_172038/run_s4_n102 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:08:59,448 - INFO - Training completed for config s4_n102:
  Training time: 0:00:28
  Final validation loss: 10.534125
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.22e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n102/checkpoint.bin
2024-11-21 01:08:59,448 - INFO - 
Configuration s4_n102 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009463534291604628",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n102",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.534125
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.22e-05
2024-11-21 01:08:59,448 - INFO - 
Starting training for config s4_n103:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:08:59,448 - INFO - Running command: ./train_gpt2cu -l 0.00032169055369867 -o hyperband_runs_20241120_172038/run_s4_n103 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:09:27,622 - INFO - Training completed for config s4_n103:
  Training time: 0:00:28
  Final validation loss: 10.744616
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.14e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n103/checkpoint.bin
2024-11-21 01:09:27,622 - INFO - 
Configuration s4_n103 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00032169055369867",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n103",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.744616
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.14e-06
2024-11-21 01:09:27,622 - INFO - 
Starting training for config s4_n104:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:09:27,622 - INFO - Running command: ./train_gpt2cu -l 5.400302267137765e-05 -o hyperband_runs_20241120_172038/run_s4_n104 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:09:55,793 - INFO - Training completed for config s4_n104:
  Training time: 0:00:28
  Final validation loss: 10.882092
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 6.94e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n104/checkpoint.bin
2024-11-21 01:09:55,793 - INFO - 
Configuration s4_n104 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "5.400302267137765e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n104",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.882092
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.94e-07
2024-11-21 01:09:55,793 - INFO - 
Starting training for config s4_n105:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:09:55,794 - INFO - Running command: ./train_gpt2cu -l 7.767767764929465e-05 -o hyperband_runs_20241120_172038/run_s4_n105 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:10:23,980 - INFO - Training completed for config s4_n105:
  Training time: 0:00:28
  Final validation loss: 10.869166
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 9.99e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n105/checkpoint.bin
2024-11-21 01:10:23,980 - INFO - 
Configuration s4_n105 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "7.767767764929465e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n105",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.869166
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.99e-07
2024-11-21 01:10:23,980 - INFO - 
Starting training for config s4_n106:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:10:23,981 - INFO - Running command: ./train_gpt2cu -l 3.266213592701384e-05 -o hyperband_runs_20241120_172038/run_s4_n106 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:10:52,186 - INFO - Training completed for config s4_n106:
  Training time: 0:00:28
  Final validation loss: 10.893713
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.20e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n106/checkpoint.bin
2024-11-21 01:10:52,187 - INFO - 
Configuration s4_n106 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "3.266213592701384e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n106",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.893713
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.20e-07
2024-11-21 01:10:52,187 - INFO - 
Starting training for config s4_n107:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:10:52,187 - INFO - Running command: ./train_gpt2cu -l 0.0003392357702583352 -o hyperband_runs_20241120_172038/run_s4_n107 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:11:20,395 - INFO - Training completed for config s4_n107:
  Training time: 0:00:28
  Final validation loss: 10.736514
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.36e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n107/checkpoint.bin
2024-11-21 01:11:20,395 - INFO - 
Configuration s4_n107 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003392357702583352",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n107",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.736514
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.36e-06
2024-11-21 01:11:20,395 - INFO - 
Starting training for config s4_n108:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:11:20,395 - INFO - Running command: ./train_gpt2cu -l 0.00036266515545703377 -o hyperband_runs_20241120_172038/run_s4_n108 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:11:48,604 - INFO - Training completed for config s4_n108:
  Training time: 0:00:28
  Final validation loss: 10.725964
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.66e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n108/checkpoint.bin
2024-11-21 01:11:48,604 - INFO - 
Configuration s4_n108 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00036266515545703377",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n108",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.725964
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.66e-06
2024-11-21 01:11:48,604 - INFO - 
Starting training for config s4_n109:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:11:48,604 - INFO - Running command: ./train_gpt2cu -l 0.00030309832624056464 -o hyperband_runs_20241120_172038/run_s4_n109 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:12:16,815 - INFO - Training completed for config s4_n109:
  Training time: 0:00:28
  Final validation loss: 10.753323
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 3.90e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n109/checkpoint.bin
2024-11-21 01:12:16,816 - INFO - 
Configuration s4_n109 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00030309832624056464",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n109",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.753323
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.90e-06
2024-11-21 01:12:16,816 - INFO - 
Starting training for config s4_n110:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:12:16,816 - INFO - Running command: ./train_gpt2cu -l 3.2261259346394364e-05 -o hyperband_runs_20241120_172038/run_s4_n110 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:12:45,049 - INFO - Training completed for config s4_n110:
  Training time: 0:00:28
  Final validation loss: 10.893934
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.15e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n110/checkpoint.bin
2024-11-21 01:12:45,049 - INFO - 
Configuration s4_n110 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "3.2261259346394364e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n110",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.893934
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.15e-07
2024-11-21 01:12:45,049 - INFO - 
Starting training for config s4_n111:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:12:45,049 - INFO - Running command: ./train_gpt2cu -l 0.0003521665560301113 -o hyperband_runs_20241120_172038/run_s4_n111 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:13:13,265 - INFO - Training completed for config s4_n111:
  Training time: 0:00:28
  Final validation loss: 10.730642
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 4.53e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n111/checkpoint.bin
2024-11-21 01:13:13,265 - INFO - 
Configuration s4_n111 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003521665560301113",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n111",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.730642
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.53e-06
2024-11-21 01:13:13,265 - INFO - 
Starting training for config s4_n112:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:13:13,265 - INFO - Running command: ./train_gpt2cu -l 0.0005740780503076311 -o hyperband_runs_20241120_172038/run_s4_n112 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:13:41,470 - INFO - Training completed for config s4_n112:
  Training time: 0:00:28
  Final validation loss: 10.641645
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 7.38e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n112/checkpoint.bin
2024-11-21 01:13:41,470 - INFO - 
Configuration s4_n112 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005740780503076311",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n112",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.641645
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.38e-06
2024-11-21 01:13:41,470 - INFO - 
Starting training for config s4_n113:
  Iterations: 9
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 01:13:41,470 - INFO - Running command: ./train_gpt2cu -l 0.00010383796328480524 -o hyperband_runs_20241120_172038/run_s4_n113 -x 9 -n 9 -y 0 -b 64 -d 524288 -h 0
2024-11-21 01:14:09,659 - INFO - Training completed for config s4_n113:
  Training time: 0:00:28
  Final validation loss: 10.855006
  Hellaswag accuracy: 0.00%
  Total iterations: 9
  Maximum learning rate: 1.34e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n113/checkpoint.bin
2024-11-21 01:14:09,660 - INFO - 
Configuration s4_n113 (bracket_4_round_0):
  Hyperparameters: {
  "learning_rate": "0.00010383796328480524",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n113",
  "max_steps": "9",
  "checkpoint_every": "9",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 9
  Total iterations: 9
  Training time: 0:00:28
  Validation Loss: 10.855006
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.34e-06
2024-11-21 01:14:09,660 - INFO - 
Eliminating 76 configurations:
  Surviving: 38
2024-11-21 01:14:12,416 - INFO - 
Bracket 4, Round 1:
  Active configs: 38
  Iterations: 27
2024-11-21 01:14:12,416 - INFO - 
Starting training for config s4_n14:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin
2024-11-21 01:14:12,416 - INFO - Running command: ./train_gpt2cu -l 0.0009599436171833041 -o hyperband_runs_20241120_172038/run_s4_n14 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:15:00,818 - INFO - Training completed for config s4_n14:
  Training time: 0:00:48
  Final validation loss: 10.047059
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.70e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin
2024-11-21 01:15:00,819 - INFO - 
Configuration s4_n14 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009599436171833041",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n14",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:48
  Validation Loss: 10.047059
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.70e-05
2024-11-21 01:15:00,819 - INFO - 
Starting training for config s4_n102:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n102/checkpoint.bin
2024-11-21 01:15:00,819 - INFO - Running command: ./train_gpt2cu -l 0.0009463534291604628 -o hyperband_runs_20241120_172038/run_s4_n102 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n102/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:15:46,995 - INFO - Training completed for config s4_n102:
  Training time: 0:00:46
  Final validation loss: 10.050197
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.65e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n102/checkpoint.bin
2024-11-21 01:15:46,996 - INFO - 
Configuration s4_n102 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009463534291604628",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n102",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n102/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:46
  Validation Loss: 10.050197
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.65e-05
2024-11-21 01:15:46,996 - INFO - 
Starting training for config s4_n56:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n56/checkpoint.bin
2024-11-21 01:15:46,996 - INFO - Running command: ./train_gpt2cu -l 0.0008679772739034899 -o hyperband_runs_20241120_172038/run_s4_n56 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n56/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:16:34,823 - INFO - Training completed for config s4_n56:
  Training time: 0:00:47
  Final validation loss: 10.070639
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.35e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n56/checkpoint.bin
2024-11-21 01:16:34,823 - INFO - 
Configuration s4_n56 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008679772739034899",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n56",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n56/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.070639
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.35e-05
2024-11-21 01:16:34,823 - INFO - 
Starting training for config s4_n66:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n66/checkpoint.bin
2024-11-21 01:16:34,824 - INFO - Running command: ./train_gpt2cu -l 0.0008647672609053191 -o hyperband_runs_20241120_172038/run_s4_n66 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n66/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:17:22,642 - INFO - Training completed for config s4_n66:
  Training time: 0:00:47
  Final validation loss: 10.071792
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.34e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n66/checkpoint.bin
2024-11-21 01:17:22,642 - INFO - 
Configuration s4_n66 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008647672609053191",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n66",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n66/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.071792
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.34e-05
2024-11-21 01:17:22,643 - INFO - 
Starting training for config s4_n83:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n83/checkpoint.bin
2024-11-21 01:17:22,643 - INFO - Running command: ./train_gpt2cu -l 0.0008162827430508194 -o hyperband_runs_20241120_172038/run_s4_n83 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n83/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:18:10,451 - INFO - Training completed for config s4_n83:
  Training time: 0:00:47
  Final validation loss: 10.084065
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.15e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n83/checkpoint.bin
2024-11-21 01:18:10,451 - INFO - 
Configuration s4_n83 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008162827430508194",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n83",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n83/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.084065
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.15e-05
2024-11-21 01:18:10,451 - INFO - 
Starting training for config s4_n12:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n12/checkpoint.bin
2024-11-21 01:18:10,451 - INFO - Running command: ./train_gpt2cu -l 0.0008160374256239891 -o hyperband_runs_20241120_172038/run_s4_n12 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n12/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:18:58,311 - INFO - Training completed for config s4_n12:
  Training time: 0:00:47
  Final validation loss: 10.084123
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.15e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n12/checkpoint.bin
2024-11-21 01:18:58,311 - INFO - 
Configuration s4_n12 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008160374256239891",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n12",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n12/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.084123
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.15e-05
2024-11-21 01:18:58,311 - INFO - 
Starting training for config s4_n39:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n39/checkpoint.bin
2024-11-21 01:18:58,312 - INFO - Running command: ./train_gpt2cu -l 0.0008099707125751382 -o hyperband_runs_20241120_172038/run_s4_n39 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n39/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:19:46,179 - INFO - Training completed for config s4_n39:
  Training time: 0:00:47
  Final validation loss: 10.085498
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.12e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n39/checkpoint.bin
2024-11-21 01:19:46,179 - INFO - 
Configuration s4_n39 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0008099707125751382",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n39",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n39/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.085498
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.12e-05
2024-11-21 01:19:46,179 - INFO - 
Starting training for config s4_n2:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n2/checkpoint.bin
2024-11-21 01:19:46,179 - INFO - Running command: ./train_gpt2cu -l 0.0007307575392695935 -o hyperband_runs_20241120_172038/run_s4_n2 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n2/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:20:34,039 - INFO - Training completed for config s4_n2:
  Training time: 0:00:47
  Final validation loss: 10.105947
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.82e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n2/checkpoint.bin
2024-11-21 01:20:34,039 - INFO - 
Configuration s4_n2 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007307575392695935",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n2",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n2/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.105947
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.82e-05
2024-11-21 01:20:34,039 - INFO - 
Starting training for config s4_n16:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n16/checkpoint.bin
2024-11-21 01:20:34,039 - INFO - Running command: ./train_gpt2cu -l 0.0007221224018725761 -o hyperband_runs_20241120_172038/run_s4_n16 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n16/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:21:21,882 - INFO - Training completed for config s4_n16:
  Training time: 0:00:47
  Final validation loss: 10.108840
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.79e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n16/checkpoint.bin
2024-11-21 01:21:21,882 - INFO - 
Configuration s4_n16 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007221224018725761",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n16",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n16/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.108840
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.79e-05
2024-11-21 01:21:21,883 - INFO - 
Starting training for config s4_n53:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n53/checkpoint.bin
2024-11-21 01:21:21,883 - INFO - Running command: ./train_gpt2cu -l 0.0007170288176891574 -o hyperband_runs_20241120_172038/run_s4_n53 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n53/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:22:09,703 - INFO - Training completed for config s4_n53:
  Training time: 0:00:47
  Final validation loss: 10.110480
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.77e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n53/checkpoint.bin
2024-11-21 01:22:09,704 - INFO - 
Configuration s4_n53 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007170288176891574",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n53",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n53/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.110480
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.77e-05
2024-11-21 01:22:09,704 - INFO - 
Starting training for config s4_n97:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n97/checkpoint.bin
2024-11-21 01:22:09,704 - INFO - Running command: ./train_gpt2cu -l 0.000716234585655273 -o hyperband_runs_20241120_172038/run_s4_n97 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n97/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:22:57,537 - INFO - Training completed for config s4_n97:
  Training time: 0:00:47
  Final validation loss: 10.110720
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.76e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n97/checkpoint.bin
2024-11-21 01:22:57,538 - INFO - 
Configuration s4_n97 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.000716234585655273",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n97",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n97/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.110720
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.76e-05
2024-11-21 01:22:57,538 - INFO - 
Starting training for config s4_n79:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n79/checkpoint.bin
2024-11-21 01:22:57,538 - INFO - Running command: ./train_gpt2cu -l 0.0006403459176372873 -o hyperband_runs_20241120_172038/run_s4_n79 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n79/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:23:45,366 - INFO - Training completed for config s4_n79:
  Training time: 0:00:47
  Final validation loss: 10.130911
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.47e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n79/checkpoint.bin
2024-11-21 01:23:45,366 - INFO - 
Configuration s4_n79 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006403459176372873",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n79",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n79/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.130911
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.47e-05
2024-11-21 01:23:45,367 - INFO - 
Starting training for config s4_n96:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n96/checkpoint.bin
2024-11-21 01:23:45,367 - INFO - Running command: ./train_gpt2cu -l 0.0006308238102118147 -o hyperband_runs_20241120_172038/run_s4_n96 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n96/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:24:33,196 - INFO - Training completed for config s4_n96:
  Training time: 0:00:47
  Final validation loss: 10.133516
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.43e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n96/checkpoint.bin
2024-11-21 01:24:33,197 - INFO - 
Configuration s4_n96 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006308238102118147",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n96",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n96/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.133516
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.43e-05
2024-11-21 01:24:33,197 - INFO - 
Starting training for config s4_n73:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n73/checkpoint.bin
2024-11-21 01:24:33,197 - INFO - Running command: ./train_gpt2cu -l 0.0006262451478113708 -o hyperband_runs_20241120_172038/run_s4_n73 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n73/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:25:21,042 - INFO - Training completed for config s4_n73:
  Training time: 0:00:47
  Final validation loss: 10.134706
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.42e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n73/checkpoint.bin
2024-11-21 01:25:21,042 - INFO - 
Configuration s4_n73 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006262451478113708",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n73",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n73/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.134706
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.42e-05
2024-11-21 01:25:21,042 - INFO - 
Starting training for config s4_n34:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n34/checkpoint.bin
2024-11-21 01:25:21,043 - INFO - Running command: ./train_gpt2cu -l 0.0005986281949357964 -o hyperband_runs_20241120_172038/run_s4_n34 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n34/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:26:08,897 - INFO - Training completed for config s4_n34:
  Training time: 0:00:47
  Final validation loss: 10.142340
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.31e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n34/checkpoint.bin
2024-11-21 01:26:08,897 - INFO - 
Configuration s4_n34 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005986281949357964",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n34",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n34/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.142340
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.31e-05
2024-11-21 01:26:08,897 - INFO - 
Starting training for config s4_n8:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n8/checkpoint.bin
2024-11-21 01:26:08,897 - INFO - Running command: ./train_gpt2cu -l 0.0005827342819023812 -o hyperband_runs_20241120_172038/run_s4_n8 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n8/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:26:56,733 - INFO - Training completed for config s4_n8:
  Training time: 0:00:47
  Final validation loss: 10.146805
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.25e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n8/checkpoint.bin
2024-11-21 01:26:56,733 - INFO - 
Configuration s4_n8 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005827342819023812",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n8",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n8/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.146805
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.25e-05
2024-11-21 01:26:56,733 - INFO - 
Starting training for config s4_n112:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n112/checkpoint.bin
2024-11-21 01:26:56,733 - INFO - Running command: ./train_gpt2cu -l 0.0005740780503076311 -o hyperband_runs_20241120_172038/run_s4_n112 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n112/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:27:44,568 - INFO - Training completed for config s4_n112:
  Training time: 0:00:47
  Final validation loss: 10.149538
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.21e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n112/checkpoint.bin
2024-11-21 01:27:44,568 - INFO - 
Configuration s4_n112 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005740780503076311",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n112",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n112/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.149538
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.21e-05
2024-11-21 01:27:44,568 - INFO - 
Starting training for config s4_n69:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n69/checkpoint.bin
2024-11-21 01:27:44,568 - INFO - Running command: ./train_gpt2cu -l 0.0005453192687893656 -o hyperband_runs_20241120_172038/run_s4_n69 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n69/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:28:32,422 - INFO - Training completed for config s4_n69:
  Training time: 0:00:47
  Final validation loss: 10.159286
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.10e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n69/checkpoint.bin
2024-11-21 01:28:32,422 - INFO - 
Configuration s4_n69 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005453192687893656",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n69",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n69/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.159286
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.10e-05
2024-11-21 01:28:32,422 - INFO - 
Starting training for config s4_n65:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n65/checkpoint.bin
2024-11-21 01:28:32,422 - INFO - Running command: ./train_gpt2cu -l 0.0005082707112054526 -o hyperband_runs_20241120_172038/run_s4_n65 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n65/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:29:20,262 - INFO - Training completed for config s4_n65:
  Training time: 0:00:47
  Final validation loss: 10.171092
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.96e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n65/checkpoint.bin
2024-11-21 01:29:20,262 - INFO - 
Configuration s4_n65 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005082707112054526",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n65",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n65/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.171092
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.96e-05
2024-11-21 01:29:20,262 - INFO - 
Starting training for config s4_n47:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n47/checkpoint.bin
2024-11-21 01:29:20,263 - INFO - Running command: ./train_gpt2cu -l 0.00047913609504335596 -o hyperband_runs_20241120_172038/run_s4_n47 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n47/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:30:08,103 - INFO - Training completed for config s4_n47:
  Training time: 0:00:47
  Final validation loss: 10.181407
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.85e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n47/checkpoint.bin
2024-11-21 01:30:08,103 - INFO - 
Configuration s4_n47 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.00047913609504335596",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n47",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n47/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.181407
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.85e-05
2024-11-21 01:30:08,103 - INFO - 
Starting training for config s4_n93:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n93/checkpoint.bin
2024-11-21 01:30:08,104 - INFO - Running command: ./train_gpt2cu -l 0.00037468857511800414 -o hyperband_runs_20241120_172038/run_s4_n93 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n93/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:30:55,943 - INFO - Training completed for config s4_n93:
  Training time: 0:00:47
  Final validation loss: 10.228343
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.45e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n93/checkpoint.bin
2024-11-21 01:30:55,944 - INFO - 
Configuration s4_n93 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.00037468857511800414",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n93",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n93/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.228343
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.45e-05
2024-11-21 01:30:55,944 - INFO - 
Starting training for config s4_n17:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n17/checkpoint.bin
2024-11-21 01:30:55,944 - INFO - Running command: ./train_gpt2cu -l 0.0003694681993618972 -o hyperband_runs_20241120_172038/run_s4_n17 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n17/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:31:43,781 - INFO - Training completed for config s4_n17:
  Training time: 0:00:47
  Final validation loss: 10.231370
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.43e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n17/checkpoint.bin
2024-11-21 01:31:43,781 - INFO - 
Configuration s4_n17 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003694681993618972",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n17",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n17/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.231370
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.43e-05
2024-11-21 01:31:43,782 - INFO - 
Starting training for config s4_n108:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n108/checkpoint.bin
2024-11-21 01:31:43,782 - INFO - Running command: ./train_gpt2cu -l 0.00036266515545703377 -o hyperband_runs_20241120_172038/run_s4_n108 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n108/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:32:31,609 - INFO - Training completed for config s4_n108:
  Training time: 0:00:47
  Final validation loss: 10.235263
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.40e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n108/checkpoint.bin
2024-11-21 01:32:31,609 - INFO - 
Configuration s4_n108 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.00036266515545703377",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n108",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n108/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.235263
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.40e-05
2024-11-21 01:32:31,609 - INFO - 
Starting training for config s4_n22:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n22/checkpoint.bin
2024-11-21 01:32:31,610 - INFO - Running command: ./train_gpt2cu -l 0.0003556119024864199 -o hyperband_runs_20241120_172038/run_s4_n22 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n22/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:33:17,813 - INFO - Training completed for config s4_n22:
  Training time: 0:00:46
  Final validation loss: 10.239241
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.37e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n22/checkpoint.bin
2024-11-21 01:33:17,813 - INFO - 
Configuration s4_n22 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003556119024864199",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n22",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n22/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:46
  Validation Loss: 10.239241
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.37e-05
2024-11-21 01:33:17,813 - INFO - 
Starting training for config s4_n0:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n0/checkpoint.bin
2024-11-21 01:33:17,813 - INFO - Running command: ./train_gpt2cu -l 0.00035331710641866486 -o hyperband_runs_20241120_172038/run_s4_n0 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n0/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:34:05,641 - INFO - Training completed for config s4_n0:
  Training time: 0:00:47
  Final validation loss: 10.240521
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.36e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n0/checkpoint.bin
2024-11-21 01:34:05,641 - INFO - 
Configuration s4_n0 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.00035331710641866486",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n0",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n0/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.240521
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.36e-05
2024-11-21 01:34:05,641 - INFO - 
Starting training for config s4_n111:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n111/checkpoint.bin
2024-11-21 01:34:05,642 - INFO - Running command: ./train_gpt2cu -l 0.0003521665560301113 -o hyperband_runs_20241120_172038/run_s4_n111 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n111/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:34:53,494 - INFO - Training completed for config s4_n111:
  Training time: 0:00:47
  Final validation loss: 10.241191
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.36e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n111/checkpoint.bin
2024-11-21 01:34:53,494 - INFO - 
Configuration s4_n111 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003521665560301113",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n111",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n111/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.241191
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.36e-05
2024-11-21 01:34:53,494 - INFO - 
Starting training for config s4_n10:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n10/checkpoint.bin
2024-11-21 01:34:53,494 - INFO - Running command: ./train_gpt2cu -l 0.00035214374366128665 -o hyperband_runs_20241120_172038/run_s4_n10 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n10/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:35:41,400 - INFO - Training completed for config s4_n10:
  Training time: 0:00:47
  Final validation loss: 10.241204
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.36e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n10/checkpoint.bin
2024-11-21 01:35:41,400 - INFO - 
Configuration s4_n10 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.00035214374366128665",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n10",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n10/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.241204
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.36e-05
2024-11-21 01:35:41,401 - INFO - 
Starting training for config s4_n68:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n68/checkpoint.bin
2024-11-21 01:35:41,401 - INFO - Running command: ./train_gpt2cu -l 0.0003446425808455775 -o hyperband_runs_20241120_172038/run_s4_n68 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n68/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:36:29,303 - INFO - Training completed for config s4_n68:
  Training time: 0:00:47
  Final validation loss: 10.245550
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.33e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n68/checkpoint.bin
2024-11-21 01:36:29,304 - INFO - 
Configuration s4_n68 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003446425808455775",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n68",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n68/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.245550
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.33e-05
2024-11-21 01:36:29,304 - INFO - 
Starting training for config s4_n107:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n107/checkpoint.bin
2024-11-21 01:36:29,304 - INFO - Running command: ./train_gpt2cu -l 0.0003392357702583352 -o hyperband_runs_20241120_172038/run_s4_n107 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n107/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:37:17,169 - INFO - Training completed for config s4_n107:
  Training time: 0:00:47
  Final validation loss: 10.248869
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.31e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n107/checkpoint.bin
2024-11-21 01:37:17,169 - INFO - 
Configuration s4_n107 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003392357702583352",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n107",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n107/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.248869
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.31e-05
2024-11-21 01:37:17,170 - INFO - 
Starting training for config s4_n103:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n103/checkpoint.bin
2024-11-21 01:37:17,170 - INFO - Running command: ./train_gpt2cu -l 0.00032169055369867 -o hyperband_runs_20241120_172038/run_s4_n103 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n103/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:38:05,008 - INFO - Training completed for config s4_n103:
  Training time: 0:00:47
  Final validation loss: 10.260313
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.24e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n103/checkpoint.bin
2024-11-21 01:38:05,008 - INFO - 
Configuration s4_n103 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.00032169055369867",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n103",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n103/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.260313
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.24e-05
2024-11-21 01:38:05,008 - INFO - 
Starting training for config s4_n92:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n92/checkpoint.bin
2024-11-21 01:38:05,008 - INFO - Running command: ./train_gpt2cu -l 0.00030916268094108144 -o hyperband_runs_20241120_172038/run_s4_n92 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n92/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:38:52,845 - INFO - Training completed for config s4_n92:
  Training time: 0:00:47
  Final validation loss: 10.268989
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.19e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n92/checkpoint.bin
2024-11-21 01:38:52,846 - INFO - 
Configuration s4_n92 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.00030916268094108144",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n92",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n92/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.268989
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.19e-05
2024-11-21 01:38:52,846 - INFO - 
Starting training for config s4_n109:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n109/checkpoint.bin
2024-11-21 01:38:52,846 - INFO - Running command: ./train_gpt2cu -l 0.00030309832624056464 -o hyperband_runs_20241120_172038/run_s4_n109 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n109/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:39:40,684 - INFO - Training completed for config s4_n109:
  Training time: 0:00:47
  Final validation loss: 10.273283
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.17e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n109/checkpoint.bin
2024-11-21 01:39:40,685 - INFO - 
Configuration s4_n109 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.00030309832624056464",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n109",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n109/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.273283
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.17e-05
2024-11-21 01:39:40,685 - INFO - 
Starting training for config s4_n29:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n29/checkpoint.bin
2024-11-21 01:39:40,685 - INFO - Running command: ./train_gpt2cu -l 0.0002755830782103017 -o hyperband_runs_20241120_172038/run_s4_n29 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n29/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:40:28,531 - INFO - Training completed for config s4_n29:
  Training time: 0:00:47
  Final validation loss: 10.295048
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.06e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n29/checkpoint.bin
2024-11-21 01:40:28,531 - INFO - 
Configuration s4_n29 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002755830782103017",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n29",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n29/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.295048
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.06e-05
2024-11-21 01:40:28,532 - INFO - 
Starting training for config s4_n101:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n101/checkpoint.bin
2024-11-21 01:40:28,532 - INFO - Running command: ./train_gpt2cu -l 0.00026913125362437496 -o hyperband_runs_20241120_172038/run_s4_n101 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n101/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:41:16,379 - INFO - Training completed for config s4_n101:
  Training time: 0:00:47
  Final validation loss: 10.300703
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.04e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n101/checkpoint.bin
2024-11-21 01:41:16,380 - INFO - 
Configuration s4_n101 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.00026913125362437496",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n101",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n101/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.300703
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.04e-05
2024-11-21 01:41:16,380 - INFO - 
Starting training for config s4_n99:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n99/checkpoint.bin
2024-11-21 01:41:16,380 - INFO - Running command: ./train_gpt2cu -l 0.0002644411243575372 -o hyperband_runs_20241120_172038/run_s4_n99 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n99/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:42:04,234 - INFO - Training completed for config s4_n99:
  Training time: 0:00:47
  Final validation loss: 10.304898
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.02e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n99/checkpoint.bin
2024-11-21 01:42:04,234 - INFO - 
Configuration s4_n99 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.0002644411243575372",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n99",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n99/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.304898
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.02e-05
2024-11-21 01:42:04,234 - INFO - 
Starting training for config s4_n45:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n45/checkpoint.bin
2024-11-21 01:42:04,234 - INFO - Running command: ./train_gpt2cu -l 0.00024190067140793267 -o hyperband_runs_20241120_172038/run_s4_n45 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n45/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:42:52,067 - INFO - Training completed for config s4_n45:
  Training time: 0:00:47
  Final validation loss: 10.326081
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 9.33e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n45/checkpoint.bin
2024-11-21 01:42:52,067 - INFO - 
Configuration s4_n45 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.00024190067140793267",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n45",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n45/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.326081
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.33e-06
2024-11-21 01:42:52,067 - INFO - 
Starting training for config s4_n59:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n59/checkpoint.bin
2024-11-21 01:42:52,067 - INFO - Running command: ./train_gpt2cu -l 0.00023567113330513875 -o hyperband_runs_20241120_172038/run_s4_n59 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n59/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:43:39,894 - INFO - Training completed for config s4_n59:
  Training time: 0:00:47
  Final validation loss: 10.332278
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 9.09e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n59/checkpoint.bin
2024-11-21 01:43:39,894 - INFO - 
Configuration s4_n59 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.00023567113330513875",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n59",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n59/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.332278
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.09e-06
2024-11-21 01:43:39,894 - INFO - 
Starting training for config s4_n85:
  Iterations: 27
  Previous iterations: 9
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n85/checkpoint.bin
2024-11-21 01:43:39,894 - INFO - Running command: ./train_gpt2cu -l 0.00023017336454977575 -o hyperband_runs_20241120_172038/run_s4_n85 -x 27 -n 27 -y 1 -e hyperband_runs_20241120_172038/run_s4_n85/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:44:27,758 - INFO - Training completed for config s4_n85:
  Training time: 0:00:47
  Final validation loss: 10.337929
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 8.88e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n85/checkpoint.bin
2024-11-21 01:44:27,758 - INFO - 
Configuration s4_n85 (bracket_4_round_1):
  Hyperparameters: {
  "learning_rate": "0.00023017336454977575",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n85",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n85/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:00:47
  Validation Loss: 10.337929
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.88e-06
2024-11-21 01:44:27,758 - INFO - 
Eliminating 26 configurations:
  Surviving: 12
2024-11-21 01:44:30,227 - INFO - 
Bracket 4, Round 2:
  Active configs: 12
  Iterations: 81
2024-11-21 01:44:30,227 - INFO - 
Starting training for config s4_n14:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin
2024-11-21 01:44:30,227 - INFO - Running command: ./train_gpt2cu -l 0.0009599436171833041 -o hyperband_runs_20241120_172038/run_s4_n14 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:46:40,827 - INFO - Training completed for config s4_n14:
  Training time: 0:02:10
  Final validation loss: 8.339468
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.11e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin
2024-11-21 01:46:40,828 - INFO - 
Configuration s4_n14 (bracket_4_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009599436171833041",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n14",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.339468
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.11e-04
2024-11-21 01:46:40,828 - INFO - 
Starting training for config s4_n102:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n102/checkpoint.bin
2024-11-21 01:46:40,828 - INFO - Running command: ./train_gpt2cu -l 0.0009463534291604628 -o hyperband_runs_20241120_172038/run_s4_n102 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s4_n102/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:48:51,438 - INFO - Training completed for config s4_n102:
  Training time: 0:02:10
  Final validation loss: 8.358015
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.10e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n102/checkpoint.bin
2024-11-21 01:48:51,438 - INFO - 
Configuration s4_n102 (bracket_4_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009463534291604628",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n102",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n102/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.358015
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-04
2024-11-21 01:48:51,438 - INFO - 
Starting training for config s4_n56:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n56/checkpoint.bin
2024-11-21 01:48:51,438 - INFO - Running command: ./train_gpt2cu -l 0.0008679772739034899 -o hyperband_runs_20241120_172038/run_s4_n56 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s4_n56/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:51:02,025 - INFO - Training completed for config s4_n56:
  Training time: 0:02:10
  Final validation loss: 8.469223
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.00e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n56/checkpoint.bin
2024-11-21 01:51:02,025 - INFO - 
Configuration s4_n56 (bracket_4_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008679772739034899",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n56",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n56/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.469223
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.00e-04
2024-11-21 01:51:02,025 - INFO - 
Starting training for config s4_n66:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n66/checkpoint.bin
2024-11-21 01:51:02,025 - INFO - Running command: ./train_gpt2cu -l 0.0008647672609053191 -o hyperband_runs_20241120_172038/run_s4_n66 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s4_n66/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:53:12,621 - INFO - Training completed for config s4_n66:
  Training time: 0:02:10
  Final validation loss: 8.473791
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.00e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n66/checkpoint.bin
2024-11-21 01:53:12,621 - INFO - 
Configuration s4_n66 (bracket_4_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008647672609053191",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n66",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n66/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.473791
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.00e-04
2024-11-21 01:53:12,621 - INFO - 
Starting training for config s4_n83:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n83/checkpoint.bin
2024-11-21 01:53:12,621 - INFO - Running command: ./train_gpt2cu -l 0.0008162827430508194 -o hyperband_runs_20241120_172038/run_s4_n83 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s4_n83/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:55:23,182 - INFO - Training completed for config s4_n83:
  Training time: 0:02:10
  Final validation loss: 8.546639
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 9.45e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n83/checkpoint.bin
2024-11-21 01:55:23,182 - INFO - 
Configuration s4_n83 (bracket_4_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008162827430508194",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n83",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n83/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.546639
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.45e-05
2024-11-21 01:55:23,182 - INFO - 
Starting training for config s4_n12:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n12/checkpoint.bin
2024-11-21 01:55:23,182 - INFO - Running command: ./train_gpt2cu -l 0.0008160374256239891 -o hyperband_runs_20241120_172038/run_s4_n12 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s4_n12/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:57:32,118 - INFO - Training completed for config s4_n12:
  Training time: 0:02:08
  Final validation loss: 8.547052
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 9.44e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n12/checkpoint.bin
2024-11-21 01:57:32,118 - INFO - 
Configuration s4_n12 (bracket_4_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008160374256239891",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n12",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n12/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:08
  Validation Loss: 8.547052
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.44e-05
2024-11-21 01:57:32,118 - INFO - 
Starting training for config s4_n39:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n39/checkpoint.bin
2024-11-21 01:57:32,118 - INFO - Running command: ./train_gpt2cu -l 0.0008099707125751382 -o hyperband_runs_20241120_172038/run_s4_n39 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s4_n39/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 01:59:41,083 - INFO - Training completed for config s4_n39:
  Training time: 0:02:08
  Final validation loss: 8.556261
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 9.37e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n39/checkpoint.bin
2024-11-21 01:59:41,083 - INFO - 
Configuration s4_n39 (bracket_4_round_2):
  Hyperparameters: {
  "learning_rate": "0.0008099707125751382",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n39",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n39/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:08
  Validation Loss: 8.556261
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.37e-05
2024-11-21 01:59:41,083 - INFO - 
Starting training for config s4_n2:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n2/checkpoint.bin
2024-11-21 01:59:41,083 - INFO - Running command: ./train_gpt2cu -l 0.0007307575392695935 -o hyperband_runs_20241120_172038/run_s4_n2 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s4_n2/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 02:01:50,819 - INFO - Training completed for config s4_n2:
  Training time: 0:02:09
  Final validation loss: 8.681059
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 8.46e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n2/checkpoint.bin
2024-11-21 02:01:50,819 - INFO - 
Configuration s4_n2 (bracket_4_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007307575392695935",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n2",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n2/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:09
  Validation Loss: 8.681059
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.46e-05
2024-11-21 02:01:50,819 - INFO - 
Starting training for config s4_n16:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n16/checkpoint.bin
2024-11-21 02:01:50,819 - INFO - Running command: ./train_gpt2cu -l 0.0007221224018725761 -o hyperband_runs_20241120_172038/run_s4_n16 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s4_n16/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 02:04:01,297 - INFO - Training completed for config s4_n16:
  Training time: 0:02:10
  Final validation loss: 8.694994
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 8.36e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n16/checkpoint.bin
2024-11-21 02:04:01,297 - INFO - 
Configuration s4_n16 (bracket_4_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007221224018725761",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n16",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n16/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.694994
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.36e-05
2024-11-21 02:04:01,297 - INFO - 
Starting training for config s4_n53:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n53/checkpoint.bin
2024-11-21 02:04:01,297 - INFO - Running command: ./train_gpt2cu -l 0.0007170288176891574 -o hyperband_runs_20241120_172038/run_s4_n53 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s4_n53/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 02:06:11,863 - INFO - Training completed for config s4_n53:
  Training time: 0:02:10
  Final validation loss: 8.703282
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 8.30e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n53/checkpoint.bin
2024-11-21 02:06:11,863 - INFO - 
Configuration s4_n53 (bracket_4_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007170288176891574",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n53",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n53/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.703282
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.30e-05
2024-11-21 02:06:11,863 - INFO - 
Starting training for config s4_n97:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n97/checkpoint.bin
2024-11-21 02:06:11,863 - INFO - Running command: ./train_gpt2cu -l 0.000716234585655273 -o hyperband_runs_20241120_172038/run_s4_n97 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s4_n97/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 02:08:22,472 - INFO - Training completed for config s4_n97:
  Training time: 0:02:10
  Final validation loss: 8.704561
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 8.29e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n97/checkpoint.bin
2024-11-21 02:08:22,472 - INFO - 
Configuration s4_n97 (bracket_4_round_2):
  Hyperparameters: {
  "learning_rate": "0.000716234585655273",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n97",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n97/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.704561
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.29e-05
2024-11-21 02:08:22,472 - INFO - 
Starting training for config s4_n79:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n79/checkpoint.bin
2024-11-21 02:08:22,472 - INFO - Running command: ./train_gpt2cu -l 0.0006403459176372873 -o hyperband_runs_20241120_172038/run_s4_n79 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s4_n79/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 02:10:33,043 - INFO - Training completed for config s4_n79:
  Training time: 0:02:10
  Final validation loss: 8.830914
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 7.41e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n79/checkpoint.bin
2024-11-21 02:10:33,043 - INFO - 
Configuration s4_n79 (bracket_4_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006403459176372873",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n79",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n79/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.830914
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.41e-05
2024-11-21 02:10:33,043 - INFO - 
Eliminating 8 configurations:
  Surviving: 4
2024-11-21 02:10:34,556 - INFO - 
Bracket 4, Round 3:
  Active configs: 4
  Iterations: 243
2024-11-21 02:10:34,556 - INFO - 
Starting training for config s4_n14:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin
2024-11-21 02:10:34,556 - INFO - Running command: ./train_gpt2cu -l 0.0009599436171833041 -o hyperband_runs_20241120_172038/run_s4_n14 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 02:16:51,809 - INFO - Training completed for config s4_n14:
  Training time: 0:06:17
  Final validation loss: 6.346178
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 3.33e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin
2024-11-21 02:16:51,810 - INFO - 
Configuration s4_n14 (bracket_4_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009599436171833041",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n14",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.346178
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.33e-04
2024-11-21 02:16:51,810 - INFO - 
Starting training for config s4_n102:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n102/checkpoint.bin
2024-11-21 02:16:51,810 - INFO - Running command: ./train_gpt2cu -l 0.0009463534291604628 -o hyperband_runs_20241120_172038/run_s4_n102 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s4_n102/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 02:23:09,009 - INFO - Training completed for config s4_n102:
  Training time: 0:06:17
  Final validation loss: 6.351839
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 3.29e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n102/checkpoint.bin
2024-11-21 02:23:09,009 - INFO - 
Configuration s4_n102 (bracket_4_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009463534291604628",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n102",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n102/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.351839
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.29e-04
2024-11-21 02:23:09,009 - INFO - 
Starting training for config s4_n56:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n56/checkpoint.bin
2024-11-21 02:23:09,009 - INFO - Running command: ./train_gpt2cu -l 0.0008679772739034899 -o hyperband_runs_20241120_172038/run_s4_n56 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s4_n56/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 02:29:26,247 - INFO - Training completed for config s4_n56:
  Training time: 0:06:17
  Final validation loss: 6.388172
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 3.01e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n56/checkpoint.bin
2024-11-21 02:29:26,248 - INFO - 
Configuration s4_n56 (bracket_4_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008679772739034899",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n56",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n56/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.388172
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.01e-04
2024-11-21 02:29:26,248 - INFO - 
Starting training for config s4_n66:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n66/checkpoint.bin
2024-11-21 02:29:26,248 - INFO - Running command: ./train_gpt2cu -l 0.0008647672609053191 -o hyperband_runs_20241120_172038/run_s4_n66 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s4_n66/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 02:35:43,505 - INFO - Training completed for config s4_n66:
  Training time: 0:06:17
  Final validation loss: 6.390935
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 3.00e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s4_n66/checkpoint.bin
2024-11-21 02:35:43,505 - INFO - 
Configuration s4_n66 (bracket_4_round_3):
  Hyperparameters: {
  "learning_rate": "0.0008647672609053191",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n66",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n66/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.390935
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.00e-04
2024-11-21 02:35:43,505 - INFO - 
Eliminating 3 configurations:
  Surviving: 1
2024-11-21 02:35:44,323 - INFO - 
Bracket 4, Round 4:
  Active configs: 1
  Iterations: 729
2024-11-21 02:35:44,323 - INFO - 
Starting training for config s4_n14:
  Iterations: 729
  Previous iterations: 243
  Previous checkpoint: hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin
2024-11-21 02:35:44,323 - INFO - Running command: ./train_gpt2cu -l 0.0009599436171833041 -o hyperband_runs_20241120_172038/run_s4_n14 -x 729 -n 729 -y 1 -e hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 02:35:45,124 - ERROR - Error training config s4_n14:
  stdout: Multi-GPU support is disabled. Using a single GPU.
+-----------------------+----------------------------------------------------+
| Parameter             | Value                                              |
+-----------------------+----------------------------------------------------+
| train data pattern    | data/fineweb_train_*.bin                           |
| val data pattern      | data/fineweb_val_*.bin                             |
| output log dir        | hyperband_runs_20241120_172038/run_s4_n14          |
| checkpoint_every      | 729                                                |
| resume                | 1                                                  |
| micro batch size B    | 64                                                 |
| sequence length T     | 1024                                               |
| total batch size      | 524288                                             |
| LR scheduler          | cosine                                             |
| learning rate (LR)    | 9.599436e-04                                       |
| warmup iterations     | 700                                                |
| final LR fraction     | 0.000000e+00                                       |
| weight decay          | 1.000000e-01                                       |
| skip update lossz     | 0.000000                                           |
| skip update gradz     | 0.000000                                           |
| max_steps             | 729                                                |
| val_loss_every        | 250                                                |
| val_max_steps         | 20                                                 |
| sample_every          | 20000                                              |
| genT                  | 64                                                 |
| overfit_single_batch  | 0                                                  |
| use_master_weights    | enabled                                            |
| gelu_fusion           | 0                                                  |
| recompute             | 1                                                  |
+-----------------------+----------------------------------------------------+
| device                | NVIDIA A10G                                        |
| peak TFlops           | -1.0                                               |
| precision             | BF16                                               |
+-----------------------+----------------------------------------------------+
| weight init method    | intermediate checkpoint                            |
| max_sequence_length T | 1024                                               |
| vocab_size V          | 50257                                              |
| padded_vocab_size Vp  | 50304                                              |
| num_layers L          | 6                                                  |
| num_heads NH          | 6                                                  |
| channels C            | 384                                                |
| num_parameters        | 30357504                                           |
+-----------------------+----------------------------------------------------+
| train_num_batches     | 729                                                |
| val_num_batches       | 20                                                 |
+-----------------------+----------------------------------------------------+
| run hellaswag         | no                                                 |
+-----------------------+----------------------------------------------------+
| num_processes         | 1                                                  |
| zero_stage            | 1                                                  |
+-----------------------+----------------------------------------------------+
num_parameters: 30357504 => bytes: 60715008
allocated 57 MiB for model parameters
batch_size B=64 * seq_len T=1024 * num_processes=1 and total_batch_size=524288
=> setting gr
  stderr: train_gpt2cu: train_gpt2.cu:1246: void load_state(int*, GPT2*, DataLoader*, const char*): Assertion `shard_num_samples == loader->shard_num_samples' failed.

2024-11-21 02:35:45,124 - INFO - 
Configuration s4_n14 (bracket_4_round_4):
  Hyperparameters: {
  "learning_rate": "0.0009599436171833041",
  "output_dir": "hyperband_runs_20241120_172038/run_s4_n14",
  "max_steps": "729",
  "checkpoint_every": "729",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s4_n14/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 729
  Total iterations: 243
  Training time: 0:00:00
  Validation Loss: inf
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 0.00e+00
2024-11-21 02:35:45,125 - INFO - 
Bracket 3:
  Initial configurations: 48
  Initial iterations: 27
2024-11-21 02:35:45,125 - INFO - 
Bracket 3, Round 0:
  Active configs: 48
  Iterations: 27
2024-11-21 02:35:45,125 - INFO - 
Starting training for config s3_n0:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:35:45,125 - INFO - Running command: ./train_gpt2cu -l 0.00014444316436555555 -o hyperband_runs_20241120_172038/run_s3_n0 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:36:54,744 - INFO - Training completed for config s3_n0:
  Training time: 0:01:09
  Final validation loss: 10.455735
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 5.57e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n0/checkpoint.bin
2024-11-21 02:36:54,744 - INFO - 
Configuration s3_n0 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.00014444316436555555",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n0",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.455735
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.57e-06
2024-11-21 02:36:54,744 - INFO - 
Starting training for config s3_n1:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:36:54,744 - INFO - Running command: ./train_gpt2cu -l 0.0004695567211550539 -o hyperband_runs_20241120_172038/run_s3_n1 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:38:04,321 - INFO - Training completed for config s3_n1:
  Training time: 0:01:09
  Final validation loss: 10.185270
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.81e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n1/checkpoint.bin
2024-11-21 02:38:04,321 - INFO - 
Configuration s3_n1 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004695567211550539",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n1",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.185270
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.81e-05
2024-11-21 02:38:04,321 - INFO - 
Starting training for config s3_n2:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:38:04,321 - INFO - Running command: ./train_gpt2cu -l 0.00035058589492170515 -o hyperband_runs_20241120_172038/run_s3_n2 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:39:13,913 - INFO - Training completed for config s3_n2:
  Training time: 0:01:09
  Final validation loss: 10.242097
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.35e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n2/checkpoint.bin
2024-11-21 02:39:13,913 - INFO - 
Configuration s3_n2 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.00035058589492170515",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n2",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.242097
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.35e-05
2024-11-21 02:39:13,914 - INFO - 
Starting training for config s3_n3:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:39:13,914 - INFO - Running command: ./train_gpt2cu -l 7.150917700119291e-05 -o hyperband_runs_20241120_172038/run_s3_n3 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:40:23,518 - INFO - Training completed for config s3_n3:
  Training time: 0:01:09
  Final validation loss: 10.625070
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.76e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n3/checkpoint.bin
2024-11-21 02:40:23,519 - INFO - 
Configuration s3_n3 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "7.150917700119291e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n3",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.625070
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.76e-06
2024-11-21 02:40:23,519 - INFO - 
Starting training for config s3_n4:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:40:23,519 - INFO - Running command: ./train_gpt2cu -l 0.00039014403501120936 -o hyperband_runs_20241120_172038/run_s3_n4 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:41:33,100 - INFO - Training completed for config s3_n4:
  Training time: 0:01:09
  Final validation loss: 10.219511
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.50e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n4/checkpoint.bin
2024-11-21 02:41:33,101 - INFO - 
Configuration s3_n4 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.00039014403501120936",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n4",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.219511
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.50e-05
2024-11-21 02:41:33,101 - INFO - 
Starting training for config s3_n5:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:41:33,101 - INFO - Running command: ./train_gpt2cu -l 6.727093684392534e-05 -o hyperband_runs_20241120_172038/run_s3_n5 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:42:42,674 - INFO - Training completed for config s3_n5:
  Training time: 0:01:09
  Final validation loss: 10.638319
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.59e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n5/checkpoint.bin
2024-11-21 02:42:42,675 - INFO - 
Configuration s3_n5 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "6.727093684392534e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n5",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.638319
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.59e-06
2024-11-21 02:42:42,675 - INFO - 
Starting training for config s3_n6:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:42:42,675 - INFO - Running command: ./train_gpt2cu -l 0.0004658268012217285 -o hyperband_runs_20241120_172038/run_s3_n6 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:43:52,242 - INFO - Training completed for config s3_n6:
  Training time: 0:01:09
  Final validation loss: 10.186730
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.80e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n6/checkpoint.bin
2024-11-21 02:43:52,242 - INFO - 
Configuration s3_n6 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004658268012217285",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n6",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.186730
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.80e-05
2024-11-21 02:43:52,242 - INFO - 
Starting training for config s3_n7:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:43:52,242 - INFO - Running command: ./train_gpt2cu -l 0.00022251947782748297 -o hyperband_runs_20241120_172038/run_s3_n7 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:45:01,823 - INFO - Training completed for config s3_n7:
  Training time: 0:01:09
  Final validation loss: 10.346144
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 8.58e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n7/checkpoint.bin
2024-11-21 02:45:01,823 - INFO - 
Configuration s3_n7 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.00022251947782748297",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n7",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.346144
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.58e-06
2024-11-21 02:45:01,823 - INFO - 
Starting training for config s3_n8:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:45:01,824 - INFO - Running command: ./train_gpt2cu -l 0.00019268638052322962 -o hyperband_runs_20241120_172038/run_s3_n8 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:46:11,383 - INFO - Training completed for config s3_n8:
  Training time: 0:01:09
  Final validation loss: 10.381922
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 7.43e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n8/checkpoint.bin
2024-11-21 02:46:11,383 - INFO - 
Configuration s3_n8 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.00019268638052322962",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n8",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.381922
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.43e-06
2024-11-21 02:46:11,383 - INFO - 
Starting training for config s3_n9:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:46:11,383 - INFO - Running command: ./train_gpt2cu -l 0.0009261629924601716 -o hyperband_runs_20241120_172038/run_s3_n9 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:47:20,963 - INFO - Training completed for config s3_n9:
  Training time: 0:01:09
  Final validation loss: 10.055882
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.57e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n9/checkpoint.bin
2024-11-21 02:47:20,963 - INFO - 
Configuration s3_n9 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009261629924601716",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n9",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.055882
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.57e-05
2024-11-21 02:47:20,963 - INFO - 
Starting training for config s3_n10:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:47:20,963 - INFO - Running command: ./train_gpt2cu -l 0.0001670134025302914 -o hyperband_runs_20241120_172038/run_s3_n10 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:48:30,534 - INFO - Training completed for config s3_n10:
  Training time: 0:01:09
  Final validation loss: 10.418095
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 6.44e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n10/checkpoint.bin
2024-11-21 02:48:30,534 - INFO - 
Configuration s3_n10 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001670134025302914",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n10",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.418095
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.44e-06
2024-11-21 02:48:30,534 - INFO - 
Starting training for config s3_n11:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:48:30,535 - INFO - Running command: ./train_gpt2cu -l 6.134061972285519e-05 -o hyperband_runs_20241120_172038/run_s3_n11 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:49:40,097 - INFO - Training completed for config s3_n11:
  Training time: 0:01:09
  Final validation loss: 10.657671
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.37e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n11/checkpoint.bin
2024-11-21 02:49:40,097 - INFO - 
Configuration s3_n11 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "6.134061972285519e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n11",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.657671
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.37e-06
2024-11-21 02:49:40,097 - INFO - 
Starting training for config s3_n12:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:49:40,097 - INFO - Running command: ./train_gpt2cu -l 0.0007432340609240755 -o hyperband_runs_20241120_172038/run_s3_n12 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:50:49,677 - INFO - Training completed for config s3_n12:
  Training time: 0:01:09
  Final validation loss: 10.102630
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.87e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n12/checkpoint.bin
2024-11-21 02:50:49,677 - INFO - 
Configuration s3_n12 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007432340609240755",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n12",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.102630
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.87e-05
2024-11-21 02:50:49,677 - INFO - 
Starting training for config s3_n13:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:50:49,677 - INFO - Running command: ./train_gpt2cu -l 0.00033012525375405554 -o hyperband_runs_20241120_172038/run_s3_n13 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:51:59,235 - INFO - Training completed for config s3_n13:
  Training time: 0:01:09
  Final validation loss: 10.254638
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.27e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n13/checkpoint.bin
2024-11-21 02:51:59,235 - INFO - 
Configuration s3_n13 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.00033012525375405554",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n13",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.254638
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.27e-05
2024-11-21 02:51:59,235 - INFO - 
Starting training for config s3_n14:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:51:59,236 - INFO - Running command: ./train_gpt2cu -l 3.9579227837110894e-05 -o hyperband_runs_20241120_172038/run_s3_n14 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:53:08,799 - INFO - Training completed for config s3_n14:
  Training time: 0:01:09
  Final validation loss: 10.737698
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.53e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n14/checkpoint.bin
2024-11-21 02:53:08,800 - INFO - 
Configuration s3_n14 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "3.9579227837110894e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n14",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.737698
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.53e-06
2024-11-21 02:53:08,800 - INFO - 
Starting training for config s3_n15:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:53:08,800 - INFO - Running command: ./train_gpt2cu -l 5.391676336875624e-05 -o hyperband_runs_20241120_172038/run_s3_n15 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:54:18,362 - INFO - Training completed for config s3_n15:
  Training time: 0:01:09
  Final validation loss: 10.683382
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.08e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n15/checkpoint.bin
2024-11-21 02:54:18,363 - INFO - 
Configuration s3_n15 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "5.391676336875624e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n15",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.683382
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.08e-06
2024-11-21 02:54:18,363 - INFO - 
Starting training for config s3_n16:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:54:18,363 - INFO - Running command: ./train_gpt2cu -l 3.724818536133494e-05 -o hyperband_runs_20241120_172038/run_s3_n16 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:55:27,918 - INFO - Training completed for config s3_n16:
  Training time: 0:01:09
  Final validation loss: 10.747080
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.44e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n16/checkpoint.bin
2024-11-21 02:55:27,919 - INFO - 
Configuration s3_n16 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "3.724818536133494e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n16",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.747080
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.44e-06
2024-11-21 02:55:27,919 - INFO - 
Starting training for config s3_n17:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:55:27,919 - INFO - Running command: ./train_gpt2cu -l 2.123978643194513e-05 -o hyperband_runs_20241120_172038/run_s3_n17 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:56:37,460 - INFO - Training completed for config s3_n17:
  Training time: 0:01:09
  Final validation loss: 10.815081
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 8.19e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n17/checkpoint.bin
2024-11-21 02:56:37,460 - INFO - 
Configuration s3_n17 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "2.123978643194513e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n17",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.815081
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.19e-07
2024-11-21 02:56:37,460 - INFO - 
Starting training for config s3_n18:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:56:37,460 - INFO - Running command: ./train_gpt2cu -l 0.0002500287821839946 -o hyperband_runs_20241120_172038/run_s3_n18 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:57:47,026 - INFO - Training completed for config s3_n18:
  Training time: 0:01:09
  Final validation loss: 10.318255
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 9.64e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n18/checkpoint.bin
2024-11-21 02:57:47,026 - INFO - 
Configuration s3_n18 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.0002500287821839946",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n18",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.318255
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.64e-06
2024-11-21 02:57:47,026 - INFO - 
Starting training for config s3_n19:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:57:47,027 - INFO - Running command: ./train_gpt2cu -l 7.079081033044853e-05 -o hyperband_runs_20241120_172038/run_s3_n19 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 02:58:56,599 - INFO - Training completed for config s3_n19:
  Training time: 0:01:09
  Final validation loss: 10.627284
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.73e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n19/checkpoint.bin
2024-11-21 02:58:56,599 - INFO - 
Configuration s3_n19 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "7.079081033044853e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n19",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.627284
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.73e-06
2024-11-21 02:58:56,599 - INFO - 
Starting training for config s3_n20:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 02:58:56,599 - INFO - Running command: ./train_gpt2cu -l 2.160169521041011e-05 -o hyperband_runs_20241120_172038/run_s3_n20 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:00:06,155 - INFO - Training completed for config s3_n20:
  Training time: 0:01:09
  Final validation loss: 10.813488
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 8.33e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n20/checkpoint.bin
2024-11-21 03:00:06,155 - INFO - 
Configuration s3_n20 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "2.160169521041011e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n20",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.813488
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.33e-07
2024-11-21 03:00:06,155 - INFO - 
Starting training for config s3_n21:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:00:06,155 - INFO - Running command: ./train_gpt2cu -l 5.239728530574597e-05 -o hyperband_runs_20241120_172038/run_s3_n21 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:01:15,747 - INFO - Training completed for config s3_n21:
  Training time: 0:01:09
  Final validation loss: 10.688852
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.02e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n21/checkpoint.bin
2024-11-21 03:01:15,747 - INFO - 
Configuration s3_n21 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "5.239728530574597e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n21",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.688852
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.02e-06
2024-11-21 03:01:15,747 - INFO - 
Starting training for config s3_n22:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:01:15,747 - INFO - Running command: ./train_gpt2cu -l 3.141696813498573e-05 -o hyperband_runs_20241120_172038/run_s3_n22 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:02:25,317 - INFO - Training completed for config s3_n22:
  Training time: 0:01:09
  Final validation loss: 10.771235
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.21e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n22/checkpoint.bin
2024-11-21 03:02:25,317 - INFO - 
Configuration s3_n22 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "3.141696813498573e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n22",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.771235
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.21e-06
2024-11-21 03:02:25,317 - INFO - 
Starting training for config s3_n23:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:02:25,317 - INFO - Running command: ./train_gpt2cu -l 0.00013155381318293534 -o hyperband_runs_20241120_172038/run_s3_n23 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:03:34,891 - INFO - Training completed for config s3_n23:
  Training time: 0:01:09
  Final validation loss: 10.479650
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 5.07e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n23/checkpoint.bin
2024-11-21 03:03:34,891 - INFO - 
Configuration s3_n23 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013155381318293534",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n23",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.479650
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.07e-06
2024-11-21 03:03:34,892 - INFO - 
Starting training for config s3_n24:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:03:34,892 - INFO - Running command: ./train_gpt2cu -l 8.710899633293431e-05 -o hyperband_runs_20241120_172038/run_s3_n24 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:04:44,473 - INFO - Training completed for config s3_n24:
  Training time: 0:01:09
  Final validation loss: 10.580271
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.36e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n24/checkpoint.bin
2024-11-21 03:04:44,473 - INFO - 
Configuration s3_n24 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "8.710899633293431e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n24",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.580271
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.36e-06
2024-11-21 03:04:44,474 - INFO - 
Starting training for config s3_n25:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:04:44,474 - INFO - Running command: ./train_gpt2cu -l 3.393238599587719e-05 -o hyperband_runs_20241120_172038/run_s3_n25 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:05:54,040 - INFO - Training completed for config s3_n25:
  Training time: 0:01:09
  Final validation loss: 10.760689
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.31e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n25/checkpoint.bin
2024-11-21 03:05:54,040 - INFO - 
Configuration s3_n25 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "3.393238599587719e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n25",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.760689
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.31e-06
2024-11-21 03:05:54,040 - INFO - 
Starting training for config s3_n26:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:05:54,040 - INFO - Running command: ./train_gpt2cu -l 3.516108018267333e-05 -o hyperband_runs_20241120_172038/run_s3_n26 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:07:03,615 - INFO - Training completed for config s3_n26:
  Training time: 0:01:09
  Final validation loss: 10.755590
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.36e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n26/checkpoint.bin
2024-11-21 03:07:03,615 - INFO - 
Configuration s3_n26 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "3.516108018267333e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n26",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.755590
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.36e-06
2024-11-21 03:07:03,615 - INFO - 
Starting training for config s3_n27:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:07:03,615 - INFO - Running command: ./train_gpt2cu -l 1.0023783864881687e-05 -o hyperband_runs_20241120_172038/run_s3_n27 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:08:13,193 - INFO - Training completed for config s3_n27:
  Training time: 0:01:09
  Final validation loss: 10.865568
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.87e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n27/checkpoint.bin
2024-11-21 03:08:13,194 - INFO - 
Configuration s3_n27 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "1.0023783864881687e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n27",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.865568
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.87e-07
2024-11-21 03:08:13,194 - INFO - 
Starting training for config s3_n28:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:08:13,194 - INFO - Running command: ./train_gpt2cu -l 8.0884556306994e-05 -o hyperband_runs_20241120_172038/run_s3_n28 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:09:22,798 - INFO - Training completed for config s3_n28:
  Training time: 0:01:09
  Final validation loss: 10.597422
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.12e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n28/checkpoint.bin
2024-11-21 03:09:22,798 - INFO - 
Configuration s3_n28 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "8.0884556306994e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n28",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.597422
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.12e-06
2024-11-21 03:09:22,799 - INFO - 
Starting training for config s3_n29:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:09:22,799 - INFO - Running command: ./train_gpt2cu -l 5.020984248033415e-05 -o hyperband_runs_20241120_172038/run_s3_n29 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:10:32,368 - INFO - Training completed for config s3_n29:
  Training time: 0:01:09
  Final validation loss: 10.696843
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.94e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n29/checkpoint.bin
2024-11-21 03:10:32,368 - INFO - 
Configuration s3_n29 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "5.020984248033415e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n29",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.696843
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.94e-06
2024-11-21 03:10:32,368 - INFO - 
Starting training for config s3_n30:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:10:32,368 - INFO - Running command: ./train_gpt2cu -l 6.2237853775258e-05 -o hyperband_runs_20241120_172038/run_s3_n30 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:11:41,940 - INFO - Training completed for config s3_n30:
  Training time: 0:01:09
  Final validation loss: 10.654690
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.40e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n30/checkpoint.bin
2024-11-21 03:11:41,940 - INFO - 
Configuration s3_n30 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "6.2237853775258e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n30",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.654690
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.40e-06
2024-11-21 03:11:41,940 - INFO - 
Starting training for config s3_n31:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:11:41,941 - INFO - Running command: ./train_gpt2cu -l 0.0007874894604926768 -o hyperband_runs_20241120_172038/run_s3_n31 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:12:51,495 - INFO - Training completed for config s3_n31:
  Training time: 0:01:09
  Final validation loss: 10.091757
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.04e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n31/checkpoint.bin
2024-11-21 03:12:51,495 - INFO - 
Configuration s3_n31 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007874894604926768",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n31",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.091757
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.04e-05
2024-11-21 03:12:51,495 - INFO - 
Starting training for config s3_n32:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:12:51,495 - INFO - Running command: ./train_gpt2cu -l 0.00043607489930654004 -o hyperband_runs_20241120_172038/run_s3_n32 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:14:01,057 - INFO - Training completed for config s3_n32:
  Training time: 0:01:09
  Final validation loss: 10.198318
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.68e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n32/checkpoint.bin
2024-11-21 03:14:01,057 - INFO - 
Configuration s3_n32 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.00043607489930654004",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n32",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.198318
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.68e-05
2024-11-21 03:14:01,057 - INFO - 
Starting training for config s3_n33:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:14:01,057 - INFO - Running command: ./train_gpt2cu -l 2.3993386674066876e-05 -o hyperband_runs_20241120_172038/run_s3_n33 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:15:10,621 - INFO - Training completed for config s3_n33:
  Training time: 0:01:09
  Final validation loss: 10.803020
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 9.25e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n33/checkpoint.bin
2024-11-21 03:15:10,621 - INFO - 
Configuration s3_n33 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "2.3993386674066876e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n33",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.803020
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.25e-07
2024-11-21 03:15:10,621 - INFO - 
Starting training for config s3_n34:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:15:10,622 - INFO - Running command: ./train_gpt2cu -l 6.593366437688266e-05 -o hyperband_runs_20241120_172038/run_s3_n34 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:16:20,165 - INFO - Training completed for config s3_n34:
  Training time: 0:01:09
  Final validation loss: 10.642574
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.54e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n34/checkpoint.bin
2024-11-21 03:16:20,165 - INFO - 
Configuration s3_n34 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "6.593366437688266e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n34",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.642574
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.54e-06
2024-11-21 03:16:20,165 - INFO - 
Starting training for config s3_n35:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:16:20,165 - INFO - Running command: ./train_gpt2cu -l 4.7302637167602624e-05 -o hyperband_runs_20241120_172038/run_s3_n35 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:17:29,715 - INFO - Training completed for config s3_n35:
  Training time: 0:01:09
  Final validation loss: 10.707703
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.82e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n35/checkpoint.bin
2024-11-21 03:17:29,715 - INFO - 
Configuration s3_n35 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "4.7302637167602624e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n35",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.707703
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.82e-06
2024-11-21 03:17:29,716 - INFO - 
Starting training for config s3_n36:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:17:29,716 - INFO - Running command: ./train_gpt2cu -l 1.8754900745662232e-05 -o hyperband_runs_20241120_172038/run_s3_n36 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:18:39,270 - INFO - Training completed for config s3_n36:
  Training time: 0:01:09
  Final validation loss: 10.826128
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 7.23e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n36/checkpoint.bin
2024-11-21 03:18:39,271 - INFO - 
Configuration s3_n36 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "1.8754900745662232e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n36",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.826128
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.23e-07
2024-11-21 03:18:39,271 - INFO - 
Starting training for config s3_n37:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:18:39,271 - INFO - Running command: ./train_gpt2cu -l 2.8440959844299757e-05 -o hyperband_runs_20241120_172038/run_s3_n37 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:19:48,845 - INFO - Training completed for config s3_n37:
  Training time: 0:01:09
  Final validation loss: 10.783849
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.10e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n37/checkpoint.bin
2024-11-21 03:19:48,845 - INFO - 
Configuration s3_n37 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "2.8440959844299757e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n37",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.783849
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.10e-06
2024-11-21 03:19:48,845 - INFO - 
Starting training for config s3_n38:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:19:48,846 - INFO - Running command: ./train_gpt2cu -l 0.0005954050896619463 -o hyperband_runs_20241120_172038/run_s3_n38 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:20:58,424 - INFO - Training completed for config s3_n38:
  Training time: 0:01:09
  Final validation loss: 10.143229
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.30e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n38/checkpoint.bin
2024-11-21 03:20:58,425 - INFO - 
Configuration s3_n38 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005954050896619463",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n38",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.143229
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.30e-05
2024-11-21 03:20:58,425 - INFO - 
Starting training for config s3_n39:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:20:58,425 - INFO - Running command: ./train_gpt2cu -l 2.4849277139832512e-05 -o hyperband_runs_20241120_172038/run_s3_n39 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:22:07,988 - INFO - Training completed for config s3_n39:
  Training time: 0:01:09
  Final validation loss: 10.799312
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 9.58e-07
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n39/checkpoint.bin
2024-11-21 03:22:07,988 - INFO - 
Configuration s3_n39 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "2.4849277139832512e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n39",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.799312
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.58e-07
2024-11-21 03:22:07,988 - INFO - 
Starting training for config s3_n40:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:22:07,988 - INFO - Running command: ./train_gpt2cu -l 0.00015849584362328216 -o hyperband_runs_20241120_172038/run_s3_n40 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:23:17,583 - INFO - Training completed for config s3_n40:
  Training time: 0:01:09
  Final validation loss: 10.431626
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 6.11e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n40/checkpoint.bin
2024-11-21 03:23:17,583 - INFO - 
Configuration s3_n40 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.00015849584362328216",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n40",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.431626
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.11e-06
2024-11-21 03:23:17,583 - INFO - 
Starting training for config s3_n41:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:23:17,583 - INFO - Running command: ./train_gpt2cu -l 0.00025759461334135697 -o hyperband_runs_20241120_172038/run_s3_n41 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:24:27,145 - INFO - Training completed for config s3_n41:
  Training time: 0:01:09
  Final validation loss: 10.311178
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 9.94e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n41/checkpoint.bin
2024-11-21 03:24:27,145 - INFO - 
Configuration s3_n41 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.00025759461334135697",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n41",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.311178
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.94e-06
2024-11-21 03:24:27,145 - INFO - 
Starting training for config s3_n42:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:24:27,145 - INFO - Running command: ./train_gpt2cu -l 6.445219917045105e-05 -o hyperband_runs_20241120_172038/run_s3_n42 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:25:36,711 - INFO - Training completed for config s3_n42:
  Training time: 0:01:09
  Final validation loss: 10.647406
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.49e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n42/checkpoint.bin
2024-11-21 03:25:36,711 - INFO - 
Configuration s3_n42 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "6.445219917045105e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n42",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.647406
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.49e-06
2024-11-21 03:25:36,712 - INFO - 
Starting training for config s3_n43:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:25:36,712 - INFO - Running command: ./train_gpt2cu -l 0.0007780267326422377 -o hyperband_runs_20241120_172038/run_s3_n43 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:26:46,299 - INFO - Training completed for config s3_n43:
  Training time: 0:01:09
  Final validation loss: 10.093980
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.00e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n43/checkpoint.bin
2024-11-21 03:26:46,299 - INFO - 
Configuration s3_n43 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007780267326422377",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n43",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.093980
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.00e-05
2024-11-21 03:26:46,299 - INFO - 
Starting training for config s3_n44:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:26:46,299 - INFO - Running command: ./train_gpt2cu -l 0.000360680857057123 -o hyperband_runs_20241120_172038/run_s3_n44 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:27:55,884 - INFO - Training completed for config s3_n44:
  Training time: 0:01:09
  Final validation loss: 10.236378
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.39e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n44/checkpoint.bin
2024-11-21 03:27:55,884 - INFO - 
Configuration s3_n44 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.000360680857057123",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n44",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.236378
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.39e-05
2024-11-21 03:27:55,885 - INFO - 
Starting training for config s3_n45:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:27:55,885 - INFO - Running command: ./train_gpt2cu -l 0.0005358458051056699 -o hyperband_runs_20241120_172038/run_s3_n45 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:29:05,466 - INFO - Training completed for config s3_n45:
  Training time: 0:01:09
  Final validation loss: 10.162124
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 2.07e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n45/checkpoint.bin
2024-11-21 03:29:05,466 - INFO - 
Configuration s3_n45 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005358458051056699",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n45",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.162124
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.07e-05
2024-11-21 03:29:05,466 - INFO - 
Starting training for config s3_n46:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:29:05,466 - INFO - Running command: ./train_gpt2cu -l 0.0009396616173600525 -o hyperband_runs_20241120_172038/run_s3_n46 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:30:15,053 - INFO - Training completed for config s3_n46:
  Training time: 0:01:09
  Final validation loss: 10.051910
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 3.62e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n46/checkpoint.bin
2024-11-21 03:30:15,053 - INFO - 
Configuration s3_n46 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.0009396616173600525",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n46",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.051910
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.62e-05
2024-11-21 03:30:15,053 - INFO - 
Starting training for config s3_n47:
  Iterations: 27
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 03:30:15,053 - INFO - Running command: ./train_gpt2cu -l 0.0004748145023182249 -o hyperband_runs_20241120_172038/run_s3_n47 -x 27 -n 27 -y 0 -b 64 -d 524288 -h 0
2024-11-21 03:31:24,625 - INFO - Training completed for config s3_n47:
  Training time: 0:01:09
  Final validation loss: 10.183198
  Hellaswag accuracy: 0.00%
  Total iterations: 27
  Maximum learning rate: 1.83e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n47/checkpoint.bin
2024-11-21 03:31:24,625 - INFO - 
Configuration s3_n47 (bracket_3_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004748145023182249",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n47",
  "max_steps": "27",
  "checkpoint_every": "27",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 27
  Total iterations: 27
  Training time: 0:01:09
  Validation Loss: 10.183198
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.83e-05
2024-11-21 03:31:24,625 - INFO - 
Eliminating 32 configurations:
  Surviving: 16
2024-11-21 03:31:26,532 - INFO - 
Bracket 3, Round 1:
  Active configs: 16
  Iterations: 81
2024-11-21 03:31:26,532 - INFO - 
Starting training for config s3_n46:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n46/checkpoint.bin
2024-11-21 03:31:26,532 - INFO - Running command: ./train_gpt2cu -l 0.0009396616173600525 -o hyperband_runs_20241120_172038/run_s3_n46 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n46/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 03:33:35,468 - INFO - Training completed for config s3_n46:
  Training time: 0:02:08
  Final validation loss: 8.367221
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.09e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n46/checkpoint.bin
2024-11-21 03:33:35,468 - INFO - 
Configuration s3_n46 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009396616173600525",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n46",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n46/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:08
  Validation Loss: 8.367221
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.09e-04
2024-11-21 03:33:35,468 - INFO - 
Starting training for config s3_n9:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n9/checkpoint.bin
2024-11-21 03:33:35,468 - INFO - Running command: ./train_gpt2cu -l 0.0009261629924601716 -o hyperband_runs_20241120_172038/run_s3_n9 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n9/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 03:35:46,180 - INFO - Training completed for config s3_n9:
  Training time: 0:02:10
  Final validation loss: 8.386037
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.07e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n9/checkpoint.bin
2024-11-21 03:35:46,181 - INFO - 
Configuration s3_n9 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.0009261629924601716",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n9",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n9/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.386037
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.07e-04
2024-11-21 03:35:46,181 - INFO - 
Starting training for config s3_n31:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n31/checkpoint.bin
2024-11-21 03:35:46,181 - INFO - Running command: ./train_gpt2cu -l 0.0007874894604926768 -o hyperband_runs_20241120_172038/run_s3_n31 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n31/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 03:37:55,090 - INFO - Training completed for config s3_n31:
  Training time: 0:02:08
  Final validation loss: 8.591052
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 9.11e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n31/checkpoint.bin
2024-11-21 03:37:55,090 - INFO - 
Configuration s3_n31 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007874894604926768",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n31",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n31/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:08
  Validation Loss: 8.591052
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.11e-05
2024-11-21 03:37:55,090 - INFO - 
Starting training for config s3_n43:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n43/checkpoint.bin
2024-11-21 03:37:55,090 - INFO - Running command: ./train_gpt2cu -l 0.0007780267326422377 -o hyperband_runs_20241120_172038/run_s3_n43 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n43/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 03:40:03,997 - INFO - Training completed for config s3_n43:
  Training time: 0:02:08
  Final validation loss: 8.605609
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 9.00e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n43/checkpoint.bin
2024-11-21 03:40:03,997 - INFO - 
Configuration s3_n43 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007780267326422377",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n43",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n43/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:08
  Validation Loss: 8.605609
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 9.00e-05
2024-11-21 03:40:03,997 - INFO - 
Starting training for config s3_n12:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n12/checkpoint.bin
2024-11-21 03:40:03,998 - INFO - Running command: ./train_gpt2cu -l 0.0007432340609240755 -o hyperband_runs_20241120_172038/run_s3_n12 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n12/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 03:42:14,790 - INFO - Training completed for config s3_n12:
  Training time: 0:02:10
  Final validation loss: 8.661060
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 8.60e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n12/checkpoint.bin
2024-11-21 03:42:14,790 - INFO - 
Configuration s3_n12 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007432340609240755",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n12",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n12/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 8.661060
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.60e-05
2024-11-21 03:42:14,790 - INFO - 
Starting training for config s3_n38:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n38/checkpoint.bin
2024-11-21 03:42:14,790 - INFO - Running command: ./train_gpt2cu -l 0.0005954050896619463 -o hyperband_runs_20241120_172038/run_s3_n38 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n38/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 03:44:23,702 - INFO - Training completed for config s3_n38:
  Training time: 0:02:08
  Final validation loss: 8.909201
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 6.89e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n38/checkpoint.bin
2024-11-21 03:44:23,702 - INFO - 
Configuration s3_n38 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005954050896619463",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n38",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n38/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:08
  Validation Loss: 8.909201
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.89e-05
2024-11-21 03:44:23,702 - INFO - 
Starting training for config s3_n45:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n45/checkpoint.bin
2024-11-21 03:44:23,702 - INFO - Running command: ./train_gpt2cu -l 0.0005358458051056699 -o hyperband_runs_20241120_172038/run_s3_n45 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n45/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 03:46:32,653 - INFO - Training completed for config s3_n45:
  Training time: 0:02:08
  Final validation loss: 9.016685
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 6.20e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n45/checkpoint.bin
2024-11-21 03:46:32,653 - INFO - 
Configuration s3_n45 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005358458051056699",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n45",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n45/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:08
  Validation Loss: 9.016685
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 6.20e-05
2024-11-21 03:46:32,653 - INFO - 
Starting training for config s3_n47:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n47/checkpoint.bin
2024-11-21 03:46:32,653 - INFO - Running command: ./train_gpt2cu -l 0.0004748145023182249 -o hyperband_runs_20241120_172038/run_s3_n47 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n47/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 03:48:41,581 - INFO - Training completed for config s3_n47:
  Training time: 0:02:08
  Final validation loss: 9.130234
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 5.49e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n47/checkpoint.bin
2024-11-21 03:48:41,582 - INFO - 
Configuration s3_n47 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004748145023182249",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n47",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n47/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:08
  Validation Loss: 9.130234
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.49e-05
2024-11-21 03:48:41,582 - INFO - 
Starting training for config s3_n1:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n1/checkpoint.bin
2024-11-21 03:48:41,582 - INFO - Running command: ./train_gpt2cu -l 0.0004695567211550539 -o hyperband_runs_20241120_172038/run_s3_n1 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n1/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 03:50:52,131 - INFO - Training completed for config s3_n1:
  Training time: 0:02:10
  Final validation loss: 9.139974
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 5.43e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n1/checkpoint.bin
2024-11-21 03:50:52,131 - INFO - 
Configuration s3_n1 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004695567211550539",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n1",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n1/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 9.139974
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.43e-05
2024-11-21 03:50:52,131 - INFO - 
Starting training for config s3_n6:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n6/checkpoint.bin
2024-11-21 03:50:52,131 - INFO - Running command: ./train_gpt2cu -l 0.0004658268012217285 -o hyperband_runs_20241120_172038/run_s3_n6 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n6/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 03:53:03,067 - INFO - Training completed for config s3_n6:
  Training time: 0:02:10
  Final validation loss: 9.146944
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 5.39e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n6/checkpoint.bin
2024-11-21 03:53:03,067 - INFO - 
Configuration s3_n6 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004658268012217285",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n6",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n6/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 9.146944
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.39e-05
2024-11-21 03:53:03,067 - INFO - 
Starting training for config s3_n32:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n32/checkpoint.bin
2024-11-21 03:53:03,067 - INFO - Running command: ./train_gpt2cu -l 0.00043607489930654004 -o hyperband_runs_20241120_172038/run_s3_n32 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n32/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 03:55:11,997 - INFO - Training completed for config s3_n32:
  Training time: 0:02:08
  Final validation loss: 9.204127
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 5.05e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n32/checkpoint.bin
2024-11-21 03:55:11,998 - INFO - 
Configuration s3_n32 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.00043607489930654004",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n32",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n32/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:08
  Validation Loss: 9.204127
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.05e-05
2024-11-21 03:55:11,998 - INFO - 
Starting training for config s3_n4:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n4/checkpoint.bin
2024-11-21 03:55:11,998 - INFO - Running command: ./train_gpt2cu -l 0.00039014403501120936 -o hyperband_runs_20241120_172038/run_s3_n4 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n4/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 03:57:23,158 - INFO - Training completed for config s3_n4:
  Training time: 0:02:11
  Final validation loss: 9.294649
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 4.51e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n4/checkpoint.bin
2024-11-21 03:57:23,158 - INFO - 
Configuration s3_n4 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.00039014403501120936",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n4",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n4/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:11
  Validation Loss: 9.294649
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.51e-05
2024-11-21 03:57:23,158 - INFO - 
Starting training for config s3_n44:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n44/checkpoint.bin
2024-11-21 03:57:23,158 - INFO - Running command: ./train_gpt2cu -l 0.000360680857057123 -o hyperband_runs_20241120_172038/run_s3_n44 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n44/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 03:59:32,133 - INFO - Training completed for config s3_n44:
  Training time: 0:02:08
  Final validation loss: 9.354750
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 4.17e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n44/checkpoint.bin
2024-11-21 03:59:32,134 - INFO - 
Configuration s3_n44 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.000360680857057123",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n44",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n44/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:08
  Validation Loss: 9.354750
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.17e-05
2024-11-21 03:59:32,134 - INFO - 
Starting training for config s3_n2:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n2/checkpoint.bin
2024-11-21 03:59:32,134 - INFO - Running command: ./train_gpt2cu -l 0.00035058589492170515 -o hyperband_runs_20241120_172038/run_s3_n2 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n2/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 04:01:42,718 - INFO - Training completed for config s3_n2:
  Training time: 0:02:10
  Final validation loss: 9.375525
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 4.06e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n2/checkpoint.bin
2024-11-21 04:01:42,718 - INFO - 
Configuration s3_n2 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.00035058589492170515",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n2",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n2/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 9.375525
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.06e-05
2024-11-21 04:01:42,718 - INFO - 
Starting training for config s3_n13:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n13/checkpoint.bin
2024-11-21 04:01:42,718 - INFO - Running command: ./train_gpt2cu -l 0.00033012525375405554 -o hyperband_runs_20241120_172038/run_s3_n13 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n13/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 04:03:53,307 - INFO - Training completed for config s3_n13:
  Training time: 0:02:10
  Final validation loss: 9.418171
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 3.82e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n13/checkpoint.bin
2024-11-21 04:03:53,307 - INFO - 
Configuration s3_n13 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.00033012525375405554",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n13",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n13/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 9.418171
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.82e-05
2024-11-21 04:03:53,308 - INFO - 
Starting training for config s3_n41:
  Iterations: 81
  Previous iterations: 27
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n41/checkpoint.bin
2024-11-21 04:03:53,308 - INFO - Running command: ./train_gpt2cu -l 0.00025759461334135697 -o hyperband_runs_20241120_172038/run_s3_n41 -x 81 -n 81 -y 1 -e hyperband_runs_20241120_172038/run_s3_n41/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 04:06:03,880 - INFO - Training completed for config s3_n41:
  Training time: 0:02:10
  Final validation loss: 9.577223
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 2.98e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n41/checkpoint.bin
2024-11-21 04:06:03,881 - INFO - 
Configuration s3_n41 (bracket_3_round_1):
  Hyperparameters: {
  "learning_rate": "0.00025759461334135697",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n41",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n41/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:02:10
  Validation Loss: 9.577223
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.98e-05
2024-11-21 04:06:03,881 - INFO - 
Eliminating 11 configurations:
  Surviving: 5
2024-11-21 04:06:05,499 - INFO - 
Bracket 3, Round 2:
  Active configs: 5
  Iterations: 243
2024-11-21 04:06:05,500 - INFO - 
Starting training for config s3_n46:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n46/checkpoint.bin
2024-11-21 04:06:05,500 - INFO - Running command: ./train_gpt2cu -l 0.0009396616173600525 -o hyperband_runs_20241120_172038/run_s3_n46 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s3_n46/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 04:12:22,664 - INFO - Training completed for config s3_n46:
  Training time: 0:06:17
  Final validation loss: 6.353650
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 3.26e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n46/checkpoint.bin
2024-11-21 04:12:22,664 - INFO - 
Configuration s3_n46 (bracket_3_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009396616173600525",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n46",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n46/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.353650
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.26e-04
2024-11-21 04:12:22,664 - INFO - 
Starting training for config s3_n9:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n9/checkpoint.bin
2024-11-21 04:12:22,664 - INFO - Running command: ./train_gpt2cu -l 0.0009261629924601716 -o hyperband_runs_20241120_172038/run_s3_n9 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s3_n9/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 04:18:39,834 - INFO - Training completed for config s3_n9:
  Training time: 0:06:17
  Final validation loss: 6.360703
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 3.22e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n9/checkpoint.bin
2024-11-21 04:18:39,834 - INFO - 
Configuration s3_n9 (bracket_3_round_2):
  Hyperparameters: {
  "learning_rate": "0.0009261629924601716",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n9",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n9/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.360703
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.22e-04
2024-11-21 04:18:39,834 - INFO - 
Starting training for config s3_n31:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n31/checkpoint.bin
2024-11-21 04:18:39,834 - INFO - Running command: ./train_gpt2cu -l 0.0007874894604926768 -o hyperband_runs_20241120_172038/run_s3_n31 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s3_n31/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 04:24:57,019 - INFO - Training completed for config s3_n31:
  Training time: 0:06:17
  Final validation loss: 6.430570
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 2.73e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n31/checkpoint.bin
2024-11-21 04:24:57,020 - INFO - 
Configuration s3_n31 (bracket_3_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007874894604926768",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n31",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n31/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.430570
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.73e-04
2024-11-21 04:24:57,020 - INFO - 
Starting training for config s3_n43:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n43/checkpoint.bin
2024-11-21 04:24:57,020 - INFO - Running command: ./train_gpt2cu -l 0.0007780267326422377 -o hyperband_runs_20241120_172038/run_s3_n43 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s3_n43/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 04:31:14,243 - INFO - Training completed for config s3_n43:
  Training time: 0:06:17
  Final validation loss: 6.441910
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 2.70e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n43/checkpoint.bin
2024-11-21 04:31:14,243 - INFO - 
Configuration s3_n43 (bracket_3_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007780267326422377",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n43",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n43/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.441910
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.70e-04
2024-11-21 04:31:14,243 - INFO - 
Starting training for config s3_n12:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n12/checkpoint.bin
2024-11-21 04:31:14,243 - INFO - Running command: ./train_gpt2cu -l 0.0007432340609240755 -o hyperband_runs_20241120_172038/run_s3_n12 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s3_n12/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 04:37:31,420 - INFO - Training completed for config s3_n12:
  Training time: 0:06:17
  Final validation loss: 6.456295
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 2.58e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s3_n12/checkpoint.bin
2024-11-21 04:37:31,420 - INFO - 
Configuration s3_n12 (bracket_3_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007432340609240755",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n12",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n12/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.456295
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.58e-04
2024-11-21 04:37:31,420 - INFO - 
Eliminating 4 configurations:
  Surviving: 1
2024-11-21 04:37:32,343 - INFO - 
Bracket 3, Round 3:
  Active configs: 1
  Iterations: 729
2024-11-21 04:37:32,343 - INFO - 
Starting training for config s3_n46:
  Iterations: 729
  Previous iterations: 243
  Previous checkpoint: hyperband_runs_20241120_172038/run_s3_n46/checkpoint.bin
2024-11-21 04:37:32,343 - INFO - Running command: ./train_gpt2cu -l 0.0009396616173600525 -o hyperband_runs_20241120_172038/run_s3_n46 -x 729 -n 729 -y 1 -e hyperband_runs_20241120_172038/run_s3_n46/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 04:37:33,151 - ERROR - Error training config s3_n46:
  stdout: Multi-GPU support is disabled. Using a single GPU.
+-----------------------+----------------------------------------------------+
| Parameter             | Value                                              |
+-----------------------+----------------------------------------------------+
| train data pattern    | data/fineweb_train_*.bin                           |
| val data pattern      | data/fineweb_val_*.bin                             |
| output log dir        | hyperband_runs_20241120_172038/run_s3_n46          |
| checkpoint_every      | 729                                                |
| resume                | 1                                                  |
| micro batch size B    | 64                                                 |
| sequence length T     | 1024                                               |
| total batch size      | 524288                                             |
| LR scheduler          | cosine                                             |
| learning rate (LR)    | 9.396616e-04                                       |
| warmup iterations     | 700                                                |
| final LR fraction     | 0.000000e+00                                       |
| weight decay          | 1.000000e-01                                       |
| skip update lossz     | 0.000000                                           |
| skip update gradz     | 0.000000                                           |
| max_steps             | 729                                                |
| val_loss_every        | 250                                                |
| val_max_steps         | 20                                                 |
| sample_every          | 20000                                              |
| genT                  | 64                                                 |
| overfit_single_batch  | 0                                                  |
| use_master_weights    | enabled                                            |
| gelu_fusion           | 0                                                  |
| recompute             | 1                                                  |
+-----------------------+----------------------------------------------------+
| device                | NVIDIA A10G                                        |
| peak TFlops           | -1.0                                               |
| precision             | BF16                                               |
+-----------------------+----------------------------------------------------+
| weight init method    | intermediate checkpoint                            |
| max_sequence_length T | 1024                                               |
| vocab_size V          | 50257                                              |
| padded_vocab_size Vp  | 50304                                              |
| num_layers L          | 6                                                  |
| num_heads NH          | 6                                                  |
| channels C            | 384                                                |
| num_parameters        | 30357504                                           |
+-----------------------+----------------------------------------------------+
| train_num_batches     | 729                                                |
| val_num_batches       | 20                                                 |
+-----------------------+----------------------------------------------------+
| run hellaswag         | no                                                 |
+-----------------------+----------------------------------------------------+
| num_processes         | 1                                                  |
| zero_stage            | 1                                                  |
+-----------------------+----------------------------------------------------+
num_parameters: 30357504 => bytes: 60715008
allocated 57 MiB for model parameters
batch_size B=64 * seq_len T=1024 * num_processes=1 and total_batch_size=524288
=> setting gr
  stderr: train_gpt2cu: train_gpt2.cu:1246: void load_state(int*, GPT2*, DataLoader*, const char*): Assertion `shard_num_samples == loader->shard_num_samples' failed.

2024-11-21 04:37:33,152 - INFO - 
Configuration s3_n46 (bracket_3_round_3):
  Hyperparameters: {
  "learning_rate": "0.0009396616173600525",
  "output_dir": "hyperband_runs_20241120_172038/run_s3_n46",
  "max_steps": "729",
  "checkpoint_every": "729",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s3_n46/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 729
  Total iterations: 243
  Training time: 0:00:00
  Validation Loss: inf
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 0.00e+00
2024-11-21 04:37:33,152 - INFO - 
Bracket 2:
  Initial configurations: 21
  Initial iterations: 81
2024-11-21 04:37:33,152 - INFO - 
Bracket 2, Round 0:
  Active configs: 21
  Iterations: 81
2024-11-21 04:37:33,152 - INFO - 
Starting training for config s2_n0:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 04:37:33,152 - INFO - Running command: ./train_gpt2cu -l 0.00012782566368280183 -o hyperband_runs_20241120_172038/run_s2_n0 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 04:40:46,891 - INFO - Training completed for config s2_n0:
  Training time: 0:03:13
  Final validation loss: 9.914272
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.48e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n0/checkpoint.bin
2024-11-21 04:40:46,891 - INFO - 
Configuration s2_n0 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "0.00012782566368280183",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n0",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 9.914272
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.48e-05
2024-11-21 04:40:46,891 - INFO - 
Starting training for config s2_n1:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 04:40:46,891 - INFO - Running command: ./train_gpt2cu -l 9.108816642221785e-05 -o hyperband_runs_20241120_172038/run_s2_n1 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 04:44:00,615 - INFO - Training completed for config s2_n1:
  Training time: 0:03:13
  Final validation loss: 10.024808
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.05e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n1/checkpoint.bin
2024-11-21 04:44:00,615 - INFO - 
Configuration s2_n1 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "9.108816642221785e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n1",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 10.024808
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.05e-05
2024-11-21 04:44:00,615 - INFO - 
Starting training for config s2_n2:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 04:44:00,615 - INFO - Running command: ./train_gpt2cu -l 0.00011043728721533223 -o hyperband_runs_20241120_172038/run_s2_n2 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 04:47:14,314 - INFO - Training completed for config s2_n2:
  Training time: 0:03:13
  Final validation loss: 9.965635
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.28e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n2/checkpoint.bin
2024-11-21 04:47:14,314 - INFO - 
Configuration s2_n2 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "0.00011043728721533223",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n2",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 9.965635
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.28e-05
2024-11-21 04:47:14,314 - INFO - 
Starting training for config s2_n3:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 04:47:14,314 - INFO - Running command: ./train_gpt2cu -l 0.0004345554056227203 -o hyperband_runs_20241120_172038/run_s2_n3 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 04:50:28,009 - INFO - Training completed for config s2_n3:
  Training time: 0:03:13
  Final validation loss: 9.207048
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 5.03e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n3/checkpoint.bin
2024-11-21 04:50:28,009 - INFO - 
Configuration s2_n3 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004345554056227203",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n3",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 9.207048
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.03e-05
2024-11-21 04:50:28,009 - INFO - 
Starting training for config s2_n4:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 04:50:28,009 - INFO - Running command: ./train_gpt2cu -l 9.386885677554732e-05 -o hyperband_runs_20241120_172038/run_s2_n4 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 04:53:41,694 - INFO - Training completed for config s2_n4:
  Training time: 0:03:13
  Final validation loss: 10.016444
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.09e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n4/checkpoint.bin
2024-11-21 04:53:41,694 - INFO - 
Configuration s2_n4 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "9.386885677554732e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n4",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 10.016444
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.09e-05
2024-11-21 04:53:41,694 - INFO - 
Starting training for config s2_n5:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 04:53:41,695 - INFO - Running command: ./train_gpt2cu -l 0.00044807871560787756 -o hyperband_runs_20241120_172038/run_s2_n5 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 04:56:55,384 - INFO - Training completed for config s2_n5:
  Training time: 0:03:13
  Final validation loss: 9.181038
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 5.18e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n5/checkpoint.bin
2024-11-21 04:56:55,385 - INFO - 
Configuration s2_n5 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "0.00044807871560787756",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n5",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 9.181038
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.18e-05
2024-11-21 04:56:55,385 - INFO - 
Starting training for config s2_n6:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 04:56:55,385 - INFO - Running command: ./train_gpt2cu -l 0.0001559789373248807 -o hyperband_runs_20241120_172038/run_s2_n6 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:00:09,100 - INFO - Training completed for config s2_n6:
  Training time: 0:03:13
  Final validation loss: 9.834875
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.80e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n6/checkpoint.bin
2024-11-21 05:00:09,101 - INFO - 
Configuration s2_n6 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001559789373248807",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n6",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 9.834875
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.80e-05
2024-11-21 05:00:09,101 - INFO - 
Starting training for config s2_n7:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 05:00:09,101 - INFO - Running command: ./train_gpt2cu -l 1.486037909486877e-05 -o hyperband_runs_20241120_172038/run_s2_n7 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:03:22,763 - INFO - Training completed for config s2_n7:
  Training time: 0:03:13
  Final validation loss: 10.456037
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.72e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n7/checkpoint.bin
2024-11-21 05:03:22,763 - INFO - 
Configuration s2_n7 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "1.486037909486877e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n7",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 10.456037
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.72e-06
2024-11-21 05:03:22,763 - INFO - 
Starting training for config s2_n8:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 05:03:22,763 - INFO - Running command: ./train_gpt2cu -l 1.6592141598775738e-05 -o hyperband_runs_20241120_172038/run_s2_n8 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:06:36,446 - INFO - Training completed for config s2_n8:
  Training time: 0:03:13
  Final validation loss: 10.424629
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.92e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n8/checkpoint.bin
2024-11-21 05:06:36,446 - INFO - 
Configuration s2_n8 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "1.6592141598775738e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n8",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 10.424629
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.92e-06
2024-11-21 05:06:36,446 - INFO - 
Starting training for config s2_n9:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 05:06:36,447 - INFO - Running command: ./train_gpt2cu -l 0.0003369961974673805 -o hyperband_runs_20241120_172038/run_s2_n9 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:09:50,126 - INFO - Training completed for config s2_n9:
  Training time: 0:03:13
  Final validation loss: 9.403521
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 3.90e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n9/checkpoint.bin
2024-11-21 05:09:50,126 - INFO - 
Configuration s2_n9 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003369961974673805",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n9",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 9.403521
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.90e-05
2024-11-21 05:09:50,126 - INFO - 
Starting training for config s2_n10:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 05:09:50,126 - INFO - Running command: ./train_gpt2cu -l 4.528618182584758e-05 -o hyperband_runs_20241120_172038/run_s2_n10 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:13:03,803 - INFO - Training completed for config s2_n10:
  Training time: 0:03:13
  Final validation loss: 10.179125
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 5.24e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n10/checkpoint.bin
2024-11-21 05:13:03,803 - INFO - 
Configuration s2_n10 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "4.528618182584758e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n10",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 10.179125
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.24e-06
2024-11-21 05:13:03,803 - INFO - 
Starting training for config s2_n11:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 05:13:03,804 - INFO - Running command: ./train_gpt2cu -l 4.572644899684557e-05 -o hyperband_runs_20241120_172038/run_s2_n11 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:16:17,480 - INFO - Training completed for config s2_n11:
  Training time: 0:03:13
  Final validation loss: 10.177140
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 5.29e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n11/checkpoint.bin
2024-11-21 05:16:17,480 - INFO - 
Configuration s2_n11 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "4.572644899684557e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n11",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 10.177140
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.29e-06
2024-11-21 05:16:17,480 - INFO - 
Starting training for config s2_n12:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 05:16:17,480 - INFO - Running command: ./train_gpt2cu -l 2.7614265428340182e-05 -o hyperband_runs_20241120_172038/run_s2_n12 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:19:31,180 - INFO - Training completed for config s2_n12:
  Training time: 0:03:13
  Final validation loss: 10.287085
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 3.20e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n12/checkpoint.bin
2024-11-21 05:19:31,180 - INFO - 
Configuration s2_n12 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "2.7614265428340182e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n12",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 10.287085
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.20e-06
2024-11-21 05:19:31,180 - INFO - 
Starting training for config s2_n13:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 05:19:31,180 - INFO - Running command: ./train_gpt2cu -l 1.8433622341218664e-05 -o hyperband_runs_20241120_172038/run_s2_n13 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:22:44,831 - INFO - Training completed for config s2_n13:
  Training time: 0:03:13
  Final validation loss: 10.395007
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 2.13e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n13/checkpoint.bin
2024-11-21 05:22:44,831 - INFO - 
Configuration s2_n13 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "1.8433622341218664e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n13",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 10.395007
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.13e-06
2024-11-21 05:22:44,831 - INFO - 
Starting training for config s2_n14:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 05:22:44,832 - INFO - Running command: ./train_gpt2cu -l 0.0005163150139135287 -o hyperband_runs_20241120_172038/run_s2_n14 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:25:58,497 - INFO - Training completed for config s2_n14:
  Training time: 0:03:13
  Final validation loss: 9.052608
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 5.97e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n14/checkpoint.bin
2024-11-21 05:25:58,497 - INFO - 
Configuration s2_n14 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005163150139135287",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n14",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 9.052608
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.97e-05
2024-11-21 05:25:58,498 - INFO - 
Starting training for config s2_n15:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 05:25:58,498 - INFO - Running command: ./train_gpt2cu -l 0.00013372844661052808 -o hyperband_runs_20241120_172038/run_s2_n15 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:29:12,121 - INFO - Training completed for config s2_n15:
  Training time: 0:03:13
  Final validation loss: 9.897632
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.55e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n15/checkpoint.bin
2024-11-21 05:29:12,121 - INFO - 
Configuration s2_n15 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013372844661052808",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n15",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 9.897632
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.55e-05
2024-11-21 05:29:12,121 - INFO - 
Starting training for config s2_n16:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 05:29:12,121 - INFO - Running command: ./train_gpt2cu -l 1.0415187475666411e-05 -o hyperband_runs_20241120_172038/run_s2_n16 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:32:25,770 - INFO - Training completed for config s2_n16:
  Training time: 0:03:13
  Final validation loss: 10.553240
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.21e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n16/checkpoint.bin
2024-11-21 05:32:25,771 - INFO - 
Configuration s2_n16 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "1.0415187475666411e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n16",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 10.553240
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.21e-06
2024-11-21 05:32:25,771 - INFO - 
Starting training for config s2_n17:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 05:32:25,771 - INFO - Running command: ./train_gpt2cu -l 0.0007712588328671406 -o hyperband_runs_20241120_172038/run_s2_n17 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:35:39,420 - INFO - Training completed for config s2_n17:
  Training time: 0:03:13
  Final validation loss: 8.616217
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 8.92e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n17/checkpoint.bin
2024-11-21 05:35:39,420 - INFO - 
Configuration s2_n17 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "0.0007712588328671406",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n17",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 8.616217
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.92e-05
2024-11-21 05:35:39,420 - INFO - 
Starting training for config s2_n18:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 05:35:39,420 - INFO - Running command: ./train_gpt2cu -l 0.0006490549217604945 -o hyperband_runs_20241120_172038/run_s2_n18 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:38:53,095 - INFO - Training completed for config s2_n18:
  Training time: 0:03:13
  Final validation loss: 8.815942
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 7.51e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n18/checkpoint.bin
2024-11-21 05:38:53,095 - INFO - 
Configuration s2_n18 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "0.0006490549217604945",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n18",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 8.815942
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 7.51e-05
2024-11-21 05:38:53,095 - INFO - 
Starting training for config s2_n19:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 05:38:53,095 - INFO - Running command: ./train_gpt2cu -l 0.0003084367014008861 -o hyperband_runs_20241120_172038/run_s2_n19 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:42:06,768 - INFO - Training completed for config s2_n19:
  Training time: 0:03:13
  Final validation loss: 9.463743
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 3.57e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n19/checkpoint.bin
2024-11-21 05:42:06,769 - INFO - 
Configuration s2_n19 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003084367014008861",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n19",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 9.463743
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.57e-05
2024-11-21 05:42:06,769 - INFO - 
Starting training for config s2_n20:
  Iterations: 81
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 05:42:06,769 - INFO - Running command: ./train_gpt2cu -l 0.0001469992535501845 -o hyperband_runs_20241120_172038/run_s2_n20 -x 81 -n 81 -y 0 -b 64 -d 524288 -h 0
2024-11-21 05:45:20,420 - INFO - Training completed for config s2_n20:
  Training time: 0:03:13
  Final validation loss: 9.860003
  Hellaswag accuracy: 0.00%
  Total iterations: 81
  Maximum learning rate: 1.70e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n20/checkpoint.bin
2024-11-21 05:45:20,420 - INFO - 
Configuration s2_n20 (bracket_2_round_0):
  Hyperparameters: {
  "learning_rate": "0.0001469992535501845",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n20",
  "max_steps": "81",
  "checkpoint_every": "81",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 81
  Total iterations: 81
  Training time: 0:03:13
  Validation Loss: 9.860003
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.70e-05
2024-11-21 05:45:20,420 - INFO - 
Eliminating 14 configurations:
  Surviving: 7
2024-11-21 05:45:21,729 - INFO - 
Bracket 2, Round 1:
  Active configs: 7
  Iterations: 243
2024-11-21 05:45:21,729 - INFO - 
Starting training for config s2_n17:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s2_n17/checkpoint.bin
2024-11-21 05:45:21,729 - INFO - Running command: ./train_gpt2cu -l 0.0007712588328671406 -o hyperband_runs_20241120_172038/run_s2_n17 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s2_n17/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 05:51:38,866 - INFO - Training completed for config s2_n17:
  Training time: 0:06:17
  Final validation loss: 6.442661
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 2.68e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n17/checkpoint.bin
2024-11-21 05:51:38,866 - INFO - 
Configuration s2_n17 (bracket_2_round_1):
  Hyperparameters: {
  "learning_rate": "0.0007712588328671406",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n17",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s2_n17/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.442661
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.68e-04
2024-11-21 05:51:38,867 - INFO - 
Starting training for config s2_n18:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s2_n18/checkpoint.bin
2024-11-21 05:51:38,867 - INFO - Running command: ./train_gpt2cu -l 0.0006490549217604945 -o hyperband_runs_20241120_172038/run_s2_n18 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s2_n18/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 05:57:56,067 - INFO - Training completed for config s2_n18:
  Training time: 0:06:17
  Final validation loss: 6.514276
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 2.25e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n18/checkpoint.bin
2024-11-21 05:57:56,067 - INFO - 
Configuration s2_n18 (bracket_2_round_1):
  Hyperparameters: {
  "learning_rate": "0.0006490549217604945",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n18",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s2_n18/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.514276
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.25e-04
2024-11-21 05:57:56,068 - INFO - 
Starting training for config s2_n14:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s2_n14/checkpoint.bin
2024-11-21 05:57:56,068 - INFO - Running command: ./train_gpt2cu -l 0.0005163150139135287 -o hyperband_runs_20241120_172038/run_s2_n14 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s2_n14/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 06:04:13,255 - INFO - Training completed for config s2_n14:
  Training time: 0:06:17
  Final validation loss: 6.626677
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 1.79e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n14/checkpoint.bin
2024-11-21 06:04:13,255 - INFO - 
Configuration s2_n14 (bracket_2_round_1):
  Hyperparameters: {
  "learning_rate": "0.0005163150139135287",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n14",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s2_n14/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.626677
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.79e-04
2024-11-21 06:04:13,255 - INFO - 
Starting training for config s2_n5:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s2_n5/checkpoint.bin
2024-11-21 06:04:13,255 - INFO - Running command: ./train_gpt2cu -l 0.00044807871560787756 -o hyperband_runs_20241120_172038/run_s2_n5 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s2_n5/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 06:10:30,401 - INFO - Training completed for config s2_n5:
  Training time: 0:06:17
  Final validation loss: 6.711439
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 1.56e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n5/checkpoint.bin
2024-11-21 06:10:30,402 - INFO - 
Configuration s2_n5 (bracket_2_round_1):
  Hyperparameters: {
  "learning_rate": "0.00044807871560787756",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n5",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s2_n5/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.711439
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.56e-04
2024-11-21 06:10:30,402 - INFO - 
Starting training for config s2_n3:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s2_n3/checkpoint.bin
2024-11-21 06:10:30,402 - INFO - Running command: ./train_gpt2cu -l 0.0004345554056227203 -o hyperband_runs_20241120_172038/run_s2_n3 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s2_n3/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 06:16:47,551 - INFO - Training completed for config s2_n3:
  Training time: 0:06:17
  Final validation loss: 6.727817
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 1.51e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n3/checkpoint.bin
2024-11-21 06:16:47,551 - INFO - 
Configuration s2_n3 (bracket_2_round_1):
  Hyperparameters: {
  "learning_rate": "0.0004345554056227203",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n3",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s2_n3/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.727817
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.51e-04
2024-11-21 06:16:47,551 - INFO - 
Starting training for config s2_n9:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s2_n9/checkpoint.bin
2024-11-21 06:16:47,551 - INFO - Running command: ./train_gpt2cu -l 0.0003369961974673805 -o hyperband_runs_20241120_172038/run_s2_n9 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s2_n9/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 06:23:04,701 - INFO - Training completed for config s2_n9:
  Training time: 0:06:17
  Final validation loss: 6.916255
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 1.17e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n9/checkpoint.bin
2024-11-21 06:23:04,701 - INFO - 
Configuration s2_n9 (bracket_2_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003369961974673805",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n9",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s2_n9/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.916255
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.17e-04
2024-11-21 06:23:04,701 - INFO - 
Starting training for config s2_n19:
  Iterations: 243
  Previous iterations: 81
  Previous checkpoint: hyperband_runs_20241120_172038/run_s2_n19/checkpoint.bin
2024-11-21 06:23:04,702 - INFO - Running command: ./train_gpt2cu -l 0.0003084367014008861 -o hyperband_runs_20241120_172038/run_s2_n19 -x 243 -n 243 -y 1 -e hyperband_runs_20241120_172038/run_s2_n19/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 06:29:21,821 - INFO - Training completed for config s2_n19:
  Training time: 0:06:17
  Final validation loss: 6.986705
  Hellaswag accuracy: 0.00%
  Total iterations: 243
  Maximum learning rate: 1.07e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s2_n19/checkpoint.bin
2024-11-21 06:29:21,821 - INFO - 
Configuration s2_n19 (bracket_2_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003084367014008861",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n19",
  "max_steps": "243",
  "checkpoint_every": "243",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s2_n19/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 243
  Total iterations: 243
  Training time: 0:06:17
  Validation Loss: 6.986705
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.07e-04
2024-11-21 06:29:21,821 - INFO - 
Eliminating 5 configurations:
  Surviving: 2
2024-11-21 06:29:22,764 - INFO - 
Bracket 2, Round 2:
  Active configs: 2
  Iterations: 729
2024-11-21 06:29:22,764 - INFO - 
Starting training for config s2_n17:
  Iterations: 729
  Previous iterations: 243
  Previous checkpoint: hyperband_runs_20241120_172038/run_s2_n17/checkpoint.bin
2024-11-21 06:29:22,764 - INFO - Running command: ./train_gpt2cu -l 0.0007712588328671406 -o hyperband_runs_20241120_172038/run_s2_n17 -x 729 -n 729 -y 1 -e hyperband_runs_20241120_172038/run_s2_n17/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 06:29:23,569 - ERROR - Error training config s2_n17:
  stdout: Multi-GPU support is disabled. Using a single GPU.
+-----------------------+----------------------------------------------------+
| Parameter             | Value                                              |
+-----------------------+----------------------------------------------------+
| train data pattern    | data/fineweb_train_*.bin                           |
| val data pattern      | data/fineweb_val_*.bin                             |
| output log dir        | hyperband_runs_20241120_172038/run_s2_n17          |
| checkpoint_every      | 729                                                |
| resume                | 1                                                  |
| micro batch size B    | 64                                                 |
| sequence length T     | 1024                                               |
| total batch size      | 524288                                             |
| LR scheduler          | cosine                                             |
| learning rate (LR)    | 7.712588e-04                                       |
| warmup iterations     | 700                                                |
| final LR fraction     | 0.000000e+00                                       |
| weight decay          | 1.000000e-01                                       |
| skip update lossz     | 0.000000                                           |
| skip update gradz     | 0.000000                                           |
| max_steps             | 729                                                |
| val_loss_every        | 250                                                |
| val_max_steps         | 20                                                 |
| sample_every          | 20000                                              |
| genT                  | 64                                                 |
| overfit_single_batch  | 0                                                  |
| use_master_weights    | enabled                                            |
| gelu_fusion           | 0                                                  |
| recompute             | 1                                                  |
+-----------------------+----------------------------------------------------+
| device                | NVIDIA A10G                                        |
| peak TFlops           | -1.0                                               |
| precision             | BF16                                               |
+-----------------------+----------------------------------------------------+
| weight init method    | intermediate checkpoint                            |
| max_sequence_length T | 1024                                               |
| vocab_size V          | 50257                                              |
| padded_vocab_size Vp  | 50304                                              |
| num_layers L          | 6                                                  |
| num_heads NH          | 6                                                  |
| channels C            | 384                                                |
| num_parameters        | 30357504                                           |
+-----------------------+----------------------------------------------------+
| train_num_batches     | 729                                                |
| val_num_batches       | 20                                                 |
+-----------------------+----------------------------------------------------+
| run hellaswag         | no                                                 |
+-----------------------+----------------------------------------------------+
| num_processes         | 1                                                  |
| zero_stage            | 1                                                  |
+-----------------------+----------------------------------------------------+
num_parameters: 30357504 => bytes: 60715008
allocated 57 MiB for model parameters
batch_size B=64 * seq_len T=1024 * num_processes=1 and total_batch_size=524288
=> setting gr
  stderr: train_gpt2cu: train_gpt2.cu:1246: void load_state(int*, GPT2*, DataLoader*, const char*): Assertion `shard_num_samples == loader->shard_num_samples' failed.

2024-11-21 06:29:23,570 - INFO - 
Configuration s2_n17 (bracket_2_round_2):
  Hyperparameters: {
  "learning_rate": "0.0007712588328671406",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n17",
  "max_steps": "729",
  "checkpoint_every": "729",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s2_n17/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 729
  Total iterations: 243
  Training time: 0:00:00
  Validation Loss: inf
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 0.00e+00
2024-11-21 06:29:23,570 - INFO - 
Starting training for config s2_n18:
  Iterations: 729
  Previous iterations: 243
  Previous checkpoint: hyperband_runs_20241120_172038/run_s2_n18/checkpoint.bin
2024-11-21 06:29:23,570 - INFO - Running command: ./train_gpt2cu -l 0.0006490549217604945 -o hyperband_runs_20241120_172038/run_s2_n18 -x 729 -n 729 -y 1 -e hyperband_runs_20241120_172038/run_s2_n18/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 06:29:24,399 - ERROR - Error training config s2_n18:
  stdout: Multi-GPU support is disabled. Using a single GPU.
+-----------------------+----------------------------------------------------+
| Parameter             | Value                                              |
+-----------------------+----------------------------------------------------+
| train data pattern    | data/fineweb_train_*.bin                           |
| val data pattern      | data/fineweb_val_*.bin                             |
| output log dir        | hyperband_runs_20241120_172038/run_s2_n18          |
| checkpoint_every      | 729                                                |
| resume                | 1                                                  |
| micro batch size B    | 64                                                 |
| sequence length T     | 1024                                               |
| total batch size      | 524288                                             |
| LR scheduler          | cosine                                             |
| learning rate (LR)    | 6.490549e-04                                       |
| warmup iterations     | 700                                                |
| final LR fraction     | 0.000000e+00                                       |
| weight decay          | 1.000000e-01                                       |
| skip update lossz     | 0.000000                                           |
| skip update gradz     | 0.000000                                           |
| max_steps             | 729                                                |
| val_loss_every        | 250                                                |
| val_max_steps         | 20                                                 |
| sample_every          | 20000                                              |
| genT                  | 64                                                 |
| overfit_single_batch  | 0                                                  |
| use_master_weights    | enabled                                            |
| gelu_fusion           | 0                                                  |
| recompute             | 1                                                  |
+-----------------------+----------------------------------------------------+
| device                | NVIDIA A10G                                        |
| peak TFlops           | -1.0                                               |
| precision             | BF16                                               |
+-----------------------+----------------------------------------------------+
| weight init method    | intermediate checkpoint                            |
| max_sequence_length T | 1024                                               |
| vocab_size V          | 50257                                              |
| padded_vocab_size Vp  | 50304                                              |
| num_layers L          | 6                                                  |
| num_heads NH          | 6                                                  |
| channels C            | 384                                                |
| num_parameters        | 30357504                                           |
+-----------------------+----------------------------------------------------+
| train_num_batches     | 729                                                |
| val_num_batches       | 20                                                 |
+-----------------------+----------------------------------------------------+
| run hellaswag         | no                                                 |
+-----------------------+----------------------------------------------------+
| num_processes         | 1                                                  |
| zero_stage            | 1                                                  |
+-----------------------+----------------------------------------------------+
num_parameters: 30357504 => bytes: 60715008
allocated 57 MiB for model parameters
batch_size B=64 * seq_len T=1024 * num_processes=1 and total_batch_size=524288
=> setting gr
  stderr: train_gpt2cu: train_gpt2.cu:1246: void load_state(int*, GPT2*, DataLoader*, const char*): Assertion `shard_num_samples == loader->shard_num_samples' failed.

2024-11-21 06:29:24,399 - INFO - 
Configuration s2_n18 (bracket_2_round_2):
  Hyperparameters: {
  "learning_rate": "0.0006490549217604945",
  "output_dir": "hyperband_runs_20241120_172038/run_s2_n18",
  "max_steps": "729",
  "checkpoint_every": "729",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s2_n18/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 729
  Total iterations: 243
  Training time: 0:00:00
  Validation Loss: inf
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 0.00e+00
2024-11-21 06:29:24,399 - INFO - 
Bracket 1:
  Initial configurations: 11
  Initial iterations: 245
2024-11-21 06:29:24,399 - INFO - 
Bracket 1, Round 0:
  Active configs: 11
  Iterations: 245
2024-11-21 06:29:24,399 - INFO - 
Starting training for config s1_n0:
  Iterations: 245
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 06:29:24,400 - INFO - Running command: ./train_gpt2cu -l 0.000898441541265866 -o hyperband_runs_20241120_172038/run_s1_n0 -x 245 -n 245 -y 0 -b 64 -d 524288 -h 0
2024-11-21 06:38:55,301 - INFO - Training completed for config s1_n0:
  Training time: 0:09:30
  Final validation loss: 6.365962
  Hellaswag accuracy: 0.00%
  Total iterations: 245
  Maximum learning rate: 3.14e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s1_n0/checkpoint.bin
2024-11-21 06:38:55,301 - INFO - 
Configuration s1_n0 (bracket_1_round_0):
  Hyperparameters: {
  "learning_rate": "0.000898441541265866",
  "output_dir": "hyperband_runs_20241120_172038/run_s1_n0",
  "max_steps": "245",
  "checkpoint_every": "245",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 245
  Total iterations: 245
  Training time: 0:09:30
  Validation Loss: 6.365962
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.14e-04
2024-11-21 06:38:55,301 - INFO - 
Starting training for config s1_n1:
  Iterations: 245
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 06:38:55,301 - INFO - Running command: ./train_gpt2cu -l 0.00013691230212764446 -o hyperband_runs_20241120_172038/run_s1_n1 -x 245 -n 245 -y 0 -b 64 -d 524288 -h 0
2024-11-21 06:48:25,937 - INFO - Training completed for config s1_n1:
  Training time: 0:09:30
  Final validation loss: 7.885308
  Hellaswag accuracy: 0.00%
  Total iterations: 245
  Maximum learning rate: 4.79e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s1_n1/checkpoint.bin
2024-11-21 06:48:25,937 - INFO - 
Configuration s1_n1 (bracket_1_round_0):
  Hyperparameters: {
  "learning_rate": "0.00013691230212764446",
  "output_dir": "hyperband_runs_20241120_172038/run_s1_n1",
  "max_steps": "245",
  "checkpoint_every": "245",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 245
  Total iterations: 245
  Training time: 0:09:30
  Validation Loss: 7.885308
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.79e-05
2024-11-21 06:48:25,938 - INFO - 
Starting training for config s1_n2:
  Iterations: 245
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 06:48:25,938 - INFO - Running command: ./train_gpt2cu -l 8.683278311619159e-05 -o hyperband_runs_20241120_172038/run_s1_n2 -x 245 -n 245 -y 0 -b 64 -d 524288 -h 0
2024-11-21 06:57:56,508 - INFO - Training completed for config s1_n2:
  Training time: 0:09:30
  Final validation loss: 8.508196
  Hellaswag accuracy: 0.00%
  Total iterations: 245
  Maximum learning rate: 3.04e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s1_n2/checkpoint.bin
2024-11-21 06:57:56,508 - INFO - 
Configuration s1_n2 (bracket_1_round_0):
  Hyperparameters: {
  "learning_rate": "8.683278311619159e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s1_n2",
  "max_steps": "245",
  "checkpoint_every": "245",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 245
  Total iterations: 245
  Training time: 0:09:30
  Validation Loss: 8.508196
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.04e-05
2024-11-21 06:57:56,508 - INFO - 
Starting training for config s1_n3:
  Iterations: 245
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 06:57:56,508 - INFO - Running command: ./train_gpt2cu -l 0.00042786948575192647 -o hyperband_runs_20241120_172038/run_s1_n3 -x 245 -n 245 -y 0 -b 64 -d 524288 -h 0
2024-11-21 07:07:27,121 - INFO - Training completed for config s1_n3:
  Training time: 0:09:30
  Final validation loss: 6.735625
  Hellaswag accuracy: 0.00%
  Total iterations: 245
  Maximum learning rate: 1.50e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s1_n3/checkpoint.bin
2024-11-21 07:07:27,122 - INFO - 
Configuration s1_n3 (bracket_1_round_0):
  Hyperparameters: {
  "learning_rate": "0.00042786948575192647",
  "output_dir": "hyperband_runs_20241120_172038/run_s1_n3",
  "max_steps": "245",
  "checkpoint_every": "245",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 245
  Total iterations: 245
  Training time: 0:09:30
  Validation Loss: 6.735625
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.50e-04
2024-11-21 07:07:27,122 - INFO - 
Starting training for config s1_n4:
  Iterations: 245
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 07:07:27,122 - INFO - Running command: ./train_gpt2cu -l 0.0003759415883226859 -o hyperband_runs_20241120_172038/run_s1_n4 -x 245 -n 245 -y 0 -b 64 -d 524288 -h 0
2024-11-21 07:16:57,786 - INFO - Training completed for config s1_n4:
  Training time: 0:09:30
  Final validation loss: 6.818033
  Hellaswag accuracy: 0.00%
  Total iterations: 245
  Maximum learning rate: 1.32e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s1_n4/checkpoint.bin
2024-11-21 07:16:57,786 - INFO - 
Configuration s1_n4 (bracket_1_round_0):
  Hyperparameters: {
  "learning_rate": "0.0003759415883226859",
  "output_dir": "hyperband_runs_20241120_172038/run_s1_n4",
  "max_steps": "245",
  "checkpoint_every": "245",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 245
  Total iterations: 245
  Training time: 0:09:30
  Validation Loss: 6.818033
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.32e-04
2024-11-21 07:16:57,786 - INFO - 
Starting training for config s1_n5:
  Iterations: 245
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 07:16:57,786 - INFO - Running command: ./train_gpt2cu -l 0.00024986121494422327 -o hyperband_runs_20241120_172038/run_s1_n5 -x 245 -n 245 -y 0 -b 64 -d 524288 -h 0
2024-11-21 07:26:28,260 - INFO - Training completed for config s1_n5:
  Training time: 0:09:30
  Final validation loss: 7.159318
  Hellaswag accuracy: 0.00%
  Total iterations: 245
  Maximum learning rate: 8.75e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s1_n5/checkpoint.bin
2024-11-21 07:26:28,260 - INFO - 
Configuration s1_n5 (bracket_1_round_0):
  Hyperparameters: {
  "learning_rate": "0.00024986121494422327",
  "output_dir": "hyperband_runs_20241120_172038/run_s1_n5",
  "max_steps": "245",
  "checkpoint_every": "245",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 245
  Total iterations: 245
  Training time: 0:09:30
  Validation Loss: 7.159318
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 8.75e-05
2024-11-21 07:26:28,260 - INFO - 
Starting training for config s1_n6:
  Iterations: 245
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 07:26:28,260 - INFO - Running command: ./train_gpt2cu -l 1.2849153464868345e-05 -o hyperband_runs_20241120_172038/run_s1_n6 -x 245 -n 245 -y 0 -b 64 -d 524288 -h 0
2024-11-21 07:35:58,761 - INFO - Training completed for config s1_n6:
  Training time: 0:09:30
  Final validation loss: 9.891838
  Hellaswag accuracy: 0.00%
  Total iterations: 245
  Maximum learning rate: 4.50e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s1_n6/checkpoint.bin
2024-11-21 07:35:58,761 - INFO - 
Configuration s1_n6 (bracket_1_round_0):
  Hyperparameters: {
  "learning_rate": "1.2849153464868345e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s1_n6",
  "max_steps": "245",
  "checkpoint_every": "245",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 245
  Total iterations: 245
  Training time: 0:09:30
  Validation Loss: 9.891838
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.50e-06
2024-11-21 07:35:58,761 - INFO - 
Starting training for config s1_n7:
  Iterations: 245
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 07:35:58,761 - INFO - Running command: ./train_gpt2cu -l 1.4411677733003698e-05 -o hyperband_runs_20241120_172038/run_s1_n7 -x 245 -n 245 -y 0 -b 64 -d 524288 -h 0
2024-11-21 07:45:29,238 - INFO - Training completed for config s1_n7:
  Training time: 0:09:30
  Final validation loss: 9.844313
  Hellaswag accuracy: 0.00%
  Total iterations: 245
  Maximum learning rate: 5.04e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s1_n7/checkpoint.bin
2024-11-21 07:45:29,238 - INFO - 
Configuration s1_n7 (bracket_1_round_0):
  Hyperparameters: {
  "learning_rate": "1.4411677733003698e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s1_n7",
  "max_steps": "245",
  "checkpoint_every": "245",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 245
  Total iterations: 245
  Training time: 0:09:30
  Validation Loss: 9.844313
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.04e-06
2024-11-21 07:45:29,238 - INFO - 
Starting training for config s1_n8:
  Iterations: 245
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 07:45:29,238 - INFO - Running command: ./train_gpt2cu -l 1.0706935152607095e-05 -o hyperband_runs_20241120_172038/run_s1_n8 -x 245 -n 245 -y 0 -b 64 -d 524288 -h 0
2024-11-21 07:54:59,732 - INFO - Training completed for config s1_n8:
  Training time: 0:09:30
  Final validation loss: 9.960435
  Hellaswag accuracy: 0.00%
  Total iterations: 245
  Maximum learning rate: 3.75e-06
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s1_n8/checkpoint.bin
2024-11-21 07:54:59,732 - INFO - 
Configuration s1_n8 (bracket_1_round_0):
  Hyperparameters: {
  "learning_rate": "1.0706935152607095e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s1_n8",
  "max_steps": "245",
  "checkpoint_every": "245",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 245
  Total iterations: 245
  Training time: 0:09:30
  Validation Loss: 9.960435
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 3.75e-06
2024-11-21 07:54:59,732 - INFO - 
Starting training for config s1_n9:
  Iterations: 245
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 07:54:59,732 - INFO - Running command: ./train_gpt2cu -l 0.000150921931970447 -o hyperband_runs_20241120_172038/run_s1_n9 -x 245 -n 245 -y 0 -b 64 -d 524288 -h 0
2024-11-21 08:04:30,227 - INFO - Training completed for config s1_n9:
  Training time: 0:09:30
  Final validation loss: 7.749087
  Hellaswag accuracy: 0.00%
  Total iterations: 245
  Maximum learning rate: 5.28e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s1_n9/checkpoint.bin
2024-11-21 08:04:30,227 - INFO - 
Configuration s1_n9 (bracket_1_round_0):
  Hyperparameters: {
  "learning_rate": "0.000150921931970447",
  "output_dir": "hyperband_runs_20241120_172038/run_s1_n9",
  "max_steps": "245",
  "checkpoint_every": "245",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 245
  Total iterations: 245
  Training time: 0:09:30
  Validation Loss: 7.749087
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.28e-05
2024-11-21 08:04:30,227 - INFO - 
Starting training for config s1_n10:
  Iterations: 245
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 08:04:30,228 - INFO - Running command: ./train_gpt2cu -l 4.769559197263193e-05 -o hyperband_runs_20241120_172038/run_s1_n10 -x 245 -n 245 -y 0 -b 64 -d 524288 -h 0
2024-11-21 08:14:00,729 - INFO - Training completed for config s1_n10:
  Training time: 0:09:30
  Final validation loss: 9.147501
  Hellaswag accuracy: 0.00%
  Total iterations: 245
  Maximum learning rate: 1.67e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s1_n10/checkpoint.bin
2024-11-21 08:14:00,730 - INFO - 
Configuration s1_n10 (bracket_1_round_0):
  Hyperparameters: {
  "learning_rate": "4.769559197263193e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s1_n10",
  "max_steps": "245",
  "checkpoint_every": "245",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 245
  Total iterations: 245
  Training time: 0:09:30
  Validation Loss: 9.147501
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.67e-05
2024-11-21 08:14:00,730 - INFO - 
Eliminating 8 configurations:
  Surviving: 3
2024-11-21 08:14:01,481 - INFO - 
Bracket 1, Round 1:
  Active configs: 3
  Iterations: 735
2024-11-21 08:14:01,481 - INFO - 
Starting training for config s1_n0:
  Iterations: 735
  Previous iterations: 245
  Previous checkpoint: hyperband_runs_20241120_172038/run_s1_n0/checkpoint.bin
2024-11-21 08:14:01,481 - INFO - Running command: ./train_gpt2cu -l 0.000898441541265866 -o hyperband_runs_20241120_172038/run_s1_n0 -x 735 -n 735 -y 1 -e hyperband_runs_20241120_172038/run_s1_n0/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 08:14:02,266 - ERROR - Error training config s1_n0:
  stdout: Multi-GPU support is disabled. Using a single GPU.
+-----------------------+----------------------------------------------------+
| Parameter             | Value                                              |
+-----------------------+----------------------------------------------------+
| train data pattern    | data/fineweb_train_*.bin                           |
| val data pattern      | data/fineweb_val_*.bin                             |
| output log dir        | hyperband_runs_20241120_172038/run_s1_n0           |
| checkpoint_every      | 735                                                |
| resume                | 1                                                  |
| micro batch size B    | 64                                                 |
| sequence length T     | 1024                                               |
| total batch size      | 524288                                             |
| LR scheduler          | cosine                                             |
| learning rate (LR)    | 8.984415e-04                                       |
| warmup iterations     | 700                                                |
| final LR fraction     | 0.000000e+00                                       |
| weight decay          | 1.000000e-01                                       |
| skip update lossz     | 0.000000                                           |
| skip update gradz     | 0.000000                                           |
| max_steps             | 735                                                |
| val_loss_every        | 250                                                |
| val_max_steps         | 20                                                 |
| sample_every          | 20000                                              |
| genT                  | 64                                                 |
| overfit_single_batch  | 0                                                  |
| use_master_weights    | enabled                                            |
| gelu_fusion           | 0                                                  |
| recompute             | 1                                                  |
+-----------------------+----------------------------------------------------+
| device                | NVIDIA A10G                                        |
| peak TFlops           | -1.0                                               |
| precision             | BF16                                               |
+-----------------------+----------------------------------------------------+
| weight init method    | intermediate checkpoint                            |
| max_sequence_length T | 1024                                               |
| vocab_size V          | 50257                                              |
| padded_vocab_size Vp  | 50304                                              |
| num_layers L          | 6                                                  |
| num_heads NH          | 6                                                  |
| channels C            | 384                                                |
| num_parameters        | 30357504                                           |
+-----------------------+----------------------------------------------------+
| train_num_batches     | 735                                                |
| val_num_batches       | 20                                                 |
+-----------------------+----------------------------------------------------+
| run hellaswag         | no                                                 |
+-----------------------+----------------------------------------------------+
| num_processes         | 1                                                  |
| zero_stage            | 1                                                  |
+-----------------------+----------------------------------------------------+
num_parameters: 30357504 => bytes: 60715008
allocated 57 MiB for model parameters
batch_size B=64 * seq_len T=1024 * num_processes=1 and total_batch_size=524288
=> setting gr
  stderr: train_gpt2cu: train_gpt2.cu:1246: void load_state(int*, GPT2*, DataLoader*, const char*): Assertion `shard_num_samples == loader->shard_num_samples' failed.

2024-11-21 08:14:02,266 - INFO - 
Configuration s1_n0 (bracket_1_round_1):
  Hyperparameters: {
  "learning_rate": "0.000898441541265866",
  "output_dir": "hyperband_runs_20241120_172038/run_s1_n0",
  "max_steps": "735",
  "checkpoint_every": "735",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s1_n0/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 735
  Total iterations: 245
  Training time: 0:00:00
  Validation Loss: inf
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 0.00e+00
2024-11-21 08:14:02,266 - INFO - 
Starting training for config s1_n3:
  Iterations: 735
  Previous iterations: 245
  Previous checkpoint: hyperband_runs_20241120_172038/run_s1_n3/checkpoint.bin
2024-11-21 08:14:02,267 - INFO - Running command: ./train_gpt2cu -l 0.00042786948575192647 -o hyperband_runs_20241120_172038/run_s1_n3 -x 735 -n 735 -y 1 -e hyperband_runs_20241120_172038/run_s1_n3/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 08:14:03,084 - ERROR - Error training config s1_n3:
  stdout: Multi-GPU support is disabled. Using a single GPU.
+-----------------------+----------------------------------------------------+
| Parameter             | Value                                              |
+-----------------------+----------------------------------------------------+
| train data pattern    | data/fineweb_train_*.bin                           |
| val data pattern      | data/fineweb_val_*.bin                             |
| output log dir        | hyperband_runs_20241120_172038/run_s1_n3           |
| checkpoint_every      | 735                                                |
| resume                | 1                                                  |
| micro batch size B    | 64                                                 |
| sequence length T     | 1024                                               |
| total batch size      | 524288                                             |
| LR scheduler          | cosine                                             |
| learning rate (LR)    | 4.278695e-04                                       |
| warmup iterations     | 700                                                |
| final LR fraction     | 0.000000e+00                                       |
| weight decay          | 1.000000e-01                                       |
| skip update lossz     | 0.000000                                           |
| skip update gradz     | 0.000000                                           |
| max_steps             | 735                                                |
| val_loss_every        | 250                                                |
| val_max_steps         | 20                                                 |
| sample_every          | 20000                                              |
| genT                  | 64                                                 |
| overfit_single_batch  | 0                                                  |
| use_master_weights    | enabled                                            |
| gelu_fusion           | 0                                                  |
| recompute             | 1                                                  |
+-----------------------+----------------------------------------------------+
| device                | NVIDIA A10G                                        |
| peak TFlops           | -1.0                                               |
| precision             | BF16                                               |
+-----------------------+----------------------------------------------------+
| weight init method    | intermediate checkpoint                            |
| max_sequence_length T | 1024                                               |
| vocab_size V          | 50257                                              |
| padded_vocab_size Vp  | 50304                                              |
| num_layers L          | 6                                                  |
| num_heads NH          | 6                                                  |
| channels C            | 384                                                |
| num_parameters        | 30357504                                           |
+-----------------------+----------------------------------------------------+
| train_num_batches     | 735                                                |
| val_num_batches       | 20                                                 |
+-----------------------+----------------------------------------------------+
| run hellaswag         | no                                                 |
+-----------------------+----------------------------------------------------+
| num_processes         | 1                                                  |
| zero_stage            | 1                                                  |
+-----------------------+----------------------------------------------------+
num_parameters: 30357504 => bytes: 60715008
allocated 57 MiB for model parameters
batch_size B=64 * seq_len T=1024 * num_processes=1 and total_batch_size=524288
=> setting gr
  stderr: train_gpt2cu: train_gpt2.cu:1246: void load_state(int*, GPT2*, DataLoader*, const char*): Assertion `shard_num_samples == loader->shard_num_samples' failed.

2024-11-21 08:14:03,084 - INFO - 
Configuration s1_n3 (bracket_1_round_1):
  Hyperparameters: {
  "learning_rate": "0.00042786948575192647",
  "output_dir": "hyperband_runs_20241120_172038/run_s1_n3",
  "max_steps": "735",
  "checkpoint_every": "735",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s1_n3/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 735
  Total iterations: 245
  Training time: 0:00:00
  Validation Loss: inf
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 0.00e+00
2024-11-21 08:14:03,084 - INFO - 
Starting training for config s1_n4:
  Iterations: 735
  Previous iterations: 245
  Previous checkpoint: hyperband_runs_20241120_172038/run_s1_n4/checkpoint.bin
2024-11-21 08:14:03,084 - INFO - Running command: ./train_gpt2cu -l 0.0003759415883226859 -o hyperband_runs_20241120_172038/run_s1_n4 -x 735 -n 735 -y 1 -e hyperband_runs_20241120_172038/run_s1_n4/checkpoint.bin -b 64 -d 524288 -h 0
2024-11-21 08:14:03,905 - ERROR - Error training config s1_n4:
  stdout: Multi-GPU support is disabled. Using a single GPU.
+-----------------------+----------------------------------------------------+
| Parameter             | Value                                              |
+-----------------------+----------------------------------------------------+
| train data pattern    | data/fineweb_train_*.bin                           |
| val data pattern      | data/fineweb_val_*.bin                             |
| output log dir        | hyperband_runs_20241120_172038/run_s1_n4           |
| checkpoint_every      | 735                                                |
| resume                | 1                                                  |
| micro batch size B    | 64                                                 |
| sequence length T     | 1024                                               |
| total batch size      | 524288                                             |
| LR scheduler          | cosine                                             |
| learning rate (LR)    | 3.759416e-04                                       |
| warmup iterations     | 700                                                |
| final LR fraction     | 0.000000e+00                                       |
| weight decay          | 1.000000e-01                                       |
| skip update lossz     | 0.000000                                           |
| skip update gradz     | 0.000000                                           |
| max_steps             | 735                                                |
| val_loss_every        | 250                                                |
| val_max_steps         | 20                                                 |
| sample_every          | 20000                                              |
| genT                  | 64                                                 |
| overfit_single_batch  | 0                                                  |
| use_master_weights    | enabled                                            |
| gelu_fusion           | 0                                                  |
| recompute             | 1                                                  |
+-----------------------+----------------------------------------------------+
| device                | NVIDIA A10G                                        |
| peak TFlops           | -1.0                                               |
| precision             | BF16                                               |
+-----------------------+----------------------------------------------------+
| weight init method    | intermediate checkpoint                            |
| max_sequence_length T | 1024                                               |
| vocab_size V          | 50257                                              |
| padded_vocab_size Vp  | 50304                                              |
| num_layers L          | 6                                                  |
| num_heads NH          | 6                                                  |
| channels C            | 384                                                |
| num_parameters        | 30357504                                           |
+-----------------------+----------------------------------------------------+
| train_num_batches     | 735                                                |
| val_num_batches       | 20                                                 |
+-----------------------+----------------------------------------------------+
| run hellaswag         | no                                                 |
+-----------------------+----------------------------------------------------+
| num_processes         | 1                                                  |
| zero_stage            | 1                                                  |
+-----------------------+----------------------------------------------------+
num_parameters: 30357504 => bytes: 60715008
allocated 57 MiB for model parameters
batch_size B=64 * seq_len T=1024 * num_processes=1 and total_batch_size=524288
=> setting gr
  stderr: train_gpt2cu: train_gpt2.cu:1246: void load_state(int*, GPT2*, DataLoader*, const char*): Assertion `shard_num_samples == loader->shard_num_samples' failed.

2024-11-21 08:14:03,906 - INFO - 
Configuration s1_n4 (bracket_1_round_1):
  Hyperparameters: {
  "learning_rate": "0.0003759415883226859",
  "output_dir": "hyperband_runs_20241120_172038/run_s1_n4",
  "max_steps": "735",
  "checkpoint_every": "735",
  "resume": "1",
  "checkpoint_path": "hyperband_runs_20241120_172038/run_s1_n4/checkpoint.bin",
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0",
  "train_data": "data/fineweb_train_*.bin",
  "val_data": "data/fineweb_val_*.bin",
  "tokenizer_path": "data/gpt2_tokenizer.bin"
}
  Current iterations: 735
  Total iterations: 245
  Training time: 0:00:00
  Validation Loss: inf
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 0.00e+00
2024-11-21 08:14:03,906 - INFO - 
Bracket 0:
  Initial configurations: 7
  Initial iterations: 735
2024-11-21 08:14:03,906 - INFO - 
Bracket 0, Round 0:
  Active configs: 7
  Iterations: 735
2024-11-21 08:14:03,906 - INFO - 
Starting training for config s0_n0:
  Iterations: 735
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 08:14:03,906 - INFO - Running command: ./train_gpt2cu -l 0.0005219286241044422 -o hyperband_runs_20241120_172038/run_s0_n0 -x 735 -n 735 -y 0 -b 64 -d 524288 -h 0
2024-11-21 08:42:28,446 - INFO - Training completed for config s0_n0:
  Training time: 0:28:24
  Final validation loss: 5.380595
  Hellaswag accuracy: 0.00%
  Total iterations: 735
  Maximum learning rate: 5.22e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s0_n0/checkpoint.bin
2024-11-21 08:42:28,447 - INFO - 
Configuration s0_n0 (bracket_0_round_0):
  Hyperparameters: {
  "learning_rate": "0.0005219286241044422",
  "output_dir": "hyperband_runs_20241120_172038/run_s0_n0",
  "max_steps": "735",
  "checkpoint_every": "735",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 735
  Total iterations: 735
  Training time: 0:28:24
  Validation Loss: 5.380595
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.22e-04
2024-11-21 08:42:28,447 - INFO - 
New best configuration found!
  Config ID: s0_n0
  Validation Loss: 5.380595
  Hellaswag Accuracy: 0.00%
  Training Time: 0:28:24
2024-11-21 08:42:28,447 - INFO - 
Starting training for config s0_n1:
  Iterations: 735
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 08:42:28,447 - INFO - Running command: ./train_gpt2cu -l 0.00015816169012591752 -o hyperband_runs_20241120_172038/run_s0_n1 -x 735 -n 735 -y 0 -b 64 -d 524288 -h 0
2024-11-21 09:10:49,588 - INFO - Training completed for config s0_n1:
  Training time: 0:28:21
  Final validation loss: 5.997062
  Hellaswag accuracy: 0.00%
  Total iterations: 735
  Maximum learning rate: 1.58e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s0_n1/checkpoint.bin
2024-11-21 09:10:49,588 - INFO - 
Configuration s0_n1 (bracket_0_round_0):
  Hyperparameters: {
  "learning_rate": "0.00015816169012591752",
  "output_dir": "hyperband_runs_20241120_172038/run_s0_n1",
  "max_steps": "735",
  "checkpoint_every": "735",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 735
  Total iterations: 735
  Training time: 0:28:21
  Validation Loss: 5.997062
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.58e-04
2024-11-21 09:10:49,589 - INFO - 
Starting training for config s0_n2:
  Iterations: 735
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 09:10:49,589 - INFO - Running command: ./train_gpt2cu -l 0.0004171294953452261 -o hyperband_runs_20241120_172038/run_s0_n2 -x 735 -n 735 -y 0 -b 64 -d 524288 -h 0
2024-11-21 09:39:10,643 - INFO - Training completed for config s0_n2:
  Training time: 0:28:21
  Final validation loss: 5.496952
  Hellaswag accuracy: 0.00%
  Total iterations: 735
  Maximum learning rate: 4.17e-04
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s0_n2/checkpoint.bin
2024-11-21 09:39:10,643 - INFO - 
Configuration s0_n2 (bracket_0_round_0):
  Hyperparameters: {
  "learning_rate": "0.0004171294953452261",
  "output_dir": "hyperband_runs_20241120_172038/run_s0_n2",
  "max_steps": "735",
  "checkpoint_every": "735",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 735
  Total iterations: 735
  Training time: 0:28:21
  Validation Loss: 5.496952
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 4.17e-04
2024-11-21 09:39:10,643 - INFO - 
Starting training for config s0_n3:
  Iterations: 735
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 09:39:10,643 - INFO - Running command: ./train_gpt2cu -l 2.6422369174019187e-05 -o hyperband_runs_20241120_172038/run_s0_n3 -x 735 -n 735 -y 0 -b 64 -d 524288 -h 0
2024-11-21 10:07:31,597 - INFO - Training completed for config s0_n3:
  Training time: 0:28:20
  Final validation loss: 7.158550
  Hellaswag accuracy: 0.00%
  Total iterations: 735
  Maximum learning rate: 2.64e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s0_n3/checkpoint.bin
2024-11-21 10:07:31,597 - INFO - 
Configuration s0_n3 (bracket_0_round_0):
  Hyperparameters: {
  "learning_rate": "2.6422369174019187e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s0_n3",
  "max_steps": "735",
  "checkpoint_every": "735",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 735
  Total iterations: 735
  Training time: 0:28:20
  Validation Loss: 7.158550
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 2.64e-05
2024-11-21 10:07:31,597 - INFO - 
Starting training for config s0_n4:
  Iterations: 735
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 10:07:31,597 - INFO - Running command: ./train_gpt2cu -l 1.8193635969103497e-05 -o hyperband_runs_20241120_172038/run_s0_n4 -x 735 -n 735 -y 0 -b 64 -d 524288 -h 0
2024-11-21 10:35:52,686 - INFO - Training completed for config s0_n4:
  Training time: 0:28:21
  Final validation loss: 7.608144
  Hellaswag accuracy: 0.00%
  Total iterations: 735
  Maximum learning rate: 1.82e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s0_n4/checkpoint.bin
2024-11-21 10:35:52,686 - INFO - 
Configuration s0_n4 (bracket_0_round_0):
  Hyperparameters: {
  "learning_rate": "1.8193635969103497e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s0_n4",
  "max_steps": "735",
  "checkpoint_every": "735",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 735
  Total iterations: 735
  Training time: 0:28:21
  Validation Loss: 7.608144
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.82e-05
2024-11-21 10:35:52,686 - INFO - 
Starting training for config s0_n5:
  Iterations: 735
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 10:35:52,686 - INFO - Running command: ./train_gpt2cu -l 5.8413385416472146e-05 -o hyperband_runs_20241120_172038/run_s0_n5 -x 735 -n 735 -y 0 -b 64 -d 524288 -h 0
2024-11-21 11:04:13,697 - INFO - Training completed for config s0_n5:
  Training time: 0:28:21
  Final validation loss: 6.526132
  Hellaswag accuracy: 0.00%
  Total iterations: 735
  Maximum learning rate: 5.84e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s0_n5/checkpoint.bin
2024-11-21 11:04:13,697 - INFO - 
Configuration s0_n5 (bracket_0_round_0):
  Hyperparameters: {
  "learning_rate": "5.8413385416472146e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s0_n5",
  "max_steps": "735",
  "checkpoint_every": "735",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 735
  Total iterations: 735
  Training time: 0:28:21
  Validation Loss: 6.526132
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 5.84e-05
2024-11-21 11:04:13,697 - INFO - 
Starting training for config s0_n6:
  Iterations: 735
  Previous iterations: 0
  Previous checkpoint: None
2024-11-21 11:04:13,697 - INFO - Running command: ./train_gpt2cu -l 1.7072694557071533e-05 -o hyperband_runs_20241120_172038/run_s0_n6 -x 735 -n 735 -y 0 -b 64 -d 524288 -h 0
2024-11-21 11:32:34,675 - INFO - Training completed for config s0_n6:
  Training time: 0:28:20
  Final validation loss: 7.695750
  Hellaswag accuracy: 0.00%
  Total iterations: 735
  Maximum learning rate: 1.71e-05
  Checkpoint saved to: hyperband_runs_20241120_172038/run_s0_n6/checkpoint.bin
2024-11-21 11:32:34,675 - INFO - 
Configuration s0_n6 (bracket_0_round_0):
  Hyperparameters: {
  "learning_rate": "1.7072694557071533e-05",
  "output_dir": "hyperband_runs_20241120_172038/run_s0_n6",
  "max_steps": "735",
  "checkpoint_every": "735",
  "resume": "0",
  "checkpoint_path": null,
  "batch_size": "64",
  "total_batch_size": "524288",
  "run_hellaswag": "0"
}
  Current iterations: 735
  Total iterations: 735
  Training time: 0:28:20
  Validation Loss: 7.695750
  Hellaswag Accuracy: 0.00%
  Maximum Learning Rate: 1.71e-05
2024-11-21 11:32:34,675 - INFO - 
Hyperband optimization completed:
  Total Duration: 18:11:56.024043
  Total Training Time: 18:10:54
  Total Configurations Tried: 1214
  Best Validation Loss: 5.380595
  Best Hellaswag Accuracy: 0.00%
  Best Configuration Total Iterations: 735
  Best Configuration Parameters:
    Learning Rate: 0.0005219286241044422
    Maximum Learning Rate: 5.22e-04
